reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711220928-172.17.0.14-1598343758170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-05b11f7e-3109-43cf-bf33-d878eef96c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9ccd68db-e731-44cd-abb0-f1cbedbedfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c3dd3efa-807c-46de-b6e3-addd99e70c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-8f148672-f205-47e1-85fa-3a07f121dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-5b8c669b-0acb-442a-983b-f8ef4138cff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-37211007-f8fd-43fa-8af6-e19cd36d9ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-8fb56bc3-e1d5-42cc-a804-40f08c65899b,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-14736a8b-a773-4612-a487-af0022940307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711220928-172.17.0.14-1598343758170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-05b11f7e-3109-43cf-bf33-d878eef96c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9ccd68db-e731-44cd-abb0-f1cbedbedfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c3dd3efa-807c-46de-b6e3-addd99e70c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-8f148672-f205-47e1-85fa-3a07f121dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-5b8c669b-0acb-442a-983b-f8ef4138cff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-37211007-f8fd-43fa-8af6-e19cd36d9ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-8fb56bc3-e1d5-42cc-a804-40f08c65899b,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-14736a8b-a773-4612-a487-af0022940307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525598185-172.17.0.14-1598343924053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5f646b18-ecd6-4a59-98c3-701bcb7049a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-760bb6f4-50e5-42a0-aa09-7d7aebb9fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-349e2083-f64a-4b92-a71f-19637f2f8187,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-40162b27-f1d4-4c95-b285-b01f0c30ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-46876056-dea5-44a5-acd4-a45f0c55c232,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c94ffe55-69a9-4ede-a44d-359869d65dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-87a8a9b6-6468-4e86-b572-c028ee9fa2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-73c22fa7-1b47-495b-b627-39916b2736fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525598185-172.17.0.14-1598343924053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5f646b18-ecd6-4a59-98c3-701bcb7049a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-760bb6f4-50e5-42a0-aa09-7d7aebb9fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-349e2083-f64a-4b92-a71f-19637f2f8187,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-40162b27-f1d4-4c95-b285-b01f0c30ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-46876056-dea5-44a5-acd4-a45f0c55c232,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c94ffe55-69a9-4ede-a44d-359869d65dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-87a8a9b6-6468-4e86-b572-c028ee9fa2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-73c22fa7-1b47-495b-b627-39916b2736fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072624380-172.17.0.14-1598344643050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-f3a64c6c-100b-492d-9aaa-7c9f13d6d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-faece201-e0dc-4cb1-b7fc-592aeddf7cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-a4f2cf7e-1669-4752-add5-6aeabb1b94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-3af9c21a-4098-41b0-a41b-b533ba6b7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-7e43bd65-df88-4ae1-86f6-a749e6ddc9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-fc13da7c-f368-43bc-a3e7-cd4972a3951a,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-0438c147-8d39-418e-be03-ad9768dab1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-ecce5dfb-a8d6-4685-9925-561e4a5f285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072624380-172.17.0.14-1598344643050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-f3a64c6c-100b-492d-9aaa-7c9f13d6d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-faece201-e0dc-4cb1-b7fc-592aeddf7cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-a4f2cf7e-1669-4752-add5-6aeabb1b94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-3af9c21a-4098-41b0-a41b-b533ba6b7a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-7e43bd65-df88-4ae1-86f6-a749e6ddc9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-fc13da7c-f368-43bc-a3e7-cd4972a3951a,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-0438c147-8d39-418e-be03-ad9768dab1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-ecce5dfb-a8d6-4685-9925-561e4a5f285b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317851487-172.17.0.14-1598344795401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-2e96716c-7eaf-4f9b-8340-b976663719d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-5eaf3951-5c4d-4eab-9950-80511be01da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-2bf63dc0-53c0-4167-a5b6-74f60954b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-7f1930de-a701-4175-9f0e-288e35d512d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-48939fb6-1183-4d3a-832e-f903b7d7425b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a6732ae8-5157-4f2c-ad6b-80923b68b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-fe2d2f53-4045-4e2c-a4dc-5ffa28b6ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-dba7e3c4-8646-4709-b095-32deb9de77ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317851487-172.17.0.14-1598344795401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-2e96716c-7eaf-4f9b-8340-b976663719d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-5eaf3951-5c4d-4eab-9950-80511be01da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-2bf63dc0-53c0-4167-a5b6-74f60954b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-7f1930de-a701-4175-9f0e-288e35d512d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-48939fb6-1183-4d3a-832e-f903b7d7425b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a6732ae8-5157-4f2c-ad6b-80923b68b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-fe2d2f53-4045-4e2c-a4dc-5ffa28b6ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-dba7e3c4-8646-4709-b095-32deb9de77ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161864226-172.17.0.14-1598346648093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-bd23db1a-bf6f-47db-81d5-c56547186fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-a1e2be94-20f0-43df-af50-54f3fe8aafbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-a6b6a38d-913b-4053-9fd2-10c00b291f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-0e14dadf-304c-48b8-a314-85da878bcd26,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-5c6347bb-8e76-4cfd-b4ff-f6aab254d501,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-fb28cfbd-2ab9-4c7f-a937-089ebf88d658,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-57e030d1-0399-4034-8cff-bce26353717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-25cd83b6-49a7-4872-a178-8dcc4f32a7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161864226-172.17.0.14-1598346648093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-bd23db1a-bf6f-47db-81d5-c56547186fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-a1e2be94-20f0-43df-af50-54f3fe8aafbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-a6b6a38d-913b-4053-9fd2-10c00b291f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-0e14dadf-304c-48b8-a314-85da878bcd26,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-5c6347bb-8e76-4cfd-b4ff-f6aab254d501,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-fb28cfbd-2ab9-4c7f-a937-089ebf88d658,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-57e030d1-0399-4034-8cff-bce26353717c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-25cd83b6-49a7-4872-a178-8dcc4f32a7c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539194105-172.17.0.14-1598346932214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-cf6e73c0-0ba9-495f-83cd-e015411a88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-c7292ec3-cfd9-4740-8af4-bdf9c7db52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b8ec0ae0-c57a-4128-931f-e2d601744f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-10b62cd9-058e-49ba-b925-f014b4612b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f09175a1-1e24-449e-a247-764e04c33f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-2a92ce08-eb0c-4582-806e-430ba083d822,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-0b092c0b-5455-4f9e-a27d-f41c4a4ddc97,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-7229a66b-7220-4c8f-8747-d9a981677edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539194105-172.17.0.14-1598346932214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-cf6e73c0-0ba9-495f-83cd-e015411a88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-c7292ec3-cfd9-4740-8af4-bdf9c7db52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b8ec0ae0-c57a-4128-931f-e2d601744f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-10b62cd9-058e-49ba-b925-f014b4612b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f09175a1-1e24-449e-a247-764e04c33f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-2a92ce08-eb0c-4582-806e-430ba083d822,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-0b092c0b-5455-4f9e-a27d-f41c4a4ddc97,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-7229a66b-7220-4c8f-8747-d9a981677edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827297359-172.17.0.14-1598347405484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-7cc45e8b-30f4-4622-9bd4-e2e871adfe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-aa1cb56f-4314-40f8-9559-578f6838f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-791f4614-b87b-45b2-9fca-377dec1ff9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-62707128-2905-42db-bb43-d39fb6423010,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-951e487c-46bc-414e-bec1-d4da22f2bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-90fd7446-ea8c-4929-aa27-f68e9fc566b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-bb235df4-e071-400c-9d6f-4e538dd7820c,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-049f4135-61a7-4f69-92aa-1a14674d9afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827297359-172.17.0.14-1598347405484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-7cc45e8b-30f4-4622-9bd4-e2e871adfe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-aa1cb56f-4314-40f8-9559-578f6838f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-791f4614-b87b-45b2-9fca-377dec1ff9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-62707128-2905-42db-bb43-d39fb6423010,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-951e487c-46bc-414e-bec1-d4da22f2bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-90fd7446-ea8c-4929-aa27-f68e9fc566b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-bb235df4-e071-400c-9d6f-4e538dd7820c,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-049f4135-61a7-4f69-92aa-1a14674d9afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811659754-172.17.0.14-1598347447629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-f755f2cb-2fb1-49b6-b361-5a087a140f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-18f87c34-68d0-43df-a15b-0423c024fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-e6b872bf-8516-48ac-b81c-dcd57409a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-6355da95-bd47-42c8-bb45-82988a61c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-78217f24-7064-48cc-8945-51e1492c450b,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-38f01e83-4806-4b51-be54-52959f1bf54e,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-210ab6af-faad-4370-8caf-3327cbbff597,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e6113001-3c81-475f-a9f3-aa0fabf49405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811659754-172.17.0.14-1598347447629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-f755f2cb-2fb1-49b6-b361-5a087a140f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-18f87c34-68d0-43df-a15b-0423c024fc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-e6b872bf-8516-48ac-b81c-dcd57409a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-6355da95-bd47-42c8-bb45-82988a61c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-78217f24-7064-48cc-8945-51e1492c450b,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-38f01e83-4806-4b51-be54-52959f1bf54e,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-210ab6af-faad-4370-8caf-3327cbbff597,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e6113001-3c81-475f-a9f3-aa0fabf49405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147637514-172.17.0.14-1598348089394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38498,DS-ded71bf9-43c6-45be-bbbb-033b928aa2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-d82452e6-c9c7-47f2-aa41-1195e073a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-02e0a403-cfa1-4f00-a70e-e56e5466272d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-de73071b-0bb3-4673-b204-f4e82fea3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-156aecd5-b9de-4d1a-9b25-b5016a143829,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-ae3a10fc-59cd-41a8-82db-d566e3469f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-d55166db-2289-4cec-b7a1-17c6044e1ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-b7e00865-5d5a-4177-ae75-b5382f749988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147637514-172.17.0.14-1598348089394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38498,DS-ded71bf9-43c6-45be-bbbb-033b928aa2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-d82452e6-c9c7-47f2-aa41-1195e073a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-02e0a403-cfa1-4f00-a70e-e56e5466272d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-de73071b-0bb3-4673-b204-f4e82fea3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-156aecd5-b9de-4d1a-9b25-b5016a143829,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-ae3a10fc-59cd-41a8-82db-d566e3469f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-d55166db-2289-4cec-b7a1-17c6044e1ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-b7e00865-5d5a-4177-ae75-b5382f749988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166984602-172.17.0.14-1598348286300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-f4a29e3b-21ec-4434-bb55-d4669e4fd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e7bd1040-921d-4fe4-868a-e85bd10be7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-64867d3b-e665-4126-bd41-ff994fbf6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-05834093-7fd6-4181-9ed4-3487399f86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-3610faed-bf51-4b35-993e-d0dcb6395c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-4eb4e719-c563-43c3-acdf-f089c29e233b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-74eb86c9-adab-4593-8e25-7d1a31374bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cf22e4ee-eea1-40f3-a829-18fd770ef094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166984602-172.17.0.14-1598348286300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-f4a29e3b-21ec-4434-bb55-d4669e4fd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e7bd1040-921d-4fe4-868a-e85bd10be7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-64867d3b-e665-4126-bd41-ff994fbf6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-05834093-7fd6-4181-9ed4-3487399f86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-3610faed-bf51-4b35-993e-d0dcb6395c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-4eb4e719-c563-43c3-acdf-f089c29e233b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-74eb86c9-adab-4593-8e25-7d1a31374bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cf22e4ee-eea1-40f3-a829-18fd770ef094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245055587-172.17.0.14-1598348321461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33693,DS-0a6db96e-fccb-4ba9-b25f-c1bce497d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-063109ac-695e-4fc5-9e26-efd12f041d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-ded3328e-7756-4d4b-98f1-a1868848e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-d2cc899b-2d84-4eb5-8147-f36ed4ed12ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-ea24a7f2-8eb6-4f25-bf73-1e2e44235a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-0a148376-d207-441a-9e47-0e177fbc7007,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-68f87e30-40de-4dd7-abb7-26ed9b553686,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0889a9f3-a404-49c8-8825-61526f3cf5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245055587-172.17.0.14-1598348321461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33693,DS-0a6db96e-fccb-4ba9-b25f-c1bce497d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-063109ac-695e-4fc5-9e26-efd12f041d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-ded3328e-7756-4d4b-98f1-a1868848e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-d2cc899b-2d84-4eb5-8147-f36ed4ed12ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-ea24a7f2-8eb6-4f25-bf73-1e2e44235a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-0a148376-d207-441a-9e47-0e177fbc7007,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-68f87e30-40de-4dd7-abb7-26ed9b553686,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-0889a9f3-a404-49c8-8825-61526f3cf5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599042717-172.17.0.14-1598348463424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-785e3230-cb80-4b7f-94e6-1a251b68a5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-bd70c814-4cc4-43d6-840f-37d6095376ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-cb3920ee-e1e6-41fc-ae1f-15d8e576ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ddc00aad-0c66-4011-9cd6-24ef493f504e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-9c202785-ef73-4408-9c82-62c895fa83be,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-46855a43-4dc4-41ec-a44f-061035597f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-56829653-ed58-4e5f-aa50-acf0a49d4aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-51ed2bcd-1db5-494a-994f-f041341d7da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599042717-172.17.0.14-1598348463424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-785e3230-cb80-4b7f-94e6-1a251b68a5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-bd70c814-4cc4-43d6-840f-37d6095376ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-cb3920ee-e1e6-41fc-ae1f-15d8e576ae37,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ddc00aad-0c66-4011-9cd6-24ef493f504e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-9c202785-ef73-4408-9c82-62c895fa83be,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-46855a43-4dc4-41ec-a44f-061035597f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-56829653-ed58-4e5f-aa50-acf0a49d4aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-51ed2bcd-1db5-494a-994f-f041341d7da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426830074-172.17.0.14-1598348906999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-fcc53c76-b9ef-47a5-acc6-f3e000cc7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-6fa29160-83ac-443b-9942-e06ea29e9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-4998c796-786a-4c64-a353-3754c7d35b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-f4c41cb5-d958-4c1d-b2f8-402a890e97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-ecd4356f-fc0c-4559-abed-1ec53eee0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-8f90f58f-4984-4216-b67f-5ea6aec42823,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-94969c28-87e3-4f6e-8384-78006a69f841,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-63921468-bc78-4793-a231-83b4e11455af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426830074-172.17.0.14-1598348906999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-fcc53c76-b9ef-47a5-acc6-f3e000cc7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-6fa29160-83ac-443b-9942-e06ea29e9ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-4998c796-786a-4c64-a353-3754c7d35b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-f4c41cb5-d958-4c1d-b2f8-402a890e97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-ecd4356f-fc0c-4559-abed-1ec53eee0a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-8f90f58f-4984-4216-b67f-5ea6aec42823,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-94969c28-87e3-4f6e-8384-78006a69f841,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-63921468-bc78-4793-a231-83b4e11455af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5225
