reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484258914-172.17.0.17-1598391862021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-6096a88a-b197-4d9d-bc3a-b7a487316a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-5eff9955-d221-4e73-a699-3c0040556c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-e9810787-7d44-48a2-adb1-d8e5e32e4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-6c3c4681-0e0c-4d5c-bdc2-bc082075d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-a2c2cb3a-8645-4602-b47a-615005d6cdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-1ee74979-0332-4aef-a590-93b3a000736b,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-049f068c-3f1d-4129-aa79-97961e82186c,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-b69ac401-dcfd-47a0-949a-016e6ba89539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484258914-172.17.0.17-1598391862021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-6096a88a-b197-4d9d-bc3a-b7a487316a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-5eff9955-d221-4e73-a699-3c0040556c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-e9810787-7d44-48a2-adb1-d8e5e32e4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-6c3c4681-0e0c-4d5c-bdc2-bc082075d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-a2c2cb3a-8645-4602-b47a-615005d6cdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-1ee74979-0332-4aef-a590-93b3a000736b,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-049f068c-3f1d-4129-aa79-97961e82186c,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-b69ac401-dcfd-47a0-949a-016e6ba89539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133215517-172.17.0.17-1598392133970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42580,DS-d953df33-66de-4a96-a2f8-d741edcfc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-ea746eb8-1d00-4384-aaa6-8f4c7a991743,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-bdcfcb15-7c28-4ee5-9e07-0a883f27b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-ed5ee6c3-2089-42d5-bd93-27e630ba4c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-8cdd5da0-cc96-4314-a83b-524ead6eea69,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b7379598-82c4-4cf7-a235-1acd6682a66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-df66946f-393d-4678-b147-46074f1d8f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-83fdc8ba-604f-43ff-b188-75b41c341c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133215517-172.17.0.17-1598392133970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42580,DS-d953df33-66de-4a96-a2f8-d741edcfc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-ea746eb8-1d00-4384-aaa6-8f4c7a991743,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-bdcfcb15-7c28-4ee5-9e07-0a883f27b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-ed5ee6c3-2089-42d5-bd93-27e630ba4c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-8cdd5da0-cc96-4314-a83b-524ead6eea69,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b7379598-82c4-4cf7-a235-1acd6682a66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-df66946f-393d-4678-b147-46074f1d8f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-83fdc8ba-604f-43ff-b188-75b41c341c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502629172-172.17.0.17-1598392327780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-4dd6d1ab-2e9f-4906-91f3-4931169022a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5a53175c-d2bb-4207-886f-a780f7793228,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-468dec5c-f6fa-433a-bc84-0cdaed1a449a,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-4177e1b9-89f8-4536-9685-6a657fcc896f,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e0e3177e-9344-4d8d-a88f-61969bcda663,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-70ea4cab-9a4f-4e9f-a0b1-403dd1e27d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-1a1e6c7a-f447-406d-8dfa-434c9c35b680,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5ee49da4-4c92-40ef-a552-ac3a67c40dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502629172-172.17.0.17-1598392327780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-4dd6d1ab-2e9f-4906-91f3-4931169022a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5a53175c-d2bb-4207-886f-a780f7793228,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-468dec5c-f6fa-433a-bc84-0cdaed1a449a,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-4177e1b9-89f8-4536-9685-6a657fcc896f,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e0e3177e-9344-4d8d-a88f-61969bcda663,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-70ea4cab-9a4f-4e9f-a0b1-403dd1e27d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-1a1e6c7a-f447-406d-8dfa-434c9c35b680,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5ee49da4-4c92-40ef-a552-ac3a67c40dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825313853-172.17.0.17-1598393419111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-2e02b41e-4f1b-4ede-86d9-0118be176e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-6f0335be-2a24-46fb-9d5e-b8722987ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-be8a2fb7-e22b-4b6c-86dc-0160593e75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-f514eef5-758a-4514-a74a-ee3f1dd784f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-78acdbc3-7036-45d2-8b91-f77b3c362a70,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-fb28ecc3-0689-4feb-946f-af5897762377,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-f906336e-4292-45cc-b23f-67691633db58,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-f47de8c4-d5f4-494c-ac5a-da8221cee2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825313853-172.17.0.17-1598393419111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-2e02b41e-4f1b-4ede-86d9-0118be176e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-6f0335be-2a24-46fb-9d5e-b8722987ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-be8a2fb7-e22b-4b6c-86dc-0160593e75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-f514eef5-758a-4514-a74a-ee3f1dd784f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-78acdbc3-7036-45d2-8b91-f77b3c362a70,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-fb28ecc3-0689-4feb-946f-af5897762377,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-f906336e-4292-45cc-b23f-67691633db58,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-f47de8c4-d5f4-494c-ac5a-da8221cee2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440475947-172.17.0.17-1598393491604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-e03853d7-a644-4484-a7fd-68b645e3e974,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0b984acc-e4e0-45ea-bc95-1a7004ad9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-4eb2801b-1554-4965-b108-31b4f8a841fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-2a7a8de0-b7d1-436a-bae4-48a1ed2ceffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-e9b9bd3d-8698-4b92-bf38-d63602b4c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-395012a0-acf7-43af-91fa-ffee7a5279cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-46d3a8a8-c736-46d9-808a-67e2d196248b,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1c1e55a0-c82d-46cb-b911-d7cc9e3eb98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440475947-172.17.0.17-1598393491604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-e03853d7-a644-4484-a7fd-68b645e3e974,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0b984acc-e4e0-45ea-bc95-1a7004ad9ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-4eb2801b-1554-4965-b108-31b4f8a841fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-2a7a8de0-b7d1-436a-bae4-48a1ed2ceffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-e9b9bd3d-8698-4b92-bf38-d63602b4c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-395012a0-acf7-43af-91fa-ffee7a5279cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-46d3a8a8-c736-46d9-808a-67e2d196248b,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1c1e55a0-c82d-46cb-b911-d7cc9e3eb98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280631790-172.17.0.17-1598393889016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-3d9184a1-927b-474b-8970-6b231c2df650,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-098e4b80-bad1-48c1-8793-72297e9f3978,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-755d69f6-3768-43a0-bc1e-cb83f71578d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-579838af-3aea-4a15-ad45-2a16655cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-5d28f0d7-e29e-4374-bbcb-925edd29c005,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-757418b9-6e9a-4390-802c-fcd9563612dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-7a810de6-abd5-4349-8f81-0095b9463a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-a735672b-4196-4b1e-a409-d6c797ab288a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280631790-172.17.0.17-1598393889016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-3d9184a1-927b-474b-8970-6b231c2df650,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-098e4b80-bad1-48c1-8793-72297e9f3978,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-755d69f6-3768-43a0-bc1e-cb83f71578d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-579838af-3aea-4a15-ad45-2a16655cd2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-5d28f0d7-e29e-4374-bbcb-925edd29c005,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-757418b9-6e9a-4390-802c-fcd9563612dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-7a810de6-abd5-4349-8f81-0095b9463a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-a735672b-4196-4b1e-a409-d6c797ab288a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943116911-172.17.0.17-1598394087120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-a7f980ce-853c-492e-8bb2-5674a915e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-11b7343b-2f38-4b41-b41b-c30da4850205,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-3ed3b04a-31b6-4e21-ad00-a284925a96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-66622eeb-28ac-4888-96ef-82c48caaff36,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-be66af3c-0e62-47f0-8d0e-085b9cebf3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-aa087f47-6590-4bdc-b328-3896790ccd05,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-86a12b42-95ab-4034-9ff1-10e5e4a01f66,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-13b550b5-748b-495c-9df1-ceb556dc13d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943116911-172.17.0.17-1598394087120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-a7f980ce-853c-492e-8bb2-5674a915e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-11b7343b-2f38-4b41-b41b-c30da4850205,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-3ed3b04a-31b6-4e21-ad00-a284925a96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-66622eeb-28ac-4888-96ef-82c48caaff36,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-be66af3c-0e62-47f0-8d0e-085b9cebf3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-aa087f47-6590-4bdc-b328-3896790ccd05,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-86a12b42-95ab-4034-9ff1-10e5e4a01f66,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-13b550b5-748b-495c-9df1-ceb556dc13d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006753101-172.17.0.17-1598394329095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-439139b9-a7af-4d5a-b867-0327998fe763,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-65aa6a5e-5d08-4068-a6ac-8e0739c52a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-bad9882f-375a-4709-842d-aa9899c1ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-780f2611-2ad2-463a-ac10-f7a40ef03841,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-63c5eec6-2ee0-4a36-9ee0-9681e70512fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6027bcf6-8e14-48a8-a16c-df81d6be8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ac5ce5b8-059e-4ba2-af03-bfdd0f9a1a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-96c08e30-7423-435e-9161-f8d3620491dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006753101-172.17.0.17-1598394329095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-439139b9-a7af-4d5a-b867-0327998fe763,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-65aa6a5e-5d08-4068-a6ac-8e0739c52a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-bad9882f-375a-4709-842d-aa9899c1ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-780f2611-2ad2-463a-ac10-f7a40ef03841,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-63c5eec6-2ee0-4a36-9ee0-9681e70512fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6027bcf6-8e14-48a8-a16c-df81d6be8d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ac5ce5b8-059e-4ba2-af03-bfdd0f9a1a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-96c08e30-7423-435e-9161-f8d3620491dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169791818-172.17.0.17-1598394664266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-7bc7f928-2431-4cf9-9b30-8fe3f920ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-210ed882-bbab-49eb-9f28-2efdaaf844bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-b7c1a1e7-10a9-49cf-94f1-02c29b71a630,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-53952748-202d-474b-bd49-d628d2f5d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-5bda24e6-a8f4-443a-8a0e-9f9dde1de2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-518fc114-1e4d-4e6e-98a8-040913b8821b,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-70db8091-f2e3-4ba5-a300-58db43fe60ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-812f83dc-be41-4b27-b5ca-2cfea8b8199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169791818-172.17.0.17-1598394664266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-7bc7f928-2431-4cf9-9b30-8fe3f920ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-210ed882-bbab-49eb-9f28-2efdaaf844bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-b7c1a1e7-10a9-49cf-94f1-02c29b71a630,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-53952748-202d-474b-bd49-d628d2f5d9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-5bda24e6-a8f4-443a-8a0e-9f9dde1de2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-518fc114-1e4d-4e6e-98a8-040913b8821b,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-70db8091-f2e3-4ba5-a300-58db43fe60ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-812f83dc-be41-4b27-b5ca-2cfea8b8199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975682277-172.17.0.17-1598394855064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-965285f4-8135-4fd1-ab27-b388ed4ebe57,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-fbe6f9eb-686f-486c-9aa7-6b15407a9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-56e63cdb-03f0-48f0-a9bc-0fee4e4c9c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7e584877-e9ee-4e9b-8070-2da5ba6819d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-62cdbff1-6524-47cc-8e7d-69b7ead31be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-4baa22c2-88c6-42c0-bc03-6ef83a89b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-34236c94-6be6-4824-8679-94fc57498a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-49f8e1e7-da4e-4dd3-babd-2426884051c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975682277-172.17.0.17-1598394855064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-965285f4-8135-4fd1-ab27-b388ed4ebe57,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-fbe6f9eb-686f-486c-9aa7-6b15407a9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-56e63cdb-03f0-48f0-a9bc-0fee4e4c9c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-7e584877-e9ee-4e9b-8070-2da5ba6819d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-62cdbff1-6524-47cc-8e7d-69b7ead31be7,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-4baa22c2-88c6-42c0-bc03-6ef83a89b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-34236c94-6be6-4824-8679-94fc57498a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-49f8e1e7-da4e-4dd3-babd-2426884051c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125161423-172.17.0.17-1598395104389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-9e3bfe21-2c66-4a75-a94d-226e75a53485,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-afd4594d-b796-4a11-b4ff-cb8ced79d065,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-854604a9-8730-408e-a35e-40c8ec5056ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-f2de0b3e-89e9-42ec-9529-befab4d1cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-5e50f394-4613-4c98-a1cf-e7d0087243e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-80a368dc-59a3-44fe-a2e9-7dbf91007bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-4dc3e2a9-1a57-4416-bef9-bcb3286dc186,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-ad9ed725-2370-4ead-abd3-d20e5b1d1818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125161423-172.17.0.17-1598395104389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-9e3bfe21-2c66-4a75-a94d-226e75a53485,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-afd4594d-b796-4a11-b4ff-cb8ced79d065,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-854604a9-8730-408e-a35e-40c8ec5056ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-f2de0b3e-89e9-42ec-9529-befab4d1cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-5e50f394-4613-4c98-a1cf-e7d0087243e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-80a368dc-59a3-44fe-a2e9-7dbf91007bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-4dc3e2a9-1a57-4416-bef9-bcb3286dc186,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-ad9ed725-2370-4ead-abd3-d20e5b1d1818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440955081-172.17.0.17-1598395182810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-b2a55fda-cd72-4aed-b948-26b4c45bcf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-8da09b38-675a-4ec3-b451-40b9c608a110,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-fdb399d0-6bac-4218-915d-70176f9c67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-791f8e52-471b-444c-a52d-8fcb91d5a583,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-a1a18263-01e6-485a-86af-240af3726cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-5ccc5117-5410-481d-a842-d9ab73e2becc,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-7523f216-acbc-45a2-a98e-f081406ef0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-52344789-c952-49cd-a201-a734d1edf6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440955081-172.17.0.17-1598395182810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-b2a55fda-cd72-4aed-b948-26b4c45bcf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-8da09b38-675a-4ec3-b451-40b9c608a110,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-fdb399d0-6bac-4218-915d-70176f9c67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-791f8e52-471b-444c-a52d-8fcb91d5a583,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-a1a18263-01e6-485a-86af-240af3726cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-5ccc5117-5410-481d-a842-d9ab73e2becc,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-7523f216-acbc-45a2-a98e-f081406ef0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-52344789-c952-49cd-a201-a734d1edf6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451184906-172.17.0.17-1598395700133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-e658f05f-adc7-408a-be41-b271c28656a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-3d38108e-5128-4a52-8429-dacbc02db9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-4209de1a-1346-43f0-a42f-3670f699abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-fd709f84-7e92-4a90-a211-aefc6f4340b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-1f25a536-a2f0-4cc0-b2af-6f5e05be7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-98cd8c6b-f524-488e-bf44-9c22b91aa569,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-fc9e1e9c-cf8a-440b-988f-080794020d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-dd886a0a-adf8-4d9f-a523-0149b9decadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451184906-172.17.0.17-1598395700133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-e658f05f-adc7-408a-be41-b271c28656a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-3d38108e-5128-4a52-8429-dacbc02db9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-4209de1a-1346-43f0-a42f-3670f699abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-fd709f84-7e92-4a90-a211-aefc6f4340b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-1f25a536-a2f0-4cc0-b2af-6f5e05be7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-98cd8c6b-f524-488e-bf44-9c22b91aa569,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-fc9e1e9c-cf8a-440b-988f-080794020d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-dd886a0a-adf8-4d9f-a523-0149b9decadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519862347-172.17.0.17-1598395796444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38791,DS-fd674b8e-f226-4e75-b212-201958fe3114,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-bc909c94-c288-4dd6-8b26-07a0a07c3811,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c0256df4-7c64-495b-aad2-a66fb4f80bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-f7ee7658-4c7f-41d3-be43-ee716332ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-5686b926-1de1-422d-901e-976966f89833,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-5189fdd9-d6f0-4eef-9c40-4582d8ea04d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-28208796-8283-4e0f-b1e8-988637ffd6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-7e289dea-3b43-4bac-8e42-76f6586bdf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519862347-172.17.0.17-1598395796444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38791,DS-fd674b8e-f226-4e75-b212-201958fe3114,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-bc909c94-c288-4dd6-8b26-07a0a07c3811,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c0256df4-7c64-495b-aad2-a66fb4f80bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-f7ee7658-4c7f-41d3-be43-ee716332ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-5686b926-1de1-422d-901e-976966f89833,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-5189fdd9-d6f0-4eef-9c40-4582d8ea04d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-28208796-8283-4e0f-b1e8-988637ffd6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-7e289dea-3b43-4bac-8e42-76f6586bdf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464281594-172.17.0.17-1598396295386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-c66037c5-fbf0-44ec-816c-5fec66d0681b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-f4eb02d7-3b21-4452-a341-9b1b3614289a,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5a64b326-a016-4782-9b18-7a180e01b791,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-106d4621-2b37-4699-963d-683a690ed179,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-a58caa7b-b03b-4d89-a125-84528a8e431a,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-6c2cadec-d788-4387-8a04-2d990d7a01ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2cb0deb6-7ee1-4e97-acbd-9a69154b2179,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-a2ebdcb5-75a5-419e-91c5-10cafba70795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464281594-172.17.0.17-1598396295386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-c66037c5-fbf0-44ec-816c-5fec66d0681b,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-f4eb02d7-3b21-4452-a341-9b1b3614289a,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5a64b326-a016-4782-9b18-7a180e01b791,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-106d4621-2b37-4699-963d-683a690ed179,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-a58caa7b-b03b-4d89-a125-84528a8e431a,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-6c2cadec-d788-4387-8a04-2d990d7a01ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2cb0deb6-7ee1-4e97-acbd-9a69154b2179,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-a2ebdcb5-75a5-419e-91c5-10cafba70795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016419462-172.17.0.17-1598396525119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-3bc84a04-1e7c-4452-b263-6910b5bdc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-509e3711-9a12-4f3f-987e-921eb841cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-075cbb1e-0ed7-4b98-b6a6-9f30ec31a8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-77489eac-7d74-464c-912c-20f8a76b0a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-30d17e75-c627-473d-a7dd-95b657e6fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-bdbef189-b96b-4f7d-940a-0389d8a84b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-90b81f74-78ef-41de-868f-96b06365897a,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-5b1d7919-ce52-4a8c-a146-89883a453ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016419462-172.17.0.17-1598396525119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-3bc84a04-1e7c-4452-b263-6910b5bdc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-509e3711-9a12-4f3f-987e-921eb841cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-075cbb1e-0ed7-4b98-b6a6-9f30ec31a8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-77489eac-7d74-464c-912c-20f8a76b0a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-30d17e75-c627-473d-a7dd-95b657e6fc31,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-bdbef189-b96b-4f7d-940a-0389d8a84b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-90b81f74-78ef-41de-868f-96b06365897a,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-5b1d7919-ce52-4a8c-a146-89883a453ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704903160-172.17.0.17-1598396557666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f9c1191e-9c13-49e8-a602-a9931aa767ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-5ae478fd-ef04-44a2-a396-4994dbff81f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-be521d33-d117-4041-a0b0-b09f034dfd72,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-85d5d29b-206b-4b0e-bc02-946a0ebc27ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-76b40960-0102-4734-b927-36754c642786,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-d26c5d98-ce1e-4842-8ade-bdb01aef883f,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-48b404c1-2101-43d1-a2ca-85ca7d4dffee,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-af9775dc-c4c3-4be3-b91f-7e06cc9eb9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704903160-172.17.0.17-1598396557666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f9c1191e-9c13-49e8-a602-a9931aa767ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-5ae478fd-ef04-44a2-a396-4994dbff81f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-be521d33-d117-4041-a0b0-b09f034dfd72,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-85d5d29b-206b-4b0e-bc02-946a0ebc27ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-76b40960-0102-4734-b927-36754c642786,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-d26c5d98-ce1e-4842-8ade-bdb01aef883f,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-48b404c1-2101-43d1-a2ca-85ca7d4dffee,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-af9775dc-c4c3-4be3-b91f-7e06cc9eb9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709572492-172.17.0.17-1598396691718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-c1ad991f-00fd-442d-b752-fe9d6a464f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-b160f04c-ba82-438e-b886-379c20e283fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-ffcf26cf-eea8-4712-ab96-0964155c3480,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-a860dd44-43d9-4ea5-9ed2-8b37f0dba438,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-4dacead7-5dde-442a-b6e6-879d1686eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-5ca0ddb4-afcc-46f0-b249-c09c60184679,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-8b81142a-98c4-4bf9-b0e9-37230b422ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-6d6c96d0-40fe-43fc-8745-c7f1677435e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709572492-172.17.0.17-1598396691718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-c1ad991f-00fd-442d-b752-fe9d6a464f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-b160f04c-ba82-438e-b886-379c20e283fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-ffcf26cf-eea8-4712-ab96-0964155c3480,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-a860dd44-43d9-4ea5-9ed2-8b37f0dba438,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-4dacead7-5dde-442a-b6e6-879d1686eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-5ca0ddb4-afcc-46f0-b249-c09c60184679,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-8b81142a-98c4-4bf9-b0e9-37230b422ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-6d6c96d0-40fe-43fc-8745-c7f1677435e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5204
