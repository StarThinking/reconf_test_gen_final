reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798452842-172.17.0.14-1598380153010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-801df7c1-8782-4d58-88cb-21b94380c609,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-b5ccd9aa-8e4c-4efd-8783-c4af9f127290,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-11ef3aaa-6a61-4a63-acfa-ac61c14a4204,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-a91cc312-389a-45bb-97fd-32f3e1a8a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-eecd7fd1-20ba-4495-a27f-ad4863eb97da,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-98f492dd-5348-49af-aa90-f272557bb1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-e2cc3b71-1751-4327-b6e3-ef1ada9dd7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-7d8c7950-e17b-42db-887a-63cf5fa6efeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798452842-172.17.0.14-1598380153010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-801df7c1-8782-4d58-88cb-21b94380c609,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-b5ccd9aa-8e4c-4efd-8783-c4af9f127290,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-11ef3aaa-6a61-4a63-acfa-ac61c14a4204,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-a91cc312-389a-45bb-97fd-32f3e1a8a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-eecd7fd1-20ba-4495-a27f-ad4863eb97da,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-98f492dd-5348-49af-aa90-f272557bb1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-e2cc3b71-1751-4327-b6e3-ef1ada9dd7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-7d8c7950-e17b-42db-887a-63cf5fa6efeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064532064-172.17.0.14-1598380247209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-c33a1137-cf07-4be9-b41a-76ffd6d4c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-37da84ef-1a44-4281-9a57-488d7a6de5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-ebd8bce0-c9b1-48f9-ba66-6e367398175f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-57415d26-c357-4f81-a3f0-5964818d66b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-88dcfc38-20cb-4e34-9f72-0b4f319f9fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-ba1d225b-366c-4f7c-86bd-750c5814ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-d57ee63d-e167-478f-9cf8-1fcd72bd435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-69b1f793-ebb3-4177-b830-aa9371465dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064532064-172.17.0.14-1598380247209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-c33a1137-cf07-4be9-b41a-76ffd6d4c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-37da84ef-1a44-4281-9a57-488d7a6de5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-ebd8bce0-c9b1-48f9-ba66-6e367398175f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-57415d26-c357-4f81-a3f0-5964818d66b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-88dcfc38-20cb-4e34-9f72-0b4f319f9fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-ba1d225b-366c-4f7c-86bd-750c5814ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-d57ee63d-e167-478f-9cf8-1fcd72bd435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-69b1f793-ebb3-4177-b830-aa9371465dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741557227-172.17.0.14-1598380439226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-539955a0-6da3-4724-85f9-e4870920795a,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-c85109b1-51ba-4cb2-925f-72d5f730ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9e75f1bc-f0a0-4b38-99de-66dc54e3b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-f92bf975-a4f1-4979-8a9a-ebb41b702a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-985a0d11-c78e-4749-966e-1e1da8dd601e,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-44f60880-b26d-4ea6-ad72-96bee8e03654,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-7d16050a-f7a8-44f9-b84b-74f0d1db2466,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-8334153b-9de6-4410-9336-a1d88e73d6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741557227-172.17.0.14-1598380439226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-539955a0-6da3-4724-85f9-e4870920795a,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-c85109b1-51ba-4cb2-925f-72d5f730ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9e75f1bc-f0a0-4b38-99de-66dc54e3b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-f92bf975-a4f1-4979-8a9a-ebb41b702a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-985a0d11-c78e-4749-966e-1e1da8dd601e,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-44f60880-b26d-4ea6-ad72-96bee8e03654,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-7d16050a-f7a8-44f9-b84b-74f0d1db2466,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-8334153b-9de6-4410-9336-a1d88e73d6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038839673-172.17.0.14-1598380539015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-07c55c16-8f19-4a88-9e4b-975a065c6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-5bc5d77a-889e-4c2c-8166-0ec2c9374258,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-0991fa0c-dddf-4c64-a37f-8c32d6a3e72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-13ef5877-b8b2-465a-94da-a78221090ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-41019ff5-8ce7-4b58-96cf-39622ca175d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-e728966a-56cd-4a7d-9cdb-d057ae4fe53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-c27eb8cc-e5e0-47ac-a1d0-75dafb544f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-226d8bcc-4686-45fa-adb8-557a021c8b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038839673-172.17.0.14-1598380539015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-07c55c16-8f19-4a88-9e4b-975a065c6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-5bc5d77a-889e-4c2c-8166-0ec2c9374258,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-0991fa0c-dddf-4c64-a37f-8c32d6a3e72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-13ef5877-b8b2-465a-94da-a78221090ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-41019ff5-8ce7-4b58-96cf-39622ca175d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-e728966a-56cd-4a7d-9cdb-d057ae4fe53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-c27eb8cc-e5e0-47ac-a1d0-75dafb544f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-226d8bcc-4686-45fa-adb8-557a021c8b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218767417-172.17.0.14-1598380567327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-182d2719-c13d-484b-af80-ca2628a99546,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9e102d0a-04c9-43df-bd88-9d9d87fe367d,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-e44e4d7a-73a4-4032-830a-7e98a61b7245,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-551c1b70-dec0-4abd-bcb2-9714af78b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-0979d570-530b-441b-86de-ccc27fc7e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-fa7ce602-76c5-4aaa-a062-f7f3cdca1218,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-3bed7766-5787-4947-af1e-a10d65620c26,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-1139af83-215a-4245-a1a5-03382759c2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218767417-172.17.0.14-1598380567327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-182d2719-c13d-484b-af80-ca2628a99546,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9e102d0a-04c9-43df-bd88-9d9d87fe367d,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-e44e4d7a-73a4-4032-830a-7e98a61b7245,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-551c1b70-dec0-4abd-bcb2-9714af78b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-0979d570-530b-441b-86de-ccc27fc7e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-fa7ce602-76c5-4aaa-a062-f7f3cdca1218,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-3bed7766-5787-4947-af1e-a10d65620c26,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-1139af83-215a-4245-a1a5-03382759c2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401907887-172.17.0.14-1598381672724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-e3ec13bf-6f9a-4d59-b205-e167af3cd95d,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-daedd4db-a6ad-49fa-975d-bdff8ae74552,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-eaadf1f6-7e29-450d-8216-3f13734ec6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-abf2cb7c-4da3-4f9c-beae-f56a4be18a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-e51b9bf0-9d4b-46f3-b6d1-be6d016e86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-155f2418-72e0-4f60-8539-7a6b96a2f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-b244b44c-dd0e-4c3f-8810-d1062ba1cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-d5827690-dd6a-435f-849d-abcb4c80e1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401907887-172.17.0.14-1598381672724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-e3ec13bf-6f9a-4d59-b205-e167af3cd95d,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-daedd4db-a6ad-49fa-975d-bdff8ae74552,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-eaadf1f6-7e29-450d-8216-3f13734ec6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-abf2cb7c-4da3-4f9c-beae-f56a4be18a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-e51b9bf0-9d4b-46f3-b6d1-be6d016e86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-155f2418-72e0-4f60-8539-7a6b96a2f31f,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-b244b44c-dd0e-4c3f-8810-d1062ba1cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-d5827690-dd6a-435f-849d-abcb4c80e1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278414852-172.17.0.14-1598381876943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42598,DS-509fb46a-a9e5-4228-a6a2-b44e2bf8ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-5a1d1d7b-4f4e-48bb-babe-aa1418405a09,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-6effd706-2e53-487c-8b51-ace536df2bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-10566338-9e2c-4ded-9f93-e9f96bd17f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-8779ab34-87e6-4637-a075-70e29f2c9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-225ed272-7008-4639-95fb-90d70668a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-84484a4d-a4e3-4bdb-a851-28c1d2384a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-552a3cec-5e4e-4f8b-b94c-f465b256a89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278414852-172.17.0.14-1598381876943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42598,DS-509fb46a-a9e5-4228-a6a2-b44e2bf8ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-5a1d1d7b-4f4e-48bb-babe-aa1418405a09,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-6effd706-2e53-487c-8b51-ace536df2bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-10566338-9e2c-4ded-9f93-e9f96bd17f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-8779ab34-87e6-4637-a075-70e29f2c9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-225ed272-7008-4639-95fb-90d70668a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-84484a4d-a4e3-4bdb-a851-28c1d2384a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-552a3cec-5e4e-4f8b-b94c-f465b256a89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964680729-172.17.0.14-1598381942935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-0ae62484-a3d6-4248-a064-183595e84f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-9c362ce5-bfee-4011-b966-9344b8640e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-034e0649-d907-4bf7-9c46-4c23bb7c45fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-c5e3c834-cce5-4e26-8423-993d81d9fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-d2fb5c17-3e56-4789-9dad-48b7be2f6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-7ffbc9a3-080b-4abd-b081-fbc190650b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-d3a2a9a7-f6ca-4ec4-b42a-5de98391c117,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-a6512b07-91db-48a2-963f-3a24d62632f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964680729-172.17.0.14-1598381942935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-0ae62484-a3d6-4248-a064-183595e84f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-9c362ce5-bfee-4011-b966-9344b8640e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-034e0649-d907-4bf7-9c46-4c23bb7c45fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-c5e3c834-cce5-4e26-8423-993d81d9fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-d2fb5c17-3e56-4789-9dad-48b7be2f6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-7ffbc9a3-080b-4abd-b081-fbc190650b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-d3a2a9a7-f6ca-4ec4-b42a-5de98391c117,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-a6512b07-91db-48a2-963f-3a24d62632f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516851324-172.17.0.14-1598382012845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-ccf34fa7-487e-4391-9514-33dfbf2c4499,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1c041bbb-b252-4536-8f13-14827ebedd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-89f45371-ddf3-41f1-ae48-baaad0b30ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-86ab12d4-cbed-4479-bd60-8b58309815bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-fb28d636-a836-44c6-9596-bdf51b82d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-b1864f96-abc3-40c8-8602-19e4a444bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-68069bd5-85ea-4d71-8dca-e9682d728961,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-1bdea817-af16-4679-ae41-0d1df328bee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516851324-172.17.0.14-1598382012845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-ccf34fa7-487e-4391-9514-33dfbf2c4499,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-1c041bbb-b252-4536-8f13-14827ebedd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-89f45371-ddf3-41f1-ae48-baaad0b30ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-86ab12d4-cbed-4479-bd60-8b58309815bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-fb28d636-a836-44c6-9596-bdf51b82d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-b1864f96-abc3-40c8-8602-19e4a444bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-68069bd5-85ea-4d71-8dca-e9682d728961,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-1bdea817-af16-4679-ae41-0d1df328bee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437268876-172.17.0.14-1598382157162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-c3c73960-a8c1-4834-ad43-5c1e98d8fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-51e4334d-b8ec-4f7a-957d-2e970b34e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-234c8e16-9b9c-4a93-adcb-e6e80234516a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-139530a0-69b8-4ba9-9ce4-92c8653b9796,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-091c0f06-8345-4933-bce3-d257671a75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-413c09a3-ac87-4699-bfd9-bb335310feba,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-21b864a1-3036-497d-868a-39cd7b1a847d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-589efffc-32ec-4c7b-ac70-b8cd1b3ed4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437268876-172.17.0.14-1598382157162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-c3c73960-a8c1-4834-ad43-5c1e98d8fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-51e4334d-b8ec-4f7a-957d-2e970b34e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-234c8e16-9b9c-4a93-adcb-e6e80234516a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-139530a0-69b8-4ba9-9ce4-92c8653b9796,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-091c0f06-8345-4933-bce3-d257671a75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-413c09a3-ac87-4699-bfd9-bb335310feba,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-21b864a1-3036-497d-868a-39cd7b1a847d,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-589efffc-32ec-4c7b-ac70-b8cd1b3ed4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604062575-172.17.0.14-1598382258800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37067,DS-9e666980-3c1c-4546-b474-bc8ffa04f667,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-048e0e2f-878e-4eed-8e32-1edd876d3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-713f7d12-9783-4c35-a4cb-57d9acfd5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-1d3e90ea-5e5f-4e40-ac0e-365dc62e2715,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-1f0672bf-b7d1-4096-a050-dd83bb2adb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-c19b6997-d22d-4f20-b51a-00655f8248bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-54806e23-fed6-425c-817d-9e23a81ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-44c449a8-c7c7-407c-bd32-6746bed52bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604062575-172.17.0.14-1598382258800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37067,DS-9e666980-3c1c-4546-b474-bc8ffa04f667,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-048e0e2f-878e-4eed-8e32-1edd876d3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-713f7d12-9783-4c35-a4cb-57d9acfd5c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-1d3e90ea-5e5f-4e40-ac0e-365dc62e2715,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-1f0672bf-b7d1-4096-a050-dd83bb2adb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-c19b6997-d22d-4f20-b51a-00655f8248bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-54806e23-fed6-425c-817d-9e23a81ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-44c449a8-c7c7-407c-bd32-6746bed52bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691422850-172.17.0.14-1598383008928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46450,DS-a9365778-7fdd-484a-9054-ff71381ed873,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-d6875a2b-7992-4abf-9ee4-e1fd1e0b419f,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-d301411a-7e25-4cb0-b54b-a1e3c3e3fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-d3c876ed-a60a-46fa-8996-3a86a53e285e,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-ef40f8e5-dc13-4e9b-a476-8a6e91adae48,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-2f0d75c3-a8e8-40f2-b0a9-02e3f86ca9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-06bff7a6-0f13-41e7-9b28-6345e299aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-95c59987-7888-4741-a8d8-16c7af38bd72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691422850-172.17.0.14-1598383008928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46450,DS-a9365778-7fdd-484a-9054-ff71381ed873,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-d6875a2b-7992-4abf-9ee4-e1fd1e0b419f,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-d301411a-7e25-4cb0-b54b-a1e3c3e3fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-d3c876ed-a60a-46fa-8996-3a86a53e285e,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-ef40f8e5-dc13-4e9b-a476-8a6e91adae48,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-2f0d75c3-a8e8-40f2-b0a9-02e3f86ca9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-06bff7a6-0f13-41e7-9b28-6345e299aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-95c59987-7888-4741-a8d8-16c7af38bd72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619235428-172.17.0.14-1598383049743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-ee26ab9a-0902-4a86-9e00-03572c0e5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-b23e33df-15a3-4788-8955-8a83222eaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-9ea114ce-a6da-4c3d-ad32-3e1102903045,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-30aa2300-add6-4840-a953-3c2a2b586ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-cb41b08b-b431-423b-bb3b-fbdb3377270f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-6dbabdf0-80c1-4e80-adca-d0bf81cb16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e9369657-03b7-4c95-8494-b1109cf92b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-61323854-45fc-495d-9348-e62e8ba751d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619235428-172.17.0.14-1598383049743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-ee26ab9a-0902-4a86-9e00-03572c0e5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-b23e33df-15a3-4788-8955-8a83222eaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-9ea114ce-a6da-4c3d-ad32-3e1102903045,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-30aa2300-add6-4840-a953-3c2a2b586ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-cb41b08b-b431-423b-bb3b-fbdb3377270f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-6dbabdf0-80c1-4e80-adca-d0bf81cb16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e9369657-03b7-4c95-8494-b1109cf92b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-61323854-45fc-495d-9348-e62e8ba751d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640555350-172.17.0.14-1598383077029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-7a0115d2-4086-4d46-a86a-ceff6e2de4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-006d32f4-fd45-4490-92a5-39bb43f1afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-27c23f8f-b009-4bb1-be07-142bcf7891d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0540e4a9-53d2-436c-bee1-637766042948,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-5001621a-3d58-494d-b094-578542fb8290,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e4df695f-7c97-4f09-986e-5c3b37140cec,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a857967b-d998-4d17-bafc-02aa4cc636f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-c13c036d-fb23-47b3-9f32-6d2edff4779f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640555350-172.17.0.14-1598383077029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-7a0115d2-4086-4d46-a86a-ceff6e2de4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-006d32f4-fd45-4490-92a5-39bb43f1afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-27c23f8f-b009-4bb1-be07-142bcf7891d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0540e4a9-53d2-436c-bee1-637766042948,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-5001621a-3d58-494d-b094-578542fb8290,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e4df695f-7c97-4f09-986e-5c3b37140cec,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-a857967b-d998-4d17-bafc-02aa4cc636f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-c13c036d-fb23-47b3-9f32-6d2edff4779f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650750991-172.17.0.14-1598383321895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-1c246cb6-c271-4d27-a890-7639ddba2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-f120d5a0-ca57-4928-a619-49aa4e2f1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ec305213-f4f8-4baf-95ae-3e117488821c,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-91e67498-43d4-491a-8b40-4fef7148bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-7d11479f-d284-4d70-a1b2-746b9c418e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-8db0624b-e060-4ecd-b71a-d11d944c16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-dac2090d-2f6d-4a04-a9f1-19bb337cfdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-444ff425-418a-4500-988b-095ae36d6a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650750991-172.17.0.14-1598383321895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-1c246cb6-c271-4d27-a890-7639ddba2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-f120d5a0-ca57-4928-a619-49aa4e2f1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ec305213-f4f8-4baf-95ae-3e117488821c,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-91e67498-43d4-491a-8b40-4fef7148bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-7d11479f-d284-4d70-a1b2-746b9c418e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-8db0624b-e060-4ecd-b71a-d11d944c16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-dac2090d-2f6d-4a04-a9f1-19bb337cfdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-444ff425-418a-4500-988b-095ae36d6a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842588475-172.17.0.14-1598383551012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-d5c31327-dd58-44b4-b421-981f8244bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-2c41b735-413b-40cd-ac77-4988af247b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-15debe3e-d97a-4830-8640-d233824e0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-ba4c8a90-8dac-4808-9717-0df6f9cb514d,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5a69cbe8-0f4b-469a-86aa-ebe84ec595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b1a88ea4-2bd1-4240-922c-a2aabdef87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-fc8d4ae9-2b83-4282-a7ea-5f1625dd8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-9a0c74d3-7f31-4143-aa5b-1dfac62295ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842588475-172.17.0.14-1598383551012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-d5c31327-dd58-44b4-b421-981f8244bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-2c41b735-413b-40cd-ac77-4988af247b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-15debe3e-d97a-4830-8640-d233824e0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-ba4c8a90-8dac-4808-9717-0df6f9cb514d,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5a69cbe8-0f4b-469a-86aa-ebe84ec595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b1a88ea4-2bd1-4240-922c-a2aabdef87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-fc8d4ae9-2b83-4282-a7ea-5f1625dd8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-9a0c74d3-7f31-4143-aa5b-1dfac62295ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812879218-172.17.0.14-1598383852422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42688,DS-9f002b99-4689-4564-a651-045770d20118,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-1115a835-1f06-4970-a9b3-0791dba2c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-ee2ecdfc-f31d-456f-8c33-58dc923dff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-6652cc4c-c3a6-41d5-a588-b87d0b453830,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-92469b70-41c3-469a-83f1-7824e423b208,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-05184768-f8d5-4b80-a9cb-61c277f1bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-74e016f3-04ae-41e7-ac68-16c298e2211d,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-da439638-c12e-44d0-8f16-8e3f3ae74426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812879218-172.17.0.14-1598383852422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42688,DS-9f002b99-4689-4564-a651-045770d20118,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-1115a835-1f06-4970-a9b3-0791dba2c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-ee2ecdfc-f31d-456f-8c33-58dc923dff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-6652cc4c-c3a6-41d5-a588-b87d0b453830,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-92469b70-41c3-469a-83f1-7824e423b208,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-05184768-f8d5-4b80-a9cb-61c277f1bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-74e016f3-04ae-41e7-ac68-16c298e2211d,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-da439638-c12e-44d0-8f16-8e3f3ae74426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596305929-172.17.0.14-1598384433746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-93f9fd3f-fb57-4cc7-b4ba-56ef659e59db,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-633c1789-cecf-46b5-af90-de4b21604847,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-9abb213e-e483-4254-9560-3c42c979480e,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-4bb9992b-60dc-4410-ab90-41bf0f5f3173,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c8ff59c3-21d5-4043-8b9a-728fd8891825,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-a66fba5c-ef11-427b-b7e2-e7040a52a491,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-040780c8-8bf5-42f1-8d6e-76cb52169d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-4e70fc95-6b89-4ea7-91b4-65b1648679d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596305929-172.17.0.14-1598384433746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-93f9fd3f-fb57-4cc7-b4ba-56ef659e59db,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-633c1789-cecf-46b5-af90-de4b21604847,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-9abb213e-e483-4254-9560-3c42c979480e,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-4bb9992b-60dc-4410-ab90-41bf0f5f3173,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c8ff59c3-21d5-4043-8b9a-728fd8891825,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-a66fba5c-ef11-427b-b7e2-e7040a52a491,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-040780c8-8bf5-42f1-8d6e-76cb52169d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-4e70fc95-6b89-4ea7-91b4-65b1648679d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960000879-172.17.0.14-1598384532874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41699,DS-518210ee-8e7d-474b-8879-b3744cce9b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-16d0527f-6d94-4768-a141-3406546d593e,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-23adf907-8a6b-4727-9fee-5415710b13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-e80a0b06-2f5c-4a1e-b8af-834b192a4693,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-339e2ddf-4d95-4123-a0fe-deb7726aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-17148027-3617-4581-b387-71ed6be4425e,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-1c2a1b09-d980-4600-9b77-58362346bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-6b404ee5-75bc-4b79-8c9f-753489329b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960000879-172.17.0.14-1598384532874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41699,DS-518210ee-8e7d-474b-8879-b3744cce9b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-16d0527f-6d94-4768-a141-3406546d593e,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-23adf907-8a6b-4727-9fee-5415710b13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-e80a0b06-2f5c-4a1e-b8af-834b192a4693,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-339e2ddf-4d95-4123-a0fe-deb7726aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-17148027-3617-4581-b387-71ed6be4425e,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-1c2a1b09-d980-4600-9b77-58362346bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-6b404ee5-75bc-4b79-8c9f-753489329b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926566276-172.17.0.14-1598384752017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-00fe515c-e7dc-4ca0-aa21-cb39b0b97b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-72df0936-8ec5-40e7-82fb-1015f9d0ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-9557acb8-35f5-41e5-a52b-1a71b230a10d,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-62f03c78-29ee-4cc4-b043-687913c50f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-691b7905-29ed-4bf9-bb9d-46a46de99f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-e445424f-0ae1-446b-96cc-3723763c6ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-61c86546-94a9-4158-81d7-19f827a65e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-a56922c2-c1a1-4685-ace0-4b0c0a657fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926566276-172.17.0.14-1598384752017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-00fe515c-e7dc-4ca0-aa21-cb39b0b97b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-72df0936-8ec5-40e7-82fb-1015f9d0ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-9557acb8-35f5-41e5-a52b-1a71b230a10d,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-62f03c78-29ee-4cc4-b043-687913c50f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-691b7905-29ed-4bf9-bb9d-46a46de99f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-e445424f-0ae1-446b-96cc-3723763c6ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-61c86546-94a9-4158-81d7-19f827a65e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-a56922c2-c1a1-4685-ace0-4b0c0a657fcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388205670-172.17.0.14-1598384891942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-2547cd20-5964-4c10-8dd6-45164c90cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4481c15c-c5c1-441e-bf25-7cfdb31cc191,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-c1a140c5-fe24-455f-9465-d75fb3bbff94,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8a22a0a9-fb6f-442c-93b0-52bc9b431f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-779ff347-8040-48ab-8847-9c7b7953a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-b3203379-47c7-4808-930f-c45265641819,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-579b93b9-f110-4280-8445-870f892d7c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-416e05c0-f1c8-471e-b602-d0f3f799be58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388205670-172.17.0.14-1598384891942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41844,DS-2547cd20-5964-4c10-8dd6-45164c90cbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4481c15c-c5c1-441e-bf25-7cfdb31cc191,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-c1a140c5-fe24-455f-9465-d75fb3bbff94,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8a22a0a9-fb6f-442c-93b0-52bc9b431f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-779ff347-8040-48ab-8847-9c7b7953a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-b3203379-47c7-4808-930f-c45265641819,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-579b93b9-f110-4280-8445-870f892d7c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-416e05c0-f1c8-471e-b602-d0f3f799be58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950353504-172.17.0.14-1598384925766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-170405c8-ca01-4c11-acec-2a43b8e6ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-2ada2613-1978-467e-be0a-6176c887ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-02807f70-3122-4ff0-b508-89c1d017ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-82b12f00-af76-4909-a087-b09ba2fc0d26,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-3576858a-95ef-4766-874d-4aa6fa948393,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-ca6b4fca-371b-48f8-8cb1-4c1470afd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2e57ab67-279d-4b4e-8706-a4810798c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-b95ebaba-c446-4924-a436-b431c289f7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950353504-172.17.0.14-1598384925766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-170405c8-ca01-4c11-acec-2a43b8e6ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-2ada2613-1978-467e-be0a-6176c887ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-02807f70-3122-4ff0-b508-89c1d017ef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-82b12f00-af76-4909-a087-b09ba2fc0d26,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-3576858a-95ef-4766-874d-4aa6fa948393,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-ca6b4fca-371b-48f8-8cb1-4c1470afd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-2e57ab67-279d-4b4e-8706-a4810798c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-b95ebaba-c446-4924-a436-b431c289f7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376812290-172.17.0.14-1598385056596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-a3819983-dbd1-4b03-9ed2-616d7f711ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-50109b3e-907d-47b2-8fdb-df91f9bea469,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4b7463ff-9564-4930-b73a-f7ea8621c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-a4072bd7-a4ae-430f-80dc-8d3b58893a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-c395342f-0a45-40a4-9b6f-d0656ebb063c,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-bcd16143-bd36-4261-a219-5a4349523333,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-0ee27c82-2c5e-4ed0-a426-e1efd2bf961f,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-48880c29-fce1-40f5-b2e4-42a01cd4e12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376812290-172.17.0.14-1598385056596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-a3819983-dbd1-4b03-9ed2-616d7f711ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-50109b3e-907d-47b2-8fdb-df91f9bea469,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4b7463ff-9564-4930-b73a-f7ea8621c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-a4072bd7-a4ae-430f-80dc-8d3b58893a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-c395342f-0a45-40a4-9b6f-d0656ebb063c,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-bcd16143-bd36-4261-a219-5a4349523333,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-0ee27c82-2c5e-4ed0-a426-e1efd2bf961f,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-48880c29-fce1-40f5-b2e4-42a01cd4e12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131941504-172.17.0.14-1598385229183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-f9b28ae4-b1cc-4e97-9618-93dea6050ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a4d11c3b-3f7c-4cf0-b89e-49fd292f5668,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-ae63a7d6-0984-47b3-bf3f-2895d29b4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-e2fd80b6-93a6-4233-9e67-af71b64699e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-4d2b80da-1959-46d6-acf5-411836550f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-47ceb1d2-f39a-4a62-a808-8a48dabfdf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-001fe33f-ae01-4d80-b722-41202763ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e5062102-8060-43cb-a83e-d44a7d53433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131941504-172.17.0.14-1598385229183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-f9b28ae4-b1cc-4e97-9618-93dea6050ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a4d11c3b-3f7c-4cf0-b89e-49fd292f5668,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-ae63a7d6-0984-47b3-bf3f-2895d29b4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-e2fd80b6-93a6-4233-9e67-af71b64699e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-4d2b80da-1959-46d6-acf5-411836550f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-47ceb1d2-f39a-4a62-a808-8a48dabfdf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-001fe33f-ae01-4d80-b722-41202763ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e5062102-8060-43cb-a83e-d44a7d53433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5144
