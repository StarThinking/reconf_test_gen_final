reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500055367-172.17.0.13-1598395595338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44055,DS-2af2d555-5b6c-466f-8114-44741f78d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2d017cea-b78c-4dd2-87da-209905e731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-4a1f85fa-c3be-4c28-88e3-54c87dfdf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-73fbea9a-d813-44e5-a206-c679ef797b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-365af967-6e17-4d48-9d61-3c2b70ee570b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-08f541bf-8145-47e6-bf52-3310ae9d36a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-dd3102f1-20c7-4b5c-ae98-fc28fb07d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-a71f1877-ba42-487a-b0f2-d7d6c2a0facd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500055367-172.17.0.13-1598395595338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44055,DS-2af2d555-5b6c-466f-8114-44741f78d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2d017cea-b78c-4dd2-87da-209905e731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-4a1f85fa-c3be-4c28-88e3-54c87dfdf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-73fbea9a-d813-44e5-a206-c679ef797b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-365af967-6e17-4d48-9d61-3c2b70ee570b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-08f541bf-8145-47e6-bf52-3310ae9d36a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-dd3102f1-20c7-4b5c-ae98-fc28fb07d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-a71f1877-ba42-487a-b0f2-d7d6c2a0facd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072083063-172.17.0.13-1598396006396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-d4b01c8e-0ca9-4f8e-b890-594674841e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-9bdd86ca-5645-4a6d-ab7c-239d5710384d,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-4ffccf93-5bf8-45c0-8350-675ae5fa8448,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-c8ea12a9-2499-421a-8c1b-aefcab4c08ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-254bdbc2-0221-4dae-a3dd-932936efe0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-084bf2e4-9ef8-402c-bc6b-0a1c0c808db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-3fd49663-20d7-43e9-9965-051a0595e542,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-fc65c868-17cf-44ea-9771-50cb4353390d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072083063-172.17.0.13-1598396006396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-d4b01c8e-0ca9-4f8e-b890-594674841e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-9bdd86ca-5645-4a6d-ab7c-239d5710384d,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-4ffccf93-5bf8-45c0-8350-675ae5fa8448,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-c8ea12a9-2499-421a-8c1b-aefcab4c08ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-254bdbc2-0221-4dae-a3dd-932936efe0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-084bf2e4-9ef8-402c-bc6b-0a1c0c808db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-3fd49663-20d7-43e9-9965-051a0595e542,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-fc65c868-17cf-44ea-9771-50cb4353390d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196219879-172.17.0.13-1598396270648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35351,DS-1d80f0b8-852e-46a3-a8d8-a7dc9422b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-ec6e09b3-60a1-4d7f-b4dd-64775384227b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e9082964-4ea5-4594-a951-27b7ce75bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-9664e2ce-0f0b-46fd-a51f-0b60678f367b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-4f198928-c92a-4790-aa41-4a468b1e9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-dac8a49f-a952-43d9-a0b2-354a1dc598c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-31d77200-dd4c-4c62-964e-e29c76618a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-6553b6cb-ef63-4730-a0c8-5b60eb5f5eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196219879-172.17.0.13-1598396270648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35351,DS-1d80f0b8-852e-46a3-a8d8-a7dc9422b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-ec6e09b3-60a1-4d7f-b4dd-64775384227b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e9082964-4ea5-4594-a951-27b7ce75bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-9664e2ce-0f0b-46fd-a51f-0b60678f367b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-4f198928-c92a-4790-aa41-4a468b1e9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-dac8a49f-a952-43d9-a0b2-354a1dc598c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-31d77200-dd4c-4c62-964e-e29c76618a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-6553b6cb-ef63-4730-a0c8-5b60eb5f5eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572180845-172.17.0.13-1598396413398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-35285caa-a4bd-45b2-9e35-80eb0b823249,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-86503bb3-bac8-4658-b161-bdfe6d538e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-d61b1d88-c08f-4a14-ac18-dca0707a5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-de5f7723-69c7-4520-bdb3-1335cc4ec6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-fe213956-8bfc-4651-b014-c00b4375dad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-2e7945e6-1d7e-4105-925b-42f9ba3a0723,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-69b4bf75-2941-4f41-9e12-6a2ffc892b01,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-57dd4f94-08f0-4f63-b648-a01a7f3275e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572180845-172.17.0.13-1598396413398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-35285caa-a4bd-45b2-9e35-80eb0b823249,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-86503bb3-bac8-4658-b161-bdfe6d538e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-d61b1d88-c08f-4a14-ac18-dca0707a5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-de5f7723-69c7-4520-bdb3-1335cc4ec6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-fe213956-8bfc-4651-b014-c00b4375dad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-2e7945e6-1d7e-4105-925b-42f9ba3a0723,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-69b4bf75-2941-4f41-9e12-6a2ffc892b01,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-57dd4f94-08f0-4f63-b648-a01a7f3275e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650112923-172.17.0.13-1598396515519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-e29fc64e-44d4-4b11-9b74-b01f144e29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-24fcb520-be97-4883-a7db-45f6b7b8028c,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-90d978ec-c99e-4569-b731-9f0a164990df,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-5d156c2e-e3c5-40ef-84a8-9bfa9cc2bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-4410427e-03bf-42e8-a665-af3c036fefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-5e42b16f-769d-406d-9baf-c21aa8aff242,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-d78bdb82-7bf6-46b1-b107-c6faa9011e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-21d834aa-9723-4844-8040-7348545403cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650112923-172.17.0.13-1598396515519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-e29fc64e-44d4-4b11-9b74-b01f144e29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-24fcb520-be97-4883-a7db-45f6b7b8028c,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-90d978ec-c99e-4569-b731-9f0a164990df,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-5d156c2e-e3c5-40ef-84a8-9bfa9cc2bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-4410427e-03bf-42e8-a665-af3c036fefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-5e42b16f-769d-406d-9baf-c21aa8aff242,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-d78bdb82-7bf6-46b1-b107-c6faa9011e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-21d834aa-9723-4844-8040-7348545403cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749048653-172.17.0.13-1598396728439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-df499956-50e4-48d8-b29b-3473c3cf1fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-ddb9daa6-6f53-4433-a4c0-2cfad71ba336,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-da74de42-242b-4da4-89de-49193b227573,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-a5d5a122-c5cf-4042-b9cc-3275b6ba3716,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d44a9f4a-6f3c-48a0-9729-cf360f8456f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-e4fd740b-e13e-4e3c-9254-c8aff7bde522,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-5a0f55a6-f50f-4705-8f45-4fb23598355f,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-22ded4d0-e787-4924-859b-58e1d8c71312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749048653-172.17.0.13-1598396728439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-df499956-50e4-48d8-b29b-3473c3cf1fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-ddb9daa6-6f53-4433-a4c0-2cfad71ba336,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-da74de42-242b-4da4-89de-49193b227573,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-a5d5a122-c5cf-4042-b9cc-3275b6ba3716,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d44a9f4a-6f3c-48a0-9729-cf360f8456f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-e4fd740b-e13e-4e3c-9254-c8aff7bde522,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-5a0f55a6-f50f-4705-8f45-4fb23598355f,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-22ded4d0-e787-4924-859b-58e1d8c71312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151089671-172.17.0.13-1598397013831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-1235d1e7-6b54-4a9b-9069-4e431b8e2632,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c9211276-0674-4d08-afd0-826e6c84efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-98f62fab-0932-42cd-9561-8bebd3b1f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-f287679f-c8a1-48f1-89b6-3a08f1901b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-7e5a37f7-1882-4377-aebf-41d05340f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-2fb22855-7b13-4bfa-bc08-4c818b54063c,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-a7043ef3-d654-4c24-a348-84b9fdc52050,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-e1376c23-aa75-435e-858d-6696a204a2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151089671-172.17.0.13-1598397013831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-1235d1e7-6b54-4a9b-9069-4e431b8e2632,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c9211276-0674-4d08-afd0-826e6c84efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-98f62fab-0932-42cd-9561-8bebd3b1f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-f287679f-c8a1-48f1-89b6-3a08f1901b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-7e5a37f7-1882-4377-aebf-41d05340f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-2fb22855-7b13-4bfa-bc08-4c818b54063c,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-a7043ef3-d654-4c24-a348-84b9fdc52050,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-e1376c23-aa75-435e-858d-6696a204a2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246559884-172.17.0.13-1598397292580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-09b71c4e-d578-4333-a2df-a8d380a69f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d8afe3f7-cc2c-4b65-855b-150dce2f0289,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-55c6d85c-a0f4-4a5d-bca7-e565541feca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-d0ba1418-2cf8-45e9-b3fc-e375f963277e,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-2884bbb9-b4b6-41ba-ba5f-89de37b85196,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-f84beb36-bf50-461e-89b0-68805f4f0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-74c27bec-df87-42ee-99e9-7551b3000cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-7855ed29-1fc5-4128-8a63-2fb60ad13d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246559884-172.17.0.13-1598397292580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-09b71c4e-d578-4333-a2df-a8d380a69f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d8afe3f7-cc2c-4b65-855b-150dce2f0289,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-55c6d85c-a0f4-4a5d-bca7-e565541feca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-d0ba1418-2cf8-45e9-b3fc-e375f963277e,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-2884bbb9-b4b6-41ba-ba5f-89de37b85196,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-f84beb36-bf50-461e-89b0-68805f4f0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-74c27bec-df87-42ee-99e9-7551b3000cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-7855ed29-1fc5-4128-8a63-2fb60ad13d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129972983-172.17.0.13-1598397356553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38452,DS-e054b869-d381-4b62-8a38-3295bd33b550,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-f7c8cf97-4f0b-43a7-ad2b-0533626e62c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-bf909c80-f5d9-428a-b034-ae2cabc3627b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-8e089ac3-0f30-4af5-821b-600ff02776f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-b45886ed-8c23-40a5-9256-db11db846453,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-cd1d1ec0-f7e0-46ff-87c5-8a4e37724741,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-20ab6be5-be3e-4d8f-b7e5-22ad7c5f3421,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-585ed0cf-87c8-40e5-aacd-3242f12baf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129972983-172.17.0.13-1598397356553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38452,DS-e054b869-d381-4b62-8a38-3295bd33b550,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-f7c8cf97-4f0b-43a7-ad2b-0533626e62c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-bf909c80-f5d9-428a-b034-ae2cabc3627b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-8e089ac3-0f30-4af5-821b-600ff02776f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-b45886ed-8c23-40a5-9256-db11db846453,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-cd1d1ec0-f7e0-46ff-87c5-8a4e37724741,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-20ab6be5-be3e-4d8f-b7e5-22ad7c5f3421,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-585ed0cf-87c8-40e5-aacd-3242f12baf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132047415-172.17.0.13-1598397389043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-cf1e1f17-b38c-4204-87b4-65cd50974e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-e22cca6d-c33a-4c6c-8773-ea244fd8a991,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-f763dc63-8c1b-43b9-98f8-f2cc0f36c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-82b74de9-1001-480b-9064-a1065eb4237f,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-567050eb-5d4b-4d21-939b-617aea1739a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4c2ce60a-501f-457e-8142-6e18134320fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-10de43c5-bb9e-4775-affa-fd87601653c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-f449a38d-0056-4331-ab44-37dd4024f348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132047415-172.17.0.13-1598397389043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-cf1e1f17-b38c-4204-87b4-65cd50974e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-e22cca6d-c33a-4c6c-8773-ea244fd8a991,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-f763dc63-8c1b-43b9-98f8-f2cc0f36c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-82b74de9-1001-480b-9064-a1065eb4237f,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-567050eb-5d4b-4d21-939b-617aea1739a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4c2ce60a-501f-457e-8142-6e18134320fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-10de43c5-bb9e-4775-affa-fd87601653c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-f449a38d-0056-4331-ab44-37dd4024f348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131846139-172.17.0.13-1598397675443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-d9b88190-08ea-45a9-8184-618b82a896e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-393e189a-6759-49f7-ad13-01c6fe4e965b,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-10c7bcd9-ed4a-4314-9675-c244214f8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-7db77bcc-552e-44ad-b9e9-b35ae5061323,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-bae6224b-4821-40e1-9b4e-868d1dbe0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-80ecc6b7-cbf8-4422-af24-f70560bf6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-834d7bf3-23fd-4912-839f-6dc5228b9fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-ee89f2ca-be68-4e8a-bf2f-9bd7965e9313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131846139-172.17.0.13-1598397675443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-d9b88190-08ea-45a9-8184-618b82a896e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-393e189a-6759-49f7-ad13-01c6fe4e965b,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-10c7bcd9-ed4a-4314-9675-c244214f8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-7db77bcc-552e-44ad-b9e9-b35ae5061323,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-bae6224b-4821-40e1-9b4e-868d1dbe0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-80ecc6b7-cbf8-4422-af24-f70560bf6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-834d7bf3-23fd-4912-839f-6dc5228b9fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-ee89f2ca-be68-4e8a-bf2f-9bd7965e9313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588313588-172.17.0.13-1598397832984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-29645ce9-44fb-4394-8aa6-d9625ce85182,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-79a37c03-fb00-4151-85ba-7306741852ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-6374ebf3-e0aa-4027-9155-7e8448ccd577,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-74d462fd-1104-4d3c-9dd1-6a3123c9d458,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-1fe6a23c-e2ea-43f8-b831-91438b31ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-6bc0e66d-cbb8-4677-b698-817f28ba8632,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-4ae1c392-a786-4e02-ba34-9d6230fe1b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-4382995b-3573-4508-be3f-eeb07d1cb959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588313588-172.17.0.13-1598397832984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-29645ce9-44fb-4394-8aa6-d9625ce85182,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-79a37c03-fb00-4151-85ba-7306741852ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-6374ebf3-e0aa-4027-9155-7e8448ccd577,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-74d462fd-1104-4d3c-9dd1-6a3123c9d458,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-1fe6a23c-e2ea-43f8-b831-91438b31ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-6bc0e66d-cbb8-4677-b698-817f28ba8632,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-4ae1c392-a786-4e02-ba34-9d6230fe1b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-4382995b-3573-4508-be3f-eeb07d1cb959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98573750-172.17.0.13-1598398153402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-1a43b886-13f0-410c-b52b-a654dab23b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-88b0213e-4541-4483-af39-eb8113ac62fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-3891ff02-7b9c-4511-8ce5-c876f0173059,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-2f14637d-31e7-438d-8534-1908bf7136b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-73161e52-4885-40ae-9d64-3ae032a29e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-10e1dcc0-5192-4c30-8fb4-f64e6835840c,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-65048f6c-1948-471f-bcea-4d75a624c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-9434fcde-6123-4b78-a0fc-3a212a64ddfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98573750-172.17.0.13-1598398153402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-1a43b886-13f0-410c-b52b-a654dab23b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-88b0213e-4541-4483-af39-eb8113ac62fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-3891ff02-7b9c-4511-8ce5-c876f0173059,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-2f14637d-31e7-438d-8534-1908bf7136b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-73161e52-4885-40ae-9d64-3ae032a29e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-10e1dcc0-5192-4c30-8fb4-f64e6835840c,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-65048f6c-1948-471f-bcea-4d75a624c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-9434fcde-6123-4b78-a0fc-3a212a64ddfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396504571-172.17.0.13-1598398923440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-881caab2-0fac-4b42-bb98-37fde8715d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-87cc906e-e585-4656-8ec4-39e8b5714bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-24223fa3-f620-42fe-b2c1-bb04bad83606,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9702e661-61db-4641-80c1-fd4f889d51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-fa8ea61b-3120-46dd-9a72-20827815ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-8277e3c1-7eec-43ea-8de7-f48106738a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-b3575aaf-23cd-456b-9d64-d702d06bf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-0bfbe6b8-59da-4481-8831-91f7da333cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396504571-172.17.0.13-1598398923440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-881caab2-0fac-4b42-bb98-37fde8715d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-87cc906e-e585-4656-8ec4-39e8b5714bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-24223fa3-f620-42fe-b2c1-bb04bad83606,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9702e661-61db-4641-80c1-fd4f889d51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-fa8ea61b-3120-46dd-9a72-20827815ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-8277e3c1-7eec-43ea-8de7-f48106738a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-b3575aaf-23cd-456b-9d64-d702d06bf7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-0bfbe6b8-59da-4481-8831-91f7da333cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403284187-172.17.0.13-1598399053713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-ac9d51d7-cee6-456c-9cf8-6937aa2d79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4918cacb-98eb-4c71-a2e7-cb5cb9a99a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-d38ece70-8549-44c4-9b37-b76c0f5595a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-0592b12b-cd18-459a-a64a-09a4f8ffebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-c4b5e21c-6b01-4ab5-a4e8-e83eba371db7,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-38c074ca-db9c-4ed6-8670-80918129fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-07dff14f-e8f2-4f98-b304-cbdffb54caee,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-52920a4f-d188-4c34-a489-816f25ef1363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-403284187-172.17.0.13-1598399053713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-ac9d51d7-cee6-456c-9cf8-6937aa2d79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4918cacb-98eb-4c71-a2e7-cb5cb9a99a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-d38ece70-8549-44c4-9b37-b76c0f5595a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-0592b12b-cd18-459a-a64a-09a4f8ffebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-c4b5e21c-6b01-4ab5-a4e8-e83eba371db7,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-38c074ca-db9c-4ed6-8670-80918129fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-07dff14f-e8f2-4f98-b304-cbdffb54caee,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-52920a4f-d188-4c34-a489-816f25ef1363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513523695-172.17.0.13-1598399656224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-c926df56-a213-484d-9b9c-b6d765847366,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-f8459438-8975-4149-be68-9224a9206c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-fc89235c-4131-4ddf-9220-96897fe9bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-0156b7ab-791f-42f2-80b8-cdb53c80e444,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-79c4bc8f-c7a4-4554-9fd0-ff1b2056c2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-b83b5e5a-da3f-45d4-bcad-b6c6331c0426,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-effc4cbd-3567-4137-8175-de94f19d4338,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-a97ad1a8-63da-4135-88bd-d1429440f277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513523695-172.17.0.13-1598399656224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-c926df56-a213-484d-9b9c-b6d765847366,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-f8459438-8975-4149-be68-9224a9206c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-fc89235c-4131-4ddf-9220-96897fe9bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-0156b7ab-791f-42f2-80b8-cdb53c80e444,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-79c4bc8f-c7a4-4554-9fd0-ff1b2056c2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-b83b5e5a-da3f-45d4-bcad-b6c6331c0426,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-effc4cbd-3567-4137-8175-de94f19d4338,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-a97ad1a8-63da-4135-88bd-d1429440f277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940736987-172.17.0.13-1598399762003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-f6360471-8c98-4f16-94c3-c7a3bb2ad9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-7ee3e1a7-b652-4241-bb4f-faa76320eaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-45bd7ab2-f9cd-4b64-907f-ea53302aeb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-720cca69-e09a-493a-8433-ed9845ae260e,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-6f697f53-ab68-4fe0-acfc-ff57e7dfd1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d34654b7-5701-4866-9c51-96ab8177321e,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-a30ad197-53ac-4e49-91c3-3029f71c7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-de7756dd-0777-40c6-a032-94c9e2f01a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940736987-172.17.0.13-1598399762003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-f6360471-8c98-4f16-94c3-c7a3bb2ad9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-7ee3e1a7-b652-4241-bb4f-faa76320eaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-45bd7ab2-f9cd-4b64-907f-ea53302aeb91,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-720cca69-e09a-493a-8433-ed9845ae260e,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-6f697f53-ab68-4fe0-acfc-ff57e7dfd1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d34654b7-5701-4866-9c51-96ab8177321e,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-a30ad197-53ac-4e49-91c3-3029f71c7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-de7756dd-0777-40c6-a032-94c9e2f01a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176683730-172.17.0.13-1598399909839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-3b3900bb-8673-49bf-94d6-f6a9d34ee183,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23381e4a-f204-4ef0-ad70-3a1c10743c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-b2d5ecec-379d-448a-a898-0b873423e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-53f58a15-c8d0-41b0-81ac-3bbbba9e3970,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-914e3056-2f51-4ccd-a843-e30ac4d99d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-ae3c35df-068b-4b37-b3c8-c2b8bfe5addd,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-374e8750-1471-436a-8a6e-b4eea1761f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-a4eec0ba-fd54-479b-b23d-44fefc254cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176683730-172.17.0.13-1598399909839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-3b3900bb-8673-49bf-94d6-f6a9d34ee183,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-23381e4a-f204-4ef0-ad70-3a1c10743c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-b2d5ecec-379d-448a-a898-0b873423e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-53f58a15-c8d0-41b0-81ac-3bbbba9e3970,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-914e3056-2f51-4ccd-a843-e30ac4d99d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-ae3c35df-068b-4b37-b3c8-c2b8bfe5addd,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-374e8750-1471-436a-8a6e-b4eea1761f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-a4eec0ba-fd54-479b-b23d-44fefc254cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117038391-172.17.0.13-1598400047030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39021,DS-4f2cfcd9-94af-4e94-8dee-d3ef48f28ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-53f4b332-d394-4b3e-adbb-ced844154f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-54907be3-a63c-43cc-8469-a76a2a9b3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-0d740f96-d6e3-4abf-8d72-8327f5b36a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-004285cd-90a9-4d53-8d4b-c59b4056c566,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-5470750e-4d62-4553-ad75-12f47cb7bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-e3819eb0-9a97-4469-bda1-6d8bef32c066,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-e15e8ac1-046d-447f-94f2-8f9696e5a7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117038391-172.17.0.13-1598400047030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39021,DS-4f2cfcd9-94af-4e94-8dee-d3ef48f28ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-53f4b332-d394-4b3e-adbb-ced844154f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-54907be3-a63c-43cc-8469-a76a2a9b3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-0d740f96-d6e3-4abf-8d72-8327f5b36a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-004285cd-90a9-4d53-8d4b-c59b4056c566,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-5470750e-4d62-4553-ad75-12f47cb7bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-e3819eb0-9a97-4469-bda1-6d8bef32c066,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-e15e8ac1-046d-447f-94f2-8f9696e5a7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215161562-172.17.0.13-1598400204920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-8eba6c9b-1de1-484f-8a02-d1e19351ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-ab333ed4-4f50-495b-8c05-2a235b496807,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-b786949b-0759-4c11-96a1-245722a2bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-1ffacb5a-bf05-4132-9d5a-8f28b82c470b,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-8b6a20c0-6738-490a-9062-ef72ca74383d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-52e5b48b-7606-4747-8559-90a1eda9f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-fa0d76ed-e0d2-4b28-910d-d7a23c3c156f,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-d01a24f4-4e32-48c8-a8a5-1bacaebb5d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215161562-172.17.0.13-1598400204920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-8eba6c9b-1de1-484f-8a02-d1e19351ae4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-ab333ed4-4f50-495b-8c05-2a235b496807,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-b786949b-0759-4c11-96a1-245722a2bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-1ffacb5a-bf05-4132-9d5a-8f28b82c470b,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-8b6a20c0-6738-490a-9062-ef72ca74383d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-52e5b48b-7606-4747-8559-90a1eda9f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-fa0d76ed-e0d2-4b28-910d-d7a23c3c156f,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-d01a24f4-4e32-48c8-a8a5-1bacaebb5d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 4880
