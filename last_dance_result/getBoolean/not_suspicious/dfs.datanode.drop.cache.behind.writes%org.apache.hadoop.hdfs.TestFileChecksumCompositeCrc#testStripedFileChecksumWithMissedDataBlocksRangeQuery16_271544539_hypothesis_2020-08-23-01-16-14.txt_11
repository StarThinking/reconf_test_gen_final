reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576378110-172.17.0.10-1598145417434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-42e76c02-a3d8-4bbc-8466-cfc08c3f423f,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-fa40b7df-ba64-4f14-8b91-103ab83ac570,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-fc7dba82-14ab-4bc5-aa51-b15b1b2f0d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-e43bfbdc-48e3-4ee3-bb5c-22cdb4a4422c,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-2398ad58-5976-4723-9624-e3aa45712fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-ad498e5a-3efe-4212-94f3-8cec856343f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-27581216-59b4-473d-a874-c950c659f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-ff603413-2419-4a52-b6fe-01e1e5501c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576378110-172.17.0.10-1598145417434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-42e76c02-a3d8-4bbc-8466-cfc08c3f423f,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-fa40b7df-ba64-4f14-8b91-103ab83ac570,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-fc7dba82-14ab-4bc5-aa51-b15b1b2f0d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-e43bfbdc-48e3-4ee3-bb5c-22cdb4a4422c,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-2398ad58-5976-4723-9624-e3aa45712fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-ad498e5a-3efe-4212-94f3-8cec856343f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-27581216-59b4-473d-a874-c950c659f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-ff603413-2419-4a52-b6fe-01e1e5501c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896600665-172.17.0.10-1598146337920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-6f125da1-3ee6-4c40-a5da-695b033ff2be,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-13be32c0-42d5-4f14-ac19-58e5f269ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-434ac899-3e84-441c-8cdd-bed99dc87d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bcc7f997-f6da-4cfc-a73a-b4a1f9114d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-3a2a01cf-4741-4560-b914-c20be9951d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-301d4e2e-f130-4a09-8a8f-908c8efc0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-87e41b10-7336-4804-a189-8e95aa3f8aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-a55b5c29-36ec-4546-9fe8-82a681998c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896600665-172.17.0.10-1598146337920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-6f125da1-3ee6-4c40-a5da-695b033ff2be,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-13be32c0-42d5-4f14-ac19-58e5f269ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-434ac899-3e84-441c-8cdd-bed99dc87d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-bcc7f997-f6da-4cfc-a73a-b4a1f9114d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-3a2a01cf-4741-4560-b914-c20be9951d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-301d4e2e-f130-4a09-8a8f-908c8efc0d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-87e41b10-7336-4804-a189-8e95aa3f8aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-a55b5c29-36ec-4546-9fe8-82a681998c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559322688-172.17.0.10-1598147537240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-5aeb7ddc-d76c-4e09-8147-038bff6f2365,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-02e78133-2155-4dda-a39b-0eff0cde5e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-48bea0f7-2a16-4b52-b307-4b424df60803,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-11f2ada8-2553-40b0-808a-56db39b2350b,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-97c27253-0c23-43ed-b18e-456f9553480e,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-39ca5af5-213b-495f-9aa6-62f561b48067,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-c57a715d-c86c-4001-9c13-820b634aa8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-77fd0703-a1d2-4d64-8b32-e20672b89f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559322688-172.17.0.10-1598147537240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-5aeb7ddc-d76c-4e09-8147-038bff6f2365,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-02e78133-2155-4dda-a39b-0eff0cde5e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-48bea0f7-2a16-4b52-b307-4b424df60803,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-11f2ada8-2553-40b0-808a-56db39b2350b,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-97c27253-0c23-43ed-b18e-456f9553480e,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-39ca5af5-213b-495f-9aa6-62f561b48067,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-c57a715d-c86c-4001-9c13-820b634aa8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-77fd0703-a1d2-4d64-8b32-e20672b89f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939202428-172.17.0.10-1598147907104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-40ef9770-bda9-4539-b5de-2865f48fe9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-2b5ccee5-19f3-45b2-90c8-649c25c5ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a673b4db-3896-4bc0-8b01-accda0a5bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8dd5669b-57ba-4ec9-9356-24d8d8e7f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0d8e0faf-7b2f-4337-8fb8-eb8892f2fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-9c3819f8-9457-4160-ade5-74357143017e,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-f3fd6632-a4ad-4701-b9df-986cd8befb85,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-16d7ef2b-6553-4856-b73f-bc93907f604b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939202428-172.17.0.10-1598147907104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-40ef9770-bda9-4539-b5de-2865f48fe9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-2b5ccee5-19f3-45b2-90c8-649c25c5ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a673b4db-3896-4bc0-8b01-accda0a5bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8dd5669b-57ba-4ec9-9356-24d8d8e7f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-0d8e0faf-7b2f-4337-8fb8-eb8892f2fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-9c3819f8-9457-4160-ade5-74357143017e,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-f3fd6632-a4ad-4701-b9df-986cd8befb85,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-16d7ef2b-6553-4856-b73f-bc93907f604b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069724872-172.17.0.10-1598148125888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-0915e266-53dd-44f1-9d6f-50315825df70,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-2e46dd52-40ae-48a5-b54b-2bd1512acac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-252eb04f-63b4-40af-b3ae-51f6dd800ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6424a45b-af73-4b1e-8c74-8a1ac8b57898,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ad6050c7-fd98-4b79-ae8e-fe27948adb30,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-fd31249c-836f-4919-bf8a-da7e15b290d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-deea78d8-107b-4087-b77c-d449f7678ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-16366568-8835-4ced-b3d8-0ccf61eb8d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069724872-172.17.0.10-1598148125888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-0915e266-53dd-44f1-9d6f-50315825df70,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-2e46dd52-40ae-48a5-b54b-2bd1512acac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-252eb04f-63b4-40af-b3ae-51f6dd800ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-6424a45b-af73-4b1e-8c74-8a1ac8b57898,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ad6050c7-fd98-4b79-ae8e-fe27948adb30,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-fd31249c-836f-4919-bf8a-da7e15b290d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-deea78d8-107b-4087-b77c-d449f7678ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-16366568-8835-4ced-b3d8-0ccf61eb8d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473686611-172.17.0.10-1598148473475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-1af7b9ae-526c-4ab1-be86-dd70539695ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-5225dcc6-f46e-47f5-907c-b9ea7d62933d,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d821ed69-3a29-4a84-a024-96dbc8e79cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-45147d75-5637-4eb7-baf4-c0f2396bc03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-5d495891-b3f5-49f5-bfb7-bd19e48ccbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f296aeee-c822-4ad8-b5bb-fa66eb0d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-df3fb7dc-494f-4d8c-b272-af0058fddd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-dcd9a263-2bbd-4bef-b8e7-854f6f3b7480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473686611-172.17.0.10-1598148473475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-1af7b9ae-526c-4ab1-be86-dd70539695ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-5225dcc6-f46e-47f5-907c-b9ea7d62933d,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d821ed69-3a29-4a84-a024-96dbc8e79cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-45147d75-5637-4eb7-baf4-c0f2396bc03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-5d495891-b3f5-49f5-bfb7-bd19e48ccbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f296aeee-c822-4ad8-b5bb-fa66eb0d23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-df3fb7dc-494f-4d8c-b272-af0058fddd96,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-dcd9a263-2bbd-4bef-b8e7-854f6f3b7480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806127627-172.17.0.10-1598148859880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-687024d8-693d-4f3a-916b-4fdb8fbe97a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-cacacf59-0909-45d2-93cc-ef2dea5f6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-590bf3d8-bc3c-4684-b556-317114571a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-1c6ef961-9ed7-4034-a2ca-68400f163a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-7d63c465-dbc8-44f4-8099-111090bda35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-564b8fb3-b1a9-4646-b93a-5a78f3632f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-220a92b0-22b1-4b61-a8cd-97bcc345b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-0bf67843-e650-49ed-a863-950b7d83567a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806127627-172.17.0.10-1598148859880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-687024d8-693d-4f3a-916b-4fdb8fbe97a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-cacacf59-0909-45d2-93cc-ef2dea5f6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-590bf3d8-bc3c-4684-b556-317114571a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-1c6ef961-9ed7-4034-a2ca-68400f163a79,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-7d63c465-dbc8-44f4-8099-111090bda35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-564b8fb3-b1a9-4646-b93a-5a78f3632f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-220a92b0-22b1-4b61-a8cd-97bcc345b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-0bf67843-e650-49ed-a863-950b7d83567a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230369190-172.17.0.10-1598149175131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-c0407ceb-f309-4154-84fc-ed3c37485f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-07b3f84d-8081-4f87-92b8-0e8a21535478,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-5f264d93-1b96-4f65-9820-c0136b36f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-c99dc693-8775-4e31-bfac-66ffa2d915fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-e042b966-b041-4e79-af48-d663c460f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-979b13c7-c6d4-439e-8a3e-3dbb1205b884,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-c3e84020-76c4-4ba4-9113-ce533dc32bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-eb2808ae-c03b-44aa-bc23-963a7962d6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230369190-172.17.0.10-1598149175131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-c0407ceb-f309-4154-84fc-ed3c37485f26,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-07b3f84d-8081-4f87-92b8-0e8a21535478,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-5f264d93-1b96-4f65-9820-c0136b36f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-c99dc693-8775-4e31-bfac-66ffa2d915fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-e042b966-b041-4e79-af48-d663c460f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-979b13c7-c6d4-439e-8a3e-3dbb1205b884,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-c3e84020-76c4-4ba4-9113-ce533dc32bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-eb2808ae-c03b-44aa-bc23-963a7962d6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833329586-172.17.0.10-1598149561949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-136d3d2c-104a-4569-9d66-3b9b24f7c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-45eb7e24-abcd-4ea0-a2c8-b35ba13a0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-cfc217a8-8fc0-4e7f-b13d-7458d34c5b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-31727b9b-cb79-4ca3-b497-3ee61d510539,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-dfd52396-5c75-4d79-957c-6261de245a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-1742689b-749b-4b1a-b8ca-1e761844c879,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0a20e7f2-4072-4fa6-a64f-b76a46509443,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-1fc63a63-4ce8-483b-93c4-11acb2fcdc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833329586-172.17.0.10-1598149561949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-136d3d2c-104a-4569-9d66-3b9b24f7c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-45eb7e24-abcd-4ea0-a2c8-b35ba13a0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-cfc217a8-8fc0-4e7f-b13d-7458d34c5b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-31727b9b-cb79-4ca3-b497-3ee61d510539,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-dfd52396-5c75-4d79-957c-6261de245a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-1742689b-749b-4b1a-b8ca-1e761844c879,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0a20e7f2-4072-4fa6-a64f-b76a46509443,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-1fc63a63-4ce8-483b-93c4-11acb2fcdc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785488388-172.17.0.10-1598149664795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-042b03a5-1fc7-4a1b-b002-db12d8ad0243,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-f83dc40b-59e9-4179-b894-8e619b2e8e92,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-2fa60e5e-f162-422a-b39a-f1431c5d95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-2e0b767a-da27-421f-8ac5-386c320c2506,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-3184941d-69b3-431c-b132-c83e5e06093a,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-1758b56e-d7dc-4018-86f9-006c791bfbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-64a845ed-4393-41aa-acf7-478be0c11460,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-8c55a9f6-e746-44c1-bc23-6e2fab30a3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785488388-172.17.0.10-1598149664795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-042b03a5-1fc7-4a1b-b002-db12d8ad0243,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-f83dc40b-59e9-4179-b894-8e619b2e8e92,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-2fa60e5e-f162-422a-b39a-f1431c5d95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-2e0b767a-da27-421f-8ac5-386c320c2506,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-3184941d-69b3-431c-b132-c83e5e06093a,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-1758b56e-d7dc-4018-86f9-006c791bfbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-64a845ed-4393-41aa-acf7-478be0c11460,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-8c55a9f6-e746-44c1-bc23-6e2fab30a3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733142103-172.17.0.10-1598149764008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-901c039e-f32a-4f54-9229-3b151d421e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-a95504d9-dc09-41bc-9982-a2769bfbfbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-afcddde6-fdf2-405f-b78a-d158d5e1c656,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b1259a85-99be-452a-b5aa-d1bb8d4109bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-7c33e1cf-9e4e-421e-b04f-8513436b40f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-950cd300-360d-4656-bc46-6a82edb74733,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-6b98309e-a003-4294-b9f3-8871ee2f7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-0b012587-27b2-46b2-a9a6-17092719f9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733142103-172.17.0.10-1598149764008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-901c039e-f32a-4f54-9229-3b151d421e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-a95504d9-dc09-41bc-9982-a2769bfbfbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-afcddde6-fdf2-405f-b78a-d158d5e1c656,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b1259a85-99be-452a-b5aa-d1bb8d4109bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-7c33e1cf-9e4e-421e-b04f-8513436b40f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-950cd300-360d-4656-bc46-6a82edb74733,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-6b98309e-a003-4294-b9f3-8871ee2f7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-0b012587-27b2-46b2-a9a6-17092719f9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510818657-172.17.0.10-1598149802209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-a750b561-2edd-4217-ae8c-12b2400bce53,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-c0096d15-bec9-483f-8fa9-5bbeb65f8d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b6b28d27-d519-4575-824f-364613105ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-2fdc5464-23fc-4722-9b76-44e15e7fb6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a7464c1c-fd7b-422e-b405-b3f97d065a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-3f09f06b-4991-4197-b5b6-e78de6a6d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-1b8df905-89bf-4371-8ea9-ba3013081d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-1c3aa4d9-b8ee-4f30-a3b7-f8b6b083f71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510818657-172.17.0.10-1598149802209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-a750b561-2edd-4217-ae8c-12b2400bce53,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-c0096d15-bec9-483f-8fa9-5bbeb65f8d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b6b28d27-d519-4575-824f-364613105ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-2fdc5464-23fc-4722-9b76-44e15e7fb6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a7464c1c-fd7b-422e-b405-b3f97d065a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-3f09f06b-4991-4197-b5b6-e78de6a6d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-1b8df905-89bf-4371-8ea9-ba3013081d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-1c3aa4d9-b8ee-4f30-a3b7-f8b6b083f71e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369523280-172.17.0.10-1598149925595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43711,DS-36ddc961-df30-43c9-90e3-eff467661ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-3f47ff4f-0401-47c1-9652-be03a650c35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-0a7c15ca-22b9-4001-80d0-123a5d5df224,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-7f4617e1-f29f-4fc2-965d-67ed958cfc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-723ac59f-4cfb-4696-826d-09f5736cb070,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-71ead48b-f273-4174-a8ae-96097e83b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-695dced8-578c-443e-89b6-424298f6c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-ced7b755-56a4-4919-a36b-1a8852bc3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369523280-172.17.0.10-1598149925595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43711,DS-36ddc961-df30-43c9-90e3-eff467661ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-3f47ff4f-0401-47c1-9652-be03a650c35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-0a7c15ca-22b9-4001-80d0-123a5d5df224,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-7f4617e1-f29f-4fc2-965d-67ed958cfc50,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-723ac59f-4cfb-4696-826d-09f5736cb070,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-71ead48b-f273-4174-a8ae-96097e83b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-695dced8-578c-443e-89b6-424298f6c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-ced7b755-56a4-4919-a36b-1a8852bc3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577443657-172.17.0.10-1598150350656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-c65fc8a4-27db-4002-9239-cfe232edf3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-bad0935c-bee4-4682-9f7d-3ca238a6ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-ef9d1a25-d866-43cb-8835-626aca6d9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-37a80a1d-a450-4b2d-992c-396275e275c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-cb401e09-fc9a-492c-8817-abf0b2128da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a0772d69-186c-49b7-afd1-1f5ac46d2568,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-13373a57-c771-4595-8d89-9b7c25a7701c,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-13d2c3d1-d6e4-4dd5-910d-4ee8f196109d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577443657-172.17.0.10-1598150350656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39810,DS-c65fc8a4-27db-4002-9239-cfe232edf3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-bad0935c-bee4-4682-9f7d-3ca238a6ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-ef9d1a25-d866-43cb-8835-626aca6d9a47,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-37a80a1d-a450-4b2d-992c-396275e275c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-cb401e09-fc9a-492c-8817-abf0b2128da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a0772d69-186c-49b7-afd1-1f5ac46d2568,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-13373a57-c771-4595-8d89-9b7c25a7701c,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-13d2c3d1-d6e4-4dd5-910d-4ee8f196109d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5126
