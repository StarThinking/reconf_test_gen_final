reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287040674-172.17.0.15-1598176074901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-11e02a0c-cc34-42c4-b5be-62c545863964,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-90e5f9bf-6de7-40ce-b3d1-f2762e8eeadc,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-a2d2d232-f72a-47a2-a5ed-8ed995c7c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-ccc8dfb8-2d04-4127-bbc5-3d1d206363a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-327277fe-5b20-40e4-acb1-a77a669af8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-47153648-4494-4105-8f99-35444578c7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-547416d2-f7c9-45b9-8a37-59acd24082db,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-9e14e2c9-c4bb-45a5-bc42-6582d4e4f5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287040674-172.17.0.15-1598176074901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-11e02a0c-cc34-42c4-b5be-62c545863964,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-90e5f9bf-6de7-40ce-b3d1-f2762e8eeadc,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-a2d2d232-f72a-47a2-a5ed-8ed995c7c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-ccc8dfb8-2d04-4127-bbc5-3d1d206363a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-327277fe-5b20-40e4-acb1-a77a669af8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-47153648-4494-4105-8f99-35444578c7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-547416d2-f7c9-45b9-8a37-59acd24082db,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-9e14e2c9-c4bb-45a5-bc42-6582d4e4f5cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871537185-172.17.0.15-1598176115298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-c6fe11ea-3aef-47a8-aba8-0d5305df121f,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-d66c0d6f-9f10-4439-ade0-bbafe44971ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-2c6849a2-030a-485b-8c19-6202ac678dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-87bd3fe5-eae0-45e2-9c43-f532c3c50fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b22a014e-fd74-4513-bbac-f840681a9718,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-0875313b-b1ed-4da1-bb53-90e85d0a1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ede3d6a4-d740-4b27-b313-884a80bb13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-146d4b5b-5fb0-444f-9c20-6af22d51ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871537185-172.17.0.15-1598176115298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-c6fe11ea-3aef-47a8-aba8-0d5305df121f,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-d66c0d6f-9f10-4439-ade0-bbafe44971ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-2c6849a2-030a-485b-8c19-6202ac678dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-87bd3fe5-eae0-45e2-9c43-f532c3c50fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b22a014e-fd74-4513-bbac-f840681a9718,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-0875313b-b1ed-4da1-bb53-90e85d0a1c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ede3d6a4-d740-4b27-b313-884a80bb13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-146d4b5b-5fb0-444f-9c20-6af22d51ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136018753-172.17.0.15-1598176388699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-e3e80a26-c283-468f-a09f-fc704d4af311,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-5c0cbf4b-8eb1-4b2e-a06e-96b6c002e20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-25a38550-fb8c-40cc-8e86-0a665b47785e,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-81a2da11-dc31-4adf-a732-9b6f89336213,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-4e11535a-72e4-4b90-befc-b7c867639ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-8faca90c-511e-424b-9965-69a648e00aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-c90c0683-bfee-464a-99dc-01c40adc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-4cdeacbc-01f2-4aaf-b128-512535b3bfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136018753-172.17.0.15-1598176388699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-e3e80a26-c283-468f-a09f-fc704d4af311,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-5c0cbf4b-8eb1-4b2e-a06e-96b6c002e20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-25a38550-fb8c-40cc-8e86-0a665b47785e,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-81a2da11-dc31-4adf-a732-9b6f89336213,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-4e11535a-72e4-4b90-befc-b7c867639ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-8faca90c-511e-424b-9965-69a648e00aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-c90c0683-bfee-464a-99dc-01c40adc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-4cdeacbc-01f2-4aaf-b128-512535b3bfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645775655-172.17.0.15-1598176496500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-1efac988-6d57-4f69-a329-f970b62b9651,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d59095c0-32db-4984-a533-32a6449b8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-2d14b405-4f72-4fe9-8999-df36839a0b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-c189ef4f-ef20-435b-830c-f99cf036fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-e73af146-cfbb-4e9c-b346-2904bd09761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-cc739275-3b91-45b2-92fb-d3ce11566cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-86c393d2-c246-4fd1-becd-af96c6bd6579,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-ca82d513-adbd-4120-8d9c-3148f76c87f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645775655-172.17.0.15-1598176496500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-1efac988-6d57-4f69-a329-f970b62b9651,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d59095c0-32db-4984-a533-32a6449b8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-2d14b405-4f72-4fe9-8999-df36839a0b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-c189ef4f-ef20-435b-830c-f99cf036fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-e73af146-cfbb-4e9c-b346-2904bd09761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-cc739275-3b91-45b2-92fb-d3ce11566cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-86c393d2-c246-4fd1-becd-af96c6bd6579,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-ca82d513-adbd-4120-8d9c-3148f76c87f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066685689-172.17.0.15-1598177668327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-c5ba219d-1bf0-49f0-87df-9448e12aadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-7b7559a6-b406-4e1d-87f1-6b657369ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-3c95e021-64a1-44e9-8356-13752d70b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-2c1b66a5-57d7-4f1d-89b7-2bf1a5585274,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-3f96d6d4-cc53-45ea-b442-a7da915fe05c,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d087d3dc-815b-46d9-ac52-80b10c79dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-f519c8ad-6c8d-4f0e-8276-37fbeac0a605,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-44e1cb9d-212d-475c-925f-82ba4c8c894a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066685689-172.17.0.15-1598177668327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-c5ba219d-1bf0-49f0-87df-9448e12aadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-7b7559a6-b406-4e1d-87f1-6b657369ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-3c95e021-64a1-44e9-8356-13752d70b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-2c1b66a5-57d7-4f1d-89b7-2bf1a5585274,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-3f96d6d4-cc53-45ea-b442-a7da915fe05c,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-d087d3dc-815b-46d9-ac52-80b10c79dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-f519c8ad-6c8d-4f0e-8276-37fbeac0a605,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-44e1cb9d-212d-475c-925f-82ba4c8c894a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138410559-172.17.0.15-1598177896175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-02ae901a-f80e-4bd4-9178-310aa6c3ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-2809722f-e3a0-48d7-92ea-a52ecde4fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-299008ec-3e1f-4c94-a24e-241856f0787e,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-fae9b5d3-b832-4098-a05b-27ad50402df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-24674e18-dcaa-4164-86b4-3749a3ed8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-0c61fc3b-3b97-4c7a-96f9-91ff2dbb2e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-b7c4651f-8e52-45c8-9864-33afbd391e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-eb7853d4-1be2-4d52-bb80-2f7fe4ec7a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138410559-172.17.0.15-1598177896175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-02ae901a-f80e-4bd4-9178-310aa6c3ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-2809722f-e3a0-48d7-92ea-a52ecde4fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-299008ec-3e1f-4c94-a24e-241856f0787e,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-fae9b5d3-b832-4098-a05b-27ad50402df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-24674e18-dcaa-4164-86b4-3749a3ed8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-0c61fc3b-3b97-4c7a-96f9-91ff2dbb2e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-b7c4651f-8e52-45c8-9864-33afbd391e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-eb7853d4-1be2-4d52-bb80-2f7fe4ec7a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030203787-172.17.0.15-1598177933766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-25263903-ce14-45ec-8882-d484073704a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-5aed0ed0-0da0-4f71-a7cd-5f93bd22d802,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-155cdd2b-0302-4e60-b18e-f1feae88fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-9c8fc699-f360-4b7b-b476-23ad508a8789,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9452e1e2-4594-4ec4-b900-6ef835138e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-5cb38df0-6fdc-4605-99f2-b134cef92ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-c70cbf19-976f-4319-8601-29145cb6e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-86e52dea-6ef2-44d4-b23a-ab0dfffa922c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030203787-172.17.0.15-1598177933766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39678,DS-25263903-ce14-45ec-8882-d484073704a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-5aed0ed0-0da0-4f71-a7cd-5f93bd22d802,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-155cdd2b-0302-4e60-b18e-f1feae88fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-9c8fc699-f360-4b7b-b476-23ad508a8789,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9452e1e2-4594-4ec4-b900-6ef835138e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-5cb38df0-6fdc-4605-99f2-b134cef92ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-c70cbf19-976f-4319-8601-29145cb6e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-86e52dea-6ef2-44d4-b23a-ab0dfffa922c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682270397-172.17.0.15-1598178201979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-8453b3fc-c080-467b-9818-62b256f4dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-38146ac6-186f-471d-a0b4-135f3602e664,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-0fdab7b8-25f2-4eef-b234-4718d9280f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-1f5d00cc-c701-4592-b857-6f2820a81bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-97ba6f44-18cf-4a32-bad6-1919f507076e,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-a8eff472-773f-4401-b88f-6eb991947f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-5437fc47-e844-4847-96f0-a066846d7437,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-f4a95666-b983-4f11-a3cc-3153642882f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682270397-172.17.0.15-1598178201979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-8453b3fc-c080-467b-9818-62b256f4dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-38146ac6-186f-471d-a0b4-135f3602e664,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-0fdab7b8-25f2-4eef-b234-4718d9280f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-1f5d00cc-c701-4592-b857-6f2820a81bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-97ba6f44-18cf-4a32-bad6-1919f507076e,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-a8eff472-773f-4401-b88f-6eb991947f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-5437fc47-e844-4847-96f0-a066846d7437,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-f4a95666-b983-4f11-a3cc-3153642882f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181782456-172.17.0.15-1598178379929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-3e914b4d-54b4-47d6-a9c1-2ad10bda5f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-aa206d4a-7972-455e-9904-437ff3390ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-8f7dbc70-35c0-4056-970d-0c705796815b,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-56e36c6b-3352-468c-b651-c9799127793b,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-5de7a285-2ba1-4abc-8a90-f4b176db224f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b504280e-3a94-4dfe-aa40-893cb38c5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-4e92ff26-21ad-4683-894e-f42feb8ba933,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-b3785c8f-c95f-4d2a-b2e3-2d15d63d7f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181782456-172.17.0.15-1598178379929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-3e914b4d-54b4-47d6-a9c1-2ad10bda5f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-aa206d4a-7972-455e-9904-437ff3390ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-8f7dbc70-35c0-4056-970d-0c705796815b,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-56e36c6b-3352-468c-b651-c9799127793b,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-5de7a285-2ba1-4abc-8a90-f4b176db224f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b504280e-3a94-4dfe-aa40-893cb38c5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-4e92ff26-21ad-4683-894e-f42feb8ba933,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-b3785c8f-c95f-4d2a-b2e3-2d15d63d7f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051004987-172.17.0.15-1598178502383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38574,DS-010c4a24-b2ac-4083-a467-3ca7a65ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-98359584-5122-44f7-8bba-b71be2a1d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9788af31-aa52-453e-8b3b-3942ba74bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-098844ca-c68e-4628-af2d-f57cd60993a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-c1ee3210-f70d-4c7e-a71c-0ccf4a0d4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-184440c7-5822-4ef7-b166-c2d428e44d20,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-54342e70-8e65-41c2-8799-78af0d6b2e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-680f53a0-8bbf-4d66-a268-f6f51e5460f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051004987-172.17.0.15-1598178502383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38574,DS-010c4a24-b2ac-4083-a467-3ca7a65ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-98359584-5122-44f7-8bba-b71be2a1d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9788af31-aa52-453e-8b3b-3942ba74bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-098844ca-c68e-4628-af2d-f57cd60993a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-c1ee3210-f70d-4c7e-a71c-0ccf4a0d4c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-184440c7-5822-4ef7-b166-c2d428e44d20,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-54342e70-8e65-41c2-8799-78af0d6b2e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-680f53a0-8bbf-4d66-a268-f6f51e5460f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909791996-172.17.0.15-1598178607002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-9663aaa9-335f-4ca6-b977-3a66845d4298,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-73ae56a4-d5e4-4a94-917d-527db17a3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b7264660-2fc6-4e7f-9d3b-bf739c58d158,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-0a22da4c-b512-4fd6-9ece-b7158c5528db,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-fc4f1387-f2c3-4615-b737-32a94e94273d,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-972a3de9-c1c8-4052-8aea-c7bd7e21f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-81e856bb-244b-4afb-b82a-03be99f99134,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-af085e76-09c2-4a29-b5e3-8db9202916ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909791996-172.17.0.15-1598178607002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-9663aaa9-335f-4ca6-b977-3a66845d4298,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-73ae56a4-d5e4-4a94-917d-527db17a3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b7264660-2fc6-4e7f-9d3b-bf739c58d158,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-0a22da4c-b512-4fd6-9ece-b7158c5528db,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-fc4f1387-f2c3-4615-b737-32a94e94273d,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-972a3de9-c1c8-4052-8aea-c7bd7e21f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-81e856bb-244b-4afb-b82a-03be99f99134,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-af085e76-09c2-4a29-b5e3-8db9202916ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095831129-172.17.0.15-1598178637643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-8e201564-622a-4dfc-9b99-3cb81f3b3d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-0a6393cc-f7c3-48f2-9972-f0dffe667a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2a512a2a-f501-4a6a-a1a9-ae1d2e155ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-1a1f19e4-b493-44a4-a22c-a7084498c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-e096769a-2d4a-471a-92ee-07e1b6e53185,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6dfbc6b2-0637-4edb-ac0a-d0d84552883d,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-3412784a-5ef3-463f-b827-00a412182339,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-209252a8-5200-4d4e-aef6-5e2fbc648f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095831129-172.17.0.15-1598178637643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-8e201564-622a-4dfc-9b99-3cb81f3b3d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-0a6393cc-f7c3-48f2-9972-f0dffe667a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-2a512a2a-f501-4a6a-a1a9-ae1d2e155ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-1a1f19e4-b493-44a4-a22c-a7084498c1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-e096769a-2d4a-471a-92ee-07e1b6e53185,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-6dfbc6b2-0637-4edb-ac0a-d0d84552883d,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-3412784a-5ef3-463f-b827-00a412182339,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-209252a8-5200-4d4e-aef6-5e2fbc648f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746119985-172.17.0.15-1598178744277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-c168adac-391f-491c-91ef-d72648ccef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-31c47f2c-5602-4fe0-bfb9-5b660163b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-327bc15c-84af-4430-ab8a-89a9762b94b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9f581488-ca1a-44cb-ac22-71f386d7ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-ef38e309-67c8-44df-9bd4-9b8d5b0176ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-606b8b51-bb71-4621-8b6d-10a9ad188908,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-6d31a861-81ba-4f0a-b27d-11c622cd338d,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-ece43322-326f-4417-9d53-19912341b659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746119985-172.17.0.15-1598178744277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-c168adac-391f-491c-91ef-d72648ccef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-31c47f2c-5602-4fe0-bfb9-5b660163b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-327bc15c-84af-4430-ab8a-89a9762b94b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9f581488-ca1a-44cb-ac22-71f386d7ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-ef38e309-67c8-44df-9bd4-9b8d5b0176ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-606b8b51-bb71-4621-8b6d-10a9ad188908,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-6d31a861-81ba-4f0a-b27d-11c622cd338d,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-ece43322-326f-4417-9d53-19912341b659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714830761-172.17.0.15-1598178805044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46002,DS-4042528c-6533-45ae-ae39-58f57b775040,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-d2d077b0-ee6b-47c9-8dd5-2ad13b9ed335,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-1b36badc-1272-42bb-aa2c-06c9d66b0681,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-6f62e25d-b625-440c-92d3-1a2eaead2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-ba89b20c-4703-4b29-8004-7e66bf4cff28,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-2fb419cf-9e9b-42b7-9420-c38d8b802ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-07e515ac-6e38-43e9-841e-cefc10fa850a,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-318ff743-cf9c-4f25-81a9-cc13d6527e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714830761-172.17.0.15-1598178805044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46002,DS-4042528c-6533-45ae-ae39-58f57b775040,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-d2d077b0-ee6b-47c9-8dd5-2ad13b9ed335,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-1b36badc-1272-42bb-aa2c-06c9d66b0681,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-6f62e25d-b625-440c-92d3-1a2eaead2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-ba89b20c-4703-4b29-8004-7e66bf4cff28,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-2fb419cf-9e9b-42b7-9420-c38d8b802ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-07e515ac-6e38-43e9-841e-cefc10fa850a,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-318ff743-cf9c-4f25-81a9-cc13d6527e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755110513-172.17.0.15-1598179116324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-b5e8d2a8-16b9-4dbc-9683-7e3f0e10a285,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-d98964c2-9c20-4570-b906-6a193a86a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-c073b27f-21c5-4e60-9bea-60f8ab99515b,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-60a877e7-f118-4fe8-bf65-ef3ebbbb402b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-1fcd1aad-dffc-43b6-82b2-5089bc4b08e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-6a6c2e80-afd1-4869-b98f-81078c4dd951,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-3db73d3e-d96a-407e-b8d8-adeb69cabe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-5c48d325-fbc4-466f-baed-1ace2fecbe1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755110513-172.17.0.15-1598179116324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-b5e8d2a8-16b9-4dbc-9683-7e3f0e10a285,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-d98964c2-9c20-4570-b906-6a193a86a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-c073b27f-21c5-4e60-9bea-60f8ab99515b,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-60a877e7-f118-4fe8-bf65-ef3ebbbb402b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-1fcd1aad-dffc-43b6-82b2-5089bc4b08e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-6a6c2e80-afd1-4869-b98f-81078c4dd951,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-3db73d3e-d96a-407e-b8d8-adeb69cabe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-5c48d325-fbc4-466f-baed-1ace2fecbe1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029030429-172.17.0.15-1598179292013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-28664881-196a-4f84-a575-433e3d6619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-eaee3698-dcfb-4405-9be6-bcba1632174f,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d750573e-2456-4540-9a8b-45e2100a3289,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-a2e661c1-8094-4bd8-a43f-f5f63558d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-fbee2bc8-0521-4e27-bf57-fe927094cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-37c181e2-0a82-47e2-8119-a06786f98f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-4b24dc76-6485-40ec-a057-9a9ad4b8b72f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8e476a49-85a3-407d-b3a3-3e808ad993af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029030429-172.17.0.15-1598179292013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-28664881-196a-4f84-a575-433e3d6619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-eaee3698-dcfb-4405-9be6-bcba1632174f,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-d750573e-2456-4540-9a8b-45e2100a3289,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-a2e661c1-8094-4bd8-a43f-f5f63558d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-fbee2bc8-0521-4e27-bf57-fe927094cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-37c181e2-0a82-47e2-8119-a06786f98f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-4b24dc76-6485-40ec-a057-9a9ad4b8b72f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8e476a49-85a3-407d-b3a3-3e808ad993af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119154371-172.17.0.15-1598179479297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41092,DS-6aff6ca9-3a58-4109-9b2c-d10c76b17afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d8f5de95-7d98-4c46-9ce5-96c08fa55bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-574c49d8-dec9-4de8-ada0-65926221ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-3117a030-f44e-4839-abfc-5d40d85d7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-953547e6-90ba-4436-b170-f94dee8f3d80,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-803f2aba-0851-4c29-9601-55b515645dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-e539641e-364b-437d-90b6-5fd1e7053fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-dc4445fd-fa94-4c16-b67a-f2cbcc1b602d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119154371-172.17.0.15-1598179479297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41092,DS-6aff6ca9-3a58-4109-9b2c-d10c76b17afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d8f5de95-7d98-4c46-9ce5-96c08fa55bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-574c49d8-dec9-4de8-ada0-65926221ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-3117a030-f44e-4839-abfc-5d40d85d7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-953547e6-90ba-4436-b170-f94dee8f3d80,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-803f2aba-0851-4c29-9601-55b515645dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-e539641e-364b-437d-90b6-5fd1e7053fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-dc4445fd-fa94-4c16-b67a-f2cbcc1b602d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644579314-172.17.0.15-1598179821716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-525b4af5-1b5d-46e1-9bc5-1a4a7b16f064,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7bcbf297-42b8-4ba2-8bd7-0f6b67edc7be,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-c0e11e03-64e9-4ada-8eeb-760c5bfcfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-cc7b085d-ae98-4407-9daf-daf551b85155,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-e7547eb7-cf0f-40b8-bc13-171655eef2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-fddf0cda-0884-4e64-91cd-d8378376767e,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-c3ac3981-6956-43de-aa1f-70809b9d2609,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d5fd7f41-33ef-44b3-a85a-7eea4d39d0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644579314-172.17.0.15-1598179821716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-525b4af5-1b5d-46e1-9bc5-1a4a7b16f064,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7bcbf297-42b8-4ba2-8bd7-0f6b67edc7be,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-c0e11e03-64e9-4ada-8eeb-760c5bfcfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-cc7b085d-ae98-4407-9daf-daf551b85155,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-e7547eb7-cf0f-40b8-bc13-171655eef2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-fddf0cda-0884-4e64-91cd-d8378376767e,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-c3ac3981-6956-43de-aa1f-70809b9d2609,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d5fd7f41-33ef-44b3-a85a-7eea4d39d0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065112248-172.17.0.15-1598180194991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-4642608f-7fcc-40aa-9bb6-ff987af03557,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-7ec37e17-d651-43aa-9fc2-75a973ddfe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-f8663ce3-749a-4af3-9bb1-381d3b61a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-deb24d26-e745-469d-a841-85b6e5363623,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f239adef-ba20-4c43-a33c-553a82180352,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-b8b8f6e0-214a-408d-be14-7a0d54d8de3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-7b6b8e44-25cc-41de-8e41-181c03fd648e,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-231e3910-9564-4848-beab-b3cd78714c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065112248-172.17.0.15-1598180194991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-4642608f-7fcc-40aa-9bb6-ff987af03557,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-7ec37e17-d651-43aa-9fc2-75a973ddfe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-f8663ce3-749a-4af3-9bb1-381d3b61a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-deb24d26-e745-469d-a841-85b6e5363623,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f239adef-ba20-4c43-a33c-553a82180352,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-b8b8f6e0-214a-408d-be14-7a0d54d8de3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-7b6b8e44-25cc-41de-8e41-181c03fd648e,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-231e3910-9564-4848-beab-b3cd78714c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5347
