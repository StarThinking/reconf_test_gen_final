reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493024605-172.17.0.17-1598370013252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-71faebec-aae2-46c1-b00f-0dd5779e1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-f64a082d-ce08-4724-89ab-8e4748e62a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-21aa7e9f-8148-4ee3-b0f9-9b751d5d44f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-2129de82-3c38-40b8-9a04-3f33e00939f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-26a6a718-6930-4af7-9830-cbcb042619d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-459b0d12-26e2-4903-b77a-b8b39f1ddfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-b44bc96d-52a9-4e18-8ce4-c72ecd2e99d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-776c645d-2b45-4943-8458-3974acf16065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493024605-172.17.0.17-1598370013252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-71faebec-aae2-46c1-b00f-0dd5779e1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-f64a082d-ce08-4724-89ab-8e4748e62a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-21aa7e9f-8148-4ee3-b0f9-9b751d5d44f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-2129de82-3c38-40b8-9a04-3f33e00939f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-26a6a718-6930-4af7-9830-cbcb042619d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-459b0d12-26e2-4903-b77a-b8b39f1ddfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-b44bc96d-52a9-4e18-8ce4-c72ecd2e99d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-776c645d-2b45-4943-8458-3974acf16065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273991903-172.17.0.17-1598370281909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-d82dd937-f607-4c90-b106-b9f4f5137437,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-c9198f76-c60e-46e4-85ec-d457804e9ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-73fbc03f-5272-4572-ba9b-a35f8c51fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-1e1a5d5e-15ff-4be1-b96f-13a463cd0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-15b5bda6-5c5f-4de1-b3fd-5a73f1b2972b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-8f4aa966-2be6-40f0-a1c1-55da51904dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-edeb78c3-87f1-4b26-bea6-1e1154387c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-98c01060-0cad-4b3f-a1a4-23e924253624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273991903-172.17.0.17-1598370281909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-d82dd937-f607-4c90-b106-b9f4f5137437,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-c9198f76-c60e-46e4-85ec-d457804e9ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-73fbc03f-5272-4572-ba9b-a35f8c51fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-1e1a5d5e-15ff-4be1-b96f-13a463cd0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-15b5bda6-5c5f-4de1-b3fd-5a73f1b2972b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-8f4aa966-2be6-40f0-a1c1-55da51904dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-edeb78c3-87f1-4b26-bea6-1e1154387c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-98c01060-0cad-4b3f-a1a4-23e924253624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322609331-172.17.0.17-1598370454884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40149,DS-c815c674-937f-4fe9-a5ba-7d82320adfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-cb6ce1be-3dc6-498e-a2ba-c1cbf5515e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-ed7ca2f3-a6ed-4bcc-9839-2586b76aba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-2ae0c32d-c6e9-4175-9329-6f82b28f85cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-34070153-d4a8-453e-b604-eece2fe30bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-d6389e79-e180-49ea-83af-7969b3b7af34,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-05894394-28c2-4b0a-a9d4-cad676610d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-225cc90f-c60d-41f7-b805-8ec585dfc880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322609331-172.17.0.17-1598370454884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40149,DS-c815c674-937f-4fe9-a5ba-7d82320adfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-cb6ce1be-3dc6-498e-a2ba-c1cbf5515e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-ed7ca2f3-a6ed-4bcc-9839-2586b76aba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-2ae0c32d-c6e9-4175-9329-6f82b28f85cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-34070153-d4a8-453e-b604-eece2fe30bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-d6389e79-e180-49ea-83af-7969b3b7af34,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-05894394-28c2-4b0a-a9d4-cad676610d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-225cc90f-c60d-41f7-b805-8ec585dfc880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670394622-172.17.0.17-1598370674995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42957,DS-6d2fb48d-8d9f-4c70-8ffe-0bcd5dd2d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-35062a48-3871-40b8-8a60-fd9586bffbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-ff357cf9-0e1d-4135-a149-e8df93db41e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-a06c5ae4-04d7-416e-bca8-61a162761ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-d727392b-c116-434b-b0fd-02c3cc4c7e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-3014fdac-42d2-43f9-bce6-73ab74bfbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-2f4c57b3-80b8-4f52-8e51-6e577ec3a632,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-ad73cccc-6df9-4f8e-a5cf-583df8b8e769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670394622-172.17.0.17-1598370674995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42957,DS-6d2fb48d-8d9f-4c70-8ffe-0bcd5dd2d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-35062a48-3871-40b8-8a60-fd9586bffbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-ff357cf9-0e1d-4135-a149-e8df93db41e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-a06c5ae4-04d7-416e-bca8-61a162761ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-d727392b-c116-434b-b0fd-02c3cc4c7e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-3014fdac-42d2-43f9-bce6-73ab74bfbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-2f4c57b3-80b8-4f52-8e51-6e577ec3a632,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-ad73cccc-6df9-4f8e-a5cf-583df8b8e769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736338124-172.17.0.17-1598370712054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-8fcb3f8f-6e84-46b6-b110-e1741b898d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-2dfa260e-dba2-407d-9515-dda01ba31f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-c6652b96-637f-40f9-8877-c349f4e86742,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-bea0eb38-7008-4eab-ac37-4b9f5696e942,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-9d2de761-dad1-4bc4-9783-fe784406408e,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-21c03fd5-f6b2-46e6-bdc8-6012e5ca742b,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-57903098-0370-441c-9ce6-71774ec715fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a41f1460-1d63-4464-831d-d07e650f0609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736338124-172.17.0.17-1598370712054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-8fcb3f8f-6e84-46b6-b110-e1741b898d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-2dfa260e-dba2-407d-9515-dda01ba31f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-c6652b96-637f-40f9-8877-c349f4e86742,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-bea0eb38-7008-4eab-ac37-4b9f5696e942,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-9d2de761-dad1-4bc4-9783-fe784406408e,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-21c03fd5-f6b2-46e6-bdc8-6012e5ca742b,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-57903098-0370-441c-9ce6-71774ec715fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-a41f1460-1d63-4464-831d-d07e650f0609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243391502-172.17.0.17-1598371094907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-214a192f-6bab-4531-a320-83b06b010f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-392eab15-ee6e-4365-9b17-0cb0d9137e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-f94feaf2-4266-45e4-8ac4-d3767a4407bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-7611edb5-9ddb-44f9-a6e0-c818f96c6c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-a2c478ee-3f56-4d70-ac4c-801348315436,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-dc8c15c5-b686-48c0-8d8d-965b6fac0108,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-095c8f31-b538-4020-a8fa-9e0001ab4efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-00b00bf3-8c8e-4c4b-8541-53ced6c1d151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243391502-172.17.0.17-1598371094907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-214a192f-6bab-4531-a320-83b06b010f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-392eab15-ee6e-4365-9b17-0cb0d9137e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-f94feaf2-4266-45e4-8ac4-d3767a4407bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-7611edb5-9ddb-44f9-a6e0-c818f96c6c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-a2c478ee-3f56-4d70-ac4c-801348315436,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-dc8c15c5-b686-48c0-8d8d-965b6fac0108,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-095c8f31-b538-4020-a8fa-9e0001ab4efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-00b00bf3-8c8e-4c4b-8541-53ced6c1d151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843661981-172.17.0.17-1598371326014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-5442add9-1417-4973-a425-aae5ed174b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-7be59868-255d-42ae-8d53-e6b65091f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-7b4ac55a-d285-4ad8-9096-03c78ca49592,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-37d079ba-d1fa-40a3-877f-f80b61cae62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-467a7e23-358c-41e0-ab32-d026ae9f4b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-b5df219a-c97b-4cfd-bbcf-18baa1cd7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-9c741ec4-0ac7-4c63-a8d3-bcc3164f512f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-fe72a4f1-1a21-43e7-a430-af0662f58423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843661981-172.17.0.17-1598371326014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-5442add9-1417-4973-a425-aae5ed174b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-7be59868-255d-42ae-8d53-e6b65091f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-7b4ac55a-d285-4ad8-9096-03c78ca49592,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-37d079ba-d1fa-40a3-877f-f80b61cae62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-467a7e23-358c-41e0-ab32-d026ae9f4b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-b5df219a-c97b-4cfd-bbcf-18baa1cd7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-9c741ec4-0ac7-4c63-a8d3-bcc3164f512f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-fe72a4f1-1a21-43e7-a430-af0662f58423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913642873-172.17.0.17-1598371681212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41037,DS-6878b6bf-089b-472b-83dd-d24972be4943,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-5a4534c7-7846-4ca7-99a1-d85b591892d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-3fc4a2e4-3ad3-431b-b73f-50d7ce7cf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-4f10945f-4c77-4a12-9e3b-c0f96c8cf66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-f0776443-2f76-40e5-9ab9-2fd2f8129bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-ac0a648d-61a3-4c44-8dce-bd8681217ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-520f901b-660b-431e-99b8-01e43e95f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-188d27d3-fc63-4dde-b34f-b58fc40ebcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913642873-172.17.0.17-1598371681212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41037,DS-6878b6bf-089b-472b-83dd-d24972be4943,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-5a4534c7-7846-4ca7-99a1-d85b591892d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-3fc4a2e4-3ad3-431b-b73f-50d7ce7cf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-4f10945f-4c77-4a12-9e3b-c0f96c8cf66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-f0776443-2f76-40e5-9ab9-2fd2f8129bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-ac0a648d-61a3-4c44-8dce-bd8681217ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-520f901b-660b-431e-99b8-01e43e95f03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-188d27d3-fc63-4dde-b34f-b58fc40ebcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997350985-172.17.0.17-1598371900788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-f483cdda-5e5b-441c-ae58-77e502736608,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-5e47976e-12c5-4fc8-812e-ff47df79d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-eabaabb5-25ee-447f-9450-c3b143ee2511,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e0c00195-7ff2-4d47-a17c-5e1a3ae40c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-128c5bde-3c77-4141-8898-581a062e5179,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-0fbf7288-804c-4267-9a20-7275b7df96a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-bdc4fb67-4468-4d8c-b7aa-3164fc5bab25,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-af752dfb-4bf5-4bab-aa40-2afa9048756b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997350985-172.17.0.17-1598371900788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-f483cdda-5e5b-441c-ae58-77e502736608,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-5e47976e-12c5-4fc8-812e-ff47df79d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-eabaabb5-25ee-447f-9450-c3b143ee2511,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e0c00195-7ff2-4d47-a17c-5e1a3ae40c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-128c5bde-3c77-4141-8898-581a062e5179,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-0fbf7288-804c-4267-9a20-7275b7df96a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-bdc4fb67-4468-4d8c-b7aa-3164fc5bab25,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-af752dfb-4bf5-4bab-aa40-2afa9048756b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307428307-172.17.0.17-1598372197303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-7297ce85-d510-4af7-913e-ab301b7ca250,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0a1961f3-d60b-4a27-a41b-9ab64b6ddb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-7ee5578f-18e0-4bc8-83ca-3c156d8b0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-14418f0f-1d78-42b4-8311-86ccf8f144cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-539c5b83-8c92-44d5-a326-bb1ac7a2fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-fd1e79c5-73db-44d6-bdfc-b63f9567cee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-d71fc2f2-f64c-40aa-99ec-6616721576ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-71b580e0-03a9-4076-8758-3f3b12066d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307428307-172.17.0.17-1598372197303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-7297ce85-d510-4af7-913e-ab301b7ca250,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0a1961f3-d60b-4a27-a41b-9ab64b6ddb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-7ee5578f-18e0-4bc8-83ca-3c156d8b0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-14418f0f-1d78-42b4-8311-86ccf8f144cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-539c5b83-8c92-44d5-a326-bb1ac7a2fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-fd1e79c5-73db-44d6-bdfc-b63f9567cee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-d71fc2f2-f64c-40aa-99ec-6616721576ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-71b580e0-03a9-4076-8758-3f3b12066d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770100688-172.17.0.17-1598372308279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-5f03949b-2b4e-4fbe-ba45-1aafb4d70fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-daca8d69-64cd-4da3-989f-ba9f2409118d,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-4ead57f3-5c87-4918-851a-6de1b29d0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-703feff7-7ec3-46d7-b7be-a7a37463f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-b861ecd7-6346-432f-8634-713420707b23,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-cd354520-c674-41aa-8a27-2006ef463a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-2f95f507-b592-4e2f-9701-72e8888dba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-20bb1a34-16b4-48e7-9913-9bb7afa59da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770100688-172.17.0.17-1598372308279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-5f03949b-2b4e-4fbe-ba45-1aafb4d70fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-daca8d69-64cd-4da3-989f-ba9f2409118d,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-4ead57f3-5c87-4918-851a-6de1b29d0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-703feff7-7ec3-46d7-b7be-a7a37463f5af,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-b861ecd7-6346-432f-8634-713420707b23,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-cd354520-c674-41aa-8a27-2006ef463a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-2f95f507-b592-4e2f-9701-72e8888dba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-20bb1a34-16b4-48e7-9913-9bb7afa59da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666536434-172.17.0.17-1598372663783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-cdaa3816-d8dc-4103-b968-d998f244f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-829a5ecf-615b-45db-a906-98de9fa74c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-0f2bcad6-d472-48de-aed2-dd94ee44b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-b26c9ee0-c5b5-4495-a905-865bc0aa5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-11de1bc1-b505-49a3-b569-79d2ea87a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-97dfe0ae-0aa6-46bd-8fff-e41171b41fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-582d51ec-fa1b-409e-8cd1-6f3075634e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-99aab7fe-6f29-4972-b09c-d5a3f01c24a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666536434-172.17.0.17-1598372663783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33555,DS-cdaa3816-d8dc-4103-b968-d998f244f34c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-829a5ecf-615b-45db-a906-98de9fa74c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-0f2bcad6-d472-48de-aed2-dd94ee44b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-b26c9ee0-c5b5-4495-a905-865bc0aa5e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-11de1bc1-b505-49a3-b569-79d2ea87a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-97dfe0ae-0aa6-46bd-8fff-e41171b41fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-582d51ec-fa1b-409e-8cd1-6f3075634e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-99aab7fe-6f29-4972-b09c-d5a3f01c24a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697103989-172.17.0.17-1598373208063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36585,DS-ff358393-86c4-4d53-95b1-b78830924960,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-da4e0f0f-892c-4da2-938d-eed104692fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-7977ff2b-8575-4f12-be52-14a00e8b5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-337b030b-b536-4dbf-82f5-1a39c93f6775,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-31a77e1a-c447-49e0-ac6e-81117e4b7112,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c9aa46ae-0929-458f-90b0-a5394edafb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-6bd4d4a6-5a6c-424d-b443-d3bf42517a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-dbf87015-c0a0-4991-874b-87cec364c179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697103989-172.17.0.17-1598373208063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36585,DS-ff358393-86c4-4d53-95b1-b78830924960,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-da4e0f0f-892c-4da2-938d-eed104692fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-7977ff2b-8575-4f12-be52-14a00e8b5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-337b030b-b536-4dbf-82f5-1a39c93f6775,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-31a77e1a-c447-49e0-ac6e-81117e4b7112,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c9aa46ae-0929-458f-90b0-a5394edafb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-6bd4d4a6-5a6c-424d-b443-d3bf42517a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-dbf87015-c0a0-4991-874b-87cec364c179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964077907-172.17.0.17-1598373493654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-9ae5d8fb-e513-4c13-b77c-3f20c88bc954,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f241ec5b-b80c-47e8-8c61-7ee1dc87ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-5ffd2772-2d2b-4bca-96a0-59d08242ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-a68eb33b-75c4-4a55-a14a-9045a1f17cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-77de6c3d-3b22-41ad-a23d-1d7dd118a737,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-d497a31e-e9aa-4a81-afd9-80cdc17f3624,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-fd0f9bd4-59c0-4631-aa1f-4c5d83dcdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-b87eb130-92dc-4de0-874c-e1e100b709fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964077907-172.17.0.17-1598373493654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-9ae5d8fb-e513-4c13-b77c-3f20c88bc954,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f241ec5b-b80c-47e8-8c61-7ee1dc87ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-5ffd2772-2d2b-4bca-96a0-59d08242ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-a68eb33b-75c4-4a55-a14a-9045a1f17cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-77de6c3d-3b22-41ad-a23d-1d7dd118a737,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-d497a31e-e9aa-4a81-afd9-80cdc17f3624,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-fd0f9bd4-59c0-4631-aa1f-4c5d83dcdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-b87eb130-92dc-4de0-874c-e1e100b709fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929519113-172.17.0.17-1598373611123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34948,DS-486d8957-6622-486a-966a-50b90a95e489,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-425f4fde-2217-4618-b718-5adc9da08419,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-677bdf1f-9c4d-4ad7-bcf5-d9130e47ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-a4bd8e63-861f-4704-ab12-7069c37449d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-a8be8f4f-eae4-4748-943b-28ee5be39fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-be9b40f4-e69a-4253-b975-74ca07f0af44,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d854eade-9644-4e71-a9af-c4273b6d2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-1bcf1040-2fc3-4524-9837-38fbb217b701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929519113-172.17.0.17-1598373611123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34948,DS-486d8957-6622-486a-966a-50b90a95e489,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-425f4fde-2217-4618-b718-5adc9da08419,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-677bdf1f-9c4d-4ad7-bcf5-d9130e47ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-a4bd8e63-861f-4704-ab12-7069c37449d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-a8be8f4f-eae4-4748-943b-28ee5be39fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-be9b40f4-e69a-4253-b975-74ca07f0af44,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d854eade-9644-4e71-a9af-c4273b6d2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-1bcf1040-2fc3-4524-9837-38fbb217b701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602090676-172.17.0.17-1598374371637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-89e3af50-a960-4907-b723-4d56f1d77def,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-db651fc8-5e18-435c-94fe-ac3e972f64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-efa17a20-14ef-4bce-a974-6310569d725b,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6fdb495c-72d8-4bb0-8732-c55f90c18fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-154539d0-1b3e-4d17-8ed5-b0315da07670,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-49e2fdc1-590d-4570-a266-b2902a792642,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-f089aeb4-a90a-41da-b277-1fc5024ed990,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-017ec35f-34dd-41d7-bd43-0a2ad10f3603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602090676-172.17.0.17-1598374371637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39865,DS-89e3af50-a960-4907-b723-4d56f1d77def,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-db651fc8-5e18-435c-94fe-ac3e972f64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-efa17a20-14ef-4bce-a974-6310569d725b,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6fdb495c-72d8-4bb0-8732-c55f90c18fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-154539d0-1b3e-4d17-8ed5-b0315da07670,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-49e2fdc1-590d-4570-a266-b2902a792642,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-f089aeb4-a90a-41da-b277-1fc5024ed990,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-017ec35f-34dd-41d7-bd43-0a2ad10f3603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5572
