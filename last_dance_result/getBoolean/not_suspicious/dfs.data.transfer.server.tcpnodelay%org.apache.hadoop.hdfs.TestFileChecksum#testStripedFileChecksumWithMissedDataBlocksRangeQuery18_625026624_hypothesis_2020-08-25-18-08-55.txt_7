reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587752007-172.17.0.3-1598379521490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-7bd83685-34f0-4f15-8515-1b9bee51b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-5fdcf265-1dc7-4e7d-82ac-6068eadbffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-489c0f83-060d-43ab-8b94-0685c4dd7c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-3707eb77-4a12-4973-b055-f75981e2f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-ae5bdeea-d192-4ed0-b068-5838a61599e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-50b4881e-0448-4bb5-ab37-e2c2fefde419,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-12a4587d-5ba9-4f28-8c9a-026fe52589b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-78d44431-e16c-4048-851f-448ec2bd6f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587752007-172.17.0.3-1598379521490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-7bd83685-34f0-4f15-8515-1b9bee51b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-5fdcf265-1dc7-4e7d-82ac-6068eadbffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-489c0f83-060d-43ab-8b94-0685c4dd7c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-3707eb77-4a12-4973-b055-f75981e2f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-ae5bdeea-d192-4ed0-b068-5838a61599e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-50b4881e-0448-4bb5-ab37-e2c2fefde419,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-12a4587d-5ba9-4f28-8c9a-026fe52589b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-78d44431-e16c-4048-851f-448ec2bd6f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416904581-172.17.0.3-1598379556484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-1194f076-4152-4ab8-b0f8-b02d72a601f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-d043eb5a-ae78-401c-9906-1e68c038c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6fb0e1fe-56e5-4ad7-b480-68edbb0d8156,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-eb7ac6b6-5d0d-4559-bb32-dcd0742ac351,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-03d61d46-3d18-4b17-82e1-be3bb83d8f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-79e86f1a-6d6b-41ca-af55-e5d9165e5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-3080fbce-faf4-4274-acdd-334eb479f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2e618c4b-6725-4c81-99f4-9f5a3da1867a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416904581-172.17.0.3-1598379556484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-1194f076-4152-4ab8-b0f8-b02d72a601f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-d043eb5a-ae78-401c-9906-1e68c038c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-6fb0e1fe-56e5-4ad7-b480-68edbb0d8156,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-eb7ac6b6-5d0d-4559-bb32-dcd0742ac351,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-03d61d46-3d18-4b17-82e1-be3bb83d8f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-79e86f1a-6d6b-41ca-af55-e5d9165e5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-3080fbce-faf4-4274-acdd-334eb479f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2e618c4b-6725-4c81-99f4-9f5a3da1867a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605683385-172.17.0.3-1598379930519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-1f813fea-4581-4bee-ba0d-9dd09ce6e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-65ea4e50-d6eb-4022-983b-e68b398f803e,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-d2f5af27-d49c-4609-80f5-b5a5333362d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0a2c455f-5523-4e5e-8fde-f41e4b9f34a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fb57652e-7500-4a7d-b7e6-24aa5c26abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-20375f8d-144f-4e18-bf7d-c818e531d029,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-53b8b100-939b-49d7-bae6-5a01b7c4f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f62ec86b-6405-46ed-bb69-043a0cb7ecbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-605683385-172.17.0.3-1598379930519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-1f813fea-4581-4bee-ba0d-9dd09ce6e1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-65ea4e50-d6eb-4022-983b-e68b398f803e,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-d2f5af27-d49c-4609-80f5-b5a5333362d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-0a2c455f-5523-4e5e-8fde-f41e4b9f34a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fb57652e-7500-4a7d-b7e6-24aa5c26abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-20375f8d-144f-4e18-bf7d-c818e531d029,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-53b8b100-939b-49d7-bae6-5a01b7c4f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f62ec86b-6405-46ed-bb69-043a0cb7ecbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410772170-172.17.0.3-1598380036271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-10b1ccf3-ec0c-4e80-aa54-435f2956f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-5689081c-7aba-405a-b62d-0558aefc6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-89836a02-6257-402c-a7d4-9d483632b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-11c63fe8-8eff-4da4-9902-8cb9e1e81332,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2830a47d-e6a4-4808-b49a-22ffb7bad56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-15751f03-4494-41cf-b308-6b9a7a2df8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-d764b1da-a4b7-43f3-9672-686ed9f5eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cecb84c6-406c-4536-af3e-c31ccd772f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410772170-172.17.0.3-1598380036271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-10b1ccf3-ec0c-4e80-aa54-435f2956f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-5689081c-7aba-405a-b62d-0558aefc6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-89836a02-6257-402c-a7d4-9d483632b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-11c63fe8-8eff-4da4-9902-8cb9e1e81332,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-2830a47d-e6a4-4808-b49a-22ffb7bad56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-15751f03-4494-41cf-b308-6b9a7a2df8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-d764b1da-a4b7-43f3-9672-686ed9f5eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cecb84c6-406c-4536-af3e-c31ccd772f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861173834-172.17.0.3-1598380064901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44027,DS-e43c66d4-e706-42bb-977e-9e10af3da648,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-4ff82bd8-6f42-4dbb-b71a-ec05a091f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-48abf851-19f2-4b02-9771-7d92a321766a,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-90dc61ad-4cf7-49b9-a9dd-93942ef37685,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-c3c540da-cf59-4d40-9244-9da2c63da1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-4035b9c7-6fe0-4cda-87de-d95c80f6adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-271f649a-1f83-48e6-900f-2f1da5d92475,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-2936bdee-8914-4107-a9a1-6e172b5b804b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861173834-172.17.0.3-1598380064901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44027,DS-e43c66d4-e706-42bb-977e-9e10af3da648,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-4ff82bd8-6f42-4dbb-b71a-ec05a091f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-48abf851-19f2-4b02-9771-7d92a321766a,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-90dc61ad-4cf7-49b9-a9dd-93942ef37685,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-c3c540da-cf59-4d40-9244-9da2c63da1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-4035b9c7-6fe0-4cda-87de-d95c80f6adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-271f649a-1f83-48e6-900f-2f1da5d92475,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-2936bdee-8914-4107-a9a1-6e172b5b804b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406231773-172.17.0.3-1598380131818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33837,DS-9b6e73b4-a8b7-4b59-ac84-ca6d187031b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-38cc58c1-5d79-4caf-b4e6-629ff6cc1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-837b072f-8bd9-412e-87aa-8a756eeada89,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-389bd4c0-d173-442b-afc6-535099ffcc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-51022c71-59de-4e59-8f37-77c2c246381f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-8ff095fb-be43-41f9-b1f7-29b7afc95739,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-0c67e45c-5681-400a-8c96-8859ed936646,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-81553973-5f5e-4fc5-9356-9a7f573c2e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406231773-172.17.0.3-1598380131818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33837,DS-9b6e73b4-a8b7-4b59-ac84-ca6d187031b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-38cc58c1-5d79-4caf-b4e6-629ff6cc1a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-837b072f-8bd9-412e-87aa-8a756eeada89,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-389bd4c0-d173-442b-afc6-535099ffcc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-51022c71-59de-4e59-8f37-77c2c246381f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-8ff095fb-be43-41f9-b1f7-29b7afc95739,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-0c67e45c-5681-400a-8c96-8859ed936646,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-81553973-5f5e-4fc5-9356-9a7f573c2e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891007679-172.17.0.3-1598380647242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-2cb755f2-84cf-4f6c-9876-4d1876a6046f,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-50aa5693-9495-45cd-bf3e-2759545b515c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-4859f0fa-0c60-4efc-b237-8bea1f39cc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-129a63c3-ef75-4d79-b5b0-994c50068630,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-a76aaa96-aac8-414b-b1a8-58a0a8453476,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-2b0bd271-f7aa-4ee5-81de-e2b3745dcd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-3d0f0f29-b9ac-474b-aee0-6c3ce12a299d,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-2d9258e1-44e2-41f3-9220-e7e328ab67fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891007679-172.17.0.3-1598380647242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-2cb755f2-84cf-4f6c-9876-4d1876a6046f,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-50aa5693-9495-45cd-bf3e-2759545b515c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-4859f0fa-0c60-4efc-b237-8bea1f39cc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-129a63c3-ef75-4d79-b5b0-994c50068630,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-a76aaa96-aac8-414b-b1a8-58a0a8453476,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-2b0bd271-f7aa-4ee5-81de-e2b3745dcd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-3d0f0f29-b9ac-474b-aee0-6c3ce12a299d,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-2d9258e1-44e2-41f3-9220-e7e328ab67fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386613719-172.17.0.3-1598380851363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-c2691baa-4133-45ca-bb84-21891490f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-0bca475f-e166-43dc-9c1c-d4f25a082a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-6144b742-e523-4080-a055-a42b88df9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-cf19c96b-7255-4ce0-9747-2c983597ab27,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-e3019265-4666-47e7-a8fd-757814a19cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-2154e76d-afa4-4344-9750-e2e7f9863bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-34f9bbb4-d717-4cf4-89e5-f2ab1a111661,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-d6090d73-8896-4adb-a253-9cab3cbad7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386613719-172.17.0.3-1598380851363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-c2691baa-4133-45ca-bb84-21891490f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-0bca475f-e166-43dc-9c1c-d4f25a082a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-6144b742-e523-4080-a055-a42b88df9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-cf19c96b-7255-4ce0-9747-2c983597ab27,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-e3019265-4666-47e7-a8fd-757814a19cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-2154e76d-afa4-4344-9750-e2e7f9863bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-34f9bbb4-d717-4cf4-89e5-f2ab1a111661,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-d6090d73-8896-4adb-a253-9cab3cbad7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66801397-172.17.0.3-1598381196267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-c74a18f7-c82c-4ea1-b5bc-989346df3fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-bbc119c6-1b07-4ec3-8005-8031296961de,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-c5fe9b4e-9e88-46c0-bec3-422d84fd42ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-a18f7268-d758-4e4e-ba67-3ce927704eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-53f7a372-579f-4da5-9a21-f714d671aeee,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-a598d5dc-20ea-40dd-b4ed-052ecc418b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-45db75eb-277e-4935-b88a-0ad52974708e,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-2da432f7-9c15-4d9f-8c9e-7aab4a4ae6d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66801397-172.17.0.3-1598381196267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-c74a18f7-c82c-4ea1-b5bc-989346df3fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-bbc119c6-1b07-4ec3-8005-8031296961de,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-c5fe9b4e-9e88-46c0-bec3-422d84fd42ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-a18f7268-d758-4e4e-ba67-3ce927704eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-53f7a372-579f-4da5-9a21-f714d671aeee,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-a598d5dc-20ea-40dd-b4ed-052ecc418b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-45db75eb-277e-4935-b88a-0ad52974708e,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-2da432f7-9c15-4d9f-8c9e-7aab4a4ae6d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581796489-172.17.0.3-1598381373948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35892,DS-16782506-9e4c-441d-af39-f0fb574a8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-cce56462-594b-44db-a8b9-8184cb181965,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-1ef9196b-9ed2-42ce-bce9-5c373310e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-42142126-a235-4295-be02-e80856718a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-bf4d19fe-6f9b-48e1-a726-e5ca6d549d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3a8f7db9-d415-4802-8398-865dee232bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-ae886fca-f758-433b-8b22-e1fa3b0c99e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-456b5b26-b74d-4f97-9d39-19bbeafe6529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1581796489-172.17.0.3-1598381373948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35892,DS-16782506-9e4c-441d-af39-f0fb574a8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-cce56462-594b-44db-a8b9-8184cb181965,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-1ef9196b-9ed2-42ce-bce9-5c373310e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-42142126-a235-4295-be02-e80856718a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-bf4d19fe-6f9b-48e1-a726-e5ca6d549d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-3a8f7db9-d415-4802-8398-865dee232bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-ae886fca-f758-433b-8b22-e1fa3b0c99e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-456b5b26-b74d-4f97-9d39-19bbeafe6529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439248040-172.17.0.3-1598381518482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-b8ea64ea-ddb0-4331-bd91-014ce093a567,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-dacfe682-e591-4f03-bdc5-947b8c6c1221,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-5ed6b45b-dd85-42fb-9651-8f7cb699df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-34bb5f14-139f-4924-bf01-db3cec7e72f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-fbe764af-4288-4190-8772-44ffd3fef75b,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-62602efb-2047-49f6-b9bd-26910b9d8509,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b2334991-1c1c-495a-a845-395a9c641faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-465977aa-38f7-4b38-b426-e2be943cb30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439248040-172.17.0.3-1598381518482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-b8ea64ea-ddb0-4331-bd91-014ce093a567,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-dacfe682-e591-4f03-bdc5-947b8c6c1221,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-5ed6b45b-dd85-42fb-9651-8f7cb699df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-34bb5f14-139f-4924-bf01-db3cec7e72f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-fbe764af-4288-4190-8772-44ffd3fef75b,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-62602efb-2047-49f6-b9bd-26910b9d8509,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b2334991-1c1c-495a-a845-395a9c641faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-465977aa-38f7-4b38-b426-e2be943cb30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1887663538-172.17.0.3-1598381641930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-1bbdaa71-d3be-4cff-b628-02c5d5cf8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-f4d0b2de-e714-4b4e-bd82-d6f9e8e8b730,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-85e0d4e7-31a0-4b7f-8c8a-245c9bd0f407,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-030ab193-e22a-46f4-a415-3bc3d2d2a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-d9692faf-5395-4cf9-a764-46f121671e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-45e9008e-547a-4b38-bb96-ce32cdb67ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-5e09363a-495e-4f1d-b27f-3e64921258db,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ffb2f98d-6250-45bd-bb06-785d634adf19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1887663538-172.17.0.3-1598381641930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-1bbdaa71-d3be-4cff-b628-02c5d5cf8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-f4d0b2de-e714-4b4e-bd82-d6f9e8e8b730,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-85e0d4e7-31a0-4b7f-8c8a-245c9bd0f407,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-030ab193-e22a-46f4-a415-3bc3d2d2a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-d9692faf-5395-4cf9-a764-46f121671e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-45e9008e-547a-4b38-bb96-ce32cdb67ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-5e09363a-495e-4f1d-b27f-3e64921258db,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ffb2f98d-6250-45bd-bb06-785d634adf19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426835127-172.17.0.3-1598381951072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-b0330425-e24b-456f-8706-a63fbcc2b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-b7691e2e-6f68-4a33-9863-7a0aa277c2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-c0ef658e-7ae9-461c-b419-dd86f8806f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-8ca83dee-fe09-4be5-86b1-7406c9e62920,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ba0e848f-a9a2-4e00-ac91-d719c2dba416,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-f70c16c5-7847-4c1b-9867-9b606059f501,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ce3e248c-70e5-4879-8d03-d3e95044461e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-d57dd789-5014-4a00-a211-246e19302c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426835127-172.17.0.3-1598381951072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-b0330425-e24b-456f-8706-a63fbcc2b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-b7691e2e-6f68-4a33-9863-7a0aa277c2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-c0ef658e-7ae9-461c-b419-dd86f8806f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-8ca83dee-fe09-4be5-86b1-7406c9e62920,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ba0e848f-a9a2-4e00-ac91-d719c2dba416,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-f70c16c5-7847-4c1b-9867-9b606059f501,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ce3e248c-70e5-4879-8d03-d3e95044461e,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-d57dd789-5014-4a00-a211-246e19302c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506243903-172.17.0.3-1598382065557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38618,DS-d30413a2-3970-426e-89da-ad07b49ddedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-689a7e94-5d1d-4122-8585-582cd2f4f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-3df3b2ef-50e0-4240-895c-b986d56e6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-069e51da-78cc-41a9-be67-4e5b8fb54549,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-e4d55d5a-53d7-48dd-960a-ca4c6f86136b,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-83a123dd-798d-4a42-ab76-4c0e04aabc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-9ee4f149-e82a-4250-b311-caa4b99eb7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-46131a0b-4f43-4e53-a845-6f39bfd6ce5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506243903-172.17.0.3-1598382065557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38618,DS-d30413a2-3970-426e-89da-ad07b49ddedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-689a7e94-5d1d-4122-8585-582cd2f4f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-3df3b2ef-50e0-4240-895c-b986d56e6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-069e51da-78cc-41a9-be67-4e5b8fb54549,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-e4d55d5a-53d7-48dd-960a-ca4c6f86136b,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-83a123dd-798d-4a42-ab76-4c0e04aabc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-9ee4f149-e82a-4250-b311-caa4b99eb7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-46131a0b-4f43-4e53-a845-6f39bfd6ce5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167865881-172.17.0.3-1598382539559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-bae2a44f-b90a-473d-bbf2-cd077bda38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-752d33ea-f0a7-48a2-85a1-08b61e532029,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-74e8aa10-887d-4ec6-b72b-ea4e45282802,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-38e5fc9f-2bd6-4e7b-a83b-1d180d47f7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-5759b861-1fd2-49f0-a967-d5a0fe4885ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-9cf58488-0df6-448d-9b9d-e31fd5632cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e35eab1d-49c7-4dc2-b775-371374ba0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-60dc81d4-0d2b-4f92-9881-8ca581908aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167865881-172.17.0.3-1598382539559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-bae2a44f-b90a-473d-bbf2-cd077bda38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-752d33ea-f0a7-48a2-85a1-08b61e532029,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-74e8aa10-887d-4ec6-b72b-ea4e45282802,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-38e5fc9f-2bd6-4e7b-a83b-1d180d47f7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-5759b861-1fd2-49f0-a967-d5a0fe4885ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-9cf58488-0df6-448d-9b9d-e31fd5632cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e35eab1d-49c7-4dc2-b775-371374ba0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-60dc81d4-0d2b-4f92-9881-8ca581908aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968947384-172.17.0.3-1598382657548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-23c73202-9758-4888-8090-004df7d6d36b,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-a007e83d-0cb1-4f32-bacb-426efad2dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-b00c2338-cc7a-492d-acf2-8a8550255a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-fe107169-f79f-4420-ac90-351ee9edf091,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-f7694aa4-d2fa-4eea-bbc2-ff993475c289,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-6630bbc6-8d8e-4393-a58a-7ef85c2545d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-f774f20a-764a-44a6-ab7c-29a2b07ed36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-d8ff1680-6e76-453b-b319-c775bc8ea09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968947384-172.17.0.3-1598382657548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-23c73202-9758-4888-8090-004df7d6d36b,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-a007e83d-0cb1-4f32-bacb-426efad2dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-b00c2338-cc7a-492d-acf2-8a8550255a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-fe107169-f79f-4420-ac90-351ee9edf091,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-f7694aa4-d2fa-4eea-bbc2-ff993475c289,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-6630bbc6-8d8e-4393-a58a-7ef85c2545d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-f774f20a-764a-44a6-ab7c-29a2b07ed36e,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-d8ff1680-6e76-453b-b319-c775bc8ea09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641090442-172.17.0.3-1598382830713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-7a5dfda9-11d1-43c1-b61a-06edcc180d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-79063165-caf1-4b91-9f82-9aa4b182555a,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-df8760a7-bcca-455c-af39-e9ef779b6edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-22c059e6-26d0-493a-9f05-6289acef0af5,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-bad9a3cd-8eb3-4c85-8618-1006cb83b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e90ddfc5-273f-4e54-9f23-5e9586bff4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-876e3627-f2e0-43df-b844-ce5af580fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-8d18af35-5c86-4f41-ae54-bb64d4d8929f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641090442-172.17.0.3-1598382830713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-7a5dfda9-11d1-43c1-b61a-06edcc180d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-79063165-caf1-4b91-9f82-9aa4b182555a,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-df8760a7-bcca-455c-af39-e9ef779b6edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-22c059e6-26d0-493a-9f05-6289acef0af5,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-bad9a3cd-8eb3-4c85-8618-1006cb83b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e90ddfc5-273f-4e54-9f23-5e9586bff4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-876e3627-f2e0-43df-b844-ce5af580fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-8d18af35-5c86-4f41-ae54-bb64d4d8929f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17782680-172.17.0.3-1598383731020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-29454dfe-4d69-4024-b1b6-57843da9e695,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-feebcb0c-32a1-421e-9d47-45d312d1e447,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4baff2db-9bb7-4621-b82f-6c2540cfdf14,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-cefcb061-60f0-42cd-baa5-46300bd3d755,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-203a0b49-2fb2-424f-bf1d-30e1846e7557,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-f57b0949-897f-46cf-963c-3523d930a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-c61e5275-b9e1-481b-b63b-acaa7004dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-78f0eac3-9bcc-4b8c-a02d-80622e2a592d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17782680-172.17.0.3-1598383731020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-29454dfe-4d69-4024-b1b6-57843da9e695,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-feebcb0c-32a1-421e-9d47-45d312d1e447,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-4baff2db-9bb7-4621-b82f-6c2540cfdf14,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-cefcb061-60f0-42cd-baa5-46300bd3d755,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-203a0b49-2fb2-424f-bf1d-30e1846e7557,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-f57b0949-897f-46cf-963c-3523d930a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-c61e5275-b9e1-481b-b63b-acaa7004dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-78f0eac3-9bcc-4b8c-a02d-80622e2a592d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5138
