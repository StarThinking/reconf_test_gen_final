reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48372684-172.17.0.5-1598437345787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-7ffd1e05-cdf3-485a-b552-ede7fb4a1b33,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-5f194713-baa4-4297-9e11-29f5c501e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-ce241833-a25e-4a86-a2d6-6e4e7a9539d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-fb59823b-e36d-40a0-acff-a0620ecfb14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-2d3bdf35-865a-4cf1-9652-53a1c03287fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-6b0170ed-c1e2-48c2-a594-0f179d3d9ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-06f5efaf-7bbf-4bd0-9231-96b337adacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-2450a158-1225-4edf-b8b0-68fc593d083e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48372684-172.17.0.5-1598437345787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-7ffd1e05-cdf3-485a-b552-ede7fb4a1b33,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-5f194713-baa4-4297-9e11-29f5c501e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-ce241833-a25e-4a86-a2d6-6e4e7a9539d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-fb59823b-e36d-40a0-acff-a0620ecfb14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-2d3bdf35-865a-4cf1-9652-53a1c03287fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-6b0170ed-c1e2-48c2-a594-0f179d3d9ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-06f5efaf-7bbf-4bd0-9231-96b337adacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-2450a158-1225-4edf-b8b0-68fc593d083e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167169857-172.17.0.5-1598437526210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-4f1c177d-fe64-4093-80dc-2eb3b6be17ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-41e73a44-aacd-4a93-9f89-b785f3a10d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-2450e002-4dae-4164-ac95-6abb709b2648,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-0c86295d-8fb4-4e04-b7f1-1f505f6173f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-0c7a8c43-9558-4039-93c6-e912494d4fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-de37263c-0cfe-46c4-91a9-4f0fb377759a,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-0dad1540-7ef8-4742-a42e-c00ec0638830,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-e922a330-ff04-4171-90f7-906483f75d38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167169857-172.17.0.5-1598437526210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-4f1c177d-fe64-4093-80dc-2eb3b6be17ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-41e73a44-aacd-4a93-9f89-b785f3a10d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-2450e002-4dae-4164-ac95-6abb709b2648,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-0c86295d-8fb4-4e04-b7f1-1f505f6173f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-0c7a8c43-9558-4039-93c6-e912494d4fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-de37263c-0cfe-46c4-91a9-4f0fb377759a,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-0dad1540-7ef8-4742-a42e-c00ec0638830,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-e922a330-ff04-4171-90f7-906483f75d38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010345036-172.17.0.5-1598437716756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-8a4c962b-a82b-4dc8-b93a-23b2ce6d208e,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-ad95063e-65d1-467b-901a-2e6e1a8a8832,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-b6f10318-247e-4079-8dd6-dd5973ea67ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-78e5d963-03b2-4e7b-884c-4679558d0054,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-56d78943-c542-4232-93ad-29d4b3cb9a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-010219c5-39c0-4228-8d11-b6faa4cdb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-b82c4da3-8bcf-4657-941d-91d6c3283ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7a7ff9f3-1cff-4bd7-90e6-74409131d594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010345036-172.17.0.5-1598437716756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-8a4c962b-a82b-4dc8-b93a-23b2ce6d208e,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-ad95063e-65d1-467b-901a-2e6e1a8a8832,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-b6f10318-247e-4079-8dd6-dd5973ea67ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-78e5d963-03b2-4e7b-884c-4679558d0054,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-56d78943-c542-4232-93ad-29d4b3cb9a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-010219c5-39c0-4228-8d11-b6faa4cdb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-b82c4da3-8bcf-4657-941d-91d6c3283ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7a7ff9f3-1cff-4bd7-90e6-74409131d594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482524167-172.17.0.5-1598438269785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-5776f63c-a006-48e2-856b-244b48f9eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-886ef377-192a-4bc2-9ea7-6e63417f2623,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-c1abe39b-4fd3-433c-b110-4d4d9f0459ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-769e8fd1-d5c7-4410-8206-1fc325aea106,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-c42c21cb-2710-4591-aaa1-78cad3d6a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9a1fb476-8411-41f8-b6e8-80ede188a180,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-412d4c0d-dc66-4464-8c81-983a1bd9cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-df8f1947-f729-4c80-9c91-7157b2b31d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482524167-172.17.0.5-1598438269785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-5776f63c-a006-48e2-856b-244b48f9eae8,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-886ef377-192a-4bc2-9ea7-6e63417f2623,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-c1abe39b-4fd3-433c-b110-4d4d9f0459ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-769e8fd1-d5c7-4410-8206-1fc325aea106,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-c42c21cb-2710-4591-aaa1-78cad3d6a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9a1fb476-8411-41f8-b6e8-80ede188a180,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-412d4c0d-dc66-4464-8c81-983a1bd9cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-df8f1947-f729-4c80-9c91-7157b2b31d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333769451-172.17.0.5-1598438408533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-eb1acae9-1c1c-4aba-92f8-a6718bec7610,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-50bc3a95-8928-47a7-94d7-3f81b1da4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-14ca2a51-808a-404c-a1ca-2c4d8dab25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7c192ab6-5862-48ef-8e1d-b28d9725cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bd4490c1-c869-4cc2-9156-4c89afc5c828,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0c30bf4e-1db6-4f61-92a3-b14cc3bc4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-3eb8407d-15a1-4e1e-891d-102e44d4b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-30420e2b-9c82-4eef-810d-0a405a0e8e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333769451-172.17.0.5-1598438408533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-eb1acae9-1c1c-4aba-92f8-a6718bec7610,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-50bc3a95-8928-47a7-94d7-3f81b1da4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-14ca2a51-808a-404c-a1ca-2c4d8dab25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7c192ab6-5862-48ef-8e1d-b28d9725cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bd4490c1-c869-4cc2-9156-4c89afc5c828,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0c30bf4e-1db6-4f61-92a3-b14cc3bc4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-3eb8407d-15a1-4e1e-891d-102e44d4b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-30420e2b-9c82-4eef-810d-0a405a0e8e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997324533-172.17.0.5-1598438605923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-091f10b8-c912-4bb6-9311-becb388ab29b,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a0e5c3a8-6855-44b3-bbdd-f22b0f31ee9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-740de1f6-2e19-4572-92d8-904b7f57f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-2d896389-c6d6-4ed1-819b-aeb252dabf67,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-8ef89f03-8475-46cf-91e8-91d9eba1e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-32633f6b-efe2-48a9-9cf2-195d0e5fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-07f83718-c24b-4fc9-ac9f-63950fd5eaab,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-32c95d7e-df64-4f7f-aaa9-3e14348d263a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997324533-172.17.0.5-1598438605923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33138,DS-091f10b8-c912-4bb6-9311-becb388ab29b,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-a0e5c3a8-6855-44b3-bbdd-f22b0f31ee9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-740de1f6-2e19-4572-92d8-904b7f57f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-2d896389-c6d6-4ed1-819b-aeb252dabf67,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-8ef89f03-8475-46cf-91e8-91d9eba1e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-32633f6b-efe2-48a9-9cf2-195d0e5fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-07f83718-c24b-4fc9-ac9f-63950fd5eaab,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-32c95d7e-df64-4f7f-aaa9-3e14348d263a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980712632-172.17.0.5-1598438771741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41823,DS-2a21249e-0881-49a9-8e56-acfa123ce559,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-077af0ef-f216-418a-bb53-96ed9e9f266f,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-b1946df0-f1cc-463b-a7f1-df6572fd09a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4bb58aba-fef5-4708-a743-b591fa189838,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-6fcf33fd-a1c5-4ee1-9964-510a7e1ea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-73191de2-edff-473d-93e1-32bd29368d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-f279dceb-e624-4b30-9ad9-f20771fa7332,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-ae111c5b-c671-4d15-8508-66201a6ff714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980712632-172.17.0.5-1598438771741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41823,DS-2a21249e-0881-49a9-8e56-acfa123ce559,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-077af0ef-f216-418a-bb53-96ed9e9f266f,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-b1946df0-f1cc-463b-a7f1-df6572fd09a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4bb58aba-fef5-4708-a743-b591fa189838,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-6fcf33fd-a1c5-4ee1-9964-510a7e1ea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-73191de2-edff-473d-93e1-32bd29368d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-f279dceb-e624-4b30-9ad9-f20771fa7332,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-ae111c5b-c671-4d15-8508-66201a6ff714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978984911-172.17.0.5-1598438831487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-0fed1585-ed16-47a1-bb03-db4e645e301b,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-c673d427-88e9-40b6-80a4-7d4e8b9d2349,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a7608909-ad58-467d-ad53-2a7292a4acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-87e0fa11-a3f1-427a-beb8-09ebd27293cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-a0a3e5be-0dab-47be-942b-d9bf2bb8e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-7b4b735e-e649-4880-89cc-7d5b18c2cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-05520277-98d4-47d7-bee0-b85068e7d463,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-ef009725-8361-46e7-8750-301680679d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978984911-172.17.0.5-1598438831487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-0fed1585-ed16-47a1-bb03-db4e645e301b,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-c673d427-88e9-40b6-80a4-7d4e8b9d2349,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-a7608909-ad58-467d-ad53-2a7292a4acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-87e0fa11-a3f1-427a-beb8-09ebd27293cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-a0a3e5be-0dab-47be-942b-d9bf2bb8e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-7b4b735e-e649-4880-89cc-7d5b18c2cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-05520277-98d4-47d7-bee0-b85068e7d463,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-ef009725-8361-46e7-8750-301680679d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390783135-172.17.0.5-1598438952132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-7df69335-5bf7-4870-95e8-8ff50a921046,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-07d04270-8198-4010-87d2-7cba7868c559,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-31182341-6d11-48cf-8f3d-da848175d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-fa8fa999-8123-4e26-8495-3af890174f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-02807906-7dd1-41ce-b364-8c9b1610928b,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-edec189d-863b-418f-964b-7ef35ff7fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c59f1e1b-6b22-49ad-858f-b00c486fe332,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-d347ef0b-c5be-42d7-b9bc-f92f15008ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390783135-172.17.0.5-1598438952132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-7df69335-5bf7-4870-95e8-8ff50a921046,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-07d04270-8198-4010-87d2-7cba7868c559,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-31182341-6d11-48cf-8f3d-da848175d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-fa8fa999-8123-4e26-8495-3af890174f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-02807906-7dd1-41ce-b364-8c9b1610928b,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-edec189d-863b-418f-964b-7ef35ff7fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c59f1e1b-6b22-49ad-858f-b00c486fe332,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-d347ef0b-c5be-42d7-b9bc-f92f15008ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265682196-172.17.0.5-1598439330847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-e2291c36-1272-4f9e-a097-ba55c9efef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8b4d8a75-1f44-45b9-a0b1-a64b7da3e161,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c8ca8caf-e024-416a-893c-8e69c8f7420a,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-129b6660-4301-4771-9cb5-e37b95bd5946,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-9c8a07af-4976-4b70-956e-549f985c5308,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-e09b9ffd-926a-4d3f-9b0a-8cfd54774375,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-b32c16a2-d5ad-49ec-868a-323c5e392e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-3e45dc69-246b-4563-a6c3-c68a5ad6d060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265682196-172.17.0.5-1598439330847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-e2291c36-1272-4f9e-a097-ba55c9efef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8b4d8a75-1f44-45b9-a0b1-a64b7da3e161,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c8ca8caf-e024-416a-893c-8e69c8f7420a,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-129b6660-4301-4771-9cb5-e37b95bd5946,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-9c8a07af-4976-4b70-956e-549f985c5308,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-e09b9ffd-926a-4d3f-9b0a-8cfd54774375,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-b32c16a2-d5ad-49ec-868a-323c5e392e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-3e45dc69-246b-4563-a6c3-c68a5ad6d060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760758031-172.17.0.5-1598439433053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-198ea81b-ffee-45e7-b18d-d65c77e49bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-e5a3dc1c-c5f4-475a-87a0-2dc14571bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-2f103a11-4b44-4737-83ed-ad918314cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-958e883c-9bba-4f92-b312-0c2b31b8f52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b7d25ca0-9481-4400-bb90-b3c1adafe795,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-293ca1c5-04d9-4464-b2a5-10b50ccec5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-2a9fe2ed-a916-4054-9b3e-1a2233ccbde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-f12743af-6692-44f3-af72-818b91cf8b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760758031-172.17.0.5-1598439433053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-198ea81b-ffee-45e7-b18d-d65c77e49bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-e5a3dc1c-c5f4-475a-87a0-2dc14571bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-2f103a11-4b44-4737-83ed-ad918314cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-958e883c-9bba-4f92-b312-0c2b31b8f52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b7d25ca0-9481-4400-bb90-b3c1adafe795,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-293ca1c5-04d9-4464-b2a5-10b50ccec5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-2a9fe2ed-a916-4054-9b3e-1a2233ccbde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-f12743af-6692-44f3-af72-818b91cf8b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106672364-172.17.0.5-1598439505780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38108,DS-6d4bc133-0610-4739-b2f5-dd9c37589476,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-fedda4ef-684c-4b10-a092-159465305ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-57acb16f-1afa-4d24-ac9b-833d9a4f3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-029ab1fd-10dc-4a00-a3b0-949685dd88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-8fef8bb3-19d2-450f-b48f-4be6d8d03040,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-291995b3-4c44-46ea-9370-ff2d53b7176d,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-f86ebd5e-ac4f-4014-9429-e8b3bede9171,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-d4c6c94a-577c-4484-997c-8f2e5c5af56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106672364-172.17.0.5-1598439505780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38108,DS-6d4bc133-0610-4739-b2f5-dd9c37589476,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-fedda4ef-684c-4b10-a092-159465305ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-57acb16f-1afa-4d24-ac9b-833d9a4f3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-029ab1fd-10dc-4a00-a3b0-949685dd88c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-8fef8bb3-19d2-450f-b48f-4be6d8d03040,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-291995b3-4c44-46ea-9370-ff2d53b7176d,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-f86ebd5e-ac4f-4014-9429-e8b3bede9171,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-d4c6c94a-577c-4484-997c-8f2e5c5af56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855611943-172.17.0.5-1598439608544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37955,DS-6339c622-cdb5-4c26-83cf-0c9ffdc82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-7a9b3095-f276-47bd-91c4-f685755eb977,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-0e5121a9-595e-43c9-9e6b-b61bf5ee094a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-74542f3c-96fe-4584-b85c-7201c3a023b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-0c834d30-b6ab-4fb1-ae5d-4309c6b12c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-43eb4482-f851-4468-b9e0-4a081c353bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-f2738c73-0feb-4022-a296-280c86172d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-b73105ea-6ccc-45e5-8d1b-cbaf27870181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855611943-172.17.0.5-1598439608544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37955,DS-6339c622-cdb5-4c26-83cf-0c9ffdc82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-7a9b3095-f276-47bd-91c4-f685755eb977,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-0e5121a9-595e-43c9-9e6b-b61bf5ee094a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-74542f3c-96fe-4584-b85c-7201c3a023b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-0c834d30-b6ab-4fb1-ae5d-4309c6b12c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-43eb4482-f851-4468-b9e0-4a081c353bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-f2738c73-0feb-4022-a296-280c86172d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-b73105ea-6ccc-45e5-8d1b-cbaf27870181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179305985-172.17.0.5-1598439641068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-2dc1af0c-385a-4d7f-a0d0-660dcfc03b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a8d5cfa2-56c4-435c-86c2-f5ff4e1c2797,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-2dc25fcd-f047-4ee7-bf0b-7c97fd614cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-60ecc28f-335c-41e3-a76d-5b640756f7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b3527fcf-fb1b-46fb-ba5d-9ef0d2f12da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-2ab519e3-e2c5-42a6-a152-2d356a886cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-77f76cb9-851b-4469-9ab8-7646d85abdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2d24858f-3395-4939-8d91-ae170fd975e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179305985-172.17.0.5-1598439641068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-2dc1af0c-385a-4d7f-a0d0-660dcfc03b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a8d5cfa2-56c4-435c-86c2-f5ff4e1c2797,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-2dc25fcd-f047-4ee7-bf0b-7c97fd614cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-60ecc28f-335c-41e3-a76d-5b640756f7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b3527fcf-fb1b-46fb-ba5d-9ef0d2f12da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-2ab519e3-e2c5-42a6-a152-2d356a886cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-77f76cb9-851b-4469-9ab8-7646d85abdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2d24858f-3395-4939-8d91-ae170fd975e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100915620-172.17.0.5-1598440619703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-15b9fa08-b589-4460-998b-a699a11726ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-e048efae-825d-43f7-809f-53bc5b47d202,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-2d3cd958-96b2-4869-b387-068ac46e796b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-2c25d473-db0c-4c2a-8b45-5367b4a6a625,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0a736713-2f06-4ac0-bda5-89efa095c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-4bf656f1-7cc4-45b3-af28-44d9ef817244,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-4fd4bb4a-09a5-4a87-bef0-459edf51282f,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-7bffb063-06e0-4abe-89b8-5b6461c851ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100915620-172.17.0.5-1598440619703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-15b9fa08-b589-4460-998b-a699a11726ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-e048efae-825d-43f7-809f-53bc5b47d202,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-2d3cd958-96b2-4869-b387-068ac46e796b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-2c25d473-db0c-4c2a-8b45-5367b4a6a625,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0a736713-2f06-4ac0-bda5-89efa095c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-4bf656f1-7cc4-45b3-af28-44d9ef817244,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-4fd4bb4a-09a5-4a87-bef0-459edf51282f,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-7bffb063-06e0-4abe-89b8-5b6461c851ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574077351-172.17.0.5-1598441154833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-6fd14456-147a-4901-b27a-03fd37467954,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-ec7e4439-8b57-4af3-a947-82be540cb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-6ecfdbd4-86a6-42e8-bfac-48743a8d04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3c087d3b-f61c-481a-bbf2-f6145cec8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-a58b1236-4437-4abd-b614-b5f771f5c8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-fbe1aba5-3547-4403-a6be-4423af60fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-46b38355-0451-4691-bcb7-bb842a9ba67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-75e2ecdf-e1ac-4bff-9ca6-a7425782cc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574077351-172.17.0.5-1598441154833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-6fd14456-147a-4901-b27a-03fd37467954,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-ec7e4439-8b57-4af3-a947-82be540cb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-6ecfdbd4-86a6-42e8-bfac-48743a8d04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3c087d3b-f61c-481a-bbf2-f6145cec8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-a58b1236-4437-4abd-b614-b5f771f5c8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-fbe1aba5-3547-4403-a6be-4423af60fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-46b38355-0451-4691-bcb7-bb842a9ba67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-75e2ecdf-e1ac-4bff-9ca6-a7425782cc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854764817-172.17.0.5-1598441573176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-bb810308-347c-4c97-8c73-813eb247d279,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-495629c5-02f0-44dc-92c6-213ce7732c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-50d52b85-5a87-4a35-8793-b39f53615842,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-3bd74538-4442-42b5-8f9e-8103f0ee99b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-87914fac-fbaa-4ea1-a082-7695bd6f52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-6176f5e0-409a-47dd-9459-90d860401141,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f35e104d-7274-4c92-a0a3-134918096af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-6a16df14-3a5c-41eb-a15b-24c33e6e3f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854764817-172.17.0.5-1598441573176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-bb810308-347c-4c97-8c73-813eb247d279,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-495629c5-02f0-44dc-92c6-213ce7732c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-50d52b85-5a87-4a35-8793-b39f53615842,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-3bd74538-4442-42b5-8f9e-8103f0ee99b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-87914fac-fbaa-4ea1-a082-7695bd6f52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-6176f5e0-409a-47dd-9459-90d860401141,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f35e104d-7274-4c92-a0a3-134918096af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-6a16df14-3a5c-41eb-a15b-24c33e6e3f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188933290-172.17.0.5-1598441705169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-1994b639-4dbd-48b9-90c9-786941cc62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-972c5210-6a84-441f-b3a8-ecd530f20ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-63330fcc-b7fc-4784-ac71-05c4817d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-bdfa6835-5e56-45ec-9f9e-b08065732fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a2bbb318-b46b-4796-874c-1af3110d127e,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bca2665e-1f39-43e5-8649-8fe90cbb5e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-97d60cb1-ac01-43cf-a1cc-69d55794496e,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-9cfdff0f-504f-4ab1-8eac-9180135022da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188933290-172.17.0.5-1598441705169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-1994b639-4dbd-48b9-90c9-786941cc62b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-972c5210-6a84-441f-b3a8-ecd530f20ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-63330fcc-b7fc-4784-ac71-05c4817d2ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-bdfa6835-5e56-45ec-9f9e-b08065732fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a2bbb318-b46b-4796-874c-1af3110d127e,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bca2665e-1f39-43e5-8649-8fe90cbb5e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-97d60cb1-ac01-43cf-a1cc-69d55794496e,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-9cfdff0f-504f-4ab1-8eac-9180135022da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929854312-172.17.0.5-1598441951237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38597,DS-fade71a8-fcb0-4ab3-8d18-5b9edc35fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-614d5b16-ff1f-4f75-adff-d8e274c760ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-15d58374-b7fc-4183-8414-a87960b5661a,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-d3aac499-008a-425e-b4f0-0c4504e92a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-c6e5db80-03ca-437f-9895-bf3271f6110f,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-da3464be-1294-4822-89b3-6256454f279a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-e9675dc9-d678-4e38-836f-6eeb33bc1f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-dc9a855d-13b0-4939-8c19-8d352770450b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929854312-172.17.0.5-1598441951237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38597,DS-fade71a8-fcb0-4ab3-8d18-5b9edc35fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-614d5b16-ff1f-4f75-adff-d8e274c760ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-15d58374-b7fc-4183-8414-a87960b5661a,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-d3aac499-008a-425e-b4f0-0c4504e92a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-c6e5db80-03ca-437f-9895-bf3271f6110f,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-da3464be-1294-4822-89b3-6256454f279a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-e9675dc9-d678-4e38-836f-6eeb33bc1f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-dc9a855d-13b0-4939-8c19-8d352770450b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348153018-172.17.0.5-1598441985580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46534,DS-18866fa9-c228-40b3-8c42-76165a7b97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-307c08cc-5917-46fd-b508-fa42105fa001,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-983ca45b-5573-4907-bf65-50057d1049a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-59873c12-8afc-44a7-a838-15b4dd115c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-0cd642b9-f975-45ca-b167-3a72ba26be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-c07280ba-9f2d-4fdf-bb5e-bd81acdb0505,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-dfce110b-e7a8-4d15-92bd-883f854b18ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-2fd16680-64ae-4d34-b67b-8afb1397db58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348153018-172.17.0.5-1598441985580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46534,DS-18866fa9-c228-40b3-8c42-76165a7b97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-307c08cc-5917-46fd-b508-fa42105fa001,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-983ca45b-5573-4907-bf65-50057d1049a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-59873c12-8afc-44a7-a838-15b4dd115c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-0cd642b9-f975-45ca-b167-3a72ba26be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-c07280ba-9f2d-4fdf-bb5e-bd81acdb0505,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-dfce110b-e7a8-4d15-92bd-883f854b18ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-2fd16680-64ae-4d34-b67b-8afb1397db58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296620437-172.17.0.5-1598442060438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-d666cc92-40c7-43d3-b7f5-efdbeb3c26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e330f949-d970-422f-91e5-32b3e763c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-482dad68-54bd-4dae-b5ae-d1cb84efe641,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-6d753278-f471-44f4-b616-7eb72f36c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-1605c66e-a5e9-46f1-9520-6295b1a85c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-2e310b5e-6cb1-43b8-9cb4-3cf5e2414e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-e124b1fa-f0b5-4eda-818d-ff2f1da534b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-13587449-957f-427c-a5d9-46a3be079fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296620437-172.17.0.5-1598442060438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-d666cc92-40c7-43d3-b7f5-efdbeb3c26f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e330f949-d970-422f-91e5-32b3e763c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-482dad68-54bd-4dae-b5ae-d1cb84efe641,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-6d753278-f471-44f4-b616-7eb72f36c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-1605c66e-a5e9-46f1-9520-6295b1a85c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-2e310b5e-6cb1-43b8-9cb4-3cf5e2414e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-e124b1fa-f0b5-4eda-818d-ff2f1da534b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-13587449-957f-427c-a5d9-46a3be079fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391467110-172.17.0.5-1598442133091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44008,DS-02db44a7-5111-4a2a-bd18-d8f25b15df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-f980c8c7-2747-4e34-bb5a-45f649e377a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-27eb5639-3ed9-481a-8f88-7776546e0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-28923ab7-1e55-4579-bb55-236aa4b50705,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a43bd7fd-2f6e-43f4-8d10-f3b1b3f6cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-b43909eb-c651-4604-945f-584f6828c8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9dbdbd6b-3ef6-440a-9b31-30c2a8023da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0ccf3835-f6d0-4eb6-96aa-d8d830430bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391467110-172.17.0.5-1598442133091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44008,DS-02db44a7-5111-4a2a-bd18-d8f25b15df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-f980c8c7-2747-4e34-bb5a-45f649e377a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-27eb5639-3ed9-481a-8f88-7776546e0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-28923ab7-1e55-4579-bb55-236aa4b50705,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a43bd7fd-2f6e-43f4-8d10-f3b1b3f6cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-b43909eb-c651-4604-945f-584f6828c8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9dbdbd6b-3ef6-440a-9b31-30c2a8023da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0ccf3835-f6d0-4eb6-96aa-d8d830430bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5281
