reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842101376-172.17.0.13-1598461777711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-5f3c4763-9402-4ef1-9d3e-a7edc9950b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c876491f-a781-47a3-b581-ad82a0f2340e,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-889cbf2b-ca22-4012-bda3-03e49b39e198,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-adad7bfa-5522-4f6a-a61a-5caffbeba9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-8d4d43ef-4646-4f3c-b7d2-17db2b50e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-75b7fba1-3063-4df3-b007-63e9d7c2d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-692e8e5e-3cf3-4389-be8c-142088ca8b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-df53335f-c99e-46a5-806e-4346d92b93d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842101376-172.17.0.13-1598461777711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-5f3c4763-9402-4ef1-9d3e-a7edc9950b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c876491f-a781-47a3-b581-ad82a0f2340e,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-889cbf2b-ca22-4012-bda3-03e49b39e198,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-adad7bfa-5522-4f6a-a61a-5caffbeba9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-8d4d43ef-4646-4f3c-b7d2-17db2b50e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-75b7fba1-3063-4df3-b007-63e9d7c2d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-692e8e5e-3cf3-4389-be8c-142088ca8b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-df53335f-c99e-46a5-806e-4346d92b93d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197813913-172.17.0.13-1598461945303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-274af2d7-53af-437f-9598-da3b457710da,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-bb877b0b-8bd8-44bb-a1fd-82be8388f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d6d5853f-d121-42ed-b0f3-69eab2e7f095,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-961aa7b7-cac3-488d-a4d2-444b14f52d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-7086097b-cffa-457f-a3da-4c093a171de0,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-639d3c85-7edb-4d8a-adf5-1362cb0a7382,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c0913f67-5685-4a5a-b7ec-237cc3f367f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-90d1e2bd-b25d-412b-a2f6-cd717312e279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197813913-172.17.0.13-1598461945303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-274af2d7-53af-437f-9598-da3b457710da,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-bb877b0b-8bd8-44bb-a1fd-82be8388f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d6d5853f-d121-42ed-b0f3-69eab2e7f095,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-961aa7b7-cac3-488d-a4d2-444b14f52d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-7086097b-cffa-457f-a3da-4c093a171de0,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-639d3c85-7edb-4d8a-adf5-1362cb0a7382,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c0913f67-5685-4a5a-b7ec-237cc3f367f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-90d1e2bd-b25d-412b-a2f6-cd717312e279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823066904-172.17.0.13-1598462192840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-72eaf14d-9198-4dba-8759-9958e06283aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-72bc3e39-98c7-4082-8f2e-c641ff397434,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-5b8a2be0-a76b-4227-8d30-868da5fb82b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-e5cbd505-ec60-4a9e-851e-fa10afa438b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-fad74fe3-ad2c-440f-a41f-5a7918fb2caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-de8f149f-d837-48aa-9f9e-1b40b685b285,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-7e4d673d-a246-49cd-b9c8-fba654a4aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-56804903-28af-42e4-a844-4d48b6bae5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823066904-172.17.0.13-1598462192840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-72eaf14d-9198-4dba-8759-9958e06283aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-72bc3e39-98c7-4082-8f2e-c641ff397434,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-5b8a2be0-a76b-4227-8d30-868da5fb82b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-e5cbd505-ec60-4a9e-851e-fa10afa438b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-fad74fe3-ad2c-440f-a41f-5a7918fb2caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-de8f149f-d837-48aa-9f9e-1b40b685b285,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-7e4d673d-a246-49cd-b9c8-fba654a4aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-56804903-28af-42e4-a844-4d48b6bae5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282560347-172.17.0.13-1598462478571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-93eb73f3-8cf0-466b-a36f-2d40f4ccd6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-8d016d86-3e87-4397-b574-6ad790cb7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-2a8235ac-11d7-4e27-bb92-4b5233df6767,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-3c85e138-3b2c-4bb7-b8e4-9416e70b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-a51d9de6-f46a-406e-a3e8-9169206135ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-456a1a98-663e-4fa3-b58d-918cf6967f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-760c1541-d807-4fdb-88bc-5267e146d969,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-aa42c715-3f76-4d75-8be2-9bfcdadd8c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282560347-172.17.0.13-1598462478571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-93eb73f3-8cf0-466b-a36f-2d40f4ccd6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-8d016d86-3e87-4397-b574-6ad790cb7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-2a8235ac-11d7-4e27-bb92-4b5233df6767,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-3c85e138-3b2c-4bb7-b8e4-9416e70b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-a51d9de6-f46a-406e-a3e8-9169206135ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-456a1a98-663e-4fa3-b58d-918cf6967f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-760c1541-d807-4fdb-88bc-5267e146d969,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-aa42c715-3f76-4d75-8be2-9bfcdadd8c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029306328-172.17.0.13-1598462509322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-6a213223-0734-40f7-9505-e8d54fb7bd18,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-5114ea21-5d9e-4404-8660-e8780b203f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-c183c4a9-07aa-4a98-9f01-9133907a987f,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-552ad70e-17dd-49fe-b239-8b1f5c7a45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7079748b-405b-449b-b0dc-4f81a05607b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-ac161db0-d0e2-44d4-beff-19f8b436aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-b05951e9-b4bc-47f2-b7da-c08367244e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-180eef00-45ae-4a40-a7d2-d3bbfdbdd6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029306328-172.17.0.13-1598462509322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-6a213223-0734-40f7-9505-e8d54fb7bd18,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-5114ea21-5d9e-4404-8660-e8780b203f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-c183c4a9-07aa-4a98-9f01-9133907a987f,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-552ad70e-17dd-49fe-b239-8b1f5c7a45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7079748b-405b-449b-b0dc-4f81a05607b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-ac161db0-d0e2-44d4-beff-19f8b436aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-b05951e9-b4bc-47f2-b7da-c08367244e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-180eef00-45ae-4a40-a7d2-d3bbfdbdd6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370190566-172.17.0.13-1598462804082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-2ee29c45-9eb6-497b-8d6f-3694276dc372,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-0c6263c5-c87a-410b-9d2d-650b9f9f3939,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-d7cc44c3-1c29-406a-85d0-5abb13816600,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-293d0995-0310-4452-8d64-85cbb67ab5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-865ae03a-0f59-4813-ba5b-32600003c319,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-5d5a8c0a-771b-4477-a9aa-12a9632f13b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-713a7f80-ef49-4928-98fe-052edc6bbe85,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-b2a21161-9df6-455d-8a0e-606a5742c494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370190566-172.17.0.13-1598462804082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-2ee29c45-9eb6-497b-8d6f-3694276dc372,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-0c6263c5-c87a-410b-9d2d-650b9f9f3939,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-d7cc44c3-1c29-406a-85d0-5abb13816600,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-293d0995-0310-4452-8d64-85cbb67ab5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-865ae03a-0f59-4813-ba5b-32600003c319,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-5d5a8c0a-771b-4477-a9aa-12a9632f13b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-713a7f80-ef49-4928-98fe-052edc6bbe85,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-b2a21161-9df6-455d-8a0e-606a5742c494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973751459-172.17.0.13-1598462986376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-43768d3d-609c-40c7-8da7-55ac6edc9811,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-92e4dd3b-f1be-4eb5-a1a0-0b00e1300832,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-f3fd0922-24d6-4d56-a7b0-48333119f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-cbb6e7ff-45aa-4651-a326-be04f481da10,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-0b6866ac-b4f0-40cf-8413-f70f4e146800,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-a9ab1756-3d87-40c6-b2c4-819f802c3132,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-2edf91c2-4d02-4aab-9eee-bdad0d201e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-2dda166f-da16-42bb-8111-42dd43884822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973751459-172.17.0.13-1598462986376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-43768d3d-609c-40c7-8da7-55ac6edc9811,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-92e4dd3b-f1be-4eb5-a1a0-0b00e1300832,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-f3fd0922-24d6-4d56-a7b0-48333119f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-cbb6e7ff-45aa-4651-a326-be04f481da10,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-0b6866ac-b4f0-40cf-8413-f70f4e146800,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-a9ab1756-3d87-40c6-b2c4-819f802c3132,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-2edf91c2-4d02-4aab-9eee-bdad0d201e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-2dda166f-da16-42bb-8111-42dd43884822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654903156-172.17.0.13-1598463393271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-66c0342f-1036-4edd-98f2-8fde7a51abea,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-0205ded5-be87-49f5-a0bf-1abf875efecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-67130141-7557-4d8f-bc26-cf8eefeb363f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-71df417d-a246-4761-9bcb-6b8b3d26648f,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-1b115b31-d39a-4ab2-a419-77ef19495ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-d42624c0-f095-4715-b6de-5fe0ead5925d,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-fa28f351-2546-405b-808d-3eb643ef4e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-08f310fb-e032-472b-8c9a-8110c337b1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654903156-172.17.0.13-1598463393271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-66c0342f-1036-4edd-98f2-8fde7a51abea,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-0205ded5-be87-49f5-a0bf-1abf875efecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-67130141-7557-4d8f-bc26-cf8eefeb363f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-71df417d-a246-4761-9bcb-6b8b3d26648f,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-1b115b31-d39a-4ab2-a419-77ef19495ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-d42624c0-f095-4715-b6de-5fe0ead5925d,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-fa28f351-2546-405b-808d-3eb643ef4e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-08f310fb-e032-472b-8c9a-8110c337b1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356661733-172.17.0.13-1598463813069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-94cdd2f0-40df-4728-b5be-affae0c657ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-6f85736a-6b42-4c09-8129-64ece46b343a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-6e1c9ea1-4b8d-4afa-aa4d-553dc0ddd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-4f89792d-250f-4164-970a-2e95c9d80adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-41108a36-1bda-4576-a86f-b8c3d6b17f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-e44ece81-29ed-4ef4-8363-70b7fcea758b,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-43115bed-b45b-435d-b060-76b8a4273d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-b902d5aa-95cb-41f1-8aac-f75ff27bb9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356661733-172.17.0.13-1598463813069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-94cdd2f0-40df-4728-b5be-affae0c657ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-6f85736a-6b42-4c09-8129-64ece46b343a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-6e1c9ea1-4b8d-4afa-aa4d-553dc0ddd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-4f89792d-250f-4164-970a-2e95c9d80adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-41108a36-1bda-4576-a86f-b8c3d6b17f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-e44ece81-29ed-4ef4-8363-70b7fcea758b,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-43115bed-b45b-435d-b060-76b8a4273d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-b902d5aa-95cb-41f1-8aac-f75ff27bb9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065580890-172.17.0.13-1598463915186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-84a75395-22c5-4d66-b477-913d04dfb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4ea045eb-7c05-4243-b3a5-e5db72b1606f,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-a766e602-1995-4644-b073-b607632f8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c4b1a55f-b02c-41f2-9969-0f7927b75e05,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-988ea696-dfcc-4a73-9ebb-e331a27e8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-219a0461-012b-46d4-a004-6f4c27654672,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-ffc566ce-79d7-4d98-a50a-8a6feacf940a,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-2d7b9061-c22f-4d5b-a9c1-e02846e0818c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065580890-172.17.0.13-1598463915186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-84a75395-22c5-4d66-b477-913d04dfb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4ea045eb-7c05-4243-b3a5-e5db72b1606f,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-a766e602-1995-4644-b073-b607632f8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-c4b1a55f-b02c-41f2-9969-0f7927b75e05,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-988ea696-dfcc-4a73-9ebb-e331a27e8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-219a0461-012b-46d4-a004-6f4c27654672,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-ffc566ce-79d7-4d98-a50a-8a6feacf940a,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-2d7b9061-c22f-4d5b-a9c1-e02846e0818c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691766021-172.17.0.13-1598464128315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-92e40cee-95cc-4937-9ade-0b8b9f5e9319,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-5eff6cbe-f563-4da2-b6ca-b2c65622a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-2146057e-607c-4197-babd-94f25bb144a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-06d958cf-30fd-49fd-b9c5-32629a6c4caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e65df639-365d-4138-81b5-64fa7a4a0085,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-5dd4c668-bbf5-4255-b250-0587565dd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-4aa3e344-66c6-43d4-8372-b39284e2f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-66078d77-1105-477d-a535-2c1fe609e8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691766021-172.17.0.13-1598464128315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-92e40cee-95cc-4937-9ade-0b8b9f5e9319,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-5eff6cbe-f563-4da2-b6ca-b2c65622a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-2146057e-607c-4197-babd-94f25bb144a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-06d958cf-30fd-49fd-b9c5-32629a6c4caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e65df639-365d-4138-81b5-64fa7a4a0085,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-5dd4c668-bbf5-4255-b250-0587565dd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-4aa3e344-66c6-43d4-8372-b39284e2f11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-66078d77-1105-477d-a535-2c1fe609e8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947134073-172.17.0.13-1598464850799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-bbb0490f-d909-42d1-9d01-8e86a50f74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-f0a7744e-c93f-490b-90e7-c6e45bfcd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-02d193d8-aeeb-4284-8edf-b53a3f7c41f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-6522b47c-7704-4dea-a2e0-569ed0f80b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-152f7524-0b9a-431c-843e-56f30594cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-5ede067e-8426-4367-bc63-1874db916e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-44b61572-85fb-4807-8881-e20e96b60109,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-70a25718-6cd9-4167-bf3a-37ad93715f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947134073-172.17.0.13-1598464850799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-bbb0490f-d909-42d1-9d01-8e86a50f74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-f0a7744e-c93f-490b-90e7-c6e45bfcd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-02d193d8-aeeb-4284-8edf-b53a3f7c41f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-6522b47c-7704-4dea-a2e0-569ed0f80b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-152f7524-0b9a-431c-843e-56f30594cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-5ede067e-8426-4367-bc63-1874db916e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-44b61572-85fb-4807-8881-e20e96b60109,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-70a25718-6cd9-4167-bf3a-37ad93715f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009874640-172.17.0.13-1598464921746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-144ba922-59ec-4cee-869f-d5f0d030b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-d50daa49-367b-419f-928c-cfec73b04b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5a367ada-2ac1-4ff0-bd6e-5087998c1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-09f8c2a1-2c63-4c9a-be0f-1c8ad0d23acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-4340a391-9535-4c67-9e1f-27350a9893e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9aaa9dd5-50ed-4cdc-a0bd-e7af0eb8fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-9724dce0-7613-43cf-a146-32c366c96e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-296fe5bf-f5f7-41f9-8f7d-4d1fd9508411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009874640-172.17.0.13-1598464921746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-144ba922-59ec-4cee-869f-d5f0d030b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-d50daa49-367b-419f-928c-cfec73b04b17,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5a367ada-2ac1-4ff0-bd6e-5087998c1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-09f8c2a1-2c63-4c9a-be0f-1c8ad0d23acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-4340a391-9535-4c67-9e1f-27350a9893e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9aaa9dd5-50ed-4cdc-a0bd-e7af0eb8fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-9724dce0-7613-43cf-a146-32c366c96e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-296fe5bf-f5f7-41f9-8f7d-4d1fd9508411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748463381-172.17.0.13-1598465074051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-22660ce6-7a41-46f6-8eb0-f9dbeb71060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-42338334-eb98-485d-9aca-b6525b12f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ffa85501-201e-4d19-9557-199c1eb87398,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-e629a084-0325-449a-8044-f499183b890c,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-44254d36-149c-4b1a-86a6-5cd001d4ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-e880defe-94b0-4105-bc8c-950e4bb3c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-c74a28d2-e125-4f18-a5b1-fa56c3f5d671,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-6ec38952-7afc-4ad3-b895-f58f41535d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748463381-172.17.0.13-1598465074051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-22660ce6-7a41-46f6-8eb0-f9dbeb71060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-42338334-eb98-485d-9aca-b6525b12f78a,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-ffa85501-201e-4d19-9557-199c1eb87398,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-e629a084-0325-449a-8044-f499183b890c,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-44254d36-149c-4b1a-86a6-5cd001d4ead3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-e880defe-94b0-4105-bc8c-950e4bb3c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-c74a28d2-e125-4f18-a5b1-fa56c3f5d671,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-6ec38952-7afc-4ad3-b895-f58f41535d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27598929-172.17.0.13-1598465346106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-35f500a7-fed8-4ece-8ac4-b68b076250c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-77048574-0e46-4421-b789-a89fc95f5c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e98f3012-a0ff-4c0f-add2-71c2822564f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0503355c-dc79-42ac-874f-ae999bca024f,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-ad04f93f-2ad8-4c03-8c9a-cc7561acd9df,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-f5ef05ef-999e-4ca4-a42b-11ade9cb690a,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-b75cee3f-03b6-47f6-abd8-0bee91e2c185,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-acebedf5-8cb1-4354-9b56-002307335dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27598929-172.17.0.13-1598465346106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-35f500a7-fed8-4ece-8ac4-b68b076250c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-77048574-0e46-4421-b789-a89fc95f5c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e98f3012-a0ff-4c0f-add2-71c2822564f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0503355c-dc79-42ac-874f-ae999bca024f,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-ad04f93f-2ad8-4c03-8c9a-cc7561acd9df,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-f5ef05ef-999e-4ca4-a42b-11ade9cb690a,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-b75cee3f-03b6-47f6-abd8-0bee91e2c185,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-acebedf5-8cb1-4354-9b56-002307335dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047574289-172.17.0.13-1598465606780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-7f82ab7e-4783-48ad-afc3-dc9146eb2def,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-f9d90bd3-854d-4b0b-9cf1-f36a63b3c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-d4c585f1-087a-43f0-8f6d-1a5e9fb58289,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-eab07f7b-3554-4834-aee4-8805917baff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-a4a061ba-f8bd-4d80-917b-256ff1fd4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-4cb1a283-f5ae-4ab6-b225-ba87faf2bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-23039169-7bb0-4634-85a2-314d8d59de60,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-b82a67ca-747b-4c52-beb1-b8ee66887b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047574289-172.17.0.13-1598465606780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-7f82ab7e-4783-48ad-afc3-dc9146eb2def,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-f9d90bd3-854d-4b0b-9cf1-f36a63b3c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-d4c585f1-087a-43f0-8f6d-1a5e9fb58289,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-eab07f7b-3554-4834-aee4-8805917baff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-a4a061ba-f8bd-4d80-917b-256ff1fd4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-4cb1a283-f5ae-4ab6-b225-ba87faf2bf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-23039169-7bb0-4634-85a2-314d8d59de60,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-b82a67ca-747b-4c52-beb1-b8ee66887b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448921818-172.17.0.13-1598465847771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39706,DS-95a1caf7-3395-4447-a811-f3b04937690a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-1f866f47-ae02-4e00-b216-8ecde95ee6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-7d11f044-0e21-4f47-8700-3d28a67523aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-9c0037c1-ff19-4920-9336-0ee35eb434f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-2c78e6f1-3b55-4685-b885-14a76a28d904,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-da29976d-2052-494b-bfd2-47de1355373c,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5ca48b9d-319a-4efa-93f7-04c79b9f30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-b7de97a2-ba2e-4906-ba77-45fb0de386f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1448921818-172.17.0.13-1598465847771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39706,DS-95a1caf7-3395-4447-a811-f3b04937690a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-1f866f47-ae02-4e00-b216-8ecde95ee6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-7d11f044-0e21-4f47-8700-3d28a67523aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-9c0037c1-ff19-4920-9336-0ee35eb434f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-2c78e6f1-3b55-4685-b885-14a76a28d904,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-da29976d-2052-494b-bfd2-47de1355373c,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5ca48b9d-319a-4efa-93f7-04c79b9f30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-b7de97a2-ba2e-4906-ba77-45fb0de386f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931270312-172.17.0.13-1598465894390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-a6458fa2-b856-4f84-b4b4-a1780792a9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-175ee560-be48-472b-9de6-ea8300d1f8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-6beda87d-9a80-487b-8328-d28999982e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-e4d2107e-1126-4c60-823b-a7155705b154,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-5c02f031-66f7-4481-9d2d-adcaccb94775,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-be41c4ee-2b50-4762-b858-0c592ca742ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-b620d2ef-31c6-4798-ac91-4c72972a1f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-d7d5fff2-ce09-48d0-b92f-1d8e3623158a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931270312-172.17.0.13-1598465894390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-a6458fa2-b856-4f84-b4b4-a1780792a9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-175ee560-be48-472b-9de6-ea8300d1f8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-6beda87d-9a80-487b-8328-d28999982e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-e4d2107e-1126-4c60-823b-a7155705b154,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-5c02f031-66f7-4481-9d2d-adcaccb94775,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-be41c4ee-2b50-4762-b858-0c592ca742ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-b620d2ef-31c6-4798-ac91-4c72972a1f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-d7d5fff2-ce09-48d0-b92f-1d8e3623158a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950792885-172.17.0.13-1598465960725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-c139a9ea-1d6f-4bf6-9140-882486a61023,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-3874bac8-48bc-446f-99b0-b2948dabfc90,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-61b839bb-97b1-42f3-8f96-4f0d539f7b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-2b121987-8157-4eba-9c5b-926b19146502,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-49db963d-e172-4c8a-9e85-c8428b6d4427,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-d8bb9951-18e0-4921-9d2a-be80fee8654a,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-4872d29e-70ac-48d3-92b9-8d32fd8c92e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-6f0fd98c-3b15-4226-b851-1421af1fa328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950792885-172.17.0.13-1598465960725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-c139a9ea-1d6f-4bf6-9140-882486a61023,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-3874bac8-48bc-446f-99b0-b2948dabfc90,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-61b839bb-97b1-42f3-8f96-4f0d539f7b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-2b121987-8157-4eba-9c5b-926b19146502,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-49db963d-e172-4c8a-9e85-c8428b6d4427,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-d8bb9951-18e0-4921-9d2a-be80fee8654a,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-4872d29e-70ac-48d3-92b9-8d32fd8c92e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-6f0fd98c-3b15-4226-b851-1421af1fa328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90121518-172.17.0.13-1598465995271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40192,DS-727e0428-74e1-42f6-bf83-5a186af217f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-ef0dbc25-b9a4-4bb0-b10a-291740d1b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a07c9ac5-e380-48df-9716-79200d3d6634,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-1f7c3d2e-6b53-4c33-9f0d-cd5f9156a257,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-7bf3960b-8f1e-47a8-a233-4000c247211b,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-325dee25-e45b-4834-b1d7-759a73de76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-1d8b0db2-b0bf-4aaf-9467-9778acc5fbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-dc690af9-7a9f-47ba-b4cc-964e71e38a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90121518-172.17.0.13-1598465995271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40192,DS-727e0428-74e1-42f6-bf83-5a186af217f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-ef0dbc25-b9a4-4bb0-b10a-291740d1b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-a07c9ac5-e380-48df-9716-79200d3d6634,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-1f7c3d2e-6b53-4c33-9f0d-cd5f9156a257,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-7bf3960b-8f1e-47a8-a233-4000c247211b,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-325dee25-e45b-4834-b1d7-759a73de76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-1d8b0db2-b0bf-4aaf-9467-9778acc5fbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-dc690af9-7a9f-47ba-b4cc-964e71e38a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459904522-172.17.0.13-1598466108416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-3f8230bd-55ad-4ff4-9c78-5c758aeffd09,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-c699b078-ad1a-41fe-bf78-4b6fbd1940fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-bfd939c1-a646-49bd-a496-51bc520cac63,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-fb7291f0-bf32-49fd-b04c-cab74dfae409,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-dad14de8-7438-46ee-8112-066470bc5b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f7fc3c8c-900d-4a04-9425-5904f94cf2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-1977e7ac-2ec9-46f6-a976-3fc6a3436ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-56ebdf93-d24c-44fe-9dd4-1a91a9c3724d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459904522-172.17.0.13-1598466108416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-3f8230bd-55ad-4ff4-9c78-5c758aeffd09,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-c699b078-ad1a-41fe-bf78-4b6fbd1940fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-bfd939c1-a646-49bd-a496-51bc520cac63,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-fb7291f0-bf32-49fd-b04c-cab74dfae409,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-dad14de8-7438-46ee-8112-066470bc5b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f7fc3c8c-900d-4a04-9425-5904f94cf2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-1977e7ac-2ec9-46f6-a976-3fc6a3436ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-56ebdf93-d24c-44fe-9dd4-1a91a9c3724d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576941586-172.17.0.13-1598466246954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-75eec0a1-2af2-4aaf-8398-4f16a17230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-443be968-ff51-4349-83c6-f4e87d92c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-03f3a027-d35e-466f-b40f-c854fe4e593a,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-f7d8f733-b5b3-487e-a874-6cea8a1e83fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-816e47c2-cbfe-4f44-8284-02cb01758460,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-705d6986-5864-4991-8cd0-8c25ece4c81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-4a3b01d1-a16c-4452-a9c5-b362a9a70cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-27c302f6-9e18-445b-a86e-6ee4dfe2c188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576941586-172.17.0.13-1598466246954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-75eec0a1-2af2-4aaf-8398-4f16a17230a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-443be968-ff51-4349-83c6-f4e87d92c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-03f3a027-d35e-466f-b40f-c854fe4e593a,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-f7d8f733-b5b3-487e-a874-6cea8a1e83fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-816e47c2-cbfe-4f44-8284-02cb01758460,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-705d6986-5864-4991-8cd0-8c25ece4c81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-4a3b01d1-a16c-4452-a9c5-b362a9a70cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-27c302f6-9e18-445b-a86e-6ee4dfe2c188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434032515-172.17.0.13-1598466283400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-bcae95b7-1b1d-4205-8da4-70e0e3169baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-fd287fbb-c5fc-420d-aec6-e6e68063e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-303207d4-9fa8-42e3-81bd-f8f0dc1c6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-d9d9e4a8-0bd1-4e03-9e50-833c94558146,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-17ca3c0a-5d84-468c-9dfb-68c7cc6886c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-79fc5189-7b8f-4fd0-bb71-7a4cf9b64965,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-a74f1159-d44a-4551-818a-72ebb0ba1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-239cc4dc-fc2a-4e35-8c74-1f0e732c9e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434032515-172.17.0.13-1598466283400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-bcae95b7-1b1d-4205-8da4-70e0e3169baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-fd287fbb-c5fc-420d-aec6-e6e68063e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-303207d4-9fa8-42e3-81bd-f8f0dc1c6d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-d9d9e4a8-0bd1-4e03-9e50-833c94558146,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-17ca3c0a-5d84-468c-9dfb-68c7cc6886c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-79fc5189-7b8f-4fd0-bb71-7a4cf9b64965,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-a74f1159-d44a-4551-818a-72ebb0ba1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-239cc4dc-fc2a-4e35-8c74-1f0e732c9e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021229264-172.17.0.13-1598466433567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-6966a5f9-16c9-44e1-8a5c-19c76e270621,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-66a07add-a512-419d-a54d-9fbee0f1dd95,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-0756a852-f335-46c6-9f85-6878723208cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-d0019bef-ec1b-42b8-8fc7-73b3fa06f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-42e6c579-a981-4d56-b1f1-cd4789c94d01,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-f247c704-e28a-456a-80c6-ef9035f7d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-92c022cb-3e57-4117-9ef0-d0399a68c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-4151f601-7e97-4e2c-92ea-681ce918ca23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021229264-172.17.0.13-1598466433567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-6966a5f9-16c9-44e1-8a5c-19c76e270621,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-66a07add-a512-419d-a54d-9fbee0f1dd95,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-0756a852-f335-46c6-9f85-6878723208cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-d0019bef-ec1b-42b8-8fc7-73b3fa06f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-42e6c579-a981-4d56-b1f1-cd4789c94d01,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-f247c704-e28a-456a-80c6-ef9035f7d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-92c022cb-3e57-4117-9ef0-d0399a68c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-4151f601-7e97-4e2c-92ea-681ce918ca23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189726607-172.17.0.13-1598466730744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-af03167b-662c-48a7-a0a4-4a4321d9dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-64b7f9d0-f112-49bc-bd93-2e463653b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-4ccdb49c-0538-4fd8-82e6-4f4433c7496c,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-d4a2cd3d-85c5-4c95-b6e7-371881c91dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-611620dc-13f8-4e06-bd24-1b5a0b60853b,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-c9dc343a-e95d-4277-91a9-8026591d1ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-5a60aa61-7003-4e5e-98c0-41b24d15f119,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-10ed74e5-23ac-48a1-afab-31cabfdb3a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189726607-172.17.0.13-1598466730744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37859,DS-af03167b-662c-48a7-a0a4-4a4321d9dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-64b7f9d0-f112-49bc-bd93-2e463653b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-4ccdb49c-0538-4fd8-82e6-4f4433c7496c,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-d4a2cd3d-85c5-4c95-b6e7-371881c91dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-611620dc-13f8-4e06-bd24-1b5a0b60853b,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-c9dc343a-e95d-4277-91a9-8026591d1ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-5a60aa61-7003-4e5e-98c0-41b24d15f119,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-10ed74e5-23ac-48a1-afab-31cabfdb3a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5422
