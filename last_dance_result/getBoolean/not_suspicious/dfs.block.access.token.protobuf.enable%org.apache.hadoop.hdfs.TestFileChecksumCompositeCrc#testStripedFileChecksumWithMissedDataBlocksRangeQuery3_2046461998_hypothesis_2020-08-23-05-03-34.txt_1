reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598092607-172.17.0.20-1598159602878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-326cd171-a7a0-4741-99f6-d6b656847830,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-03dba111-d7a2-42b2-ad9d-80479d7a8102,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-b5fb24f3-cb4c-41f8-bcb1-2c50dba293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-0a2980e9-f6b3-4977-af83-5138673c2033,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-e279cca6-1350-4b31-a5c8-8417fd6e6096,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-53eb5076-8a9e-404b-9a62-16544106dacc,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-c8608c71-b105-4de0-9e50-ddf4b5d79651,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-a8d9b255-37dd-4a1a-9455-c5ca07edb55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598092607-172.17.0.20-1598159602878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-326cd171-a7a0-4741-99f6-d6b656847830,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-03dba111-d7a2-42b2-ad9d-80479d7a8102,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-b5fb24f3-cb4c-41f8-bcb1-2c50dba293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-0a2980e9-f6b3-4977-af83-5138673c2033,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-e279cca6-1350-4b31-a5c8-8417fd6e6096,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-53eb5076-8a9e-404b-9a62-16544106dacc,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-c8608c71-b105-4de0-9e50-ddf4b5d79651,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-a8d9b255-37dd-4a1a-9455-c5ca07edb55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325445176-172.17.0.20-1598159832918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-81599826-d545-4a6f-909c-0d5f9af499d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-b17f7235-c363-45b2-bdd9-81901110cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-abb6ffb0-799e-4b03-9ff4-2fc34e0d9219,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-e0f36c6b-86b9-40de-afaf-489676612bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4f553d5c-2027-4b7a-a8f6-252d0a8736d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7ee4588f-3f12-4e63-8e4c-da4863eaf844,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ed99ca33-e7a2-4202-b0a0-51619ed4947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-c6d747b1-d3ee-412e-8cbd-7490f4002a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325445176-172.17.0.20-1598159832918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-81599826-d545-4a6f-909c-0d5f9af499d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-b17f7235-c363-45b2-bdd9-81901110cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-abb6ffb0-799e-4b03-9ff4-2fc34e0d9219,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-e0f36c6b-86b9-40de-afaf-489676612bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4f553d5c-2027-4b7a-a8f6-252d0a8736d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7ee4588f-3f12-4e63-8e4c-da4863eaf844,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ed99ca33-e7a2-4202-b0a0-51619ed4947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-c6d747b1-d3ee-412e-8cbd-7490f4002a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580848713-172.17.0.20-1598159973402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-70b00f13-04b9-459b-8b08-035a3721bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-c59d27a5-6cd5-4eb7-85e4-8d7f70b1be5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-e2ae699d-b94d-4b72-b857-d455cf1d2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-fb94cc2e-6415-46ad-803b-4d93c804dfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-2a1ff673-d330-4543-8dca-4e7ac62cffda,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-a48d4a85-9d5b-4119-a019-e5093b5a628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-b0ccb779-930c-4154-8759-345fd9c1d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-e97fcd96-5987-48e2-af96-50748f6d60da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580848713-172.17.0.20-1598159973402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-70b00f13-04b9-459b-8b08-035a3721bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-c59d27a5-6cd5-4eb7-85e4-8d7f70b1be5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-e2ae699d-b94d-4b72-b857-d455cf1d2dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-fb94cc2e-6415-46ad-803b-4d93c804dfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-2a1ff673-d330-4543-8dca-4e7ac62cffda,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-a48d4a85-9d5b-4119-a019-e5093b5a628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-b0ccb779-930c-4154-8759-345fd9c1d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-e97fcd96-5987-48e2-af96-50748f6d60da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760833146-172.17.0.20-1598160188584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-86b18dcc-c505-4ccc-a032-0d5068d481ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-8c880944-6dd5-4751-96bc-efcad843e095,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-8fe96a5a-c869-4acc-8b98-eb46353da047,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-914d5fe5-adc7-463d-8cc6-c2ffded89f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-2fcc2021-63cf-4be1-a461-c4acbaa177b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-fc0e1b48-9155-44e4-9d3d-27d8ee589278,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-dfd4c23b-5f14-46f0-8834-25c19b34c162,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-cfceb1a8-9389-4785-b309-9bc294ef422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760833146-172.17.0.20-1598160188584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-86b18dcc-c505-4ccc-a032-0d5068d481ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-8c880944-6dd5-4751-96bc-efcad843e095,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-8fe96a5a-c869-4acc-8b98-eb46353da047,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-914d5fe5-adc7-463d-8cc6-c2ffded89f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-2fcc2021-63cf-4be1-a461-c4acbaa177b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-fc0e1b48-9155-44e4-9d3d-27d8ee589278,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-dfd4c23b-5f14-46f0-8834-25c19b34c162,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-cfceb1a8-9389-4785-b309-9bc294ef422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580212041-172.17.0.20-1598160644049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-a93b11d0-358b-4a7e-a3e0-57d94ba7b2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-89352cd6-d064-4871-885e-e816d38fcf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-3788b698-5f3b-4c14-ad9d-3c2ffe13f774,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-d531cdb9-00c2-405e-a305-f1d16183d032,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-945a5e15-3bb5-413f-a6bc-f5b756d90124,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-2dd0aaf2-b5ee-4820-841a-df1588f4ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-925103d2-dba5-43cf-b6cc-21b72ecf2208,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-11d07a6e-2a96-454f-9440-023c85b4e4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580212041-172.17.0.20-1598160644049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-a93b11d0-358b-4a7e-a3e0-57d94ba7b2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-89352cd6-d064-4871-885e-e816d38fcf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-3788b698-5f3b-4c14-ad9d-3c2ffe13f774,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-d531cdb9-00c2-405e-a305-f1d16183d032,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-945a5e15-3bb5-413f-a6bc-f5b756d90124,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-2dd0aaf2-b5ee-4820-841a-df1588f4ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-925103d2-dba5-43cf-b6cc-21b72ecf2208,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-11d07a6e-2a96-454f-9440-023c85b4e4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935897822-172.17.0.20-1598160724991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-57de646b-af84-45e4-b6fe-d3c13c784d47,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ef4335ab-5e32-44c1-9e98-d14703e848ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-7a44c39e-68fc-467b-ab0e-8494010563c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-2f4732b6-16cf-4df2-813b-26636e6cc7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-46396ed5-e1f3-415f-8e8e-c72fc7ecfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d704f2c8-b897-42c4-a182-72d2a7d05e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-61fc0774-d6a5-40bd-a670-d6e69e3f77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-15fb4d51-8ad0-42bf-9a49-0351d848e927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935897822-172.17.0.20-1598160724991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-57de646b-af84-45e4-b6fe-d3c13c784d47,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ef4335ab-5e32-44c1-9e98-d14703e848ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-7a44c39e-68fc-467b-ab0e-8494010563c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-2f4732b6-16cf-4df2-813b-26636e6cc7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-46396ed5-e1f3-415f-8e8e-c72fc7ecfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d704f2c8-b897-42c4-a182-72d2a7d05e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-61fc0774-d6a5-40bd-a670-d6e69e3f77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-15fb4d51-8ad0-42bf-9a49-0351d848e927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109981516-172.17.0.20-1598160902220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-2d0d5315-cbb5-4e84-a57f-72dd4cea28ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2f565940-9a4f-477d-8a7b-cc66c08b7648,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-27e72f19-5f3a-483d-883b-9417c13dcd27,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-60b0dd5f-48d8-4f23-8e7f-e3166ea86809,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-c2a3071a-8fdb-4271-bb5a-fd676de1c442,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-b31bd179-4e3f-491d-9936-45caad4ecdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-0e285694-22ec-4e34-9ed5-3ddcef02a334,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-26a6f3c5-e22c-4442-b707-3c91d1c48511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109981516-172.17.0.20-1598160902220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-2d0d5315-cbb5-4e84-a57f-72dd4cea28ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2f565940-9a4f-477d-8a7b-cc66c08b7648,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-27e72f19-5f3a-483d-883b-9417c13dcd27,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-60b0dd5f-48d8-4f23-8e7f-e3166ea86809,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-c2a3071a-8fdb-4271-bb5a-fd676de1c442,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-b31bd179-4e3f-491d-9936-45caad4ecdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-0e285694-22ec-4e34-9ed5-3ddcef02a334,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-26a6f3c5-e22c-4442-b707-3c91d1c48511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816617129-172.17.0.20-1598161018232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-0365ec12-25ac-4492-a549-5d77a4603778,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-1a93f1aa-688c-4efc-b2bc-91e93f9de167,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-eb66a991-ae15-45bc-b454-70eac2b288a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7097ae5b-45f0-43f6-aaab-fec9b65312e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-badb4745-52e7-4e5c-9f77-52179896cb67,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-1c1f2ed9-4279-4283-8a27-070b13c05b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-8e053805-8c93-4954-8b13-4ac9e399932f,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-8864b036-c952-4b84-9fa0-40f224b5ee46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816617129-172.17.0.20-1598161018232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-0365ec12-25ac-4492-a549-5d77a4603778,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-1a93f1aa-688c-4efc-b2bc-91e93f9de167,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-eb66a991-ae15-45bc-b454-70eac2b288a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7097ae5b-45f0-43f6-aaab-fec9b65312e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-badb4745-52e7-4e5c-9f77-52179896cb67,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-1c1f2ed9-4279-4283-8a27-070b13c05b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-8e053805-8c93-4954-8b13-4ac9e399932f,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-8864b036-c952-4b84-9fa0-40f224b5ee46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466897542-172.17.0.20-1598161310100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37748,DS-50146cc4-5438-498b-a626-a4ab4dc49e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-f4dc734f-c9f7-406a-9fde-6a70dadae222,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-35fc9c6e-26ab-4856-a688-e740e84a474d,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-26bafec9-e95e-432a-9963-32a43e582533,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-5da4ef69-2693-45c8-ac46-6068f5be738a,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-a599213b-7ac1-4d03-a1c0-da8cf6bc88f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-fa2ec470-0d94-4e19-b929-b7278b2963d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-bf1ba40c-d4de-40ee-b5df-d6f8a6bcc2de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466897542-172.17.0.20-1598161310100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37748,DS-50146cc4-5438-498b-a626-a4ab4dc49e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-f4dc734f-c9f7-406a-9fde-6a70dadae222,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-35fc9c6e-26ab-4856-a688-e740e84a474d,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-26bafec9-e95e-432a-9963-32a43e582533,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-5da4ef69-2693-45c8-ac46-6068f5be738a,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-a599213b-7ac1-4d03-a1c0-da8cf6bc88f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-fa2ec470-0d94-4e19-b929-b7278b2963d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-bf1ba40c-d4de-40ee-b5df-d6f8a6bcc2de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513424289-172.17.0.20-1598161416164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-c7e6423b-536e-46fd-a015-9cdc51a7ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-6cf42869-9a12-4235-adf6-c3b8cf64f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-37ead3a9-e99a-474d-a051-9e626ea1bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-918a2dc5-52b7-46c1-b42d-a06683455bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-f9238595-7587-4b13-aca2-df11b1c13052,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-27160d8e-0f17-4af4-8f95-67739b9744f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-9fa0474e-f205-4df0-8b69-3d3378175670,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-aa06981f-019a-433c-bfaa-a8202f833057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513424289-172.17.0.20-1598161416164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40497,DS-c7e6423b-536e-46fd-a015-9cdc51a7ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-6cf42869-9a12-4235-adf6-c3b8cf64f60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-37ead3a9-e99a-474d-a051-9e626ea1bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-918a2dc5-52b7-46c1-b42d-a06683455bab,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-f9238595-7587-4b13-aca2-df11b1c13052,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-27160d8e-0f17-4af4-8f95-67739b9744f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-9fa0474e-f205-4df0-8b69-3d3378175670,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-aa06981f-019a-433c-bfaa-a8202f833057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39106402-172.17.0.20-1598162256799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-232e78f9-d52c-47f7-bcb1-5292a0fb03ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-1b2948a5-f33b-423a-aea7-823d7f8f1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-050d0a41-1784-4fdc-801f-76000708194d,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-7a4ecd4c-7359-4631-99ba-1a2779b4fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-26236f78-7c89-49a6-9c70-c66a2bf6bc19,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0e1cc854-8890-41ca-97ca-5c933c1bc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-cfcff313-2043-4fc3-b442-a96cf43bbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-64dddeb4-f2ef-4dd9-aa19-c2a16d94e5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39106402-172.17.0.20-1598162256799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-232e78f9-d52c-47f7-bcb1-5292a0fb03ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-1b2948a5-f33b-423a-aea7-823d7f8f1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-050d0a41-1784-4fdc-801f-76000708194d,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-7a4ecd4c-7359-4631-99ba-1a2779b4fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-26236f78-7c89-49a6-9c70-c66a2bf6bc19,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-0e1cc854-8890-41ca-97ca-5c933c1bc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-cfcff313-2043-4fc3-b442-a96cf43bbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-64dddeb4-f2ef-4dd9-aa19-c2a16d94e5d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035947970-172.17.0.20-1598162291173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-e13e9ddc-96cb-4559-8993-3804aa335305,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-336129c9-7e4d-4fb1-b7a3-8cf3479523fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-8be86df6-24a4-4d42-9367-4baeb5a5d465,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b23afaf9-7031-4ba5-9428-59c79fce7043,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-42a64517-ed0f-4eff-bdc1-52e535eedfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-de152844-224d-4d0d-b851-aadb8be92471,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-7e03f253-c3dd-465d-8a6a-dee0a5b3da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4aab2b1b-e9d1-425d-ad4c-7de009079d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035947970-172.17.0.20-1598162291173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-e13e9ddc-96cb-4559-8993-3804aa335305,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-336129c9-7e4d-4fb1-b7a3-8cf3479523fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-8be86df6-24a4-4d42-9367-4baeb5a5d465,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b23afaf9-7031-4ba5-9428-59c79fce7043,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-42a64517-ed0f-4eff-bdc1-52e535eedfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-de152844-224d-4d0d-b851-aadb8be92471,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-7e03f253-c3dd-465d-8a6a-dee0a5b3da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4aab2b1b-e9d1-425d-ad4c-7de009079d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934532248-172.17.0.20-1598162461446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-2dd20971-12eb-4809-8310-ad3dbdc5f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d5b496eb-88be-48b2-8b39-c95ca1a7672b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-0f6c6495-7159-4bae-876a-52db022cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-ed5e6d93-f352-4c13-8e7e-dbfcc95f7674,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-a35ac93e-7175-46ce-944c-472dfe727e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f9c5e666-55cb-4e22-b032-2812cb1d451d,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-9451aeb7-a4be-405a-911b-a51294957582,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-2242885c-f65f-40dd-808f-acd02a9b495b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934532248-172.17.0.20-1598162461446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-2dd20971-12eb-4809-8310-ad3dbdc5f5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d5b496eb-88be-48b2-8b39-c95ca1a7672b,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-0f6c6495-7159-4bae-876a-52db022cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-ed5e6d93-f352-4c13-8e7e-dbfcc95f7674,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-a35ac93e-7175-46ce-944c-472dfe727e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f9c5e666-55cb-4e22-b032-2812cb1d451d,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-9451aeb7-a4be-405a-911b-a51294957582,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-2242885c-f65f-40dd-808f-acd02a9b495b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995416736-172.17.0.20-1598162497677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-beed6435-aa9d-4656-99a0-d4df42f89b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8a6f3660-f994-4f38-a702-0110ca18c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-472ec1c5-e2e6-4a80-b0f7-fa25b7a44952,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-e527e56b-fff2-4970-8822-6fb7b569cd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-cdeb22d4-a44c-49a9-987a-f863f0ef8537,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-8a6c4624-c3ca-4213-8454-9faa4bd2e115,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-08f6afc2-a256-4583-ba15-8c8cacf1315e,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-2c7f2553-76a9-46f2-830c-97c3437681d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995416736-172.17.0.20-1598162497677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-beed6435-aa9d-4656-99a0-d4df42f89b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8a6f3660-f994-4f38-a702-0110ca18c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-472ec1c5-e2e6-4a80-b0f7-fa25b7a44952,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-e527e56b-fff2-4970-8822-6fb7b569cd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-cdeb22d4-a44c-49a9-987a-f863f0ef8537,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-8a6c4624-c3ca-4213-8454-9faa4bd2e115,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-08f6afc2-a256-4583-ba15-8c8cacf1315e,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-2c7f2553-76a9-46f2-830c-97c3437681d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608713847-172.17.0.20-1598162533813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-e0daa068-7d62-49ad-be2b-eb2f894f0998,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-2074e825-f54f-426b-b37d-f18cf82a8887,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-f9336b83-1365-4132-bf66-0353a274feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-4d874766-2504-4509-8a2e-c8e2935cd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-32dd9020-3647-4e35-a7e1-3f0680445cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-4000ff2c-85ed-459d-a599-baf24e1d40e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-91275f3a-218f-4c39-ab7d-a0831a1017d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-6e3bfe0c-c854-44b1-bab6-7956c7106cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608713847-172.17.0.20-1598162533813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-e0daa068-7d62-49ad-be2b-eb2f894f0998,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-2074e825-f54f-426b-b37d-f18cf82a8887,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-f9336b83-1365-4132-bf66-0353a274feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-4d874766-2504-4509-8a2e-c8e2935cd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-32dd9020-3647-4e35-a7e1-3f0680445cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-4000ff2c-85ed-459d-a599-baf24e1d40e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-91275f3a-218f-4c39-ab7d-a0831a1017d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-6e3bfe0c-c854-44b1-bab6-7956c7106cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611736119-172.17.0.20-1598162785548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8d5df471-c7de-4ecc-b6d7-5a582fd8a890,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c9a1ca6e-0607-4274-abd8-d43497706f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6ad566e0-637b-4d4f-8096-d41abc512dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-6361bc38-7406-4a0a-8a29-41a712a2fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-06b12800-9a6c-42f6-96a1-b26067ba48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-bb8d1d37-44eb-4131-b60f-d163cf151eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-8e701114-68d0-4976-95ee-8c149cdcb2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-ed4095e5-6984-435a-b47f-38d4ee615955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611736119-172.17.0.20-1598162785548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8d5df471-c7de-4ecc-b6d7-5a582fd8a890,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c9a1ca6e-0607-4274-abd8-d43497706f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6ad566e0-637b-4d4f-8096-d41abc512dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-6361bc38-7406-4a0a-8a29-41a712a2fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-06b12800-9a6c-42f6-96a1-b26067ba48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-bb8d1d37-44eb-4131-b60f-d163cf151eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-8e701114-68d0-4976-95ee-8c149cdcb2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-ed4095e5-6984-435a-b47f-38d4ee615955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190002170-172.17.0.20-1598163341593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-fd03ac88-a4f1-4e46-8be7-04c30e703a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-45cc16a3-1ba5-4568-aa52-2546256d3780,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-bc7aec48-e33c-4e2a-b911-7a53fe1bf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-4c9844e2-5420-4383-9f03-81f43b7c639f,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-45d41e18-0e83-42e3-8cd6-0bfe64fc51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-975fc00f-6c1f-4174-b718-e9bcaef34dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-2e3c9cd3-1cf4-45b3-9803-5e04ac9bfbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-d147728b-6cf7-4b48-8692-4491bc84be25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190002170-172.17.0.20-1598163341593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-fd03ac88-a4f1-4e46-8be7-04c30e703a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-45cc16a3-1ba5-4568-aa52-2546256d3780,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-bc7aec48-e33c-4e2a-b911-7a53fe1bf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-4c9844e2-5420-4383-9f03-81f43b7c639f,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-45d41e18-0e83-42e3-8cd6-0bfe64fc51f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-975fc00f-6c1f-4174-b718-e9bcaef34dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-2e3c9cd3-1cf4-45b3-9803-5e04ac9bfbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-d147728b-6cf7-4b48-8692-4491bc84be25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900261359-172.17.0.20-1598163695494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-f838dd70-93a9-4aa7-ae95-afbc4905b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-dc3b1596-b7d5-418c-9da1-c5eb824f3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-72fb6ff8-2b68-4a04-a8fa-d7b93fb53bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-1b8f5685-031b-481f-b513-56deded9afde,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-f3c34af7-268a-48cc-9983-bb030a2ea551,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-5931ed3b-822d-4add-a32e-50cd6c7e4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-ad42fb8d-e81c-4293-b684-8aac7edafe87,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-a93c79a4-ebcc-44ed-840b-8ade103f20b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900261359-172.17.0.20-1598163695494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-f838dd70-93a9-4aa7-ae95-afbc4905b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-dc3b1596-b7d5-418c-9da1-c5eb824f3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-72fb6ff8-2b68-4a04-a8fa-d7b93fb53bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-1b8f5685-031b-481f-b513-56deded9afde,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-f3c34af7-268a-48cc-9983-bb030a2ea551,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-5931ed3b-822d-4add-a32e-50cd6c7e4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-ad42fb8d-e81c-4293-b684-8aac7edafe87,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-a93c79a4-ebcc-44ed-840b-8ade103f20b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466150765-172.17.0.20-1598163768564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41495,DS-51bcee57-2201-4d61-93ed-1ceed4526906,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-95ccbf05-9588-48ce-afa8-e4a0ed3c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-511564b3-e6f3-45ce-b5e4-1b094e9ea130,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-3a0a61eb-a005-439e-a162-71869ad020c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-48132d11-b821-4d1c-ba5e-decfbd8d3ded,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-6d19fcdb-1ee0-4c82-aa73-e217be9be0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-1f623350-f0d4-463d-bc62-35da77feca66,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-1a59cd0c-e566-4f78-abf3-cee4157e2d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466150765-172.17.0.20-1598163768564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41495,DS-51bcee57-2201-4d61-93ed-1ceed4526906,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-95ccbf05-9588-48ce-afa8-e4a0ed3c5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-511564b3-e6f3-45ce-b5e4-1b094e9ea130,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-3a0a61eb-a005-439e-a162-71869ad020c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-48132d11-b821-4d1c-ba5e-decfbd8d3ded,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-6d19fcdb-1ee0-4c82-aa73-e217be9be0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-1f623350-f0d4-463d-bc62-35da77feca66,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-1a59cd0c-e566-4f78-abf3-cee4157e2d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457202103-172.17.0.20-1598163915909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-af4a89b7-3b96-445b-8778-db813fe1dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-db3d10d9-7f0e-41be-b684-a059661f1192,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-aac74d14-6e34-4dbf-b1f2-549b41f7a606,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-df52f721-ed5c-4918-a93e-124043ba79d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-dfa35cc7-562c-4bda-98f2-a63c9c72d973,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-a2f3990f-42a5-4f71-ac79-27612fd712df,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-fab6f090-b26e-4572-80dc-2143e830ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6a2acd14-8ded-474d-8f6d-e99837ca2f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457202103-172.17.0.20-1598163915909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-af4a89b7-3b96-445b-8778-db813fe1dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-db3d10d9-7f0e-41be-b684-a059661f1192,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-aac74d14-6e34-4dbf-b1f2-549b41f7a606,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-df52f721-ed5c-4918-a93e-124043ba79d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-dfa35cc7-562c-4bda-98f2-a63c9c72d973,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-a2f3990f-42a5-4f71-ac79-27612fd712df,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-fab6f090-b26e-4572-80dc-2143e830ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6a2acd14-8ded-474d-8f6d-e99837ca2f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5416
