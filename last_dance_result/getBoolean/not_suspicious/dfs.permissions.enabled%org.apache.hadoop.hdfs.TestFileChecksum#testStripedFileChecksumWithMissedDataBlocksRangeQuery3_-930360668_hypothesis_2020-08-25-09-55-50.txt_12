reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315271791-172.17.0.12-1598349564854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-77432e9d-bb49-43d4-8fd3-bfe5e696b720,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-8c0e376c-d0d1-4b19-8c51-fe5dd633b008,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ca0f6f48-3aa7-4576-907b-d960b3ff8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-39134422-94bb-4e76-ae2a-36409ce6cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-055b6ad4-26bf-40b0-8f2d-727e74104cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-1e28edd3-7825-4039-a15c-1d3e5a5ecc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-efcd834e-a6e0-40af-b3ae-9fc7ae0b8250,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-daae091f-fe1e-49e1-9d36-9a91c31bd09c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315271791-172.17.0.12-1598349564854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-77432e9d-bb49-43d4-8fd3-bfe5e696b720,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-8c0e376c-d0d1-4b19-8c51-fe5dd633b008,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ca0f6f48-3aa7-4576-907b-d960b3ff8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-39134422-94bb-4e76-ae2a-36409ce6cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-055b6ad4-26bf-40b0-8f2d-727e74104cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-1e28edd3-7825-4039-a15c-1d3e5a5ecc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-efcd834e-a6e0-40af-b3ae-9fc7ae0b8250,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-daae091f-fe1e-49e1-9d36-9a91c31bd09c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738101035-172.17.0.12-1598349756752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-a3ec8a06-dcb9-4357-ab8a-ad7aa1ce8714,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-51f2aa46-1bef-4d14-a73c-e00a36ed823b,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b56958dc-7a45-4fd7-ac8f-9aa7c8a87db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-7c577681-6f4a-40a6-966c-805810de64b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-65ef8f53-ab2a-4fa8-a90d-6e6fcfbce598,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-c404456b-a993-43bb-a4b9-d2653b83a289,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-0a5c09e6-3d1c-402c-819a-13c83b3e2555,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-3d53850a-cd8b-48d3-a8d1-e8b693531adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738101035-172.17.0.12-1598349756752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-a3ec8a06-dcb9-4357-ab8a-ad7aa1ce8714,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-51f2aa46-1bef-4d14-a73c-e00a36ed823b,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b56958dc-7a45-4fd7-ac8f-9aa7c8a87db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-7c577681-6f4a-40a6-966c-805810de64b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-65ef8f53-ab2a-4fa8-a90d-6e6fcfbce598,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-c404456b-a993-43bb-a4b9-d2653b83a289,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-0a5c09e6-3d1c-402c-819a-13c83b3e2555,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-3d53850a-cd8b-48d3-a8d1-e8b693531adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175880833-172.17.0.12-1598350255745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-9493828b-bcca-4b93-85ef-f26b4ee1a303,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-8e3f2e0a-668a-41ca-98e2-24c341ff94f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-5b4be9ea-1cac-4a09-8cd0-d80c28ea5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-9c2b9219-60ab-4034-8508-0c78106c0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-441acdaf-68e3-41f4-9eee-881b6d4e62c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-a949aba6-754e-43de-94db-5b93ef3bbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a3a8ba70-fb9e-494b-8011-26db5b158649,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8c7a3173-53c6-4db3-97c4-3ba51026ae6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175880833-172.17.0.12-1598350255745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-9493828b-bcca-4b93-85ef-f26b4ee1a303,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-8e3f2e0a-668a-41ca-98e2-24c341ff94f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-5b4be9ea-1cac-4a09-8cd0-d80c28ea5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-9c2b9219-60ab-4034-8508-0c78106c0d95,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-441acdaf-68e3-41f4-9eee-881b6d4e62c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-a949aba6-754e-43de-94db-5b93ef3bbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a3a8ba70-fb9e-494b-8011-26db5b158649,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8c7a3173-53c6-4db3-97c4-3ba51026ae6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654115929-172.17.0.12-1598350838441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-3a072339-f5a4-45f1-a3e8-950969bbb0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-604d3061-0702-40d2-83a0-71422c0b8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-8b725cff-7422-4461-bb4e-627eed6745e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-cf59e050-1e71-40ef-b45d-e74c194a2330,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-a19088ad-8a94-4fa5-ac62-27e011c8ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-0a415f20-45f6-4d41-8a45-1d00d67076b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-841e6def-1cfe-4af5-82b7-90355f7e6bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-3c22f0e1-680e-42a5-9c66-fdb5c0506726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654115929-172.17.0.12-1598350838441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-3a072339-f5a4-45f1-a3e8-950969bbb0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-604d3061-0702-40d2-83a0-71422c0b8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-8b725cff-7422-4461-bb4e-627eed6745e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-cf59e050-1e71-40ef-b45d-e74c194a2330,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-a19088ad-8a94-4fa5-ac62-27e011c8ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-0a415f20-45f6-4d41-8a45-1d00d67076b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-841e6def-1cfe-4af5-82b7-90355f7e6bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-3c22f0e1-680e-42a5-9c66-fdb5c0506726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000050560-172.17.0.12-1598351105016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-eccbb69c-00fa-4110-a95c-00760d5ab48b,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-93ba3e47-c4d9-45a9-98a4-299a7d2ab048,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-f5700614-8e9a-4844-95c0-5f7e5bd74aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-272626c6-37c5-4e15-92ea-2d1f95a4f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-195a3f99-0308-4456-a70b-068c470a237b,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-786e2bc5-69a9-4a2c-a3d9-e9427c3e2773,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-bf42841f-00e4-45d7-943e-c347df869111,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-8619e151-a30a-4615-9110-7a44de8b4645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000050560-172.17.0.12-1598351105016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-eccbb69c-00fa-4110-a95c-00760d5ab48b,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-93ba3e47-c4d9-45a9-98a4-299a7d2ab048,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-f5700614-8e9a-4844-95c0-5f7e5bd74aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-272626c6-37c5-4e15-92ea-2d1f95a4f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-195a3f99-0308-4456-a70b-068c470a237b,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-786e2bc5-69a9-4a2c-a3d9-e9427c3e2773,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-bf42841f-00e4-45d7-943e-c347df869111,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-8619e151-a30a-4615-9110-7a44de8b4645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588989510-172.17.0.12-1598352542976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-50e492e4-b64f-4b5e-b69d-be3b49dc30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-53869002-344c-4b41-8382-f36930520b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-2f38b030-2be2-460e-a543-4a48885ecfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-463e97e4-9e06-4d31-96b6-09956a3ebb85,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-7a61e862-12f6-4f0a-9375-c7d373988de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-4f7ce1bd-7abb-413b-b7bc-c5d282ef2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-da5c26aa-b0c9-477d-809b-bf5d0a00dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-39352f96-66cf-4790-b2c0-042385c15e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588989510-172.17.0.12-1598352542976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-50e492e4-b64f-4b5e-b69d-be3b49dc30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-53869002-344c-4b41-8382-f36930520b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-2f38b030-2be2-460e-a543-4a48885ecfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-463e97e4-9e06-4d31-96b6-09956a3ebb85,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-7a61e862-12f6-4f0a-9375-c7d373988de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-4f7ce1bd-7abb-413b-b7bc-c5d282ef2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-da5c26aa-b0c9-477d-809b-bf5d0a00dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-39352f96-66cf-4790-b2c0-042385c15e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138162174-172.17.0.12-1598352839890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-fad8c15f-9e66-4182-96ff-0c47cddd15e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-9ef9b1ec-03a9-4039-afe9-c5a3e2b8a849,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-e3e2b2e5-0bb0-4774-bd7c-f40b22d9e331,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-cf7ffeb0-b389-462a-afe7-ff4e07f3d703,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-6436ce29-a473-4895-8ff4-6d1d04459138,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-f27dbf45-2ff6-4b45-94be-b1cda5d897c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-19172004-d010-4037-97f7-eb63b870ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bda79ca7-79a8-4420-be44-3025d2427a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138162174-172.17.0.12-1598352839890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-fad8c15f-9e66-4182-96ff-0c47cddd15e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-9ef9b1ec-03a9-4039-afe9-c5a3e2b8a849,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-e3e2b2e5-0bb0-4774-bd7c-f40b22d9e331,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-cf7ffeb0-b389-462a-afe7-ff4e07f3d703,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-6436ce29-a473-4895-8ff4-6d1d04459138,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-f27dbf45-2ff6-4b45-94be-b1cda5d897c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-19172004-d010-4037-97f7-eb63b870ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bda79ca7-79a8-4420-be44-3025d2427a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349955842-172.17.0.12-1598353657187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-108aa7db-453e-40a9-96b5-dacb47407388,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-817cae7e-6251-4e43-a577-9a4994e56ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ddf8989e-66ed-4d44-9e7a-fbd16421a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-1c788038-99fc-4483-9c6a-bf001862e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-07186d74-9292-4258-b50c-cdf2575ec806,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2906742f-5c42-4a9c-a21c-b7ad6ebc8224,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-61500d17-7ef9-4a8d-9250-7135b89f8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-f59392eb-fc01-459f-9a35-8cc5694b4a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349955842-172.17.0.12-1598353657187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-108aa7db-453e-40a9-96b5-dacb47407388,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-817cae7e-6251-4e43-a577-9a4994e56ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ddf8989e-66ed-4d44-9e7a-fbd16421a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-1c788038-99fc-4483-9c6a-bf001862e9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-07186d74-9292-4258-b50c-cdf2575ec806,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2906742f-5c42-4a9c-a21c-b7ad6ebc8224,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-61500d17-7ef9-4a8d-9250-7135b89f8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-f59392eb-fc01-459f-9a35-8cc5694b4a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78135458-172.17.0.12-1598354017619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-22bcb2f7-f094-4e7e-a012-cecf1869db21,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-f475e144-b002-4b99-a982-9e4ad23698ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-c9552bd8-4c1e-4b25-aa10-28fc42ee4712,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-129f5c59-36e4-4e7d-a69e-43b047e877f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-b2e7bf01-4346-454f-9780-7746a03472e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-422c5982-9e06-43f7-923e-5a6a2a82f314,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-66fd642d-5d29-4b8d-ab2c-ef2ffdec6012,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-def8b845-f079-4fab-b4a8-abbe4c3ea6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78135458-172.17.0.12-1598354017619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-22bcb2f7-f094-4e7e-a012-cecf1869db21,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-f475e144-b002-4b99-a982-9e4ad23698ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-c9552bd8-4c1e-4b25-aa10-28fc42ee4712,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-129f5c59-36e4-4e7d-a69e-43b047e877f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-b2e7bf01-4346-454f-9780-7746a03472e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-422c5982-9e06-43f7-923e-5a6a2a82f314,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-66fd642d-5d29-4b8d-ab2c-ef2ffdec6012,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-def8b845-f079-4fab-b4a8-abbe4c3ea6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81836626-172.17.0.12-1598354151463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-7ea1f2a3-2c3c-415f-a50b-7af6947826da,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-fbf3fda7-4812-4c10-984c-5d8350d5c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-713902fd-2a0f-47d8-a893-60c4ded494f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-451b7610-47d8-40e2-a478-261b29f802cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-dceb6e4f-a489-41e5-a507-121947141269,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-9cce3868-4470-4e39-adbb-04347b0efee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-380256e8-7ca3-4cb0-96aa-8467b580bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-1a78f6b2-2f67-4b69-99a7-f17cdfa0623e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81836626-172.17.0.12-1598354151463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-7ea1f2a3-2c3c-415f-a50b-7af6947826da,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-fbf3fda7-4812-4c10-984c-5d8350d5c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-713902fd-2a0f-47d8-a893-60c4ded494f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-451b7610-47d8-40e2-a478-261b29f802cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-dceb6e4f-a489-41e5-a507-121947141269,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-9cce3868-4470-4e39-adbb-04347b0efee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-380256e8-7ca3-4cb0-96aa-8467b580bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-1a78f6b2-2f67-4b69-99a7-f17cdfa0623e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099220407-172.17.0.12-1598354425674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-2b80b274-3cba-4e3f-a77e-397e241bf658,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8b99b081-cb7d-4a59-998b-0b3c2ab8bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-79708074-a7ee-4a61-959f-6eac79785bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-9b731a37-2679-43d8-aff7-735e888a4009,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-baf07630-4ee0-4bfb-8b7c-c72e48192a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-27844962-83ea-44c7-8317-34651733b938,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-b7cd1242-e448-4939-83f8-fdf9ebdb3a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-5114490a-c30e-4317-89b9-979697e1757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099220407-172.17.0.12-1598354425674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-2b80b274-3cba-4e3f-a77e-397e241bf658,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8b99b081-cb7d-4a59-998b-0b3c2ab8bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-79708074-a7ee-4a61-959f-6eac79785bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-9b731a37-2679-43d8-aff7-735e888a4009,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-baf07630-4ee0-4bfb-8b7c-c72e48192a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-27844962-83ea-44c7-8317-34651733b938,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-b7cd1242-e448-4939-83f8-fdf9ebdb3a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-5114490a-c30e-4317-89b9-979697e1757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542992028-172.17.0.12-1598354491528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-d068bfba-f28b-453a-bb3b-6804cdf3c959,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-ef604969-00a9-4753-bd7e-7c294f4d6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-283ff0e3-27e5-4cff-a8b0-8a861cc010f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-629f8ac6-c58d-4b88-ab40-b5f2bde7ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-96e38e5f-c5aa-43e6-9712-9d8a961bdb31,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-16197be6-e230-4df8-a7da-d7b04a5029f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-c77b63c6-6c23-4a30-af2a-9bf387b5c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-24bcaf72-f5a3-4497-9a64-f9e9073c628e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542992028-172.17.0.12-1598354491528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-d068bfba-f28b-453a-bb3b-6804cdf3c959,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-ef604969-00a9-4753-bd7e-7c294f4d6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-283ff0e3-27e5-4cff-a8b0-8a861cc010f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-629f8ac6-c58d-4b88-ab40-b5f2bde7ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-96e38e5f-c5aa-43e6-9712-9d8a961bdb31,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-16197be6-e230-4df8-a7da-d7b04a5029f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-c77b63c6-6c23-4a30-af2a-9bf387b5c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-24bcaf72-f5a3-4497-9a64-f9e9073c628e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5165
