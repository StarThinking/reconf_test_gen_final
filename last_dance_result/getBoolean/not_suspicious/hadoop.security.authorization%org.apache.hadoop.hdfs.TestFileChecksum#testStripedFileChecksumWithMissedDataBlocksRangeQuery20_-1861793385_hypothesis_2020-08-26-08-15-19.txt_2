reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464404363-172.17.0.19-1598429730878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-84cf4f26-ab51-46f4-8f47-63c90d1db300,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-e8670d29-a971-4b93-9795-2a1bc3b70768,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-529c2080-eace-440c-9d7d-4b0630e02da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-cc713e21-ecfc-408a-90a8-7e8ca6e72612,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e21b52ed-39af-4c59-9d23-4486a31642da,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-2ba607f0-2d2d-4d86-b016-7ff18158be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-3b33e8cb-811b-4aa2-a2f5-1ad4c4c7cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8c535d47-4571-430b-aa70-514db01d3cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464404363-172.17.0.19-1598429730878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-84cf4f26-ab51-46f4-8f47-63c90d1db300,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-e8670d29-a971-4b93-9795-2a1bc3b70768,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-529c2080-eace-440c-9d7d-4b0630e02da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-cc713e21-ecfc-408a-90a8-7e8ca6e72612,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e21b52ed-39af-4c59-9d23-4486a31642da,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-2ba607f0-2d2d-4d86-b016-7ff18158be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-3b33e8cb-811b-4aa2-a2f5-1ad4c4c7cca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8c535d47-4571-430b-aa70-514db01d3cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827812240-172.17.0.19-1598429766138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-ba1b933f-1e1c-45b5-a7a8-5ee6d5ca08f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c05a2ab8-4d9f-4dd3-98e2-9c81a2f32671,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-be293f0d-2009-41eb-9ae7-6d0e7f0e6450,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-4e3accfd-eac1-4c24-9526-371ce9ae57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-92f7199a-6f11-4b0b-b915-ab6c9cf2026b,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-240e83ea-3555-4774-9a61-35ba2702417a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-c06d39f6-0974-4b51-938f-3459c563818b,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-e2abbacd-0b5e-4cc6-8af8-33d4d8290534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827812240-172.17.0.19-1598429766138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-ba1b933f-1e1c-45b5-a7a8-5ee6d5ca08f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c05a2ab8-4d9f-4dd3-98e2-9c81a2f32671,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-be293f0d-2009-41eb-9ae7-6d0e7f0e6450,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-4e3accfd-eac1-4c24-9526-371ce9ae57d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-92f7199a-6f11-4b0b-b915-ab6c9cf2026b,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-240e83ea-3555-4774-9a61-35ba2702417a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-c06d39f6-0974-4b51-938f-3459c563818b,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-e2abbacd-0b5e-4cc6-8af8-33d4d8290534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615913682-172.17.0.19-1598430000064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-c70b9817-e12e-4e04-8eea-869f05719bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-850205b7-5c93-4ab2-9b10-3bb522d9949f,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c1d5e7d4-1189-4f61-a4da-6726afabb381,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-6dd5e80e-2e6c-413d-acd1-55703fc79137,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-c7c5d4be-2cba-43cf-89c3-3a6a098a0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-c130445d-6743-49c6-b3ec-29569c39cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-85a810eb-4052-4ecc-b65f-6df0eb308ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-fc9f9c3e-4a84-442d-bd4c-c23f2ad074bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615913682-172.17.0.19-1598430000064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-c70b9817-e12e-4e04-8eea-869f05719bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-850205b7-5c93-4ab2-9b10-3bb522d9949f,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c1d5e7d4-1189-4f61-a4da-6726afabb381,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-6dd5e80e-2e6c-413d-acd1-55703fc79137,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-c7c5d4be-2cba-43cf-89c3-3a6a098a0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-c130445d-6743-49c6-b3ec-29569c39cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-85a810eb-4052-4ecc-b65f-6df0eb308ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-fc9f9c3e-4a84-442d-bd4c-c23f2ad074bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364171457-172.17.0.19-1598430038635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-2b7254aa-094c-4cbe-abab-4e3805f9a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-f4606219-0dc7-46fe-acc3-c17dc63ab0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-01bf86ea-276c-4134-b441-87c3e913549f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-df5b0271-1593-46d0-abff-a5aeec047691,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-b7ec21b1-0f3a-4916-a5a8-3bf62c9002d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a99038dc-e207-4a1d-9a11-953b22c0d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-db6270e5-0d57-4b5c-8329-86ea0b6f8245,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-ac0fe4c1-4cb8-485b-93ed-e1861a68c468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364171457-172.17.0.19-1598430038635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-2b7254aa-094c-4cbe-abab-4e3805f9a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-f4606219-0dc7-46fe-acc3-c17dc63ab0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-01bf86ea-276c-4134-b441-87c3e913549f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-df5b0271-1593-46d0-abff-a5aeec047691,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-b7ec21b1-0f3a-4916-a5a8-3bf62c9002d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a99038dc-e207-4a1d-9a11-953b22c0d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-db6270e5-0d57-4b5c-8329-86ea0b6f8245,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-ac0fe4c1-4cb8-485b-93ed-e1861a68c468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510572913-172.17.0.19-1598430284722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-50b3c74c-af22-453b-80df-92e695448544,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-3780e221-9e82-43c1-bc19-97f0d30cea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-7872f172-fd00-41d6-b43e-895f251f1642,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-9a06fdc6-9da1-459c-a21d-7fbac64ec6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-875be4a7-6ed0-4082-ba51-3542621e4549,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-ff0bf648-659c-4667-a68b-e6c6928e54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-69adba1c-85e0-42b5-a311-82d6c40d7430,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-808fb038-4496-4d0d-ab9d-bf72ed4fc6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510572913-172.17.0.19-1598430284722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-50b3c74c-af22-453b-80df-92e695448544,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-3780e221-9e82-43c1-bc19-97f0d30cea3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-7872f172-fd00-41d6-b43e-895f251f1642,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-9a06fdc6-9da1-459c-a21d-7fbac64ec6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-875be4a7-6ed0-4082-ba51-3542621e4549,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-ff0bf648-659c-4667-a68b-e6c6928e54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-69adba1c-85e0-42b5-a311-82d6c40d7430,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-808fb038-4496-4d0d-ab9d-bf72ed4fc6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504881126-172.17.0.19-1598430996492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-5057cd68-1348-45fa-92bc-fa892b72b071,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-79e93554-1a19-4409-8fd6-cf224198e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-30840f42-02ad-4df2-8ce7-4df52bedccff,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-4edc63d6-177a-489e-8e39-14205738e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-8a67128d-c4b4-40f9-b41d-fceacaee8fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-2c9ef055-f00e-46a1-82d6-5e11b6515c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-8cf1ebb9-637c-4000-b47b-598816ec3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-73fe9552-7a13-4be4-830a-a205da5beb03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504881126-172.17.0.19-1598430996492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-5057cd68-1348-45fa-92bc-fa892b72b071,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-79e93554-1a19-4409-8fd6-cf224198e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-30840f42-02ad-4df2-8ce7-4df52bedccff,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-4edc63d6-177a-489e-8e39-14205738e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-8a67128d-c4b4-40f9-b41d-fceacaee8fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-2c9ef055-f00e-46a1-82d6-5e11b6515c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-8cf1ebb9-637c-4000-b47b-598816ec3f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-73fe9552-7a13-4be4-830a-a205da5beb03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529061358-172.17.0.19-1598431368309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-3be78948-c7ff-43ae-b603-6f0bc30e6de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-4ea94f07-8347-42fe-855e-4d8c695bea41,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-8af77e16-9c2f-43ce-94a9-148e721c17a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-c388aa72-e5e1-44a1-93c0-e73000cdb878,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-d2a6d18b-6a97-4c9a-8916-4166ae9e8341,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-e3327961-749a-4b48-8d86-b70b7c3fb001,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-2dfdc373-b11f-4740-bfee-0c0472aca386,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-049f9aac-7066-4a83-998d-829db322404b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529061358-172.17.0.19-1598431368309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-3be78948-c7ff-43ae-b603-6f0bc30e6de3,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-4ea94f07-8347-42fe-855e-4d8c695bea41,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-8af77e16-9c2f-43ce-94a9-148e721c17a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-c388aa72-e5e1-44a1-93c0-e73000cdb878,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-d2a6d18b-6a97-4c9a-8916-4166ae9e8341,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-e3327961-749a-4b48-8d86-b70b7c3fb001,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-2dfdc373-b11f-4740-bfee-0c0472aca386,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-049f9aac-7066-4a83-998d-829db322404b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263379015-172.17.0.19-1598431578584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-7b1de1a1-ee93-493c-875b-824009af9be7,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-3425fded-9e37-4cb3-99d4-80c4fc771b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-79bdb3ba-6afe-4273-9109-07417a5a5422,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0a222320-f349-481b-868e-3bd9d51e304a,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-1cca6b6b-4f55-4b14-96af-17df2e878757,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-31680d55-a27f-4c5c-b9e0-39d160a2c852,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-88e3e9d3-703b-44e9-bc9c-2e6cb6e39c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-36a7c14e-014b-4351-982b-cbb51944e497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263379015-172.17.0.19-1598431578584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-7b1de1a1-ee93-493c-875b-824009af9be7,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-3425fded-9e37-4cb3-99d4-80c4fc771b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-79bdb3ba-6afe-4273-9109-07417a5a5422,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0a222320-f349-481b-868e-3bd9d51e304a,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-1cca6b6b-4f55-4b14-96af-17df2e878757,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-31680d55-a27f-4c5c-b9e0-39d160a2c852,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-88e3e9d3-703b-44e9-bc9c-2e6cb6e39c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-36a7c14e-014b-4351-982b-cbb51944e497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784787425-172.17.0.19-1598431984140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36586,DS-a2b79aaf-4ec4-45d7-98f5-dcf183183f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-f71f56d6-1d4b-4376-acd9-4fe7b4a43e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-0c33ca05-6745-4ff5-8e39-697609db84f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ba15dd0d-1814-4ede-883d-d0369e8cdbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-4439a6db-ea58-4697-8bb7-311d697ee705,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-fe720985-2af0-4749-8883-af2966e328fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-8b7b2618-a617-49a0-8778-1803f659d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-08fe02b0-54fe-46ff-ab00-bc8b4e088608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784787425-172.17.0.19-1598431984140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36586,DS-a2b79aaf-4ec4-45d7-98f5-dcf183183f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-f71f56d6-1d4b-4376-acd9-4fe7b4a43e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-0c33ca05-6745-4ff5-8e39-697609db84f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ba15dd0d-1814-4ede-883d-d0369e8cdbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-4439a6db-ea58-4697-8bb7-311d697ee705,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-fe720985-2af0-4749-8883-af2966e328fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-8b7b2618-a617-49a0-8778-1803f659d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-08fe02b0-54fe-46ff-ab00-bc8b4e088608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050761289-172.17.0.19-1598432709225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-7b4dd065-d87e-4366-b10c-49d3102ea153,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-92b8d4f2-86cd-4535-b0ad-a19af33cdff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-d6146b09-8ece-4247-b2f5-c86c02a5ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-5e27674e-24d1-4a94-8a79-5d9b176c2086,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-5ce086c1-fbc4-4dc1-a14d-cd97c80ec8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-23929b15-9598-4dac-8645-8e8036daafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-05b6d241-f04a-48d3-8db7-edbb97c44272,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b995b252-0c3e-4a11-9af4-cb07c26ce667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050761289-172.17.0.19-1598432709225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-7b4dd065-d87e-4366-b10c-49d3102ea153,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-92b8d4f2-86cd-4535-b0ad-a19af33cdff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-d6146b09-8ece-4247-b2f5-c86c02a5ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-5e27674e-24d1-4a94-8a79-5d9b176c2086,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-5ce086c1-fbc4-4dc1-a14d-cd97c80ec8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-23929b15-9598-4dac-8645-8e8036daafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-05b6d241-f04a-48d3-8db7-edbb97c44272,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b995b252-0c3e-4a11-9af4-cb07c26ce667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603352486-172.17.0.19-1598433933907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-c79048e8-4fc9-474c-94b2-62ed4cb0afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2ea409c5-0602-474d-9290-b29a37bb3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-a853585c-c59d-4804-bb5c-84447cfcb702,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-7e364f61-5831-4dd3-886c-006f54418cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-da8b5c95-a449-4ce7-85da-7401ecebfffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-b7fc2361-c8e1-49a4-be9a-320a53030d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-5553b52f-7451-4d70-92bd-88872038e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-329e0b1f-ff74-4d10-a1bf-6af292956744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603352486-172.17.0.19-1598433933907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-c79048e8-4fc9-474c-94b2-62ed4cb0afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2ea409c5-0602-474d-9290-b29a37bb3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-a853585c-c59d-4804-bb5c-84447cfcb702,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-7e364f61-5831-4dd3-886c-006f54418cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-da8b5c95-a449-4ce7-85da-7401ecebfffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-b7fc2361-c8e1-49a4-be9a-320a53030d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-5553b52f-7451-4d70-92bd-88872038e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-329e0b1f-ff74-4d10-a1bf-6af292956744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353669570-172.17.0.19-1598433997336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-37b8fb01-06e8-4c87-b71c-2f05f5e7aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-7610d4cb-ca30-4c42-b3d7-bae605ffa6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-c18d07a7-cd4a-492c-8ac4-1712edc90ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-2ba6cd65-f86c-43e7-aeaf-30d4067666f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-f83146be-5e95-4e86-8f62-f59a7748344c,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-78bfff90-2c1a-432c-a0a8-cd12cec16242,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-2d3469d7-9b19-4b80-bf51-fa7ed3fc5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-bc541eda-f2b7-416a-91aa-27ee9c9bed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353669570-172.17.0.19-1598433997336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-37b8fb01-06e8-4c87-b71c-2f05f5e7aeac,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-7610d4cb-ca30-4c42-b3d7-bae605ffa6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-c18d07a7-cd4a-492c-8ac4-1712edc90ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-2ba6cd65-f86c-43e7-aeaf-30d4067666f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-f83146be-5e95-4e86-8f62-f59a7748344c,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-78bfff90-2c1a-432c-a0a8-cd12cec16242,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-2d3469d7-9b19-4b80-bf51-fa7ed3fc5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-bc541eda-f2b7-416a-91aa-27ee9c9bed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5233
