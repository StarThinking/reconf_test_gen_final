reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773957643-172.17.0.13-1598111303174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-0ad726e3-0308-49b6-ac61-0d0102d6938c,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-547a7f27-3ab9-41cf-81b6-467c09c1559a,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-c58c8a9e-1fbf-4e98-90aa-aadb55156fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-c76c1fa6-894f-4a94-aed5-7f30ddb05130,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-0b1ebf7a-2613-4618-9097-c490fde0cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-6459c6d3-2bcc-4bf7-b195-9e07323254b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-af5cb0d6-4c28-4109-895b-ac2f4403b843,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-510ef6ec-a9d0-4051-9443-17fef3d5d107,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773957643-172.17.0.13-1598111303174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36683,DS-0ad726e3-0308-49b6-ac61-0d0102d6938c,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-547a7f27-3ab9-41cf-81b6-467c09c1559a,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-c58c8a9e-1fbf-4e98-90aa-aadb55156fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-c76c1fa6-894f-4a94-aed5-7f30ddb05130,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-0b1ebf7a-2613-4618-9097-c490fde0cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-6459c6d3-2bcc-4bf7-b195-9e07323254b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-af5cb0d6-4c28-4109-895b-ac2f4403b843,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-510ef6ec-a9d0-4051-9443-17fef3d5d107,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460510706-172.17.0.13-1598111388719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42074,DS-98c3e608-305e-468d-8001-5593d8472626,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-881a4d22-8ceb-45fd-8b96-2dfc3d28a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-2dead9bd-5991-4a49-a10b-6e1c16cae40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-9b0fea39-2b01-4486-99f9-7c2a38703cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-75a7e4af-29ba-4095-bbe9-cef323c3e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-7ced4aa9-4af1-4419-8e5f-695ac02ced84,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-57b7d5eb-6948-4cb6-b013-dcbcd9776ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-b97b6fcf-ab60-4447-af39-4206116d0f78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460510706-172.17.0.13-1598111388719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42074,DS-98c3e608-305e-468d-8001-5593d8472626,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-881a4d22-8ceb-45fd-8b96-2dfc3d28a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-2dead9bd-5991-4a49-a10b-6e1c16cae40e,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-9b0fea39-2b01-4486-99f9-7c2a38703cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-75a7e4af-29ba-4095-bbe9-cef323c3e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-7ced4aa9-4af1-4419-8e5f-695ac02ced84,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-57b7d5eb-6948-4cb6-b013-dcbcd9776ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-b97b6fcf-ab60-4447-af39-4206116d0f78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866446471-172.17.0.13-1598111429069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-d3c0e7a3-676d-4431-9c5d-d3fe3e76ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-663ad817-9ebf-4dd9-91a8-3b7d9408cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-657b71e6-e56e-43d7-abb5-c63c33253c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-dcfcb669-81ef-46e9-8e38-f11b9643d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-49c0e4f4-b0ed-48fd-b1f1-0ee6cbe9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-747ebed6-9f5d-4662-9283-b2ba415f58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-d1cab6f9-10af-40a4-adae-115e2092dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-c619a400-c8b4-473d-bfa8-bebf9964c915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866446471-172.17.0.13-1598111429069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-d3c0e7a3-676d-4431-9c5d-d3fe3e76ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-663ad817-9ebf-4dd9-91a8-3b7d9408cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-657b71e6-e56e-43d7-abb5-c63c33253c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-dcfcb669-81ef-46e9-8e38-f11b9643d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-49c0e4f4-b0ed-48fd-b1f1-0ee6cbe9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-747ebed6-9f5d-4662-9283-b2ba415f58f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-d1cab6f9-10af-40a4-adae-115e2092dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-c619a400-c8b4-473d-bfa8-bebf9964c915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525487143-172.17.0.13-1598111737978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-d147be70-4916-4433-9839-8ab74873ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f5c12a2f-3071-4ac9-83c0-e231eff14b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-7d309b82-1376-46cb-9f65-71de2b3512e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-6f429267-aa7e-438e-8e4a-2e36e278586c,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-c78aa897-72b9-47cd-ada0-b27356b9ee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-bf0e7b9e-8076-46ff-bb49-7855f20e759f,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-21ab99b5-87cf-415a-8769-4a301f5daef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-ecd26170-0c3e-4bb1-95f2-833f29e596d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525487143-172.17.0.13-1598111737978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-d147be70-4916-4433-9839-8ab74873ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f5c12a2f-3071-4ac9-83c0-e231eff14b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-7d309b82-1376-46cb-9f65-71de2b3512e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-6f429267-aa7e-438e-8e4a-2e36e278586c,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-c78aa897-72b9-47cd-ada0-b27356b9ee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-bf0e7b9e-8076-46ff-bb49-7855f20e759f,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-21ab99b5-87cf-415a-8769-4a301f5daef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-ecd26170-0c3e-4bb1-95f2-833f29e596d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717762277-172.17.0.13-1598112270517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-60b2def3-334d-4c0e-b3b5-54c31ead3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b5f12dda-96f4-4e39-aa00-dfee4cd5df25,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-4aaf27d9-d12a-4d6a-acbc-a832ae9d0723,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-5f033b94-c95c-4f67-a099-e23f09ab0de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-db5d34bc-a347-4fdd-bbd5-c4643daf227a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-00d49cb9-e2dc-4778-992f-da6b69429be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-131d62e7-0acc-43ba-a25e-fd9dd8d04543,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-e46515cb-2522-401f-9a44-d7df8244900f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717762277-172.17.0.13-1598112270517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-60b2def3-334d-4c0e-b3b5-54c31ead3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b5f12dda-96f4-4e39-aa00-dfee4cd5df25,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-4aaf27d9-d12a-4d6a-acbc-a832ae9d0723,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-5f033b94-c95c-4f67-a099-e23f09ab0de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-db5d34bc-a347-4fdd-bbd5-c4643daf227a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-00d49cb9-e2dc-4778-992f-da6b69429be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-131d62e7-0acc-43ba-a25e-fd9dd8d04543,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-e46515cb-2522-401f-9a44-d7df8244900f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421821918-172.17.0.13-1598112317418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-edce4406-9729-4556-9b92-9eb6fa5513bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-8fb0a650-f57e-40f7-83be-a80ef84bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-d3afc74f-59ee-475d-a0c3-c11a94f8257e,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-226a7eff-5f5a-4003-ac30-f8912272b03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-0e31ce60-8afb-4700-b21b-bd24694b008c,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-5994d907-d78f-4e7e-aba7-2959d74586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-4f7d628a-a161-48e8-a5a6-55d45d8bc34f,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-dfcf127d-dc6a-4494-a4c0-3f694de924fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421821918-172.17.0.13-1598112317418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-edce4406-9729-4556-9b92-9eb6fa5513bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-8fb0a650-f57e-40f7-83be-a80ef84bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-d3afc74f-59ee-475d-a0c3-c11a94f8257e,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-226a7eff-5f5a-4003-ac30-f8912272b03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-0e31ce60-8afb-4700-b21b-bd24694b008c,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-5994d907-d78f-4e7e-aba7-2959d74586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-4f7d628a-a161-48e8-a5a6-55d45d8bc34f,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-dfcf127d-dc6a-4494-a4c0-3f694de924fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871779268-172.17.0.13-1598112667143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35529,DS-792b0b21-cb06-47d1-a48a-5f31c1e81014,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-fd8ac405-321c-405f-8398-e996c8cad2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-06295639-b733-41b3-8167-3d85e109ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-299d041f-f07b-4efa-a6dd-18c26979f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-c618ea5e-08ca-4eb2-8e14-5cad29a82999,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-bc9e7e67-8cfa-47b2-91f9-a32bee116fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-c2d371ce-259d-4588-ad93-5b076a198d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-6785ee3b-539d-41c6-b134-24f4ff9c2c6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871779268-172.17.0.13-1598112667143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35529,DS-792b0b21-cb06-47d1-a48a-5f31c1e81014,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-fd8ac405-321c-405f-8398-e996c8cad2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-06295639-b733-41b3-8167-3d85e109ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-299d041f-f07b-4efa-a6dd-18c26979f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-c618ea5e-08ca-4eb2-8e14-5cad29a82999,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-bc9e7e67-8cfa-47b2-91f9-a32bee116fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-c2d371ce-259d-4588-ad93-5b076a198d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-6785ee3b-539d-41c6-b134-24f4ff9c2c6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706850869-172.17.0.13-1598112843833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-701d624f-1173-4be4-8228-2e492480ea48,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-bbfd583e-fbb0-4ad0-aae5-8247cbe7f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-6d0fe7a8-2dce-4abc-aaf7-62732bd2e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-0bc1676e-7c0d-4548-b983-c43956025cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-2689cbf5-7085-462e-a04f-cc8ee88d99e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-3f257c67-dade-4abc-8290-1817a279f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-bb33c068-0091-4f04-a98d-9b164592a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-defab766-2000-4b0a-926d-e1ea11d6df8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706850869-172.17.0.13-1598112843833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-701d624f-1173-4be4-8228-2e492480ea48,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-bbfd583e-fbb0-4ad0-aae5-8247cbe7f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-6d0fe7a8-2dce-4abc-aaf7-62732bd2e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-0bc1676e-7c0d-4548-b983-c43956025cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-2689cbf5-7085-462e-a04f-cc8ee88d99e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-3f257c67-dade-4abc-8290-1817a279f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-bb33c068-0091-4f04-a98d-9b164592a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-defab766-2000-4b0a-926d-e1ea11d6df8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514416597-172.17.0.13-1598113025382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-c3b51400-7ee9-4f5d-a5e0-ada1108447d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-78b2fb77-f4e4-4e80-8b7a-438e195a1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-5716ee41-83cc-4aad-a10a-4691d9ae430f,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0264c8fa-1088-42ac-8ee9-9e8f5dd34363,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-d7da3845-f879-47b1-8f92-2e074ab64a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-122310e0-5837-425c-aae6-aed666b71457,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1c148e44-2fd0-45e1-945c-adf2213af648,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-4bf9c22f-f46e-4624-8432-88eef6ac9e76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514416597-172.17.0.13-1598113025382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-c3b51400-7ee9-4f5d-a5e0-ada1108447d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-78b2fb77-f4e4-4e80-8b7a-438e195a1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-5716ee41-83cc-4aad-a10a-4691d9ae430f,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0264c8fa-1088-42ac-8ee9-9e8f5dd34363,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-d7da3845-f879-47b1-8f92-2e074ab64a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-122310e0-5837-425c-aae6-aed666b71457,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1c148e44-2fd0-45e1-945c-adf2213af648,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-4bf9c22f-f46e-4624-8432-88eef6ac9e76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186689226-172.17.0.13-1598113123006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-b4107d83-2790-43fb-9913-5860de162895,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-4c1ff0ec-3add-4b58-84de-e470bc967656,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-b810b520-389c-4c8e-9ab4-eea16c19cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-bf249985-3e39-441d-99ad-215dd8463a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-d25f9f49-1c53-4cc6-8339-e324450ee013,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-35695a3f-7e1b-44d5-9c99-3a19c33ea702,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-8562808e-a291-41b7-81fd-b5a80f9e526e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-82e0f701-cec1-40ed-8592-7d6579abaec4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186689226-172.17.0.13-1598113123006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33277,DS-b4107d83-2790-43fb-9913-5860de162895,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-4c1ff0ec-3add-4b58-84de-e470bc967656,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-b810b520-389c-4c8e-9ab4-eea16c19cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-bf249985-3e39-441d-99ad-215dd8463a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-d25f9f49-1c53-4cc6-8339-e324450ee013,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-35695a3f-7e1b-44d5-9c99-3a19c33ea702,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-8562808e-a291-41b7-81fd-b5a80f9e526e,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-82e0f701-cec1-40ed-8592-7d6579abaec4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438718760-172.17.0.13-1598113219088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-4bfe41e8-6761-4c65-a8c7-7ddcf56033cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-998faece-dcb3-4982-81fd-0f624a5129d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-c13bb8ab-b43b-4ef3-91db-0e6d1f9c428d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-ef36848b-97e4-4e02-b916-2b244f49f896,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-70a132a0-b74f-46d3-bea3-dd69b9109ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-54df2d91-9b93-4fc0-b604-9a477f73db75,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-f7011846-b2d5-4339-b58c-9e8424da4132,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-9c26bd51-51f7-47aa-83ee-1463998075ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438718760-172.17.0.13-1598113219088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-4bfe41e8-6761-4c65-a8c7-7ddcf56033cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-998faece-dcb3-4982-81fd-0f624a5129d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-c13bb8ab-b43b-4ef3-91db-0e6d1f9c428d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-ef36848b-97e4-4e02-b916-2b244f49f896,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-70a132a0-b74f-46d3-bea3-dd69b9109ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-54df2d91-9b93-4fc0-b604-9a477f73db75,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-f7011846-b2d5-4339-b58c-9e8424da4132,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-9c26bd51-51f7-47aa-83ee-1463998075ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130830568-172.17.0.13-1598113264372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-ec2b8b6e-eca3-402d-b5a1-048940b38a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-8149e7e2-4d7c-43ce-a7ad-cf4700f13266,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-6c756356-5ef0-4b04-a648-8b588465c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-3dd177c5-a98d-4531-8b6d-e8ba02c3e8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-26a6216d-8af2-41e2-8bdc-12150be27d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-652ebdfc-5f4f-405d-a4ae-69c602f5a330,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-10de2a46-59ba-405c-ac91-02f12657bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-7a6ef28e-4d3f-4ad8-a19b-239da564af39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130830568-172.17.0.13-1598113264372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-ec2b8b6e-eca3-402d-b5a1-048940b38a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-8149e7e2-4d7c-43ce-a7ad-cf4700f13266,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-6c756356-5ef0-4b04-a648-8b588465c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-3dd177c5-a98d-4531-8b6d-e8ba02c3e8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-26a6216d-8af2-41e2-8bdc-12150be27d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-652ebdfc-5f4f-405d-a4ae-69c602f5a330,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-10de2a46-59ba-405c-ac91-02f12657bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-7a6ef28e-4d3f-4ad8-a19b-239da564af39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615026254-172.17.0.13-1598113506183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-ad1372a9-658b-446d-866b-10047be40cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-2c8c7616-0324-40df-bdd4-bf6299336a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-040b0774-0276-4fe1-92bc-1ddaa4262192,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-5d17cb3e-bb7a-4b7c-a86e-6cd340e51b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-294879ff-208d-4b95-8ad4-54417f5a3363,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-9717bcf5-cee1-4670-b678-40941c562fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-f6bfaf80-3099-4348-ac64-194befa402f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-e10562e1-63eb-4c2d-a95c-8911c5a5e148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615026254-172.17.0.13-1598113506183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-ad1372a9-658b-446d-866b-10047be40cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-2c8c7616-0324-40df-bdd4-bf6299336a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-040b0774-0276-4fe1-92bc-1ddaa4262192,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-5d17cb3e-bb7a-4b7c-a86e-6cd340e51b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-294879ff-208d-4b95-8ad4-54417f5a3363,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-9717bcf5-cee1-4670-b678-40941c562fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-f6bfaf80-3099-4348-ac64-194befa402f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-e10562e1-63eb-4c2d-a95c-8911c5a5e148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719144712-172.17.0.13-1598113557469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-2ca1c4b3-5e22-4997-88e7-4b1eb9395257,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-bd3dacc8-ca40-45f6-baf7-d7173c5298c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-43ff8cca-8f08-46eb-9288-c4b26452e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-6f415704-1548-418a-9145-ec58bca01cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-cde962f2-6f0b-4738-bb00-cec8b552b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-763c9014-0d38-4eca-adea-870154b2f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-e337bfcf-f27d-48a6-9dde-554841b9f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-96476143-6137-4595-b0a8-318dbe8cf1c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719144712-172.17.0.13-1598113557469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-2ca1c4b3-5e22-4997-88e7-4b1eb9395257,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-bd3dacc8-ca40-45f6-baf7-d7173c5298c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-43ff8cca-8f08-46eb-9288-c4b26452e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-6f415704-1548-418a-9145-ec58bca01cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-cde962f2-6f0b-4738-bb00-cec8b552b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-763c9014-0d38-4eca-adea-870154b2f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-e337bfcf-f27d-48a6-9dde-554841b9f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-96476143-6137-4595-b0a8-318dbe8cf1c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452242363-172.17.0.13-1598113696571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40175,DS-f127d7bb-ab6e-4e20-997e-b967e3d4c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b474922b-fef8-4cae-9c02-1d27c544ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-7ff4eb29-b9d9-49f1-9898-fcf4e7f5a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-636c59b8-20d5-4ee0-9bbe-870cd93ca3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-b5820eef-0a25-429b-8cc6-08ee450049a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-314a8937-9de5-4e42-b82c-7353f50d5738,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-c3f50e66-a166-48f9-bc85-1f463f37bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-9846c66b-1294-4cae-9f7b-6773a11c57a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452242363-172.17.0.13-1598113696571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40175,DS-f127d7bb-ab6e-4e20-997e-b967e3d4c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-b474922b-fef8-4cae-9c02-1d27c544ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-7ff4eb29-b9d9-49f1-9898-fcf4e7f5a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-636c59b8-20d5-4ee0-9bbe-870cd93ca3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-b5820eef-0a25-429b-8cc6-08ee450049a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-314a8937-9de5-4e42-b82c-7353f50d5738,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-c3f50e66-a166-48f9-bc85-1f463f37bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-9846c66b-1294-4cae-9f7b-6773a11c57a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073767221-172.17.0.13-1598113865959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32924,DS-f1fc8840-553e-4a78-aaf1-8a8ba3542daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-efc265d9-6cd8-468f-af27-087757248e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-5a7682c4-1cfe-4d15-9e72-1212a05d20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-7e844b14-6ca4-44db-9ea1-bd97c598adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-cc32eb9b-fce6-4920-b8a7-aa9bfc0affc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-8d268fdc-7b47-4d0d-9c3d-5bc04ff8686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-070cd3c1-1378-4b89-a318-57c69183f02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-e10d5b0f-7adb-475b-9343-bb51634241b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073767221-172.17.0.13-1598113865959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32924,DS-f1fc8840-553e-4a78-aaf1-8a8ba3542daf,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-efc265d9-6cd8-468f-af27-087757248e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-5a7682c4-1cfe-4d15-9e72-1212a05d20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-7e844b14-6ca4-44db-9ea1-bd97c598adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-cc32eb9b-fce6-4920-b8a7-aa9bfc0affc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-8d268fdc-7b47-4d0d-9c3d-5bc04ff8686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-070cd3c1-1378-4b89-a318-57c69183f02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-e10d5b0f-7adb-475b-9343-bb51634241b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88480097-172.17.0.13-1598114130576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-c30be6d0-58b6-4ae7-8044-848c06f243ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-db299e9f-1034-4586-b198-19bf6c094156,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-438afc70-c341-4b27-9e05-d2381416d664,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-da2ba529-ef2f-464c-890e-6a59ae45ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-74143591-45a3-43e9-a9e7-7507f009dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-a657e2d3-ec15-451f-aaf6-38271df5816f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-7ccd9519-b254-4b8a-b6ea-7e3fb6318732,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-b3483160-5c00-490d-abb2-5a9fc3c5dfcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88480097-172.17.0.13-1598114130576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-c30be6d0-58b6-4ae7-8044-848c06f243ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-db299e9f-1034-4586-b198-19bf6c094156,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-438afc70-c341-4b27-9e05-d2381416d664,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-da2ba529-ef2f-464c-890e-6a59ae45ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-74143591-45a3-43e9-a9e7-7507f009dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-a657e2d3-ec15-451f-aaf6-38271df5816f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-7ccd9519-b254-4b8a-b6ea-7e3fb6318732,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-b3483160-5c00-490d-abb2-5a9fc3c5dfcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218080602-172.17.0.13-1598114437217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-8b3d6967-f35d-4652-8393-168562f52ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-9cea9fa0-83f0-494a-a4fb-3c865de32d04,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-1dfe0671-5011-469e-bde6-e97fef10ac37,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-159b7272-aaa9-4332-82d4-0b275d9f434f,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-593f51a2-d3eb-4581-bf53-7d8b951a9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-d30889ab-cafd-4355-916a-7a9e00cb08a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-579238e7-20cd-43ae-b256-920ce40a1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-2427c8be-cfdf-4437-a5cb-94b9880e9a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218080602-172.17.0.13-1598114437217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-8b3d6967-f35d-4652-8393-168562f52ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-9cea9fa0-83f0-494a-a4fb-3c865de32d04,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-1dfe0671-5011-469e-bde6-e97fef10ac37,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-159b7272-aaa9-4332-82d4-0b275d9f434f,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-593f51a2-d3eb-4581-bf53-7d8b951a9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-d30889ab-cafd-4355-916a-7a9e00cb08a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-579238e7-20cd-43ae-b256-920ce40a1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-2427c8be-cfdf-4437-a5cb-94b9880e9a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887673876-172.17.0.13-1598114854501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-04b2055f-e0e8-4718-a5ef-1f2ea93fc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-3e0ae47d-4bb1-44f6-90b2-a6d5a830841f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-29b386f9-c1b9-44aa-bead-548fbf9e5779,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-8b2e2d54-9099-4a19-a3f9-c0962c4a17d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e4f2831f-73bf-45bd-b58c-8d7ff98561bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3a69b20d-9b98-42b1-a805-4d05d3093714,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-10511b2a-8060-4b5f-93ab-2bc6ed3b873a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-46952cae-a879-47eb-b5fd-43cc2d14b3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887673876-172.17.0.13-1598114854501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37821,DS-04b2055f-e0e8-4718-a5ef-1f2ea93fc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-3e0ae47d-4bb1-44f6-90b2-a6d5a830841f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-29b386f9-c1b9-44aa-bead-548fbf9e5779,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-8b2e2d54-9099-4a19-a3f9-c0962c4a17d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e4f2831f-73bf-45bd-b58c-8d7ff98561bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3a69b20d-9b98-42b1-a805-4d05d3093714,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-10511b2a-8060-4b5f-93ab-2bc6ed3b873a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-46952cae-a879-47eb-b5fd-43cc2d14b3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493592690-172.17.0.13-1598115194611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-f13fa022-723b-4def-ac0d-1710271ff837,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-cba2e56c-d0a5-47c8-aa6b-c31a7f514817,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-bd0c0555-ac61-479c-ace3-ccceea94acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-71fc669f-ab25-4f76-9194-55b55ba51f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-85aa36bf-8527-4356-ba91-69739f14113b,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-88a1430f-ff77-4cb1-ae39-fe78ba5b00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-3f32851e-f604-4186-a6de-60112b252be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-64032846-ecc9-4e22-9f9d-3dc62b0c2362,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493592690-172.17.0.13-1598115194611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-f13fa022-723b-4def-ac0d-1710271ff837,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-cba2e56c-d0a5-47c8-aa6b-c31a7f514817,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-bd0c0555-ac61-479c-ace3-ccceea94acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-71fc669f-ab25-4f76-9194-55b55ba51f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-85aa36bf-8527-4356-ba91-69739f14113b,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-88a1430f-ff77-4cb1-ae39-fe78ba5b00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-3f32851e-f604-4186-a6de-60112b252be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-64032846-ecc9-4e22-9f9d-3dc62b0c2362,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93768234-172.17.0.13-1598115238467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-c1f463f0-d519-460c-998c-43b3c31204f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-4252c039-b689-4ae6-92f2-df19a7cb9514,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2141b6c9-6102-4709-998b-9be4e25d5a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-3a227bf7-8904-4f82-bd8c-620117713cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c893c802-c33d-4c56-b7ae-b18fa8d82819,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-2f5475b7-d628-46d1-b192-95464d620462,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-c904ce99-adf7-4fb6-87ca-14cdf6c8c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b83c6474-3375-4755-8dce-d2f0c9115b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93768234-172.17.0.13-1598115238467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-c1f463f0-d519-460c-998c-43b3c31204f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-4252c039-b689-4ae6-92f2-df19a7cb9514,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2141b6c9-6102-4709-998b-9be4e25d5a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-3a227bf7-8904-4f82-bd8c-620117713cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c893c802-c33d-4c56-b7ae-b18fa8d82819,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-2f5475b7-d628-46d1-b192-95464d620462,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-c904ce99-adf7-4fb6-87ca-14cdf6c8c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-b83c6474-3375-4755-8dce-d2f0c9115b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557832500-172.17.0.13-1598115333817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-a6af880d-e09e-47ab-8bfd-8989d2c0e401,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5024c019-c423-4a2b-9619-5a7b3b5be16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-f2f7c4cb-eaf2-48f5-a304-2cc612eafa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-89b8ddac-77c8-415d-b0b4-bfac97a61768,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-d5fc5e14-791b-43b8-8b02-7ff1978ddfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-dfa26ea6-f67c-4b25-9b5c-c5f5a876e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-3e57bc70-0f8a-487f-8620-63b109e29244,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-a09bc468-f84a-4e81-a7a1-c10feab0ed11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557832500-172.17.0.13-1598115333817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-a6af880d-e09e-47ab-8bfd-8989d2c0e401,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5024c019-c423-4a2b-9619-5a7b3b5be16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-f2f7c4cb-eaf2-48f5-a304-2cc612eafa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-89b8ddac-77c8-415d-b0b4-bfac97a61768,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-d5fc5e14-791b-43b8-8b02-7ff1978ddfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-dfa26ea6-f67c-4b25-9b5c-c5f5a876e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-3e57bc70-0f8a-487f-8620-63b109e29244,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-a09bc468-f84a-4e81-a7a1-c10feab0ed11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138889769-172.17.0.13-1598115950651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-0db319cd-6727-4252-9f90-5117a8d5a639,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-81f22124-87cb-4f85-a1bf-545fe65d454c,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-7f15d040-24a9-4bf0-a125-08faacac3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-58598dd6-166a-4934-816b-8b14ef032f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-1c0a728f-ebf1-4463-b973-985a6da7f960,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-03efcb80-fbcd-4ccd-a4f3-47cf70054498,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-a33fa8d2-8748-4cb4-9544-0d2d4a2ba146,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-b320052a-7502-47eb-8eed-5cf939888e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138889769-172.17.0.13-1598115950651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37223,DS-0db319cd-6727-4252-9f90-5117a8d5a639,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-81f22124-87cb-4f85-a1bf-545fe65d454c,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-7f15d040-24a9-4bf0-a125-08faacac3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-58598dd6-166a-4934-816b-8b14ef032f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-1c0a728f-ebf1-4463-b973-985a6da7f960,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-03efcb80-fbcd-4ccd-a4f3-47cf70054498,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-a33fa8d2-8748-4cb4-9544-0d2d4a2ba146,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-b320052a-7502-47eb-8eed-5cf939888e0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461362782-172.17.0.13-1598116036940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-b9184f54-0a54-40f6-8df4-8b6cacea366c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-655c1dd0-f4b7-48f9-83cd-89aced0f01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-c16784bf-d328-49c1-bab8-bf9b15003a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-26f1ad20-2148-4641-8ad1-814eb5360457,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-cca1ff76-b607-4ca6-9a2f-1434a9edd22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-9bd94a4c-8b6a-4123-9bb9-3fcdce658550,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-35ade8da-95d3-4237-9171-457cb1791610,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-c9b35fa3-8b57-491b-80c1-59b48766c559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461362782-172.17.0.13-1598116036940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-b9184f54-0a54-40f6-8df4-8b6cacea366c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-655c1dd0-f4b7-48f9-83cd-89aced0f01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-c16784bf-d328-49c1-bab8-bf9b15003a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-26f1ad20-2148-4641-8ad1-814eb5360457,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-cca1ff76-b607-4ca6-9a2f-1434a9edd22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-9bd94a4c-8b6a-4123-9bb9-3fcdce658550,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-35ade8da-95d3-4237-9171-457cb1791610,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-c9b35fa3-8b57-491b-80c1-59b48766c559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458734541-172.17.0.13-1598116212580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43183,DS-a4767fb0-24b7-41a6-ab45-8a4c858adc46,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-3774961f-dd98-4eaa-bff0-4f04b01110f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-feb39ec7-5154-4597-b5e0-824f1b892343,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e9257126-ee9b-48f2-8e7f-536fd8f9d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-acc8051c-cbf6-4d32-8464-c8f7ea4ca905,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-009d4555-16d0-4f5b-9fb7-7597345a0170,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-b23cf7d5-75d3-4c6d-8902-246188df3325,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-c3f35107-06f5-4e58-a216-21c58b032011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458734541-172.17.0.13-1598116212580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43183,DS-a4767fb0-24b7-41a6-ab45-8a4c858adc46,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-3774961f-dd98-4eaa-bff0-4f04b01110f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-feb39ec7-5154-4597-b5e0-824f1b892343,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e9257126-ee9b-48f2-8e7f-536fd8f9d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-acc8051c-cbf6-4d32-8464-c8f7ea4ca905,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-009d4555-16d0-4f5b-9fb7-7597345a0170,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-b23cf7d5-75d3-4c6d-8902-246188df3325,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-c3f35107-06f5-4e58-a216-21c58b032011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928086193-172.17.0.13-1598116294242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-859e95b7-98c6-478f-b07b-e09618cd9214,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-0fe20d34-b036-45c4-9e70-5eaed5edd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-32f52ef2-8ef4-4707-be2f-af4791ef7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-b9ef02e6-d359-4bc8-968b-757da0382c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-52e5e0aa-1b87-45f4-95ee-fd174a0d1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-1d009dd5-64d9-4970-9bcc-0eaf450b0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-585ba851-160b-464c-9ced-148500c446ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-da6c01f5-87c8-4b85-8fed-e27805c92325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928086193-172.17.0.13-1598116294242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-859e95b7-98c6-478f-b07b-e09618cd9214,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-0fe20d34-b036-45c4-9e70-5eaed5edd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-32f52ef2-8ef4-4707-be2f-af4791ef7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-b9ef02e6-d359-4bc8-968b-757da0382c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-52e5e0aa-1b87-45f4-95ee-fd174a0d1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-1d009dd5-64d9-4970-9bcc-0eaf450b0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-585ba851-160b-464c-9ced-148500c446ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-da6c01f5-87c8-4b85-8fed-e27805c92325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948813030-172.17.0.13-1598116557420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-4aff089d-4468-472e-aadf-5f764ceb0f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4a3cead-8ed6-46e9-9a4c-71f2a5283a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-58b35263-a737-4a1a-b49e-2faa09899fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-786b0656-b1dd-41b4-bf96-da8a5241593f,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-7ce941ad-fd4a-49ea-a542-4c1c31ac2e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-7996a442-2f6e-490e-b877-a2dcb56dcae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-0b0bd8bc-322a-4c84-87f4-9277658a30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-627b6365-017d-40d1-afda-fc4bc3aa3785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948813030-172.17.0.13-1598116557420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-4aff089d-4468-472e-aadf-5f764ceb0f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4a3cead-8ed6-46e9-9a4c-71f2a5283a42,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-58b35263-a737-4a1a-b49e-2faa09899fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-786b0656-b1dd-41b4-bf96-da8a5241593f,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-7ce941ad-fd4a-49ea-a542-4c1c31ac2e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-7996a442-2f6e-490e-b877-a2dcb56dcae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-0b0bd8bc-322a-4c84-87f4-9277658a30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-627b6365-017d-40d1-afda-fc4bc3aa3785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627578767-172.17.0.13-1598116639731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-d1d62ef4-7201-402e-b4e5-863bae04c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-8a621df6-6cff-4ac5-906f-9d81aa3734bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-a4bb2883-6207-4edd-9228-2cc36e969bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-2667fdb0-8f2d-4d8d-acc3-b93cd007326f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-386b4240-014d-49db-b6c9-2bd04b4522fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-60da2145-572b-4e41-b7d0-ad47ede022de,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-818d4c68-68d6-47ea-9d7c-f932c49bf447,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-6368c801-a7c2-414d-b949-144be03348e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627578767-172.17.0.13-1598116639731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-d1d62ef4-7201-402e-b4e5-863bae04c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-8a621df6-6cff-4ac5-906f-9d81aa3734bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-a4bb2883-6207-4edd-9228-2cc36e969bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-2667fdb0-8f2d-4d8d-acc3-b93cd007326f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-386b4240-014d-49db-b6c9-2bd04b4522fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-60da2145-572b-4e41-b7d0-ad47ede022de,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-818d4c68-68d6-47ea-9d7c-f932c49bf447,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-6368c801-a7c2-414d-b949-144be03348e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166576012-172.17.0.13-1598116800796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-78892287-2b1d-4b7f-bba9-54eaf0c0f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-48ec75af-76ad-46dc-9e92-6bb590ec9800,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-a73a99e1-09c1-4e4b-b6a8-a093ddee3fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-3b5ef227-5e37-4b86-827c-06b1084d12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-8f993848-a48c-43b4-b404-328785923e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-9772a5ed-c4bf-4762-9d08-252a5fe5e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f8e8a3d8-8bf6-49aa-a031-6c677fa3ff58,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-f8ee19f8-c665-4f41-b147-e23a234067d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166576012-172.17.0.13-1598116800796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38607,DS-78892287-2b1d-4b7f-bba9-54eaf0c0f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-48ec75af-76ad-46dc-9e92-6bb590ec9800,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-a73a99e1-09c1-4e4b-b6a8-a093ddee3fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-3b5ef227-5e37-4b86-827c-06b1084d12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-8f993848-a48c-43b4-b404-328785923e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-9772a5ed-c4bf-4762-9d08-252a5fe5e7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f8e8a3d8-8bf6-49aa-a031-6c677fa3ff58,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-f8ee19f8-c665-4f41-b147-e23a234067d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714501065-172.17.0.13-1598116935412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45329,DS-1ee26747-d3ec-4545-ac72-1cf813eff07f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c5e1c560-4877-45c7-bf1f-61939448684f,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-a0c55eb2-e904-4915-91dd-12877e911f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-f95454ef-9a98-47cb-a617-dbf6b36f2441,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-bf94c7cc-9199-4608-aebe-92f2822e5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-b2d41751-255e-4414-b067-9857b4f295b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-5d5d06dc-1bce-4c47-98f8-7d2b4aee40be,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-226df411-6abc-4148-82a1-6dbf9d7c0517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714501065-172.17.0.13-1598116935412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45329,DS-1ee26747-d3ec-4545-ac72-1cf813eff07f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-c5e1c560-4877-45c7-bf1f-61939448684f,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-a0c55eb2-e904-4915-91dd-12877e911f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-f95454ef-9a98-47cb-a617-dbf6b36f2441,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-bf94c7cc-9199-4608-aebe-92f2822e5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-b2d41751-255e-4414-b067-9857b4f295b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-5d5d06dc-1bce-4c47-98f8-7d2b4aee40be,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-226df411-6abc-4148-82a1-6dbf9d7c0517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234647711-172.17.0.13-1598117025333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-895d671d-4625-4003-b86a-4a8b82f9f14e,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-17d7dddf-4874-4535-a1db-d3126b92bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-3e12c219-6f41-49f6-b699-e902ad564998,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-89f88e34-7e78-4a84-99a9-3534e1b0c529,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-fcf200bb-ec06-4c5a-9f75-0b312d33db98,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-9e201a22-b219-4932-a406-3130a7f91d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-455139d7-b100-436a-a5b0-b7d05eaece0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-1ebfb810-6476-4052-9b2d-785fd69a6bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234647711-172.17.0.13-1598117025333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-895d671d-4625-4003-b86a-4a8b82f9f14e,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-17d7dddf-4874-4535-a1db-d3126b92bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-3e12c219-6f41-49f6-b699-e902ad564998,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-89f88e34-7e78-4a84-99a9-3534e1b0c529,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-fcf200bb-ec06-4c5a-9f75-0b312d33db98,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-9e201a22-b219-4932-a406-3130a7f91d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-455139d7-b100-436a-a5b0-b7d05eaece0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-1ebfb810-6476-4052-9b2d-785fd69a6bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649475853-172.17.0.13-1598117154911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-0cf33fbe-8728-4773-89f4-224f45e8f738,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-d47d64d6-196d-422d-822f-72b9f409ae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cd3440ea-e942-42eb-a14c-1696718467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-f38f6613-6c82-469c-9d60-47b477570ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b11499aa-7747-41b6-897c-4cf4bba19c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-d6f9c921-406b-4b3c-b129-76102fd9fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-3ba15c1f-fe3a-4cab-b74e-1fb45afdb3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-ab245848-b2b3-46e3-bbb6-ca102cd4742c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649475853-172.17.0.13-1598117154911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-0cf33fbe-8728-4773-89f4-224f45e8f738,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-d47d64d6-196d-422d-822f-72b9f409ae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cd3440ea-e942-42eb-a14c-1696718467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-f38f6613-6c82-469c-9d60-47b477570ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b11499aa-7747-41b6-897c-4cf4bba19c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-d6f9c921-406b-4b3c-b129-76102fd9fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-3ba15c1f-fe3a-4cab-b74e-1fb45afdb3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-ab245848-b2b3-46e3-bbb6-ca102cd4742c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767874431-172.17.0.13-1598117237039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-08f40623-a833-4166-afbb-99cb43bafc94,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-30f2955e-8ec1-4e98-9f04-e7b9d0e17c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b61a9dce-5637-4fec-9df5-7b7faf39cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-f63e0fc3-f085-4f20-9d31-f2e01474335c,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-ad0a9341-a909-4ea7-9938-729ed3f95f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-ab56dca8-a261-4bdf-9d79-26b62ed8e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-59d98a92-dbdb-4e9e-ab64-3ccb53261f82,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-0b56912b-cd27-47b9-8ca9-7068081fe899,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767874431-172.17.0.13-1598117237039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-08f40623-a833-4166-afbb-99cb43bafc94,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-30f2955e-8ec1-4e98-9f04-e7b9d0e17c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b61a9dce-5637-4fec-9df5-7b7faf39cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-f63e0fc3-f085-4f20-9d31-f2e01474335c,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-ad0a9341-a909-4ea7-9938-729ed3f95f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-ab56dca8-a261-4bdf-9d79-26b62ed8e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-59d98a92-dbdb-4e9e-ab64-3ccb53261f82,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-0b56912b-cd27-47b9-8ca9-7068081fe899,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989129045-172.17.0.13-1598117445588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42393,DS-ad981c58-ec8e-4e09-bcf5-38f8cdb3396e,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-e4efad54-fb30-404e-8427-babe1ce3cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-2a39bf0b-6331-4c18-93d7-cd439a4ce226,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-b8b4c8c1-33b8-4d1b-9b5e-7ce21f736ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-87414cda-5a17-47ce-85ca-3c02e6ebf3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-19201972-22ae-40b9-bcc6-2b3b939e32bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-52ecafba-7a74-471d-8296-32bcaa9f0968,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c3ac7726-1467-4c32-87c9-d50b0d1a1329,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989129045-172.17.0.13-1598117445588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42393,DS-ad981c58-ec8e-4e09-bcf5-38f8cdb3396e,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-e4efad54-fb30-404e-8427-babe1ce3cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-2a39bf0b-6331-4c18-93d7-cd439a4ce226,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-b8b4c8c1-33b8-4d1b-9b5e-7ce21f736ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-87414cda-5a17-47ce-85ca-3c02e6ebf3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-19201972-22ae-40b9-bcc6-2b3b939e32bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-52ecafba-7a74-471d-8296-32bcaa9f0968,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c3ac7726-1467-4c32-87c9-d50b0d1a1329,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241723207-172.17.0.13-1598117486451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33400,DS-83b7d2cb-1ec4-4223-a8ab-e3d2e342e113,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-27e50305-bd58-483e-af9f-e62e4559438c,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-38ea79cc-79ee-43db-85e3-01250caa3fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-a5c692ec-90f9-4997-a7ba-8de9724cecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-d2b59720-2dd5-401d-abd5-3b8d5980fe06,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c007f3aa-b8a4-4c74-89f5-6e45832ad636,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-df42dae7-680c-46e6-bd90-3f854b993de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-d9b5ad5a-bd6e-4203-b867-712197d7fb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241723207-172.17.0.13-1598117486451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33400,DS-83b7d2cb-1ec4-4223-a8ab-e3d2e342e113,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-27e50305-bd58-483e-af9f-e62e4559438c,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-38ea79cc-79ee-43db-85e3-01250caa3fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-a5c692ec-90f9-4997-a7ba-8de9724cecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-d2b59720-2dd5-401d-abd5-3b8d5980fe06,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c007f3aa-b8a4-4c74-89f5-6e45832ad636,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-df42dae7-680c-46e6-bd90-3f854b993de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-d9b5ad5a-bd6e-4203-b867-712197d7fb48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818512410-172.17.0.13-1598117616057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-0db7b677-8219-4e1c-987e-81b206aebf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-67d1e2a6-b9cb-4e4c-953c-602815d77515,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-acef0cff-881e-463f-b546-86046c8c6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-05c4df47-f073-4309-b206-b87810cf41e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-1069117a-8159-4261-a90e-9967eb6c9845,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-b8b19d1a-bb15-4cf9-baf1-ff04c4220e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-e34e8f63-7646-4825-92cf-8fdda3cf1946,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-6f739bd0-d7d4-48ca-8ea6-29ec2d301789,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818512410-172.17.0.13-1598117616057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-0db7b677-8219-4e1c-987e-81b206aebf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-67d1e2a6-b9cb-4e4c-953c-602815d77515,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-acef0cff-881e-463f-b546-86046c8c6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-05c4df47-f073-4309-b206-b87810cf41e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-1069117a-8159-4261-a90e-9967eb6c9845,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-b8b19d1a-bb15-4cf9-baf1-ff04c4220e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-e34e8f63-7646-4825-92cf-8fdda3cf1946,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-6f739bd0-d7d4-48ca-8ea6-29ec2d301789,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619568229-172.17.0.13-1598117665531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-f5fd0d56-663a-4d25-b1ff-4347f6e16c18,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-4fd47c72-687a-4104-a5f9-5678b76577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f8eb32ea-6880-4c76-94cc-9d523c892ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2230f6b3-a496-4083-bc1e-c096085d1420,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-76a0e745-5c0a-47e3-b17b-892efbc4443d,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-cdac4cd9-2400-4146-aa53-406a4b04da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-894ca288-f856-4e30-bad3-c887f8c979c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-f05d8110-b7b3-4476-9657-840e1cc2c11e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619568229-172.17.0.13-1598117665531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-f5fd0d56-663a-4d25-b1ff-4347f6e16c18,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-4fd47c72-687a-4104-a5f9-5678b76577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-f8eb32ea-6880-4c76-94cc-9d523c892ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2230f6b3-a496-4083-bc1e-c096085d1420,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-76a0e745-5c0a-47e3-b17b-892efbc4443d,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-cdac4cd9-2400-4146-aa53-406a4b04da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-894ca288-f856-4e30-bad3-c887f8c979c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-f05d8110-b7b3-4476-9657-840e1cc2c11e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 6527
