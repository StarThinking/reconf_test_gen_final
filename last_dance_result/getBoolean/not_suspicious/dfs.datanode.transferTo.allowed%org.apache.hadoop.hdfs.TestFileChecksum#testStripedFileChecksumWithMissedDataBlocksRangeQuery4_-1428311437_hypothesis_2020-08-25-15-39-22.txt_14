reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908543-172.17.0.11-1598370393446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-d8f957db-1ace-45e5-a2e2-a7e2647bf234,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-6493e29b-a3fa-4d33-a9d1-ebd2554e9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-fa3e71a4-7d24-4e63-b15e-c959475768d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b4d2ccf1-f485-4c1d-af5e-46e2c11f8604,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-5c2356b4-d844-4647-82e8-d64ac0646346,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-a8fd8fae-a077-4139-9bcc-4bfe28914316,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-2b017b75-e169-4557-ba82-da991fb5736a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-7baa6e6a-b077-4f15-baca-38f6e9558919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908543-172.17.0.11-1598370393446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-d8f957db-1ace-45e5-a2e2-a7e2647bf234,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-6493e29b-a3fa-4d33-a9d1-ebd2554e9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-fa3e71a4-7d24-4e63-b15e-c959475768d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b4d2ccf1-f485-4c1d-af5e-46e2c11f8604,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-5c2356b4-d844-4647-82e8-d64ac0646346,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-a8fd8fae-a077-4139-9bcc-4bfe28914316,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-2b017b75-e169-4557-ba82-da991fb5736a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-7baa6e6a-b077-4f15-baca-38f6e9558919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757959101-172.17.0.11-1598370834685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-48970277-3cef-43d8-b110-b5fcc4c0af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-d137f988-2bd7-4bc6-ba66-59678e0901a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-0376a765-f8e3-4b03-b5c2-81c05a5b6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-530dfad7-fb41-4009-9e1e-8788264f9267,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1d1b9aee-8cd1-437d-868c-d0101417abcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-d571fce2-38b3-4246-84d3-9e415180c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-9efb08f4-8226-4996-ae49-79dedcc19862,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-2673adb8-a520-49a6-b5c7-4432fc95ccf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757959101-172.17.0.11-1598370834685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-48970277-3cef-43d8-b110-b5fcc4c0af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-d137f988-2bd7-4bc6-ba66-59678e0901a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-0376a765-f8e3-4b03-b5c2-81c05a5b6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-530dfad7-fb41-4009-9e1e-8788264f9267,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1d1b9aee-8cd1-437d-868c-d0101417abcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-d571fce2-38b3-4246-84d3-9e415180c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-9efb08f4-8226-4996-ae49-79dedcc19862,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-2673adb8-a520-49a6-b5c7-4432fc95ccf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712025377-172.17.0.11-1598370983032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39933,DS-c9d2ee23-4233-4826-8d75-b4a9cc93e064,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-b6eb2d6f-19a2-4789-8da1-75ec467094ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-bdc3fcc5-4d1e-40d6-9773-13a7ca3df79d,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-b95abb9f-bb53-44a1-820f-c85218902c05,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1081df55-fcb6-4bc4-be53-e789c2ba6ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-a1416de8-bb2f-4eed-8393-c2397e524f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-43db776f-8696-4b0d-9d00-bb220767384a,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-67809d65-0342-4ee5-9dc6-f0ea3f45da49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712025377-172.17.0.11-1598370983032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39933,DS-c9d2ee23-4233-4826-8d75-b4a9cc93e064,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-b6eb2d6f-19a2-4789-8da1-75ec467094ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-bdc3fcc5-4d1e-40d6-9773-13a7ca3df79d,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-b95abb9f-bb53-44a1-820f-c85218902c05,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1081df55-fcb6-4bc4-be53-e789c2ba6ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-a1416de8-bb2f-4eed-8393-c2397e524f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-43db776f-8696-4b0d-9d00-bb220767384a,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-67809d65-0342-4ee5-9dc6-f0ea3f45da49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642332946-172.17.0.11-1598371020213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-d64222b5-2cc3-4a17-826b-42e0046f7ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d1da172d-2202-4e41-819b-9435269f1c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-d9f2c0a7-3000-47a5-ad4b-31a3df3ed346,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-3117b24a-e64c-4859-a784-81bb215dc7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-9b6f7a07-f0e1-45cf-bb05-494a2532d007,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-b642ece5-9b9b-44e4-b0a0-d0afb2df7690,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-1afd7d98-08c4-4afa-b277-0fcb554016b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-ccbae701-2406-4630-bfc0-8a151856f22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642332946-172.17.0.11-1598371020213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-d64222b5-2cc3-4a17-826b-42e0046f7ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d1da172d-2202-4e41-819b-9435269f1c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-d9f2c0a7-3000-47a5-ad4b-31a3df3ed346,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-3117b24a-e64c-4859-a784-81bb215dc7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-9b6f7a07-f0e1-45cf-bb05-494a2532d007,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-b642ece5-9b9b-44e4-b0a0-d0afb2df7690,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-1afd7d98-08c4-4afa-b277-0fcb554016b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-ccbae701-2406-4630-bfc0-8a151856f22d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022168631-172.17.0.11-1598372011850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-1ae0509b-ff0b-4d48-9b30-f57713466f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-3636f38e-64d0-4af1-beb0-f62bb6f8b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-011ebb03-1634-4c74-b915-bf285b79808b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-8a2c3a24-4772-4e72-9f82-fece3efdf2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-47b784d0-4ff0-44b8-89fd-b1e4e4e403cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-fce6e152-91b8-4fa6-aa0f-6779af4cb01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-6ae38b89-70b6-4fbe-80ba-e1d21deaca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-29d0aa1a-2a68-4728-90be-8023d9250919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022168631-172.17.0.11-1598372011850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-1ae0509b-ff0b-4d48-9b30-f57713466f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-3636f38e-64d0-4af1-beb0-f62bb6f8b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-011ebb03-1634-4c74-b915-bf285b79808b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-8a2c3a24-4772-4e72-9f82-fece3efdf2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-47b784d0-4ff0-44b8-89fd-b1e4e4e403cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-fce6e152-91b8-4fa6-aa0f-6779af4cb01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-6ae38b89-70b6-4fbe-80ba-e1d21deaca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-29d0aa1a-2a68-4728-90be-8023d9250919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547574646-172.17.0.11-1598372084453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-13ef81b2-0119-4082-9077-f62356f893af,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-6da0e845-70ce-490c-93d0-5fd0e7065660,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-0bc0a078-7d69-4718-97e1-8b5a3f4e08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-cdd03219-4fc5-4131-8798-7ec683ad9645,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-7a5f2aa2-1e22-412f-ae5c-ecc2d8605874,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-36b1f84f-5bd5-497e-9782-6ec16a2eac14,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bdf40f6d-53b2-40c1-a617-a800b6d51904,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-255436cd-3ab6-481f-a6fb-95014c2d8484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547574646-172.17.0.11-1598372084453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-13ef81b2-0119-4082-9077-f62356f893af,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-6da0e845-70ce-490c-93d0-5fd0e7065660,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-0bc0a078-7d69-4718-97e1-8b5a3f4e08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-cdd03219-4fc5-4131-8798-7ec683ad9645,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-7a5f2aa2-1e22-412f-ae5c-ecc2d8605874,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-36b1f84f-5bd5-497e-9782-6ec16a2eac14,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bdf40f6d-53b2-40c1-a617-a800b6d51904,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-255436cd-3ab6-481f-a6fb-95014c2d8484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420072011-172.17.0.11-1598372231644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-3f7b2430-aab7-41d6-86a0-1bf01eac25dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-9dce188b-eed1-4778-a3b9-045939f57e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-6148d45c-075a-4ba9-9bb4-e37d5013b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-da929499-dde1-4135-b893-a222c86ad9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-f0baf97c-1012-4ec9-b469-8d3222df7b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-1e6e4e3a-f654-4f0c-88ac-a89223e6d805,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-11edccf7-0739-4a82-beee-00d9d8c15683,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-11831024-13d6-4ecc-b3f7-367290a4167a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420072011-172.17.0.11-1598372231644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-3f7b2430-aab7-41d6-86a0-1bf01eac25dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-9dce188b-eed1-4778-a3b9-045939f57e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-6148d45c-075a-4ba9-9bb4-e37d5013b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-da929499-dde1-4135-b893-a222c86ad9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-f0baf97c-1012-4ec9-b469-8d3222df7b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-1e6e4e3a-f654-4f0c-88ac-a89223e6d805,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-11edccf7-0739-4a82-beee-00d9d8c15683,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-11831024-13d6-4ecc-b3f7-367290a4167a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233517824-172.17.0.11-1598372309191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-d8917fc1-29a3-4e5d-94a2-a9f8e6999698,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-b350bd1a-fd9d-4656-b318-a1ab3f9d0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-aaebfb07-023e-4886-b71e-f895329725a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-204fa114-aeee-44f4-86da-55d7b2814cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-3c6a5cad-708c-4a39-864e-b6f0bc9449c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-ee29e25d-8679-4c1b-a27d-d77a904fb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-752eae99-5602-4aa3-85ca-3a73af067151,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-741e7ab3-35f5-4e9b-baf0-d02ebb7a8f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233517824-172.17.0.11-1598372309191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-d8917fc1-29a3-4e5d-94a2-a9f8e6999698,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-b350bd1a-fd9d-4656-b318-a1ab3f9d0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-aaebfb07-023e-4886-b71e-f895329725a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-204fa114-aeee-44f4-86da-55d7b2814cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-3c6a5cad-708c-4a39-864e-b6f0bc9449c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-ee29e25d-8679-4c1b-a27d-d77a904fb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-752eae99-5602-4aa3-85ca-3a73af067151,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-741e7ab3-35f5-4e9b-baf0-d02ebb7a8f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244151855-172.17.0.11-1598372746737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-d45a0b77-4795-454c-91c9-10582d9bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-702cfdb6-4ac5-4326-a331-62044c62fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-b857f704-2723-4ccb-a29d-d7bf97957665,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-481afb8e-37e8-4498-bcf6-1e0be9807917,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-c31e744f-c9ec-4d40-b707-55e2e385b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c31d5dc4-6fb9-484b-ae8a-b320e5d9d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3ab89967-2dff-4219-869a-7647cd4dd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-18e162ad-19f0-4663-9f9f-9319f7904517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244151855-172.17.0.11-1598372746737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-d45a0b77-4795-454c-91c9-10582d9bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-702cfdb6-4ac5-4326-a331-62044c62fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-b857f704-2723-4ccb-a29d-d7bf97957665,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-481afb8e-37e8-4498-bcf6-1e0be9807917,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-c31e744f-c9ec-4d40-b707-55e2e385b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c31d5dc4-6fb9-484b-ae8a-b320e5d9d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3ab89967-2dff-4219-869a-7647cd4dd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-18e162ad-19f0-4663-9f9f-9319f7904517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952154117-172.17.0.11-1598373260414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-05ef2ae2-84c7-462f-b1f5-fa2b3fc56358,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-09d0df35-6690-4e42-8227-c2ac314ac949,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-dc204b02-6cb3-4620-9c80-978d3eea6843,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2acd4ac6-3a03-49ae-81b8-1053b4437fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-02765fc8-8335-46d7-907f-25431be4a299,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-a6e3c564-be3f-4367-a13f-d9358be1f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-be5efce1-8426-4fba-9549-73818ec1cdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-ce434188-8c61-442d-a295-43aa77b1c148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952154117-172.17.0.11-1598373260414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-05ef2ae2-84c7-462f-b1f5-fa2b3fc56358,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-09d0df35-6690-4e42-8227-c2ac314ac949,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-dc204b02-6cb3-4620-9c80-978d3eea6843,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2acd4ac6-3a03-49ae-81b8-1053b4437fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-02765fc8-8335-46d7-907f-25431be4a299,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-a6e3c564-be3f-4367-a13f-d9358be1f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-be5efce1-8426-4fba-9549-73818ec1cdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-ce434188-8c61-442d-a295-43aa77b1c148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941787133-172.17.0.11-1598373853454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-2135a6ca-2b5c-42c0-9a65-5292af164fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c6594c6e-6884-47b1-a510-732cc839be59,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-542cd342-6270-4e72-acd9-6398d2d8e452,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-be1d57d6-dc17-4041-af2f-ab8a66439968,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-b83e994e-7447-428e-a3dd-5da2d6afb90b,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-2641f797-38b5-4523-8f55-03cb3ca1f946,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-6f1860b3-3312-47d4-a23b-a1d8179e2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-00cbe6f5-56ab-44bb-8532-075bf4a8b16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941787133-172.17.0.11-1598373853454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-2135a6ca-2b5c-42c0-9a65-5292af164fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c6594c6e-6884-47b1-a510-732cc839be59,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-542cd342-6270-4e72-acd9-6398d2d8e452,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-be1d57d6-dc17-4041-af2f-ab8a66439968,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-b83e994e-7447-428e-a3dd-5da2d6afb90b,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-2641f797-38b5-4523-8f55-03cb3ca1f946,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-6f1860b3-3312-47d4-a23b-a1d8179e2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-00cbe6f5-56ab-44bb-8532-075bf4a8b16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804153160-172.17.0.11-1598374217515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-e95ba452-1c12-411b-a651-510845c4c91d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-a50d55b0-1928-445d-8ed8-4e6077194a01,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-8a1423b2-41e5-4d97-9b0f-ab655d403b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-10af221f-5d1d-4a08-80e1-777aa703527c,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-32fa54a9-c30d-4901-a416-f309ee037410,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-f5267d7c-4321-4f5a-9aa4-1dcac2e4d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-3ac560d0-53b3-4622-ba8f-d7c124411b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-a47c20ea-aad8-4539-a9c1-f2c745cd125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804153160-172.17.0.11-1598374217515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-e95ba452-1c12-411b-a651-510845c4c91d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-a50d55b0-1928-445d-8ed8-4e6077194a01,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-8a1423b2-41e5-4d97-9b0f-ab655d403b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-10af221f-5d1d-4a08-80e1-777aa703527c,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-32fa54a9-c30d-4901-a416-f309ee037410,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-f5267d7c-4321-4f5a-9aa4-1dcac2e4d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-3ac560d0-53b3-4622-ba8f-d7c124411b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-a47c20ea-aad8-4539-a9c1-f2c745cd125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229469503-172.17.0.11-1598374779106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-6886038a-1812-4360-b193-86d8672fe0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-3593e364-105c-44dc-aca1-d58319670622,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-9891df62-8a1f-478e-81ee-ab230a17e2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-ee3fe1c9-f91a-48f3-9457-54a0f0f80995,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-dd208ab7-3801-4a09-8f68-cef44a3c7c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4138ff15-d8bb-4423-8008-6a2863cac354,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-f44133e0-0c1f-468b-b499-dd4a573dfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c34fe634-ec15-4a40-a567-b91971d07b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229469503-172.17.0.11-1598374779106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-6886038a-1812-4360-b193-86d8672fe0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-3593e364-105c-44dc-aca1-d58319670622,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-9891df62-8a1f-478e-81ee-ab230a17e2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-ee3fe1c9-f91a-48f3-9457-54a0f0f80995,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-dd208ab7-3801-4a09-8f68-cef44a3c7c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4138ff15-d8bb-4423-8008-6a2863cac354,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-f44133e0-0c1f-468b-b499-dd4a573dfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-c34fe634-ec15-4a40-a567-b91971d07b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940978932-172.17.0.11-1598375004673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-55c66205-4613-453b-99f3-d77fb7236a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a57e7924-95bb-465d-b676-364d6b7a3bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e0d31cc2-3a91-4414-957e-4aacf6896509,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-8a19551d-f68a-4350-8c46-788e5593f534,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-1f28a6b6-b0aa-42b2-ab49-89f9c45fbe13,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-966c8bf7-175a-4a82-a959-dbffcd2bf5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-7f2743b3-0917-4efa-ad4e-70dae3a952bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-fe991c52-dc9d-4ff7-b704-307b7cbab855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940978932-172.17.0.11-1598375004673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34595,DS-55c66205-4613-453b-99f3-d77fb7236a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a57e7924-95bb-465d-b676-364d6b7a3bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e0d31cc2-3a91-4414-957e-4aacf6896509,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-8a19551d-f68a-4350-8c46-788e5593f534,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-1f28a6b6-b0aa-42b2-ab49-89f9c45fbe13,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-966c8bf7-175a-4a82-a959-dbffcd2bf5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-7f2743b3-0917-4efa-ad4e-70dae3a952bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-fe991c52-dc9d-4ff7-b704-307b7cbab855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132866097-172.17.0.11-1598375151792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40587,DS-d1eb7ab1-8802-41e9-aca4-6b8beda92794,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-6e2a324f-1685-4e44-8813-63d63a061631,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c3afe2e5-be01-4efb-94d9-8d8960fe1444,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-0d49a2bd-e7a9-45a1-bc10-ff6192e83102,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-d9bb76de-aa5e-4fb7-80cd-dfa5b4506291,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3be59a67-3b73-48c3-a649-3d2cdb721cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-c8e2a5bf-ee18-49d6-8f62-b785803c262b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-b4d68f6f-d284-4b00-b5eb-b7bdb7fff300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132866097-172.17.0.11-1598375151792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40587,DS-d1eb7ab1-8802-41e9-aca4-6b8beda92794,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-6e2a324f-1685-4e44-8813-63d63a061631,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c3afe2e5-be01-4efb-94d9-8d8960fe1444,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-0d49a2bd-e7a9-45a1-bc10-ff6192e83102,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-d9bb76de-aa5e-4fb7-80cd-dfa5b4506291,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3be59a67-3b73-48c3-a649-3d2cdb721cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-c8e2a5bf-ee18-49d6-8f62-b785803c262b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-b4d68f6f-d284-4b00-b5eb-b7bdb7fff300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507527877-172.17.0.11-1598375190419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-ad6f8315-bf13-4edc-91ef-e17698986f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-9e689718-6faa-4816-be7a-662a23dc24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2196dd80-ed1f-46e0-8592-33f7ab32e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-585b5527-7f4d-4f13-b16a-23d1dd2a01fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-28470563-0ff6-4571-bb0c-bbcb6bbeefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-60007f7e-64fe-4900-b27f-c95ccaa7eaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-72996ee8-a651-47e7-bf25-02e1cb8e7057,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-2bbd17cb-746d-46fc-8a81-a06147360eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507527877-172.17.0.11-1598375190419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-ad6f8315-bf13-4edc-91ef-e17698986f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-9e689718-6faa-4816-be7a-662a23dc24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2196dd80-ed1f-46e0-8592-33f7ab32e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-585b5527-7f4d-4f13-b16a-23d1dd2a01fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-28470563-0ff6-4571-bb0c-bbcb6bbeefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-60007f7e-64fe-4900-b27f-c95ccaa7eaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-72996ee8-a651-47e7-bf25-02e1cb8e7057,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-2bbd17cb-746d-46fc-8a81-a06147360eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5514
