reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664587669-172.17.0.16-1598127125719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-1d2a02d5-86bd-4df5-aaa8-3444c430c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-80fc6056-1423-44f9-91d0-f6bedaa5e038,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-d8a84906-d7cf-41bf-a926-90adba9c73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-303b2e03-81d5-412a-91cd-5d6fc99177d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d61ee66b-5a54-4415-b289-5b46f6351ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-5ea41be1-8042-45a9-8b75-0664cf02c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-0fa05183-bc34-4eda-85da-e2ae559eac02,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1dc89417-1c7f-4f87-abae-283e797196c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664587669-172.17.0.16-1598127125719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-1d2a02d5-86bd-4df5-aaa8-3444c430c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-80fc6056-1423-44f9-91d0-f6bedaa5e038,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-d8a84906-d7cf-41bf-a926-90adba9c73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-303b2e03-81d5-412a-91cd-5d6fc99177d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d61ee66b-5a54-4415-b289-5b46f6351ece,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-5ea41be1-8042-45a9-8b75-0664cf02c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-0fa05183-bc34-4eda-85da-e2ae559eac02,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-1dc89417-1c7f-4f87-abae-283e797196c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330969791-172.17.0.16-1598127305987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-5ca55aea-3521-45f9-bab3-5324da3f6594,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-a8de8dc5-bc3c-4254-96c5-b83045d3b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-0adac1ca-9d9a-489d-88de-6b56c14c8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-8393c7b6-c809-46f4-aea7-5fea2ac04047,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4fcecf39-2db6-4ac6-9536-b9014c6d262a,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d5bcf85d-8466-4bd5-bd82-f47c5c347329,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-87ced49c-182f-4073-8714-9b8abdd56369,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-b4d005a7-1d33-4cbe-9149-b0f63dcd71f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330969791-172.17.0.16-1598127305987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-5ca55aea-3521-45f9-bab3-5324da3f6594,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-a8de8dc5-bc3c-4254-96c5-b83045d3b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-0adac1ca-9d9a-489d-88de-6b56c14c8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-8393c7b6-c809-46f4-aea7-5fea2ac04047,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4fcecf39-2db6-4ac6-9536-b9014c6d262a,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d5bcf85d-8466-4bd5-bd82-f47c5c347329,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-87ced49c-182f-4073-8714-9b8abdd56369,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-b4d005a7-1d33-4cbe-9149-b0f63dcd71f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84334946-172.17.0.16-1598128649977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-c931a7a6-2983-4d88-8ef6-89ceb083304a,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-08585a61-205b-41d0-945b-aed5af3ee957,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-973fafd0-ac20-4f87-ae1e-1a3e884708c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-b915064d-0e42-4693-8601-778e17e06b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-1439ca26-4ff0-401d-8ad9-0f0865b0765b,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-71b0de44-d622-44b8-aa91-259c1b8b3ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-cbc7f2b8-349b-45f6-9f6f-d90c3704dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-05cf8999-e994-4081-be2c-22a63126309d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84334946-172.17.0.16-1598128649977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-c931a7a6-2983-4d88-8ef6-89ceb083304a,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-08585a61-205b-41d0-945b-aed5af3ee957,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-973fafd0-ac20-4f87-ae1e-1a3e884708c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-b915064d-0e42-4693-8601-778e17e06b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-1439ca26-4ff0-401d-8ad9-0f0865b0765b,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-71b0de44-d622-44b8-aa91-259c1b8b3ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-cbc7f2b8-349b-45f6-9f6f-d90c3704dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-05cf8999-e994-4081-be2c-22a63126309d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442471867-172.17.0.16-1598128741349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-7f74339c-6025-4aa1-899a-c81bf35b1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-5721d8e3-9b4c-4775-81bc-2485df1efeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-97b4a4d7-ec77-461a-8a49-692e3c25cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-1f4ec3d8-147c-4618-a545-1b2de066a406,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-33705eae-fd50-4bb0-941b-82ec4e82357f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-28a8bec2-cbea-4a3e-946e-6ff9cb8b0011,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-3d684553-def4-4daf-90c2-d09e7ebc5aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-51bc317a-10eb-422d-95ef-ef6224083c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442471867-172.17.0.16-1598128741349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-7f74339c-6025-4aa1-899a-c81bf35b1c93,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-5721d8e3-9b4c-4775-81bc-2485df1efeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-97b4a4d7-ec77-461a-8a49-692e3c25cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-1f4ec3d8-147c-4618-a545-1b2de066a406,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-33705eae-fd50-4bb0-941b-82ec4e82357f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-28a8bec2-cbea-4a3e-946e-6ff9cb8b0011,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-3d684553-def4-4daf-90c2-d09e7ebc5aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-51bc317a-10eb-422d-95ef-ef6224083c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825341807-172.17.0.16-1598130295957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-9d49fa4f-ff27-43ff-8e28-9ab19c949414,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-b191f30d-6b6d-42c0-a54f-b3b9a3919b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-ed678182-2132-4566-bed9-47163c813ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-05e1cb07-b2a5-42f8-82b5-97ed7489ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-96311f36-f9d6-419a-8e6f-ecf0c12b9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-64e7e1fa-f114-434f-89e7-46da1b170ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-8e159ca0-4cd6-4f69-8477-20acf64f1037,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b5fb4f4-8ddd-408d-932f-1534ec1a1a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825341807-172.17.0.16-1598130295957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37269,DS-9d49fa4f-ff27-43ff-8e28-9ab19c949414,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-b191f30d-6b6d-42c0-a54f-b3b9a3919b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-ed678182-2132-4566-bed9-47163c813ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-05e1cb07-b2a5-42f8-82b5-97ed7489ae52,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-96311f36-f9d6-419a-8e6f-ecf0c12b9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-64e7e1fa-f114-434f-89e7-46da1b170ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-8e159ca0-4cd6-4f69-8477-20acf64f1037,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b5fb4f4-8ddd-408d-932f-1534ec1a1a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898454394-172.17.0.16-1598130375297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-edebf741-d897-4c51-aa3e-eb0a2e585b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-14abd747-9690-41f4-ac6f-608846cb3008,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-2592dca3-9bee-4a87-b063-e6ecd2d1cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-aeec62b4-b4b6-4cc3-a2a1-f3daee7ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-6d85f341-0011-457f-beec-6f8f37bd79cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-990b8523-84b6-42d7-a056-b8635c40668c,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-c098d969-2e86-4b02-80bf-26f55095aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-a2ce12fd-1b12-49a9-9db0-b416c03b394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898454394-172.17.0.16-1598130375297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-edebf741-d897-4c51-aa3e-eb0a2e585b86,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-14abd747-9690-41f4-ac6f-608846cb3008,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-2592dca3-9bee-4a87-b063-e6ecd2d1cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-aeec62b4-b4b6-4cc3-a2a1-f3daee7ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-6d85f341-0011-457f-beec-6f8f37bd79cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-990b8523-84b6-42d7-a056-b8635c40668c,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-c098d969-2e86-4b02-80bf-26f55095aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-a2ce12fd-1b12-49a9-9db0-b416c03b394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085776639-172.17.0.16-1598131064962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-afc1d5e2-47a9-4766-bb05-008eec8b77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-ba330280-4263-43de-9b66-d762c3c67b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9dedac84-7fc3-48d1-99c2-96edda21cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-189727b3-69cc-45c2-937e-2ec7fd344000,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-3b296d59-4b95-4085-870f-57f12019c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-13774352-737e-45f2-926f-e1899680693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-639702b9-d485-41fc-843c-c2d910d189af,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-830b6f0d-ded8-4790-9447-2972119399b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085776639-172.17.0.16-1598131064962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-afc1d5e2-47a9-4766-bb05-008eec8b77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-ba330280-4263-43de-9b66-d762c3c67b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9dedac84-7fc3-48d1-99c2-96edda21cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-189727b3-69cc-45c2-937e-2ec7fd344000,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-3b296d59-4b95-4085-870f-57f12019c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-13774352-737e-45f2-926f-e1899680693b,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-639702b9-d485-41fc-843c-c2d910d189af,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-830b6f0d-ded8-4790-9447-2972119399b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424202326-172.17.0.16-1598132467206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-bdfd68ae-9b1e-49e2-80b7-791a629aa946,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-aac4edcf-73bc-4d49-be6c-852a6caabe19,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-52bb666a-e223-4056-955c-d9347c942083,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-f8213d86-e433-4808-a980-49d1583eef25,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-e2a84516-afe6-4ed8-b902-50e67e98e929,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-5ba79318-c41a-4ddc-a741-278181019f02,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-52210120-3536-49cc-b611-4439aefb75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-0697e8c6-e01e-4532-a5bd-42af8e5fb207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424202326-172.17.0.16-1598132467206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-bdfd68ae-9b1e-49e2-80b7-791a629aa946,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-aac4edcf-73bc-4d49-be6c-852a6caabe19,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-52bb666a-e223-4056-955c-d9347c942083,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-f8213d86-e433-4808-a980-49d1583eef25,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-e2a84516-afe6-4ed8-b902-50e67e98e929,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-5ba79318-c41a-4ddc-a741-278181019f02,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-52210120-3536-49cc-b611-4439aefb75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-0697e8c6-e01e-4532-a5bd-42af8e5fb207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014939616-172.17.0.16-1598132994586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45450,DS-7f13f7ec-47c4-43a1-9f9f-96f59ee94057,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-6430ab58-254f-4c3d-8765-83231a909163,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-3e65bf97-8c8b-47e6-90cd-21c5b28666e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-14434296-4abf-4151-9830-61db7367e396,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-7b0ed677-cc87-47e0-86e6-69187a7150e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-ba48d6d2-7a07-4909-a99c-8bc39adcb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-756c9df5-4224-48ae-8c00-ffca5f2af150,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-a1f45d3b-cfa3-4e98-8437-30dbe935cde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014939616-172.17.0.16-1598132994586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45450,DS-7f13f7ec-47c4-43a1-9f9f-96f59ee94057,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-6430ab58-254f-4c3d-8765-83231a909163,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-3e65bf97-8c8b-47e6-90cd-21c5b28666e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-14434296-4abf-4151-9830-61db7367e396,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-7b0ed677-cc87-47e0-86e6-69187a7150e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-ba48d6d2-7a07-4909-a99c-8bc39adcb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-756c9df5-4224-48ae-8c00-ffca5f2af150,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-a1f45d3b-cfa3-4e98-8437-30dbe935cde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546615448-172.17.0.16-1598133089901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-158be191-67f3-4486-9365-5ffc215df8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1772ff85-753b-4c8a-bbc8-866e83cc14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-53d70f9c-c3d2-4a17-9636-b8b46490a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-ce39d611-5756-46e3-a060-02004554e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-36fd4ba1-5530-41aa-b6bc-de7ef7cd4576,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-a63de096-0e34-4766-bb35-9de2a7c682fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2c0d1ffc-cbaf-4e11-9772-dbc1f184ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-1eefb1eb-5f0f-4b25-a713-d2b2cef22036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546615448-172.17.0.16-1598133089901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-158be191-67f3-4486-9365-5ffc215df8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1772ff85-753b-4c8a-bbc8-866e83cc14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-53d70f9c-c3d2-4a17-9636-b8b46490a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-ce39d611-5756-46e3-a060-02004554e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-36fd4ba1-5530-41aa-b6bc-de7ef7cd4576,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-a63de096-0e34-4766-bb35-9de2a7c682fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-2c0d1ffc-cbaf-4e11-9772-dbc1f184ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-1eefb1eb-5f0f-4b25-a713-d2b2cef22036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827018942-172.17.0.16-1598133187220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46707,DS-dd88aaeb-ff9e-4444-9a3f-dc3a530704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-b0592f1e-e4bc-4918-bacc-60176b215ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-bfd1e68b-8148-4944-9614-e65a1d8dbdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-617945a5-80fd-4fcf-ac6a-96862660aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-8ad643c6-8d30-477b-9c1d-d9cbda25669f,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-af6ee4b2-db22-4ad3-80d1-db1926a9b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-d87a6001-e5b0-49ae-9412-141adbf808f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-09c737d3-202d-412b-9b3f-eb5100dff363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827018942-172.17.0.16-1598133187220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46707,DS-dd88aaeb-ff9e-4444-9a3f-dc3a530704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-b0592f1e-e4bc-4918-bacc-60176b215ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-bfd1e68b-8148-4944-9614-e65a1d8dbdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-617945a5-80fd-4fcf-ac6a-96862660aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-8ad643c6-8d30-477b-9c1d-d9cbda25669f,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-af6ee4b2-db22-4ad3-80d1-db1926a9b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-d87a6001-e5b0-49ae-9412-141adbf808f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-09c737d3-202d-412b-9b3f-eb5100dff363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6798
