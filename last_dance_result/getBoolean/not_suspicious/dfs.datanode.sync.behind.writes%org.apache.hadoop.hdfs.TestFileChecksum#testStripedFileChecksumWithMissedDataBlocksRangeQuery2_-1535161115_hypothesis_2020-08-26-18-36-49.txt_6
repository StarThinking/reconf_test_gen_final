reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497663875-172.17.0.8-1598467623942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-345460f7-eed3-4f31-bf65-462179f1dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-8963bea6-0bb1-4af3-a358-dd0458154226,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-e1ff64bd-b081-4fd5-b637-ee21f83c1857,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-22c0e09a-cf06-41ad-8dfa-ca7c4acde710,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-4a75cad3-8b01-4b76-bf02-b299a861bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-cedd8812-16db-45aa-93dd-da9f7ec0f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-ffab4a4d-04ae-41c2-b8a2-d25f67d673dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-ca031ccb-9566-45d5-844a-40f025b30423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497663875-172.17.0.8-1598467623942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-345460f7-eed3-4f31-bf65-462179f1dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-8963bea6-0bb1-4af3-a358-dd0458154226,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-e1ff64bd-b081-4fd5-b637-ee21f83c1857,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-22c0e09a-cf06-41ad-8dfa-ca7c4acde710,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-4a75cad3-8b01-4b76-bf02-b299a861bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-cedd8812-16db-45aa-93dd-da9f7ec0f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-ffab4a4d-04ae-41c2-b8a2-d25f67d673dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-ca031ccb-9566-45d5-844a-40f025b30423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924343406-172.17.0.8-1598467854260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-9c4b7ca8-262f-4a31-8c25-1325d405e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-7a9df934-7240-4167-a8c0-8b1a7eac50f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-54975d82-37c9-4c2f-b51e-01d0f93031f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-62dfd2a1-cb27-40da-a929-01ec22a45b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-948f5600-f563-46d6-be15-55c1b126bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5b827d39-e2a8-4bf0-8053-bed3d5c784d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-26da6080-6df4-48f1-88f6-78a398287c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-db65d919-cfa0-4ce4-ac9a-4e8e2e1288d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924343406-172.17.0.8-1598467854260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-9c4b7ca8-262f-4a31-8c25-1325d405e46e,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-7a9df934-7240-4167-a8c0-8b1a7eac50f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-54975d82-37c9-4c2f-b51e-01d0f93031f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-62dfd2a1-cb27-40da-a929-01ec22a45b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-948f5600-f563-46d6-be15-55c1b126bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5b827d39-e2a8-4bf0-8053-bed3d5c784d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-26da6080-6df4-48f1-88f6-78a398287c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-db65d919-cfa0-4ce4-ac9a-4e8e2e1288d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723283203-172.17.0.8-1598468534312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-eb576e79-ee83-450a-b2fb-e221fe823ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-7e67ccb2-8da2-4192-9ac7-bb2a3374a866,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-1d836cdd-f77e-47a1-aacb-c93a7bb8dd46,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-749ecaa7-13a5-4caa-a153-a9e40a0ae79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c7b91142-aa4a-4928-bd46-4c75d8a95f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-9b333419-b164-4bc5-bf1f-15e90bb9fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ff105da9-d50e-48d6-9c5f-e951c9acfd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-15c8dae0-9a53-4628-8cd7-bcd3a79eed55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723283203-172.17.0.8-1598468534312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40217,DS-eb576e79-ee83-450a-b2fb-e221fe823ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-7e67ccb2-8da2-4192-9ac7-bb2a3374a866,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-1d836cdd-f77e-47a1-aacb-c93a7bb8dd46,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-749ecaa7-13a5-4caa-a153-a9e40a0ae79b,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c7b91142-aa4a-4928-bd46-4c75d8a95f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-9b333419-b164-4bc5-bf1f-15e90bb9fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ff105da9-d50e-48d6-9c5f-e951c9acfd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-15c8dae0-9a53-4628-8cd7-bcd3a79eed55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884064701-172.17.0.8-1598469337478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-89a55136-e6e7-4b9a-8baf-5f995b4d94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-24e63050-e195-4091-ac55-cf158aaec9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-7ff47a53-33ab-4b99-b9de-4aca3c043542,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-d9298c2d-0b0d-408d-803d-fc106bc4abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-798fbc75-7e98-4d1a-8343-3b45568af919,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-f1755ebf-0c9b-47cb-aaf9-456dcb504ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-8569d544-c375-4f45-8ba2-f2ed69acb19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-6bdcda87-83b4-4071-a6fa-29b92b9a92db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884064701-172.17.0.8-1598469337478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-89a55136-e6e7-4b9a-8baf-5f995b4d94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-24e63050-e195-4091-ac55-cf158aaec9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-7ff47a53-33ab-4b99-b9de-4aca3c043542,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-d9298c2d-0b0d-408d-803d-fc106bc4abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-798fbc75-7e98-4d1a-8343-3b45568af919,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-f1755ebf-0c9b-47cb-aaf9-456dcb504ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-8569d544-c375-4f45-8ba2-f2ed69acb19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-6bdcda87-83b4-4071-a6fa-29b92b9a92db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351441619-172.17.0.8-1598470500019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-e1f071bc-0a46-4ffb-8450-9781ab3ea521,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-8c4e914d-8480-4937-a14c-37e821cfc29a,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-49b76227-cf83-4a7b-891b-820de7b187da,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-6bea6ed8-ad43-486e-902d-1fbfbb31293d,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b62a64b9-ab86-4ae4-a9eb-400fb0388f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-ed4cf132-100e-4399-bc9e-171ab387bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-ebf9b038-4cfb-4df1-b97b-038a8e0c1954,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-c88299dd-fa40-49c6-88e4-5924fa019f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351441619-172.17.0.8-1598470500019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-e1f071bc-0a46-4ffb-8450-9781ab3ea521,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-8c4e914d-8480-4937-a14c-37e821cfc29a,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-49b76227-cf83-4a7b-891b-820de7b187da,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-6bea6ed8-ad43-486e-902d-1fbfbb31293d,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-b62a64b9-ab86-4ae4-a9eb-400fb0388f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-ed4cf132-100e-4399-bc9e-171ab387bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-ebf9b038-4cfb-4df1-b97b-038a8e0c1954,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-c88299dd-fa40-49c6-88e4-5924fa019f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842605062-172.17.0.8-1598470635975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-ad43e4f2-be97-43a3-b1ea-17db906769f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-01a5106f-525e-494a-a8c5-ad5bcf54f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-abf1a98d-c511-4cc1-b40c-da68aad58c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-114a6cb4-0f6b-4982-8e6a-e7c2eccc89de,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-ee6de02a-03ea-43e3-b452-e97672d38bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-8dd3332f-4392-42ef-a718-44fe918338f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-6e0b4347-79db-458b-aed9-b4f56cf6939b,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-f9539dd6-fff0-490f-bd27-c62dbf2b5b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842605062-172.17.0.8-1598470635975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-ad43e4f2-be97-43a3-b1ea-17db906769f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-01a5106f-525e-494a-a8c5-ad5bcf54f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-abf1a98d-c511-4cc1-b40c-da68aad58c89,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-114a6cb4-0f6b-4982-8e6a-e7c2eccc89de,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-ee6de02a-03ea-43e3-b452-e97672d38bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-8dd3332f-4392-42ef-a718-44fe918338f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-6e0b4347-79db-458b-aed9-b4f56cf6939b,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-f9539dd6-fff0-490f-bd27-c62dbf2b5b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140753925-172.17.0.8-1598470968846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-3f05144a-d624-4c69-8dce-7a4403ef7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-7883ecf4-9c16-4aee-a993-855ca564e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-a9f50679-015b-4ba0-9448-fa6d2ff4a504,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-62b159d4-640c-4672-ac6d-d9b5b90331c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-660ba19c-bc40-4f92-89ac-df8ca7b7e519,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-4f738c99-904c-4d62-b9e1-a8a0f7eaea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-fb5e57ae-8bc0-4186-84b5-dda33883baef,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-3bb0ce3b-ab49-4c1e-9f1a-20adb64a23cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140753925-172.17.0.8-1598470968846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-3f05144a-d624-4c69-8dce-7a4403ef7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-7883ecf4-9c16-4aee-a993-855ca564e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-a9f50679-015b-4ba0-9448-fa6d2ff4a504,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-62b159d4-640c-4672-ac6d-d9b5b90331c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-660ba19c-bc40-4f92-89ac-df8ca7b7e519,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-4f738c99-904c-4d62-b9e1-a8a0f7eaea72,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-fb5e57ae-8bc0-4186-84b5-dda33883baef,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-3bb0ce3b-ab49-4c1e-9f1a-20adb64a23cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125814759-172.17.0.8-1598471251698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-ebebb3a8-1539-4d2c-81bb-b653bccee7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-8f3e71a2-e0d7-490c-bec9-06d4ca45e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7fe0c173-c724-47e0-bc8d-150bd8bbb575,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-16975e57-37a3-4368-973f-330bd7e063bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-b83eaf97-02b6-4d90-9927-e259a52d79a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-76721c40-0531-4605-b4f7-a48c672ed73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-9151b5d8-4a79-4627-9e98-7e05a12711e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-f0eab8d6-9640-4449-a7b8-f08b85bec488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125814759-172.17.0.8-1598471251698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-ebebb3a8-1539-4d2c-81bb-b653bccee7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-8f3e71a2-e0d7-490c-bec9-06d4ca45e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7fe0c173-c724-47e0-bc8d-150bd8bbb575,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-16975e57-37a3-4368-973f-330bd7e063bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-b83eaf97-02b6-4d90-9927-e259a52d79a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-76721c40-0531-4605-b4f7-a48c672ed73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-9151b5d8-4a79-4627-9e98-7e05a12711e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-f0eab8d6-9640-4449-a7b8-f08b85bec488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250574755-172.17.0.8-1598471448703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35604,DS-2f275bfa-fc9c-4827-b084-ae5410723b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-961a73e6-0006-4ede-b8e1-eb12ea7cae00,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-fd073012-b459-415f-b4ff-8b7b0c0d9cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-80ea4670-8549-4f6c-add1-b6eea279c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ecab6a6c-b355-4d4c-9747-af6f151bde26,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-48d024b1-92f0-4be2-8b84-1ac27b0d6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-365b226c-9127-436e-a9f9-d07a3b0c672a,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-fd55a01d-769f-4e8f-bcc1-80435344fc41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250574755-172.17.0.8-1598471448703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35604,DS-2f275bfa-fc9c-4827-b084-ae5410723b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-961a73e6-0006-4ede-b8e1-eb12ea7cae00,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-fd073012-b459-415f-b4ff-8b7b0c0d9cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-80ea4670-8549-4f6c-add1-b6eea279c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-ecab6a6c-b355-4d4c-9747-af6f151bde26,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-48d024b1-92f0-4be2-8b84-1ac27b0d6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-365b226c-9127-436e-a9f9-d07a3b0c672a,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-fd55a01d-769f-4e8f-bcc1-80435344fc41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897598006-172.17.0.8-1598471488612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-814e527e-732d-4f3b-9cd8-0d4c80d4fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e21f740a-0a6f-4188-ac16-f3a222efddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-6335c222-e861-4b3c-a890-2f32f23a94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-72089290-2936-497e-8745-0d2b39b2363e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-e384c9aa-f038-4061-b331-1774ee48266f,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-ebddffc7-4974-4407-bd4a-0bfeca047c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-9e8dbc7f-71af-41df-8470-6413296704f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-2d2a88b0-b6b9-461b-a68c-eae7422ad878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897598006-172.17.0.8-1598471488612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-814e527e-732d-4f3b-9cd8-0d4c80d4fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e21f740a-0a6f-4188-ac16-f3a222efddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-6335c222-e861-4b3c-a890-2f32f23a94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-72089290-2936-497e-8745-0d2b39b2363e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-e384c9aa-f038-4061-b331-1774ee48266f,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-ebddffc7-4974-4407-bd4a-0bfeca047c30,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-9e8dbc7f-71af-41df-8470-6413296704f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-2d2a88b0-b6b9-461b-a68c-eae7422ad878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107422001-172.17.0.8-1598471525780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-af3ae2bf-12b3-45dc-adf5-0859b77c8697,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-58893e43-5368-4e67-a137-b847e4d7c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-28d26d50-a85e-4631-95d5-ba0eadcf477f,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-b0ea0f2b-9a17-4b57-8e52-c21d798fa716,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-e6e0ea10-946b-47a5-accd-0796be35bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-6a07387b-827e-4ddf-9c6b-e6472e9b09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-06c3c087-2b1f-4222-9147-bc522fec27bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-81c6f4e4-241c-4af6-a5d1-e77936540733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107422001-172.17.0.8-1598471525780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-af3ae2bf-12b3-45dc-adf5-0859b77c8697,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-58893e43-5368-4e67-a137-b847e4d7c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-28d26d50-a85e-4631-95d5-ba0eadcf477f,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-b0ea0f2b-9a17-4b57-8e52-c21d798fa716,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-e6e0ea10-946b-47a5-accd-0796be35bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-6a07387b-827e-4ddf-9c6b-e6472e9b09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-06c3c087-2b1f-4222-9147-bc522fec27bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-81c6f4e4-241c-4af6-a5d1-e77936540733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960487412-172.17.0.8-1598472048376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-9c31ff53-2a89-4465-8715-a64b84cfe0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9dda9918-50f8-4b57-b9b4-834f087588b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-e2612e5e-1c6b-47c4-993b-18b4c6e7f925,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-e544875a-b135-4acd-9506-97ab6aef2268,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-26a785b5-7b51-4a9f-a402-66fd1d1317e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-00d777f8-c6cc-49de-9aed-8a0c6a83f500,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-91bf080d-c50a-433f-bf88-894d4ff89637,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-70bf2155-7329-410b-8b78-09ba1f892258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960487412-172.17.0.8-1598472048376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-9c31ff53-2a89-4465-8715-a64b84cfe0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9dda9918-50f8-4b57-b9b4-834f087588b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-e2612e5e-1c6b-47c4-993b-18b4c6e7f925,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-e544875a-b135-4acd-9506-97ab6aef2268,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-26a785b5-7b51-4a9f-a402-66fd1d1317e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-00d777f8-c6cc-49de-9aed-8a0c6a83f500,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-91bf080d-c50a-433f-bf88-894d4ff89637,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-70bf2155-7329-410b-8b78-09ba1f892258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550006170-172.17.0.8-1598472404934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-47d6c78a-a0eb-4f15-9ad2-f15863c304dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-3a0fcbbf-0e22-47f3-b9d3-d3472cf8f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-a8dca0d8-feaa-4a33-8e2c-e955e1360e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-1e4390ee-b1d9-4555-a5b1-e8bd3c77727e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f1fb1ae0-2bef-4d08-be93-b4a496e66b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-542a95e0-fb8a-44e3-9406-04afb070c202,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-239a8750-5d29-426b-8314-e0a2d425f182,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-4b96915e-f0db-44db-81fe-00268b3ef9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550006170-172.17.0.8-1598472404934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-47d6c78a-a0eb-4f15-9ad2-f15863c304dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-3a0fcbbf-0e22-47f3-b9d3-d3472cf8f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-a8dca0d8-feaa-4a33-8e2c-e955e1360e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-1e4390ee-b1d9-4555-a5b1-e8bd3c77727e,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f1fb1ae0-2bef-4d08-be93-b4a496e66b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-542a95e0-fb8a-44e3-9406-04afb070c202,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-239a8750-5d29-426b-8314-e0a2d425f182,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-4b96915e-f0db-44db-81fe-00268b3ef9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939873703-172.17.0.8-1598472586077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-a851c950-a62d-44c8-9364-43a5be9a33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6b65d103-878b-43ff-9b29-f300e776065f,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-cb53a27a-f7a0-47cf-8816-5b2f44fba522,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-81ebec27-857f-4bde-9ef3-3a7602bad86c,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-00c43766-b4f2-4e94-97e3-c07448a8a655,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-54d36a9f-a80a-406e-bee6-10d61da115d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-955b6350-422c-4cc2-a856-c6c55ac13320,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-47f01965-caaf-4afd-b033-7ce30528a9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939873703-172.17.0.8-1598472586077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-a851c950-a62d-44c8-9364-43a5be9a33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6b65d103-878b-43ff-9b29-f300e776065f,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-cb53a27a-f7a0-47cf-8816-5b2f44fba522,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-81ebec27-857f-4bde-9ef3-3a7602bad86c,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-00c43766-b4f2-4e94-97e3-c07448a8a655,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-54d36a9f-a80a-406e-bee6-10d61da115d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-955b6350-422c-4cc2-a856-c6c55ac13320,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-47f01965-caaf-4afd-b033-7ce30528a9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5630
