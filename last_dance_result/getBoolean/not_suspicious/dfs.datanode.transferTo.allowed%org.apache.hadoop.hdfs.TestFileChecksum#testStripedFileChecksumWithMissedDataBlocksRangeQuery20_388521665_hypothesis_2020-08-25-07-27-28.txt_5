reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950092379-172.17.0.3-1598340922027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-67c81058-f351-439a-9272-775ce809589e,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-80df3dd3-d761-4227-a8fa-bd6b5c6bfba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a4cde936-6747-424a-96ae-e349a1a0bc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-0763159c-474a-4deb-bb93-59495f6d25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2faa06a5-5a6b-46fb-a7a3-a3a0f76f4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-8ae69a90-ddf5-462f-8c04-148f73c945ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-32e99a01-53ab-4a72-898c-9221bccb9737,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-14c03495-30e7-4108-bb5b-8de68935a21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950092379-172.17.0.3-1598340922027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-67c81058-f351-439a-9272-775ce809589e,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-80df3dd3-d761-4227-a8fa-bd6b5c6bfba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a4cde936-6747-424a-96ae-e349a1a0bc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-0763159c-474a-4deb-bb93-59495f6d25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2faa06a5-5a6b-46fb-a7a3-a3a0f76f4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-8ae69a90-ddf5-462f-8c04-148f73c945ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-32e99a01-53ab-4a72-898c-9221bccb9737,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-14c03495-30e7-4108-bb5b-8de68935a21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228852238-172.17.0.3-1598341223213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41223,DS-24c00026-a1ca-403e-9d02-884beb517dab,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-64615264-675b-48f3-b9e5-751fc0a425a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8047c576-f859-420b-bc7e-d8ed7dc097e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-b8839065-d9cc-4da6-b5e9-e219a9ef2c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-92f0b74b-90b3-4d05-a72d-e034a08d8059,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-d5e6c9d8-5bc3-402f-8968-7933d616d438,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-9386e279-92a6-45b2-be36-cac1a27a622e,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-8955cbc6-fc1b-430a-bd4b-06606cdea2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228852238-172.17.0.3-1598341223213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41223,DS-24c00026-a1ca-403e-9d02-884beb517dab,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-64615264-675b-48f3-b9e5-751fc0a425a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8047c576-f859-420b-bc7e-d8ed7dc097e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-b8839065-d9cc-4da6-b5e9-e219a9ef2c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-92f0b74b-90b3-4d05-a72d-e034a08d8059,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-d5e6c9d8-5bc3-402f-8968-7933d616d438,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-9386e279-92a6-45b2-be36-cac1a27a622e,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-8955cbc6-fc1b-430a-bd4b-06606cdea2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379999661-172.17.0.3-1598341513273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-091957be-e626-4408-9ea0-1b792fcc48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-59fe0aef-c063-4229-ac46-52915034d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-4bba1dc6-c98b-4e8d-9e94-785e1b21dc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-31bb36c9-b676-4960-b6d6-2a6091842d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-427ae8a1-033e-423b-8643-2edf8b18d400,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-5d20f613-e11b-4115-8277-a8c0925aea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-b4e3b8fa-279d-42b5-abb7-f524cb5aca65,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-e0e39ca5-34f9-497e-9f6a-95fc9e52b109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379999661-172.17.0.3-1598341513273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45738,DS-091957be-e626-4408-9ea0-1b792fcc48e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-59fe0aef-c063-4229-ac46-52915034d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-4bba1dc6-c98b-4e8d-9e94-785e1b21dc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-31bb36c9-b676-4960-b6d6-2a6091842d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-427ae8a1-033e-423b-8643-2edf8b18d400,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-5d20f613-e11b-4115-8277-a8c0925aea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-b4e3b8fa-279d-42b5-abb7-f524cb5aca65,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-e0e39ca5-34f9-497e-9f6a-95fc9e52b109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916067049-172.17.0.3-1598342667849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-0f340e05-51a2-460c-9bd9-0a76fd840ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-8411c2e6-1464-450c-98e3-c6d7301c4675,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-e5c41d04-b42d-496b-b5fa-f1eed4462549,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-2d41c8c5-982e-47c8-add1-49cd15164f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-0e02c298-8222-41a2-bb24-013b378174e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-e8dca228-2f34-4875-8045-f342168b9128,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-35691246-173e-4f66-a768-6927f14c903e,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-42dd1a1b-a2d1-498c-a2a6-0b22546dd44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916067049-172.17.0.3-1598342667849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38805,DS-0f340e05-51a2-460c-9bd9-0a76fd840ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-8411c2e6-1464-450c-98e3-c6d7301c4675,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-e5c41d04-b42d-496b-b5fa-f1eed4462549,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-2d41c8c5-982e-47c8-add1-49cd15164f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-0e02c298-8222-41a2-bb24-013b378174e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-e8dca228-2f34-4875-8045-f342168b9128,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-35691246-173e-4f66-a768-6927f14c903e,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-42dd1a1b-a2d1-498c-a2a6-0b22546dd44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257543405-172.17.0.3-1598342855588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37752,DS-c204af4f-19cc-4c7d-bb4a-0a36a562de68,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-b1c0a88b-c5c9-43ec-a01c-f8a1c9632f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-66fa8c7e-4f40-4be7-8957-42efae913382,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-6785b55c-9aed-45e2-b998-6de9a5a36fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e52af193-a938-45c3-bf78-3e4dc1c44d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-77b3b0f2-16ec-49d0-9b7d-459bfe950077,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-9fe961a4-6d63-4149-bd4a-85ab2eda86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-72166ef5-c6e3-4236-8e3b-f22812d6f3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257543405-172.17.0.3-1598342855588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37752,DS-c204af4f-19cc-4c7d-bb4a-0a36a562de68,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-b1c0a88b-c5c9-43ec-a01c-f8a1c9632f80,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-66fa8c7e-4f40-4be7-8957-42efae913382,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-6785b55c-9aed-45e2-b998-6de9a5a36fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e52af193-a938-45c3-bf78-3e4dc1c44d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-77b3b0f2-16ec-49d0-9b7d-459bfe950077,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-9fe961a4-6d63-4149-bd4a-85ab2eda86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-72166ef5-c6e3-4236-8e3b-f22812d6f3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624395453-172.17.0.3-1598343362654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-c061feb5-6761-4d2a-af8e-9729b478cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-31305ba6-05c5-44a7-95bc-99d64b6771a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-04540e39-38b3-404a-a708-d352a306b695,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-7902a930-9568-43ee-800b-c371cfe29ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-635223c2-c872-4138-b996-3fa2b0d50465,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-fbcd8dad-bc1f-4183-a2fe-f2e45d5fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d1a8ab51-4e9e-49df-8cb6-fe7a5ec1a729,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-bcf03a95-24ee-4a4d-ad33-b68645804d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624395453-172.17.0.3-1598343362654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-c061feb5-6761-4d2a-af8e-9729b478cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-31305ba6-05c5-44a7-95bc-99d64b6771a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-04540e39-38b3-404a-a708-d352a306b695,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-7902a930-9568-43ee-800b-c371cfe29ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-635223c2-c872-4138-b996-3fa2b0d50465,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-fbcd8dad-bc1f-4183-a2fe-f2e45d5fb173,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d1a8ab51-4e9e-49df-8cb6-fe7a5ec1a729,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-bcf03a95-24ee-4a4d-ad33-b68645804d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787352324-172.17.0.3-1598343733210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-df9829b3-2770-46ba-a603-6272ff37e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-07756732-8db6-4762-aa70-1a305c0d9782,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-57cefb5d-6e53-4aa7-936d-b8936423ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-cd51e74f-cae3-44ca-b7f2-1d5fd2f9f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f88e6c3a-dee5-459f-a6de-c2ea34b21632,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3813d30f-5fe5-49b8-945c-c208a818aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-ce5633c8-61cd-4356-a3bc-30f76ced0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-87bbee81-d1b1-449d-848b-787684b40d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787352324-172.17.0.3-1598343733210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-df9829b3-2770-46ba-a603-6272ff37e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-07756732-8db6-4762-aa70-1a305c0d9782,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-57cefb5d-6e53-4aa7-936d-b8936423ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-cd51e74f-cae3-44ca-b7f2-1d5fd2f9f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f88e6c3a-dee5-459f-a6de-c2ea34b21632,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3813d30f-5fe5-49b8-945c-c208a818aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-ce5633c8-61cd-4356-a3bc-30f76ced0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-87bbee81-d1b1-449d-848b-787684b40d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566270744-172.17.0.3-1598343772130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-e67f5739-fde6-47c3-867b-7ae8646ef759,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-a7c73426-baad-454e-ab77-03dd1b262676,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-0b021348-c713-48f2-acac-99709281c829,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-ebec8e8f-297d-4ee8-9061-309f94a75aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-4701d30a-a128-4c43-86a9-43747da398d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-7014726c-9eec-4da0-8b1f-a42bb4e33430,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-0f9dceec-3052-48c6-8370-c556215d6678,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3c36013a-0e33-49ca-a2d1-a7b716484e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566270744-172.17.0.3-1598343772130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-e67f5739-fde6-47c3-867b-7ae8646ef759,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-a7c73426-baad-454e-ab77-03dd1b262676,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-0b021348-c713-48f2-acac-99709281c829,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-ebec8e8f-297d-4ee8-9061-309f94a75aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-4701d30a-a128-4c43-86a9-43747da398d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-7014726c-9eec-4da0-8b1f-a42bb4e33430,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-0f9dceec-3052-48c6-8370-c556215d6678,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3c36013a-0e33-49ca-a2d1-a7b716484e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641246893-172.17.0.3-1598343953842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33020,DS-2f646e6f-9635-4512-89f9-15c2fe32c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-9adcb34d-af8f-44ef-9cb4-e87d9ea630ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-ab4190c5-a4a5-4d28-86d6-04489e024611,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-598a839b-8d60-499d-8ab5-908c57141c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-c51a6b3e-991e-4487-a9f9-92b57d7bcc81,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-6363f238-e0f6-43f7-98a9-2048589fdce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-fb33d5fe-9d67-4a64-9627-2ecec0f99020,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6a1c5410-9622-4b62-85bd-839beda790f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641246893-172.17.0.3-1598343953842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33020,DS-2f646e6f-9635-4512-89f9-15c2fe32c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-9adcb34d-af8f-44ef-9cb4-e87d9ea630ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-ab4190c5-a4a5-4d28-86d6-04489e024611,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-598a839b-8d60-499d-8ab5-908c57141c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-c51a6b3e-991e-4487-a9f9-92b57d7bcc81,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-6363f238-e0f6-43f7-98a9-2048589fdce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-fb33d5fe-9d67-4a64-9627-2ecec0f99020,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6a1c5410-9622-4b62-85bd-839beda790f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332153787-172.17.0.3-1598344789351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-1b7453ea-9935-487d-b599-ebfa9302b292,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-67bb0c91-83c1-43a5-8686-686e1a7a7d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-5a42f83a-83f2-485e-afa0-20f78c93d665,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-4062ce8e-4037-4e67-bf85-ae3f1d200bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c8dd7efd-25cf-4287-8f5d-aa3777d64349,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-a744f83d-3cba-4c60-94dc-400ecfb469a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-71884b8c-d16e-48f2-abc3-be4b7ff17b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-24a3e932-6d63-4dd7-9bbf-030c0218223e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332153787-172.17.0.3-1598344789351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-1b7453ea-9935-487d-b599-ebfa9302b292,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-67bb0c91-83c1-43a5-8686-686e1a7a7d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-5a42f83a-83f2-485e-afa0-20f78c93d665,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-4062ce8e-4037-4e67-bf85-ae3f1d200bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c8dd7efd-25cf-4287-8f5d-aa3777d64349,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-a744f83d-3cba-4c60-94dc-400ecfb469a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-71884b8c-d16e-48f2-abc3-be4b7ff17b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-24a3e932-6d63-4dd7-9bbf-030c0218223e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545531592-172.17.0.3-1598344864347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-5661c934-2ce7-44ef-8c27-53c8a082b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-e045cea4-ff8c-467a-a6a8-abb540f4f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-984fe537-0333-463c-8896-d7c1307bac53,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4d65fc54-ecbe-4520-8bbd-363d3781aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-253653ff-92e6-4164-b28f-58d7a5331c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-9056ae2d-5758-4ccc-a901-ab5228f3efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-2cbb11fa-4923-4707-9215-098a9e57682c,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-8ddc5a5d-cbde-409d-82da-d3908119f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545531592-172.17.0.3-1598344864347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-5661c934-2ce7-44ef-8c27-53c8a082b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-e045cea4-ff8c-467a-a6a8-abb540f4f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-984fe537-0333-463c-8896-d7c1307bac53,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4d65fc54-ecbe-4520-8bbd-363d3781aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-253653ff-92e6-4164-b28f-58d7a5331c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-9056ae2d-5758-4ccc-a901-ab5228f3efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-2cbb11fa-4923-4707-9215-098a9e57682c,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-8ddc5a5d-cbde-409d-82da-d3908119f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499517871-172.17.0.3-1598345355361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-213e378f-f98b-4304-a76d-a05e8d621ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-02b39989-6178-4f7e-9e95-f066f8bba496,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-155b3725-3303-4904-b871-a86e2b1e884d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-61990071-366e-4be2-9d53-e8dd87d240df,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-3630f040-4bf2-4c90-9e61-23f0bc36b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-6dc8da8e-e143-476d-abb8-c903ae3b240d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-db830649-4635-4bc2-8747-f6edac45cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-02a8ebc6-f819-4d2a-8950-882db2defe65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499517871-172.17.0.3-1598345355361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41407,DS-213e378f-f98b-4304-a76d-a05e8d621ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-02b39989-6178-4f7e-9e95-f066f8bba496,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-155b3725-3303-4904-b871-a86e2b1e884d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-61990071-366e-4be2-9d53-e8dd87d240df,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-3630f040-4bf2-4c90-9e61-23f0bc36b0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-6dc8da8e-e143-476d-abb8-c903ae3b240d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-db830649-4635-4bc2-8747-f6edac45cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-02a8ebc6-f819-4d2a-8950-882db2defe65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5429
