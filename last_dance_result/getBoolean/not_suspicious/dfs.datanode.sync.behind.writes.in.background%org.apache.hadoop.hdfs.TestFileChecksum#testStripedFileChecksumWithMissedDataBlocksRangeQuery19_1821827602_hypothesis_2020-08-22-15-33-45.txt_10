reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937265024-172.17.0.9-1598110937832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-50544ba6-35d8-4a39-b653-701462a12bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5e0b617f-eba7-46da-a2f1-bb9b3077701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-9d6e52dd-5414-4db3-8f93-84c531db0e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-e574e636-5906-4e8c-87c9-be5c405bc015,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-01583872-79b6-4376-8303-6f44516a7ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-6a1889c5-fcd9-4295-bccd-9876f60f2659,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-311c588d-87e0-4fdd-83f2-b0ffafde2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-76655d5e-84ae-4083-b697-8800a5c81dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937265024-172.17.0.9-1598110937832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-50544ba6-35d8-4a39-b653-701462a12bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5e0b617f-eba7-46da-a2f1-bb9b3077701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-9d6e52dd-5414-4db3-8f93-84c531db0e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-e574e636-5906-4e8c-87c9-be5c405bc015,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-01583872-79b6-4376-8303-6f44516a7ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-6a1889c5-fcd9-4295-bccd-9876f60f2659,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-311c588d-87e0-4fdd-83f2-b0ffafde2a69,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-76655d5e-84ae-4083-b697-8800a5c81dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301913113-172.17.0.9-1598111186751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-c0b8ebff-086a-4608-a921-99e5d1b73bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-0709967f-20e5-41fa-a03c-e39d81dae1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-f1bd7d41-c89b-4951-b0d7-ec90e131c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6854fa21-d407-4a06-ba50-f7d506f374f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-35c1b0df-72cd-409c-a51e-089f1d80f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-4a3291a6-5867-4c22-ae34-46a7194c56e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b61a9df5-816b-42d1-a12e-434a65cffb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-99433626-44f2-45ef-a7a6-c24d2698319f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301913113-172.17.0.9-1598111186751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-c0b8ebff-086a-4608-a921-99e5d1b73bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-0709967f-20e5-41fa-a03c-e39d81dae1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-f1bd7d41-c89b-4951-b0d7-ec90e131c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6854fa21-d407-4a06-ba50-f7d506f374f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-35c1b0df-72cd-409c-a51e-089f1d80f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-4a3291a6-5867-4c22-ae34-46a7194c56e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b61a9df5-816b-42d1-a12e-434a65cffb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-99433626-44f2-45ef-a7a6-c24d2698319f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16458520-172.17.0.9-1598111456983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-4d606cc6-0de8-481b-9207-e99619fa5432,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-07c9172f-f798-4b5f-b4c6-0789dd89d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-df5d63a0-f5e2-4716-b337-53031b529c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-516a9db1-2af8-43f1-85bb-943a65c7fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0b4c016a-f1ca-407e-b1e3-dda0c61ab0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9deb8b76-e14a-49a8-9b15-d59dda139737,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-9b32f820-ae7b-49d5-876f-3c7e1876e4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-56271915-9581-4b56-bd7d-c62347011e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16458520-172.17.0.9-1598111456983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-4d606cc6-0de8-481b-9207-e99619fa5432,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-07c9172f-f798-4b5f-b4c6-0789dd89d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-df5d63a0-f5e2-4716-b337-53031b529c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-516a9db1-2af8-43f1-85bb-943a65c7fb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0b4c016a-f1ca-407e-b1e3-dda0c61ab0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9deb8b76-e14a-49a8-9b15-d59dda139737,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-9b32f820-ae7b-49d5-876f-3c7e1876e4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-56271915-9581-4b56-bd7d-c62347011e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382129604-172.17.0.9-1598111643721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-09272cd4-ef1d-4a80-aad8-f08173f284e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-fafa4e4a-43a9-48bb-81bd-bba1fb73a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-88e0582d-0d90-40dc-9b84-3acf86bdc76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-15c5e20e-ba91-4586-8d4e-16cf7b640804,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-8106eb2f-670d-4ae4-a9d1-6bb77df9bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4e28a30a-72be-40d9-8b18-9e4cb6f921c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-d7d6fa89-150a-4d04-abc9-3a7ba9de21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0cf985d1-b304-41be-b872-b00824fb54f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382129604-172.17.0.9-1598111643721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-09272cd4-ef1d-4a80-aad8-f08173f284e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-fafa4e4a-43a9-48bb-81bd-bba1fb73a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-88e0582d-0d90-40dc-9b84-3acf86bdc76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-15c5e20e-ba91-4586-8d4e-16cf7b640804,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-8106eb2f-670d-4ae4-a9d1-6bb77df9bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4e28a30a-72be-40d9-8b18-9e4cb6f921c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-d7d6fa89-150a-4d04-abc9-3a7ba9de21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-0cf985d1-b304-41be-b872-b00824fb54f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599410735-172.17.0.9-1598111837590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-cae7eb5f-0d4c-40b0-ad84-e2ffb9ea7082,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-69b8ef0d-ca58-47f0-b475-07bfcd653675,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-8e05fbae-24e4-41df-8bb1-1833c1863254,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-73dbecd4-3799-470c-bf97-f4a263c95425,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-a2e908c6-5641-4024-b5bf-2edceeb1ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-09306d7b-2e70-4e62-b83a-5994746720e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-41cd51f3-e306-47d3-9cd0-d16ee3e71e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-68132f08-a2bc-48e8-99fc-8364c6372f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599410735-172.17.0.9-1598111837590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-cae7eb5f-0d4c-40b0-ad84-e2ffb9ea7082,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-69b8ef0d-ca58-47f0-b475-07bfcd653675,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-8e05fbae-24e4-41df-8bb1-1833c1863254,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-73dbecd4-3799-470c-bf97-f4a263c95425,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-a2e908c6-5641-4024-b5bf-2edceeb1ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-09306d7b-2e70-4e62-b83a-5994746720e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-41cd51f3-e306-47d3-9cd0-d16ee3e71e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-68132f08-a2bc-48e8-99fc-8364c6372f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006557845-172.17.0.9-1598112307935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-309c4bb1-2227-4b4e-8191-67e208236f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-fced159c-d04a-450f-bc02-60e29813ea97,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-a5d783ca-b39b-4d48-9ca3-00f903cd36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0eb1ed04-8d3b-4a66-ac6c-bb21c04eda79,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-351cddc5-066a-4ccd-bfc3-3407ced8beb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-c1b2de30-cd17-44d3-9026-7f2fa750bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-ff2e063f-2005-40ab-834a-b6b89c2e5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-7d099dee-79e7-4339-88b6-6c37dff2baaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006557845-172.17.0.9-1598112307935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-309c4bb1-2227-4b4e-8191-67e208236f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-fced159c-d04a-450f-bc02-60e29813ea97,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-a5d783ca-b39b-4d48-9ca3-00f903cd36ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0eb1ed04-8d3b-4a66-ac6c-bb21c04eda79,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-351cddc5-066a-4ccd-bfc3-3407ced8beb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-c1b2de30-cd17-44d3-9026-7f2fa750bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-ff2e063f-2005-40ab-834a-b6b89c2e5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-7d099dee-79e7-4339-88b6-6c37dff2baaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854889849-172.17.0.9-1598113506602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-db4d0325-216e-40ed-a04b-6485857b1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-8053fec6-7f96-4cad-844d-5c685d1d9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-8385c4b8-2a41-43d6-aa07-aa72b6a4c8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-4c7374ee-c386-43bd-b3f3-6642d9c4758c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-08681c21-09d1-4fb5-8061-2731c1fad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f7d09ce6-d0d4-4698-99f0-daf5e7d2c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-de5212bf-7b33-444e-8faa-292d8ec3c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-445247f3-9b4a-42d3-a1f7-e9a8fc454fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854889849-172.17.0.9-1598113506602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-db4d0325-216e-40ed-a04b-6485857b1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-8053fec6-7f96-4cad-844d-5c685d1d9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-8385c4b8-2a41-43d6-aa07-aa72b6a4c8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-4c7374ee-c386-43bd-b3f3-6642d9c4758c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-08681c21-09d1-4fb5-8061-2731c1fad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f7d09ce6-d0d4-4698-99f0-daf5e7d2c8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-de5212bf-7b33-444e-8faa-292d8ec3c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-445247f3-9b4a-42d3-a1f7-e9a8fc454fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470134515-172.17.0.9-1598113875613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-8eb91aeb-1021-4e12-9146-f51a71899f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-ff848720-ad14-4ba7-8ec2-68ccf5324863,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-26aa789f-ca0a-4ca1-98c0-577c564afcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-3418c0c4-2b05-4b92-af6c-399b81fa7a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-8829989f-1273-41b1-8845-ff220ff8cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8f8dffc1-b11a-4de4-9262-518c979200c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-aa095384-9e18-46c9-b2b6-e8e76d43a88f,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-fed92ded-0396-4c79-b2d6-616cbd6eb280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470134515-172.17.0.9-1598113875613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44439,DS-8eb91aeb-1021-4e12-9146-f51a71899f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-ff848720-ad14-4ba7-8ec2-68ccf5324863,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-26aa789f-ca0a-4ca1-98c0-577c564afcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-3418c0c4-2b05-4b92-af6c-399b81fa7a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-8829989f-1273-41b1-8845-ff220ff8cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8f8dffc1-b11a-4de4-9262-518c979200c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-aa095384-9e18-46c9-b2b6-e8e76d43a88f,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-fed92ded-0396-4c79-b2d6-616cbd6eb280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758583796-172.17.0.9-1598114018155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-e8917e51-55ba-4d6b-8690-dc4a8e0eb286,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-745f78be-4de0-40cf-83b9-44b0d14cbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-504d4fdf-49ca-402d-ab9e-d5ecf27ee7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-069d2bfb-85bf-4d57-908d-f35f248cfbed,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-66b28e06-ed79-492f-97ee-0328cdb5cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a4ca165c-72cf-4d84-8a53-5b7fccd96eed,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-345e9302-7046-495f-af8e-98039bd1fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-78cd5b83-0ada-403a-a79e-a58f10109d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758583796-172.17.0.9-1598114018155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-e8917e51-55ba-4d6b-8690-dc4a8e0eb286,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-745f78be-4de0-40cf-83b9-44b0d14cbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-504d4fdf-49ca-402d-ab9e-d5ecf27ee7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-069d2bfb-85bf-4d57-908d-f35f248cfbed,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-66b28e06-ed79-492f-97ee-0328cdb5cab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a4ca165c-72cf-4d84-8a53-5b7fccd96eed,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-345e9302-7046-495f-af8e-98039bd1fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-78cd5b83-0ada-403a-a79e-a58f10109d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961034112-172.17.0.9-1598114583092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44114,DS-2f834113-75d1-4630-81fe-4b2ca9f36773,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-1e26919b-0be4-4ddb-9f95-60c1a01b16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-f6d114fb-239f-4ffb-b90b-51df00c9be87,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-91fcc354-ac6a-4cb4-98f1-d764de41e115,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-05493116-c3cf-413e-bdd3-e4283c20b186,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-f44d2164-766d-431a-8897-2806f5700506,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-72963784-a555-4673-b8b4-d2bb84db1d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-9fdb3555-c15f-4b74-98df-ad4396bbbfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961034112-172.17.0.9-1598114583092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44114,DS-2f834113-75d1-4630-81fe-4b2ca9f36773,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-1e26919b-0be4-4ddb-9f95-60c1a01b16cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-f6d114fb-239f-4ffb-b90b-51df00c9be87,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-91fcc354-ac6a-4cb4-98f1-d764de41e115,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-05493116-c3cf-413e-bdd3-e4283c20b186,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-f44d2164-766d-431a-8897-2806f5700506,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-72963784-a555-4673-b8b4-d2bb84db1d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-9fdb3555-c15f-4b74-98df-ad4396bbbfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600915466-172.17.0.9-1598114998447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-8aa702ca-4510-4176-b7c2-ab98326feb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-2ec24c72-cb44-4f9f-b14a-9c1d7c92a422,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-e15ce1d8-c4e6-4d39-9a3e-a58af44095b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c82003ce-d2e7-467a-84d9-a5977f6efe35,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-488cdfd3-8901-4435-a3dc-ec943fa18476,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-a8e322cb-039c-4d74-b6b6-cf03465dc268,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-96025f81-1ea1-4605-b48a-f725e9500e73,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-2ca39bda-76dc-4c96-a12a-789dbf9aeb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600915466-172.17.0.9-1598114998447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-8aa702ca-4510-4176-b7c2-ab98326feb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-2ec24c72-cb44-4f9f-b14a-9c1d7c92a422,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-e15ce1d8-c4e6-4d39-9a3e-a58af44095b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c82003ce-d2e7-467a-84d9-a5977f6efe35,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-488cdfd3-8901-4435-a3dc-ec943fa18476,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-a8e322cb-039c-4d74-b6b6-cf03465dc268,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-96025f81-1ea1-4605-b48a-f725e9500e73,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-2ca39bda-76dc-4c96-a12a-789dbf9aeb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5408
