reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037050283-172.17.0.10-1598158230851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-8bfa2692-843c-4487-8a2b-0f73ed5277ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9ab0e705-d291-42b6-907c-12844216977a,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-defe9523-fed2-451b-b8ff-3103aea9cbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-9738b455-45b8-4f26-8d72-819e1b04725f,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-ef47982c-3661-4c55-b0c3-3c28bd7ec33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-60867f38-0f68-4ad6-8478-be4d2d668303,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5e09da30-b401-415d-8318-59a2548a8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-a784f93e-b7af-4dcf-a5a3-8c670874cb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037050283-172.17.0.10-1598158230851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46754,DS-8bfa2692-843c-4487-8a2b-0f73ed5277ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9ab0e705-d291-42b6-907c-12844216977a,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-defe9523-fed2-451b-b8ff-3103aea9cbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-9738b455-45b8-4f26-8d72-819e1b04725f,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-ef47982c-3661-4c55-b0c3-3c28bd7ec33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-60867f38-0f68-4ad6-8478-be4d2d668303,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5e09da30-b401-415d-8318-59a2548a8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-a784f93e-b7af-4dcf-a5a3-8c670874cb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784563331-172.17.0.10-1598158884001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-4f368b28-42b7-4bd1-a172-3b40ee716778,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-d369ae11-03fd-4568-84a4-3c6ea6a39cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-6cf1f277-13a8-458d-ac1b-5ec104608237,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-621e3605-9820-4856-bc3f-9909ee46972b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-e94991c5-d8aa-4afa-92d7-081c277b9684,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a10d5e01-1f73-4958-8d72-3f00b3813cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-8758e3e6-32ac-4ae9-b13e-7598b7b64f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-5125fb76-1f27-4832-ab44-f899d6964a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784563331-172.17.0.10-1598158884001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-4f368b28-42b7-4bd1-a172-3b40ee716778,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-d369ae11-03fd-4568-84a4-3c6ea6a39cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-6cf1f277-13a8-458d-ac1b-5ec104608237,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-621e3605-9820-4856-bc3f-9909ee46972b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-e94991c5-d8aa-4afa-92d7-081c277b9684,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a10d5e01-1f73-4958-8d72-3f00b3813cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-8758e3e6-32ac-4ae9-b13e-7598b7b64f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-5125fb76-1f27-4832-ab44-f899d6964a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703990118-172.17.0.10-1598158997064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-b4350f97-183b-43f5-a612-42a26aafff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-aedf3b69-8642-46e1-82f5-fe82126daf89,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-25c982a9-bd47-4e4f-9f4a-d4caa838ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-7643ec47-6437-4489-a8b9-be2d163b7cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a4d298f4-0857-4ca0-879b-1195968fcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-623a21a3-604c-404a-84c9-32213c03bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-788f3ffc-5e3f-4aed-82cb-87a3faaa965e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-9f073a9b-3da2-4947-8192-ebe49ee67887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703990118-172.17.0.10-1598158997064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37352,DS-b4350f97-183b-43f5-a612-42a26aafff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-aedf3b69-8642-46e1-82f5-fe82126daf89,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-25c982a9-bd47-4e4f-9f4a-d4caa838ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-7643ec47-6437-4489-a8b9-be2d163b7cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a4d298f4-0857-4ca0-879b-1195968fcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-623a21a3-604c-404a-84c9-32213c03bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-788f3ffc-5e3f-4aed-82cb-87a3faaa965e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-9f073a9b-3da2-4947-8192-ebe49ee67887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599248677-172.17.0.10-1598159111185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-e4fc54f0-996d-4609-b020-4f7467807516,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-ffec1b96-3947-4709-8cd7-99fc3ca8044b,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-87085225-ba91-4d70-8f51-4d874a6fc827,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-bfffbe43-a6ae-41e7-bb45-2cdca0247662,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ac8bbd19-7ecd-4f8f-a4cb-8deeb5313e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-da6527a2-6d73-4285-812f-ee905cbf0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-0d11043c-412d-4c97-8c5a-6adc1d912fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-07a0679d-b694-45d7-8925-81c1b6a9bfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599248677-172.17.0.10-1598159111185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-e4fc54f0-996d-4609-b020-4f7467807516,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-ffec1b96-3947-4709-8cd7-99fc3ca8044b,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-87085225-ba91-4d70-8f51-4d874a6fc827,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-bfffbe43-a6ae-41e7-bb45-2cdca0247662,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ac8bbd19-7ecd-4f8f-a4cb-8deeb5313e80,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-da6527a2-6d73-4285-812f-ee905cbf0af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-0d11043c-412d-4c97-8c5a-6adc1d912fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-07a0679d-b694-45d7-8925-81c1b6a9bfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778298953-172.17.0.10-1598159176420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-b02170a7-f470-4283-95c4-b9928c034d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-e13a9ee7-0e46-4bfd-9ba1-9b1260a7fa85,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-141a3f55-783f-41da-bf48-44784faa1de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-5be1342b-92f8-455a-b8b7-d2dd4faf7702,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-0f6de371-309f-4c5f-9d6f-a5c5344869e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-24777251-c47f-40b2-9cdb-71fc7ea33b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-14e506d0-354d-4b52-9387-680362bc8eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-42a18260-b09a-4d9c-966b-77c208050aa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778298953-172.17.0.10-1598159176420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-b02170a7-f470-4283-95c4-b9928c034d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-e13a9ee7-0e46-4bfd-9ba1-9b1260a7fa85,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-141a3f55-783f-41da-bf48-44784faa1de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-5be1342b-92f8-455a-b8b7-d2dd4faf7702,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-0f6de371-309f-4c5f-9d6f-a5c5344869e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-24777251-c47f-40b2-9cdb-71fc7ea33b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-14e506d0-354d-4b52-9387-680362bc8eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-42a18260-b09a-4d9c-966b-77c208050aa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108546659-172.17.0.10-1598159972315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-3d890761-f461-4e7b-8ec2-17a65e921d66,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-6a2a9232-11d1-412f-9bf1-d30e429b0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b1c9e549-3e06-45a0-8d00-391c1ae02c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-6022eb36-17fc-4db4-b6e3-9a45ec84f794,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-2a860fed-8c0f-4ad4-9fb3-0dfb76a4e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-ea42e8ec-5554-4ec1-8a0b-9dc9d5682781,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-9453d894-af77-4ab9-9ef9-b68627049c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-b9965955-15bf-4d08-96d3-8b1c67007dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108546659-172.17.0.10-1598159972315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-3d890761-f461-4e7b-8ec2-17a65e921d66,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-6a2a9232-11d1-412f-9bf1-d30e429b0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-b1c9e549-3e06-45a0-8d00-391c1ae02c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-6022eb36-17fc-4db4-b6e3-9a45ec84f794,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-2a860fed-8c0f-4ad4-9fb3-0dfb76a4e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-ea42e8ec-5554-4ec1-8a0b-9dc9d5682781,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-9453d894-af77-4ab9-9ef9-b68627049c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-b9965955-15bf-4d08-96d3-8b1c67007dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582450880-172.17.0.10-1598160033347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-eefe2948-2cea-4908-879f-727e0dacbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-e9a50d9f-c492-4f4e-905c-f7da5b3aa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-0bf940f2-a5be-4e3b-8c93-9305b0a3b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-1366e36a-4e84-438f-ae39-89a8e0c626ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-bc6f26af-56e5-4c9e-a0c2-c4138eba07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-574d5bf5-0fb9-4e12-9881-49d2a5dd1743,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-1c1143f2-71f4-464f-85e0-4eeffd29d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-ba763cd7-6e3c-4e88-998c-95a2390645c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582450880-172.17.0.10-1598160033347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-eefe2948-2cea-4908-879f-727e0dacbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-e9a50d9f-c492-4f4e-905c-f7da5b3aa2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-0bf940f2-a5be-4e3b-8c93-9305b0a3b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-1366e36a-4e84-438f-ae39-89a8e0c626ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-bc6f26af-56e5-4c9e-a0c2-c4138eba07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-574d5bf5-0fb9-4e12-9881-49d2a5dd1743,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-1c1143f2-71f4-464f-85e0-4eeffd29d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-ba763cd7-6e3c-4e88-998c-95a2390645c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516484748-172.17.0.10-1598160887309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-8d865e74-2646-4af2-97e1-ad1b709436e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-c05e4fa7-eba6-4ce8-b851-9e80e7d3ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-5f6142cd-0aa5-4a47-9274-cb7e09e78867,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-11f4a0b0-b411-44e6-b041-2d3f33eee9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-1a9c4100-441a-4386-b2e2-74b2c15ae949,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-d54aacd0-d550-4ac8-a74b-c94fff74d843,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-987581f4-8b75-4c90-8186-685c577faf68,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-4ed23665-32fa-4913-9d5f-517c43e08a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516484748-172.17.0.10-1598160887309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-8d865e74-2646-4af2-97e1-ad1b709436e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-c05e4fa7-eba6-4ce8-b851-9e80e7d3ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-5f6142cd-0aa5-4a47-9274-cb7e09e78867,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-11f4a0b0-b411-44e6-b041-2d3f33eee9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-1a9c4100-441a-4386-b2e2-74b2c15ae949,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-d54aacd0-d550-4ac8-a74b-c94fff74d843,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-987581f4-8b75-4c90-8186-685c577faf68,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-4ed23665-32fa-4913-9d5f-517c43e08a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295606086-172.17.0.10-1598160922780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-17e1f8f2-7a5c-46a9-9a16-b87f57f883ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-98e99c8a-d1df-44a3-a7bd-f774eefda2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-00b936f4-fa52-4eb0-ba8e-63164dc8b510,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-4b5632db-9d21-448e-8502-b3299bb5c96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-8066d373-8fe4-4b21-9fef-044e1d352704,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c3bd86ed-d846-4574-b661-b867345363ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-98e58632-8bcb-4e72-b99a-cb836b1ee365,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2cad9608-a2a2-4de6-80e8-51fac97c9989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295606086-172.17.0.10-1598160922780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-17e1f8f2-7a5c-46a9-9a16-b87f57f883ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-98e99c8a-d1df-44a3-a7bd-f774eefda2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-00b936f4-fa52-4eb0-ba8e-63164dc8b510,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-4b5632db-9d21-448e-8502-b3299bb5c96a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-8066d373-8fe4-4b21-9fef-044e1d352704,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c3bd86ed-d846-4574-b661-b867345363ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-98e58632-8bcb-4e72-b99a-cb836b1ee365,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2cad9608-a2a2-4de6-80e8-51fac97c9989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385457884-172.17.0.10-1598161072167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44370,DS-571467d4-f2d6-4fd2-954d-6c811c974122,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-b3f74794-caea-4949-8e49-5cdbd3bfffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-78f45599-5e51-4867-81fc-0ab99fdda7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-714c290b-3659-4ce7-bda5-55d86a3c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-df0b6fbc-e4f2-4046-83d3-3c1ca651341d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-0e39057a-8e94-4991-9a22-2301ddfda9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d3ff048b-db0a-4b51-bc80-ed239346fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-90e8d584-2140-4b81-9e91-72be18d267be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385457884-172.17.0.10-1598161072167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44370,DS-571467d4-f2d6-4fd2-954d-6c811c974122,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-b3f74794-caea-4949-8e49-5cdbd3bfffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-78f45599-5e51-4867-81fc-0ab99fdda7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-714c290b-3659-4ce7-bda5-55d86a3c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-df0b6fbc-e4f2-4046-83d3-3c1ca651341d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-0e39057a-8e94-4991-9a22-2301ddfda9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d3ff048b-db0a-4b51-bc80-ed239346fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-90e8d584-2140-4b81-9e91-72be18d267be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076165103-172.17.0.10-1598161137531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-8c96aeef-6681-4f90-8f14-9ebee07443ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-e30511d1-7650-4c1e-8e97-551cf4b14b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-20880d9f-b46f-4587-9371-821a5f4aaf85,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-8d584388-eb80-4f83-be81-ae551006d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-4269bc7e-64c1-4967-b6d6-f42a2d154d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-89d3d89a-817f-4295-adc8-1d7a2b5ccfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-1da114c4-6378-4ab2-b8bb-529f2e78587e,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-268b27bb-a63f-4c06-8be7-e0a000157eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076165103-172.17.0.10-1598161137531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-8c96aeef-6681-4f90-8f14-9ebee07443ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-e30511d1-7650-4c1e-8e97-551cf4b14b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-20880d9f-b46f-4587-9371-821a5f4aaf85,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-8d584388-eb80-4f83-be81-ae551006d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-4269bc7e-64c1-4967-b6d6-f42a2d154d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-89d3d89a-817f-4295-adc8-1d7a2b5ccfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-1da114c4-6378-4ab2-b8bb-529f2e78587e,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-268b27bb-a63f-4c06-8be7-e0a000157eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784105875-172.17.0.10-1598162326058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-67d4c1b7-3c9c-497b-b848-bca12679766d,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f5882234-c9ba-4319-a2fe-0028015d34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-893bae30-4cbc-42cc-ac52-476332be2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-88702484-94df-46f3-b3a9-2c201afc0f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-84e24aed-0a55-40c1-a0e1-ccef02f13ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-20f43bf7-e91a-4c46-82d1-9d2c626c526f,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-b1472e5e-df0d-4fcb-8517-0b33c0fdbc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ba170fc1-897e-442a-953d-790ad3e2efe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784105875-172.17.0.10-1598162326058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-67d4c1b7-3c9c-497b-b848-bca12679766d,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f5882234-c9ba-4319-a2fe-0028015d34a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-893bae30-4cbc-42cc-ac52-476332be2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-88702484-94df-46f3-b3a9-2c201afc0f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-84e24aed-0a55-40c1-a0e1-ccef02f13ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-20f43bf7-e91a-4c46-82d1-9d2c626c526f,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-b1472e5e-df0d-4fcb-8517-0b33c0fdbc44,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ba170fc1-897e-442a-953d-790ad3e2efe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019530785-172.17.0.10-1598162488800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-2e23b656-73d4-4509-b055-99214d6151d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-5c4588ed-a3d4-4154-a0f3-6b8e1550ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-adf0db94-6513-4e76-ae84-76bc6885a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-ae99cb66-d9ab-4c0b-8d65-b2e7ed54a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-53843592-22ac-4ace-bdcd-65e5853f6518,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-8ea7fe9c-fb83-4ae9-bb34-7efc5a34ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-66fbcd16-9a1b-402e-b395-ad48867d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-6401a147-ccce-4b85-b635-22d6fdec8444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019530785-172.17.0.10-1598162488800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-2e23b656-73d4-4509-b055-99214d6151d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-5c4588ed-a3d4-4154-a0f3-6b8e1550ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-adf0db94-6513-4e76-ae84-76bc6885a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-ae99cb66-d9ab-4c0b-8d65-b2e7ed54a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-53843592-22ac-4ace-bdcd-65e5853f6518,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-8ea7fe9c-fb83-4ae9-bb34-7efc5a34ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-66fbcd16-9a1b-402e-b395-ad48867d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-6401a147-ccce-4b85-b635-22d6fdec8444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332639226-172.17.0.10-1598162765317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-ce50b1f7-e7af-4d59-9e3b-28e583cca741,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-28536558-96c0-4483-a134-18000a18872e,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-0826f328-6ef7-43d5-99bc-e85f0503ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-9668ebe8-1e60-43ba-9652-8757668a2592,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-7e718f45-27bd-4d83-887c-bbdad70bd55b,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7ee120e2-a53b-4d51-b135-484a3c12f303,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-34bd3e43-8b2c-4761-b4a8-70818fb936de,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-e3cb2553-e7ca-4ff7-b136-1044cc7324fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332639226-172.17.0.10-1598162765317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-ce50b1f7-e7af-4d59-9e3b-28e583cca741,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-28536558-96c0-4483-a134-18000a18872e,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-0826f328-6ef7-43d5-99bc-e85f0503ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-9668ebe8-1e60-43ba-9652-8757668a2592,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-7e718f45-27bd-4d83-887c-bbdad70bd55b,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7ee120e2-a53b-4d51-b135-484a3c12f303,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-34bd3e43-8b2c-4761-b4a8-70818fb936de,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-e3cb2553-e7ca-4ff7-b136-1044cc7324fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310819877-172.17.0.10-1598162795050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38481,DS-c1961428-f4ef-46fc-be06-b934ce067b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-0113c49f-5ddd-42aa-a68f-6863653a58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-0e906488-610b-47c0-aeaa-84e1fb1471c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-aa6e3853-8eee-4474-8686-6dfcdd0b58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-98ed3144-eee0-437e-a6d3-fef647e18225,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-be8bb794-ac8d-4a92-b7fe-aaad62b01491,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-7e03d399-9f39-4959-bd46-751b59a19379,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-65b9d4f6-b291-455b-a8fe-e100245c6464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310819877-172.17.0.10-1598162795050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38481,DS-c1961428-f4ef-46fc-be06-b934ce067b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-0113c49f-5ddd-42aa-a68f-6863653a58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-0e906488-610b-47c0-aeaa-84e1fb1471c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-aa6e3853-8eee-4474-8686-6dfcdd0b58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-98ed3144-eee0-437e-a6d3-fef647e18225,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-be8bb794-ac8d-4a92-b7fe-aaad62b01491,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-7e03d399-9f39-4959-bd46-751b59a19379,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-65b9d4f6-b291-455b-a8fe-e100245c6464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5023
