reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543006989-172.17.0.13-1598329861553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-a376e247-469d-49a6-8511-ad7b7f71ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-118c35e7-d0e8-45cc-9ea7-6273c7264d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-41a29fd9-850d-4407-8edf-153b88c9a650,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-e7452860-8c59-4804-9db1-186a15fe46b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-66f7f6da-a4df-480b-930b-1e387454c472,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-b445a581-3535-44c1-b7b1-d0411cd7087a,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-ebc15f68-493d-41a1-95af-5550e2984570,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-1b3fc72b-d7ed-4e54-9622-a1ffd1a24974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543006989-172.17.0.13-1598329861553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-a376e247-469d-49a6-8511-ad7b7f71ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-118c35e7-d0e8-45cc-9ea7-6273c7264d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-41a29fd9-850d-4407-8edf-153b88c9a650,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-e7452860-8c59-4804-9db1-186a15fe46b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-66f7f6da-a4df-480b-930b-1e387454c472,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-b445a581-3535-44c1-b7b1-d0411cd7087a,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-ebc15f68-493d-41a1-95af-5550e2984570,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-1b3fc72b-d7ed-4e54-9622-a1ffd1a24974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566906926-172.17.0.13-1598330208293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-a6f3f888-17ed-427c-a7e2-ee29389ca3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-281594f7-7a65-47f1-86f2-53f68a0f1dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-ecc473b6-eae7-434e-8020-8505302b8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-b2c1e7a1-7a5b-4164-aef3-c4b9af53548f,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-5e5506b5-d485-4899-b01e-40c3c70537c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-b2337d02-18c1-4601-9adb-2101a09eea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-793c0501-1b89-4b6c-add8-06339655cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-dd3a6eef-4f91-47c2-9a9a-6ee8ab662ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566906926-172.17.0.13-1598330208293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-a6f3f888-17ed-427c-a7e2-ee29389ca3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-281594f7-7a65-47f1-86f2-53f68a0f1dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-ecc473b6-eae7-434e-8020-8505302b8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-b2c1e7a1-7a5b-4164-aef3-c4b9af53548f,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-5e5506b5-d485-4899-b01e-40c3c70537c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-b2337d02-18c1-4601-9adb-2101a09eea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-793c0501-1b89-4b6c-add8-06339655cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-dd3a6eef-4f91-47c2-9a9a-6ee8ab662ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927463591-172.17.0.13-1598331186113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-fb2019ca-67d3-41d3-9720-1c13edfd88db,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-9749aca1-d4c4-4b2a-8b7f-3001a4c216dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-61ebd391-2d91-437e-8a03-317f3d87180d,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-7cf1e357-c9d5-4f8a-a378-d08018c5c41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-6ebba1e1-fc64-4e08-b2f7-38a7b3b1e89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-784c6172-d54b-4172-8126-31969caa7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-548daf26-b959-41a7-8e56-8edc406891bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-c188ac22-cd33-4d19-9527-81287ca6f785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927463591-172.17.0.13-1598331186113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-fb2019ca-67d3-41d3-9720-1c13edfd88db,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-9749aca1-d4c4-4b2a-8b7f-3001a4c216dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-61ebd391-2d91-437e-8a03-317f3d87180d,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-7cf1e357-c9d5-4f8a-a378-d08018c5c41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-6ebba1e1-fc64-4e08-b2f7-38a7b3b1e89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-784c6172-d54b-4172-8126-31969caa7d84,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-548daf26-b959-41a7-8e56-8edc406891bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-c188ac22-cd33-4d19-9527-81287ca6f785,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712762935-172.17.0.13-1598331636172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44381,DS-fc4a7b98-c2ca-4756-9a5f-f6148e0b833e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-715d088f-a4e2-45c1-840d-c9792800b252,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9c16d485-0aa2-4cf1-922a-50f1f1ea2c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-92961fb3-888d-471e-bdf1-10f93c7a4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-3dddb1af-8e4d-47da-810f-0fdac0405510,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-1d2ec956-a682-4b8e-a770-38a700cce283,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b6062d16-6b3c-4e16-ad18-614ce5c835c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-b0be77fd-9329-420e-8e64-38deb9c82732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712762935-172.17.0.13-1598331636172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44381,DS-fc4a7b98-c2ca-4756-9a5f-f6148e0b833e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-715d088f-a4e2-45c1-840d-c9792800b252,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9c16d485-0aa2-4cf1-922a-50f1f1ea2c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-92961fb3-888d-471e-bdf1-10f93c7a4e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-3dddb1af-8e4d-47da-810f-0fdac0405510,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-1d2ec956-a682-4b8e-a770-38a700cce283,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b6062d16-6b3c-4e16-ad18-614ce5c835c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-b0be77fd-9329-420e-8e64-38deb9c82732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816546065-172.17.0.13-1598331736562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-a7449d29-31d7-40c6-b22d-1f42258bcff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-5b747c48-baf1-4251-8605-33fba838dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-ab4a9053-64b6-4238-ae85-db4ed912aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-88058d6c-bafd-4fa1-b648-3747c019c471,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-717eed1d-75a6-4aef-ab1a-e0477e9e1729,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-0e9e2e9f-f36c-4f91-a807-27ee6f1d6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b9af4a52-a658-44c3-9e8f-7c9a6c16782e,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-87414e92-7946-412d-b9a7-db23664edaa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816546065-172.17.0.13-1598331736562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-a7449d29-31d7-40c6-b22d-1f42258bcff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-5b747c48-baf1-4251-8605-33fba838dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-ab4a9053-64b6-4238-ae85-db4ed912aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-88058d6c-bafd-4fa1-b648-3747c019c471,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-717eed1d-75a6-4aef-ab1a-e0477e9e1729,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-0e9e2e9f-f36c-4f91-a807-27ee6f1d6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b9af4a52-a658-44c3-9e8f-7c9a6c16782e,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-87414e92-7946-412d-b9a7-db23664edaa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469655591-172.17.0.13-1598331795192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-723bb4dc-9648-4d50-a682-359823f64abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-8dadac43-a8cd-4d84-a307-6b2858d1b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-17d7a3da-ba00-4a66-ab76-74bd5792c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-7e9f16bd-7d1f-4def-88e3-ccd8889487b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-83945db1-b49d-4750-b0e7-26d72334120c,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-d5076fb9-864a-4739-a8c3-97444f054f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-5964dd2a-4997-4f11-b785-c13372d9b984,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a073c0c0-be03-4f8b-b806-053fa2d1a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469655591-172.17.0.13-1598331795192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-723bb4dc-9648-4d50-a682-359823f64abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-8dadac43-a8cd-4d84-a307-6b2858d1b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-17d7a3da-ba00-4a66-ab76-74bd5792c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-7e9f16bd-7d1f-4def-88e3-ccd8889487b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-83945db1-b49d-4750-b0e7-26d72334120c,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-d5076fb9-864a-4739-a8c3-97444f054f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-5964dd2a-4997-4f11-b785-c13372d9b984,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a073c0c0-be03-4f8b-b806-053fa2d1a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095442962-172.17.0.13-1598331860585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39358,DS-c9180843-1872-4b83-bd1b-79ef3995b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-1b98e5fc-6064-49b7-a01b-f5c2ff0078ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-5358a407-03d2-4354-8bb8-8bd4bbbf2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-a7860a1c-afeb-4fd9-b488-4068b01f9c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a7292632-25ff-4bd7-8611-37ee548f0559,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-91c6cfe7-63e8-4beb-b2c4-27057e4de761,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-f6fc8c75-1aba-4fef-988e-a9e955c24ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-af360e37-5a58-4a59-aa84-47f6df408aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095442962-172.17.0.13-1598331860585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39358,DS-c9180843-1872-4b83-bd1b-79ef3995b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-1b98e5fc-6064-49b7-a01b-f5c2ff0078ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-5358a407-03d2-4354-8bb8-8bd4bbbf2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-a7860a1c-afeb-4fd9-b488-4068b01f9c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-a7292632-25ff-4bd7-8611-37ee548f0559,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-91c6cfe7-63e8-4beb-b2c4-27057e4de761,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-f6fc8c75-1aba-4fef-988e-a9e955c24ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-af360e37-5a58-4a59-aa84-47f6df408aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491619602-172.17.0.13-1598332441752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34413,DS-ffdfec55-1a4b-49e2-9df7-989819b7fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-a36e19e0-009a-428f-9a86-0ec57151fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-0e7fd051-75c5-4708-8be5-0e50fbad0cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-b6ecd3e0-057d-45c5-b707-4ec0180290b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-42278e91-eecb-4257-b448-e561769a10ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-2e520e8c-f866-4f27-a90c-ea8ad6be7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-2f99074d-4ebf-4668-adfe-1fe0cd3e7607,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-0960e7ef-4137-4843-80ed-ace2b7ec592f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491619602-172.17.0.13-1598332441752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34413,DS-ffdfec55-1a4b-49e2-9df7-989819b7fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-a36e19e0-009a-428f-9a86-0ec57151fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-0e7fd051-75c5-4708-8be5-0e50fbad0cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-b6ecd3e0-057d-45c5-b707-4ec0180290b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-42278e91-eecb-4257-b448-e561769a10ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-2e520e8c-f866-4f27-a90c-ea8ad6be7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-2f99074d-4ebf-4668-adfe-1fe0cd3e7607,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-0960e7ef-4137-4843-80ed-ace2b7ec592f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657657747-172.17.0.13-1598332986089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-e5878cb9-1ca6-44d2-8ce4-603c9a72ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-c1a69189-cde5-4456-bfdc-752f963f023e,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-911375e9-6b8a-4178-be12-15a530c07c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-28135f90-ab85-4de2-8dbc-df2af3d3bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-40de8cb2-7658-4cda-8e69-187d331ab0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c21aa3cc-12f6-4c7c-8439-c86ee7fa87b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-9b17000f-fcdf-484c-880d-53496ad7ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-72e5a57b-a687-4d6a-86e8-748b371c7b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657657747-172.17.0.13-1598332986089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-e5878cb9-1ca6-44d2-8ce4-603c9a72ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-c1a69189-cde5-4456-bfdc-752f963f023e,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-911375e9-6b8a-4178-be12-15a530c07c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-28135f90-ab85-4de2-8dbc-df2af3d3bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-40de8cb2-7658-4cda-8e69-187d331ab0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c21aa3cc-12f6-4c7c-8439-c86ee7fa87b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-9b17000f-fcdf-484c-880d-53496ad7ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-72e5a57b-a687-4d6a-86e8-748b371c7b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168644054-172.17.0.13-1598333966318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-322b4a04-83ca-4177-9cea-cd89447e2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-71b56670-31ac-4d4d-b3c1-3ad14ca64536,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-856e2d1d-a5c2-4524-973e-b45800ddb1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ce1aad19-060c-47c8-ae8b-fe6e53e43e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-c668b386-1bd3-4710-aa5e-feecccc5d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-e2d438ab-96bd-42c3-8a16-0db817ce27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-99d109ca-8e75-480c-ad8e-a048cd365073,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7dbe8751-f150-489b-ad98-ac831fdf920e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168644054-172.17.0.13-1598333966318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34855,DS-322b4a04-83ca-4177-9cea-cd89447e2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-71b56670-31ac-4d4d-b3c1-3ad14ca64536,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-856e2d1d-a5c2-4524-973e-b45800ddb1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ce1aad19-060c-47c8-ae8b-fe6e53e43e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-c668b386-1bd3-4710-aa5e-feecccc5d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-e2d438ab-96bd-42c3-8a16-0db817ce27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-99d109ca-8e75-480c-ad8e-a048cd365073,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7dbe8751-f150-489b-ad98-ac831fdf920e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708970183-172.17.0.13-1598334039036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-e9dcf7fe-5ce9-416b-a234-571076f49636,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d88a95fb-3c70-4a2c-ae8b-138bc4ace03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-0ed29ddc-a430-4ecf-bbd3-374b76530668,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-948e3c9d-f7dc-472a-96a7-2f29effdbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-050e9369-c3fb-4c76-a7d1-2a0a331bb9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-dd0c5974-c450-411c-bae1-5f7912c93c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-63303cf9-c954-4fa6-b1df-c435c2f48a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-4360bb16-9bb2-4ba7-8e65-eb9be1e8da14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708970183-172.17.0.13-1598334039036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-e9dcf7fe-5ce9-416b-a234-571076f49636,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d88a95fb-3c70-4a2c-ae8b-138bc4ace03f,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-0ed29ddc-a430-4ecf-bbd3-374b76530668,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-948e3c9d-f7dc-472a-96a7-2f29effdbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-050e9369-c3fb-4c76-a7d1-2a0a331bb9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-dd0c5974-c450-411c-bae1-5f7912c93c13,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-63303cf9-c954-4fa6-b1df-c435c2f48a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-4360bb16-9bb2-4ba7-8e65-eb9be1e8da14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977379138-172.17.0.13-1598334213125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-f77b2d10-74eb-48be-acba-7551a313ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-21c0b15e-e485-4d5c-a0a4-b07c224de5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0e602c4a-07d7-4447-a48a-6c884b6c482f,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-4e0e7ccd-07b0-42d8-be2a-eb1fb9d66f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-5ec2da51-7dc5-48bd-8b9b-1b3b42d779ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-27d70d26-eef0-4015-93c4-9d1507a5ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-e1caeb46-07ae-433a-90e9-bd1cd0b5a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-2a0ab564-6b19-4f69-8941-315f74027b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977379138-172.17.0.13-1598334213125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-f77b2d10-74eb-48be-acba-7551a313ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-21c0b15e-e485-4d5c-a0a4-b07c224de5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-0e602c4a-07d7-4447-a48a-6c884b6c482f,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-4e0e7ccd-07b0-42d8-be2a-eb1fb9d66f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-5ec2da51-7dc5-48bd-8b9b-1b3b42d779ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-27d70d26-eef0-4015-93c4-9d1507a5ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-e1caeb46-07ae-433a-90e9-bd1cd0b5a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-2a0ab564-6b19-4f69-8941-315f74027b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5078
