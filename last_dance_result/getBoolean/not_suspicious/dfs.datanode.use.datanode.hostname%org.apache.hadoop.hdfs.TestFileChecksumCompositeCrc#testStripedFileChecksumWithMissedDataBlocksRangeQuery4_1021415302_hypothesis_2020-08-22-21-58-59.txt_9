reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772647595-172.17.0.11-1598133689651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-dbd96cba-f388-469f-a9b9-65bdcbde616d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-d5832d58-e3b0-4202-b569-394b8023eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2fbc82e0-8855-4124-b1ee-01d44d2cb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-10e3d869-a673-4641-9551-8c9db86fbbba,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-5d5f12aa-0f6d-4ba0-97cb-b27f694c65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-2423ada1-932f-4910-bf3f-21fb13001718,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-e3fecc4b-7b1f-435e-9fd1-34b2f03af408,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-e30cc1b3-a680-4767-ad49-0f9cbbd75f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772647595-172.17.0.11-1598133689651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-dbd96cba-f388-469f-a9b9-65bdcbde616d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-d5832d58-e3b0-4202-b569-394b8023eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2fbc82e0-8855-4124-b1ee-01d44d2cb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-10e3d869-a673-4641-9551-8c9db86fbbba,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-5d5f12aa-0f6d-4ba0-97cb-b27f694c65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-2423ada1-932f-4910-bf3f-21fb13001718,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-e3fecc4b-7b1f-435e-9fd1-34b2f03af408,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-e30cc1b3-a680-4767-ad49-0f9cbbd75f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218123242-172.17.0.11-1598133781422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-b99427ce-7939-4a26-804d-67fb76ee54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-394f9b3e-081a-4f55-95f6-66ee2883afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e05f9c1b-e5b0-4b2e-871c-f2d3e8c3a846,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-ab9c19a6-2100-45d1-b7ea-9bfeaabf79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-bf7aa9ba-b6cc-4749-879c-d050677c4952,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-173b0a9b-c978-4b6b-b63c-95bf946aaef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-6f200746-5a3e-426a-9d70-a7a748ef5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-26ac14db-3040-4813-9ee2-87f254e643a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218123242-172.17.0.11-1598133781422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-b99427ce-7939-4a26-804d-67fb76ee54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-394f9b3e-081a-4f55-95f6-66ee2883afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e05f9c1b-e5b0-4b2e-871c-f2d3e8c3a846,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-ab9c19a6-2100-45d1-b7ea-9bfeaabf79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-bf7aa9ba-b6cc-4749-879c-d050677c4952,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-173b0a9b-c978-4b6b-b63c-95bf946aaef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-6f200746-5a3e-426a-9d70-a7a748ef5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-26ac14db-3040-4813-9ee2-87f254e643a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007704342-172.17.0.11-1598133986979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-63ea9a81-3b35-43d2-9b1d-cf9bb385e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-afbe8f6a-5425-4da7-9ccc-9e0ddfeb4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-39371d00-4af7-48b8-be45-3a1462db3303,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-91389a81-6517-487a-a4d3-e7592816d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-57c91226-bc5d-45a3-a5a2-f42149d85f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-6e908b4f-74dc-4a7d-bc30-143831506034,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3e3e3081-18c2-4c4d-bcc6-19aba0e59809,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-a0e23c0d-f5bf-46de-a258-f511b39622bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007704342-172.17.0.11-1598133986979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-63ea9a81-3b35-43d2-9b1d-cf9bb385e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-afbe8f6a-5425-4da7-9ccc-9e0ddfeb4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-39371d00-4af7-48b8-be45-3a1462db3303,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-91389a81-6517-487a-a4d3-e7592816d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-57c91226-bc5d-45a3-a5a2-f42149d85f20,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-6e908b4f-74dc-4a7d-bc30-143831506034,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3e3e3081-18c2-4c4d-bcc6-19aba0e59809,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-a0e23c0d-f5bf-46de-a258-f511b39622bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377838589-172.17.0.11-1598134025134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-1c0c21b3-fc3c-419b-94cd-66acf7a7b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-47979aa6-d390-44c8-9b5f-3f4a4a1afb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c3eed244-f961-4e6b-8d29-d45095d90ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-588b40db-9525-46a8-9ae3-944ac73a75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e2d76d90-84c6-4e76-937a-1a65fbc501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-7ad7e67a-d714-434a-83c4-2e8b56f39d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-27460e0e-2add-43f5-ba67-f25e34c176f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c5234a93-ae51-4513-b584-2d24a26a8ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377838589-172.17.0.11-1598134025134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-1c0c21b3-fc3c-419b-94cd-66acf7a7b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-47979aa6-d390-44c8-9b5f-3f4a4a1afb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c3eed244-f961-4e6b-8d29-d45095d90ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-588b40db-9525-46a8-9ae3-944ac73a75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-e2d76d90-84c6-4e76-937a-1a65fbc501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-7ad7e67a-d714-434a-83c4-2e8b56f39d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-27460e0e-2add-43f5-ba67-f25e34c176f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c5234a93-ae51-4513-b584-2d24a26a8ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504575484-172.17.0.11-1598134133991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45800,DS-3d552c8c-141a-492f-89b8-bdf0ad1220c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-7baf5a89-8256-4044-8b0c-a8338dccdad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-07c98c17-d10f-4186-91f2-2adf1bf24f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-f8caca35-460b-433a-a961-0b1900e120ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-2a5c6470-10e0-48a5-a795-c5305a1e117a,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-a7b977c5-2b08-4628-8756-67aef6904715,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-c5410f42-cab0-4bc7-9bec-bd83d4387db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-994339e6-8aa6-486c-89c9-3f395c73c808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504575484-172.17.0.11-1598134133991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45800,DS-3d552c8c-141a-492f-89b8-bdf0ad1220c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-7baf5a89-8256-4044-8b0c-a8338dccdad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-07c98c17-d10f-4186-91f2-2adf1bf24f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-f8caca35-460b-433a-a961-0b1900e120ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-2a5c6470-10e0-48a5-a795-c5305a1e117a,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-a7b977c5-2b08-4628-8756-67aef6904715,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-c5410f42-cab0-4bc7-9bec-bd83d4387db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-994339e6-8aa6-486c-89c9-3f395c73c808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872053167-172.17.0.11-1598134314328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-32c485dd-962d-4dd1-b0f6-7786b75cc04f,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-beceeb8b-427b-4fe3-8864-a32806f6fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-aaed70a4-411e-4ff5-8467-a3bea426650c,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-68755cd1-ecd7-490c-aeea-f12b874f0693,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6c815636-cf49-4031-9b30-6629904eb906,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ad656839-e5a1-4334-a02d-3ed1ad214508,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-8730aeb0-f79e-4605-87c3-d8cac8c520a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-3f791bd2-8bca-4d9d-b7fe-7be9ad647e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872053167-172.17.0.11-1598134314328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-32c485dd-962d-4dd1-b0f6-7786b75cc04f,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-beceeb8b-427b-4fe3-8864-a32806f6fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-aaed70a4-411e-4ff5-8467-a3bea426650c,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-68755cd1-ecd7-490c-aeea-f12b874f0693,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6c815636-cf49-4031-9b30-6629904eb906,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ad656839-e5a1-4334-a02d-3ed1ad214508,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-8730aeb0-f79e-4605-87c3-d8cac8c520a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-3f791bd2-8bca-4d9d-b7fe-7be9ad647e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577599218-172.17.0.11-1598134765484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-1d767a12-44b3-4ff0-b0cc-e63c1b7bf914,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-55abc479-200a-4b0e-b6f8-9df3b20bff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-722e9d85-aafd-4b27-8893-c071f719c819,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-a53a87d8-60a4-4169-b998-d117352562f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-d6005872-ed2a-488c-ba52-a52fc14c4649,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-52f70995-7cc3-42dd-ab3d-d0edb6a29c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-5a5b08ae-d921-4504-b4ac-41b2fbfacc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-499e1c4c-e720-4158-809d-721109ec8e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577599218-172.17.0.11-1598134765484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-1d767a12-44b3-4ff0-b0cc-e63c1b7bf914,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-55abc479-200a-4b0e-b6f8-9df3b20bff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-722e9d85-aafd-4b27-8893-c071f719c819,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-a53a87d8-60a4-4169-b998-d117352562f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-d6005872-ed2a-488c-ba52-a52fc14c4649,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-52f70995-7cc3-42dd-ab3d-d0edb6a29c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-5a5b08ae-d921-4504-b4ac-41b2fbfacc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-499e1c4c-e720-4158-809d-721109ec8e41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805590093-172.17.0.11-1598134809035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7427a27-a4f6-44cc-a18d-432e76a0e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-9f974bbb-d84e-4c0a-b61e-63be65a65184,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-0425e71f-0f0c-4a11-912a-7a770661af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-1ef4d5d5-6733-41c0-90c4-2d6bc5fb0b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f1b0c250-a126-4f69-9677-2f7565e46957,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-c7f040e7-5bc2-4b74-a9de-91fedb400d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-4f9443eb-9d62-46c9-9f81-419ceb141d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-752f2f84-2e66-4fdc-9d7e-baccb0797bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805590093-172.17.0.11-1598134809035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7427a27-a4f6-44cc-a18d-432e76a0e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-9f974bbb-d84e-4c0a-b61e-63be65a65184,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-0425e71f-0f0c-4a11-912a-7a770661af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-1ef4d5d5-6733-41c0-90c4-2d6bc5fb0b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f1b0c250-a126-4f69-9677-2f7565e46957,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-c7f040e7-5bc2-4b74-a9de-91fedb400d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-4f9443eb-9d62-46c9-9f81-419ceb141d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-752f2f84-2e66-4fdc-9d7e-baccb0797bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136266800-172.17.0.11-1598136096438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-8fff4419-787c-4e19-bd5a-48a4e700f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5b1b4e2b-351b-473a-a046-411dec05d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-462ecedb-7ea0-4911-9909-7d85010337f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-b6d260fa-2cb8-4a1c-ac8b-a4e46c6b1d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-f3747ac4-0afb-4d36-85d3-1dc310b5786d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-735fe000-9c96-4cef-a5d5-9b29cc038252,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d7322e20-000e-4297-822e-3ab3c8c591d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6f7cc6c7-9375-4bd6-a799-02c951b5883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136266800-172.17.0.11-1598136096438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-8fff4419-787c-4e19-bd5a-48a4e700f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5b1b4e2b-351b-473a-a046-411dec05d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-462ecedb-7ea0-4911-9909-7d85010337f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-b6d260fa-2cb8-4a1c-ac8b-a4e46c6b1d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-f3747ac4-0afb-4d36-85d3-1dc310b5786d,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-735fe000-9c96-4cef-a5d5-9b29cc038252,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d7322e20-000e-4297-822e-3ab3c8c591d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-6f7cc6c7-9375-4bd6-a799-02c951b5883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185078137-172.17.0.11-1598136585024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-2128bf91-89d4-4dd9-9525-2cd6bb830044,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-b596ff83-82d4-4f18-807f-a29053a7b086,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-cbbf195d-9acf-49fa-8746-597c89f2cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-dea775e1-bfce-4707-98e9-b6f964283783,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-22cd711e-8983-433b-87f1-26a07d95bd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-9286dfbf-8e2e-40ee-a998-c4ccb5487e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-180606ca-d709-4cbd-ae1a-74014714dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-fdbb7994-0867-44fd-9b56-1448a0d503c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185078137-172.17.0.11-1598136585024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-2128bf91-89d4-4dd9-9525-2cd6bb830044,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-b596ff83-82d4-4f18-807f-a29053a7b086,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-cbbf195d-9acf-49fa-8746-597c89f2cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-dea775e1-bfce-4707-98e9-b6f964283783,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-22cd711e-8983-433b-87f1-26a07d95bd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-9286dfbf-8e2e-40ee-a998-c4ccb5487e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-180606ca-d709-4cbd-ae1a-74014714dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-fdbb7994-0867-44fd-9b56-1448a0d503c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905995888-172.17.0.11-1598136879826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-8942b30f-33ef-4401-b0eb-6b77cf787891,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-ece80ad2-ffbf-4d1d-b06c-f76cd346a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-a8b35230-6b80-4ba6-871e-47bd9d15bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-1e89551f-4ed0-4b2b-8356-c391b6d0e989,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3ced98a3-391c-40ba-8ceb-ec23d6a39b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-10d29c01-e374-4419-8078-23ba7707a1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-81604f1e-dc2c-45fe-b03f-937a997ef7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-fdc20bdd-3839-4a8e-87bf-a904ff9fdaf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905995888-172.17.0.11-1598136879826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-8942b30f-33ef-4401-b0eb-6b77cf787891,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-ece80ad2-ffbf-4d1d-b06c-f76cd346a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-a8b35230-6b80-4ba6-871e-47bd9d15bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-1e89551f-4ed0-4b2b-8356-c391b6d0e989,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-3ced98a3-391c-40ba-8ceb-ec23d6a39b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-10d29c01-e374-4419-8078-23ba7707a1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-81604f1e-dc2c-45fe-b03f-937a997ef7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-fdc20bdd-3839-4a8e-87bf-a904ff9fdaf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223089198-172.17.0.11-1598137159011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-a61f390c-f16e-47c6-84db-a01490d2382c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-58808f4c-dd63-4db8-b910-9db098e4d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-3e2c38ad-0667-4a83-907a-a982b44369f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-d2bc9fd4-b0f9-4e20-9067-612851fc91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-43e51745-5b5f-4826-a87a-1bed88ae96da,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-2aa1fd31-4c50-4d3c-a4e9-07f4ee174f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-0809f7f8-e3f4-4689-a3c8-a49a1fc4e93a,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-c252c369-5370-4e08-950d-2408b560f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223089198-172.17.0.11-1598137159011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-a61f390c-f16e-47c6-84db-a01490d2382c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-58808f4c-dd63-4db8-b910-9db098e4d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-3e2c38ad-0667-4a83-907a-a982b44369f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-d2bc9fd4-b0f9-4e20-9067-612851fc91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-43e51745-5b5f-4826-a87a-1bed88ae96da,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-2aa1fd31-4c50-4d3c-a4e9-07f4ee174f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-0809f7f8-e3f4-4689-a3c8-a49a1fc4e93a,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-c252c369-5370-4e08-950d-2408b560f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056545587-172.17.0.11-1598137507078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-0cc5e125-5b02-4bf2-a92d-715dca1706a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-28f2269e-0c4c-4910-8138-9361b7a55fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ec64e84e-e5bc-4d1b-87fe-2d42bc269fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-af6ab7b7-f8f5-416b-a288-7cf4bf378920,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-c1da2e3a-e5cc-4bb9-ad22-f0a543fb73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-df825986-f6c3-4d99-b706-24bae00a9d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-86e95fd1-e93e-4c6f-9d4e-7dbfaaa77506,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b8f69d6d-77ce-4a03-b668-b3f68858dc2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056545587-172.17.0.11-1598137507078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-0cc5e125-5b02-4bf2-a92d-715dca1706a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-28f2269e-0c4c-4910-8138-9361b7a55fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ec64e84e-e5bc-4d1b-87fe-2d42bc269fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-af6ab7b7-f8f5-416b-a288-7cf4bf378920,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-c1da2e3a-e5cc-4bb9-ad22-f0a543fb73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-df825986-f6c3-4d99-b706-24bae00a9d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-86e95fd1-e93e-4c6f-9d4e-7dbfaaa77506,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b8f69d6d-77ce-4a03-b668-b3f68858dc2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517697998-172.17.0.11-1598137542534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-1dd95198-7bd7-4b4b-a6bb-e1f42b6a96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-c06dde7b-7b84-41ed-aae4-9cc21ee97d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-ca7192ed-7854-447e-8385-ccafd4db96d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-a352d926-7a11-4db0-a418-6300138cf906,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-833f4fb0-91e8-4529-92b4-177f3031b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-7a4b3dd8-adc6-4445-b672-f71a500564eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-5e38970c-04dd-4c48-9c10-a48c3c140384,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-7ce97e4a-e2a4-4e53-958f-36ac295124f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517697998-172.17.0.11-1598137542534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-1dd95198-7bd7-4b4b-a6bb-e1f42b6a96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-c06dde7b-7b84-41ed-aae4-9cc21ee97d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-ca7192ed-7854-447e-8385-ccafd4db96d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-a352d926-7a11-4db0-a418-6300138cf906,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-833f4fb0-91e8-4529-92b4-177f3031b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-7a4b3dd8-adc6-4445-b672-f71a500564eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-5e38970c-04dd-4c48-9c10-a48c3c140384,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-7ce97e4a-e2a4-4e53-958f-36ac295124f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034080289-172.17.0.11-1598137797045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41773,DS-742b2375-af0b-49eb-9b08-df422b9904a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-a9202b9b-f5f4-4a18-a615-4da917b4bed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b5d38406-df54-4683-9df2-8eb6925b7b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f84f6201-55aa-4ac5-87b2-89d3c66290dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-73ee03aa-8659-4c4f-a1df-bbb30c0ad353,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-2aeddb16-21ad-4883-b365-3a5762f332c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-fbe360b4-2e00-4b25-9c2b-4fb1b2b5be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-24158c21-d43f-4a7b-9876-ae22ea9890bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034080289-172.17.0.11-1598137797045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41773,DS-742b2375-af0b-49eb-9b08-df422b9904a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-a9202b9b-f5f4-4a18-a615-4da917b4bed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b5d38406-df54-4683-9df2-8eb6925b7b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-f84f6201-55aa-4ac5-87b2-89d3c66290dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-73ee03aa-8659-4c4f-a1df-bbb30c0ad353,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-2aeddb16-21ad-4883-b365-3a5762f332c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-fbe360b4-2e00-4b25-9c2b-4fb1b2b5be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-24158c21-d43f-4a7b-9876-ae22ea9890bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597048733-172.17.0.11-1598137986845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-8d5a4b99-01f1-4043-98ff-336c24dbe26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f92ac55e-a85d-48b4-94ed-2ad8ed44b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-0ceff7ce-8552-4dde-904b-1c7d009ba0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-b1338f12-3821-4031-91fe-57108a204ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-4934d490-2e34-4f8d-a0e8-805c9a35cd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-9d4acd6a-c209-4d6c-88b1-1bee9f83744e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-d2713d83-4ab7-4de6-bc09-cedae09edb10,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-0de43473-8bfa-4660-a8c2-07a89926dcdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597048733-172.17.0.11-1598137986845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-8d5a4b99-01f1-4043-98ff-336c24dbe26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f92ac55e-a85d-48b4-94ed-2ad8ed44b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-0ceff7ce-8552-4dde-904b-1c7d009ba0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-b1338f12-3821-4031-91fe-57108a204ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-4934d490-2e34-4f8d-a0e8-805c9a35cd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-9d4acd6a-c209-4d6c-88b1-1bee9f83744e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-d2713d83-4ab7-4de6-bc09-cedae09edb10,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-0de43473-8bfa-4660-a8c2-07a89926dcdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875419409-172.17.0.11-1598138074407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-a46728a5-a37e-4783-8c38-45b3730e5708,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-450759ee-3ebd-4060-9f59-69d81531a352,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-7a951bb7-550d-4f82-beeb-50453aafd22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-1e7b85e7-274e-4fb2-a230-42ae93cf40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-4dac7803-1f92-4aec-9e63-950a9542e459,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-7f470ed6-bb25-4b4f-8fb3-8d172264285e,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-cc4e80ff-8918-4d1e-a443-0450f1081b30,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9e43b485-f0d9-4322-93d2-fcd516c55862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875419409-172.17.0.11-1598138074407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-a46728a5-a37e-4783-8c38-45b3730e5708,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-450759ee-3ebd-4060-9f59-69d81531a352,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-7a951bb7-550d-4f82-beeb-50453aafd22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-1e7b85e7-274e-4fb2-a230-42ae93cf40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-4dac7803-1f92-4aec-9e63-950a9542e459,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-7f470ed6-bb25-4b4f-8fb3-8d172264285e,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-cc4e80ff-8918-4d1e-a443-0450f1081b30,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9e43b485-f0d9-4322-93d2-fcd516c55862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977003376-172.17.0.11-1598138136908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-94a9490e-05ff-4c81-a4d2-e5d2c0e1b99a,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-6b1231e9-baf1-443a-932a-897edb1ba201,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-14ecabe7-58c5-454c-8212-872a92087b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f8b11873-5f6f-422e-ac35-4582de44dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-0e0e9349-4ed5-4cbf-8639-e3b55dd47836,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-17437ded-d5ff-4548-9f19-658d0a55ae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-05cacf24-75ab-4cc1-9638-cdd2e3494834,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-59543fd4-2790-4680-83a6-ee1ec01ba384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977003376-172.17.0.11-1598138136908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-94a9490e-05ff-4c81-a4d2-e5d2c0e1b99a,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-6b1231e9-baf1-443a-932a-897edb1ba201,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-14ecabe7-58c5-454c-8212-872a92087b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f8b11873-5f6f-422e-ac35-4582de44dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-0e0e9349-4ed5-4cbf-8639-e3b55dd47836,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-17437ded-d5ff-4548-9f19-658d0a55ae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-05cacf24-75ab-4cc1-9638-cdd2e3494834,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-59543fd4-2790-4680-83a6-ee1ec01ba384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125360137-172.17.0.11-1598138438353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-298f620f-4b2d-4082-839d-b2e057694982,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-22fecc77-0d7d-4924-9fd5-62238bc40449,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-d9e59377-a27e-46e6-b002-7a9bdce4a528,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-c6f39a00-fe7c-4ad4-ad7b-44fce3d88ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-7f440c1b-03c2-4cf3-8758-fc3a1c852984,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-3c1d81a9-0a56-4cf5-a17e-2dfdc0bff9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-45abbb0d-74f6-4e2e-a159-55cc67729571,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-932af5f8-4301-4765-9204-1c2dee78036d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125360137-172.17.0.11-1598138438353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-298f620f-4b2d-4082-839d-b2e057694982,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-22fecc77-0d7d-4924-9fd5-62238bc40449,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-d9e59377-a27e-46e6-b002-7a9bdce4a528,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-c6f39a00-fe7c-4ad4-ad7b-44fce3d88ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-7f440c1b-03c2-4cf3-8758-fc3a1c852984,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-3c1d81a9-0a56-4cf5-a17e-2dfdc0bff9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-45abbb0d-74f6-4e2e-a159-55cc67729571,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-932af5f8-4301-4765-9204-1c2dee78036d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822926710-172.17.0.11-1598138739580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-50b3948c-e55f-4d8e-9d84-f4ae29e600ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-abc73523-eb22-4520-a4c7-e03d079f4757,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-aafe3ff7-8ac2-43c7-81e2-ec5ca0eb0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-85f037f5-774e-48f5-aa67-b7a3dad0a007,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-2fea5ab6-0e75-4a98-8fdb-050c2887b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-356f1bc6-afa3-4617-b48a-77bf850363db,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-ff068c9d-8608-4311-8983-91508d467498,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-4b0356ef-ade1-4948-ae97-7fbe39696c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822926710-172.17.0.11-1598138739580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-50b3948c-e55f-4d8e-9d84-f4ae29e600ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-abc73523-eb22-4520-a4c7-e03d079f4757,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-aafe3ff7-8ac2-43c7-81e2-ec5ca0eb0e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-85f037f5-774e-48f5-aa67-b7a3dad0a007,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-2fea5ab6-0e75-4a98-8fdb-050c2887b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-356f1bc6-afa3-4617-b48a-77bf850363db,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-ff068c9d-8608-4311-8983-91508d467498,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-4b0356ef-ade1-4948-ae97-7fbe39696c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5283
