reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146424130-172.17.0.20-1598193837499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-6f13b0a9-4b4a-4813-be5d-22cc6729ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-30119d31-6f1b-4382-92e5-b7ffe72ce3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-b20a3c82-a9ed-4bb8-9a17-ee97c7edd522,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-8ca05804-a6a9-4a5f-a211-174aa2210bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-182d82a1-99b9-4257-9bdb-63956b14d474,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-faf0fdec-57b5-4bef-b6fa-daf44e43173d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-51ceeb56-c502-409a-a8b5-fda10b6ad6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-7847a409-b400-4a16-9ca4-81778608ad18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146424130-172.17.0.20-1598193837499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-6f13b0a9-4b4a-4813-be5d-22cc6729ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-30119d31-6f1b-4382-92e5-b7ffe72ce3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-b20a3c82-a9ed-4bb8-9a17-ee97c7edd522,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-8ca05804-a6a9-4a5f-a211-174aa2210bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-182d82a1-99b9-4257-9bdb-63956b14d474,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-faf0fdec-57b5-4bef-b6fa-daf44e43173d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-51ceeb56-c502-409a-a8b5-fda10b6ad6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-7847a409-b400-4a16-9ca4-81778608ad18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052687775-172.17.0.20-1598194022506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-34e78370-81a4-44e0-b82c-f6da3860df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-86387c3e-4716-45fa-a361-22ba001a618f,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e684f219-15c0-441f-ad82-47e27eb5429a,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-02fedb73-4023-4f26-bec8-d4466ae0d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-d1083b58-c6d4-44b0-a324-62fcf8b2ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-46753eb8-7cc7-47e1-903d-a72b3de94435,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-0772c598-b8ba-4ec4-9693-a1c38920db34,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-47424e48-d619-4afc-9c8b-232706294cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052687775-172.17.0.20-1598194022506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-34e78370-81a4-44e0-b82c-f6da3860df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-86387c3e-4716-45fa-a361-22ba001a618f,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e684f219-15c0-441f-ad82-47e27eb5429a,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-02fedb73-4023-4f26-bec8-d4466ae0d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-d1083b58-c6d4-44b0-a324-62fcf8b2ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-46753eb8-7cc7-47e1-903d-a72b3de94435,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-0772c598-b8ba-4ec4-9693-a1c38920db34,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-47424e48-d619-4afc-9c8b-232706294cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146152540-172.17.0.20-1598194376456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-0da85378-1ecd-419c-809b-24db432957ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-1bdc6718-4b31-4deb-b97d-50e6be69b493,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-eb9e3e5d-ffbf-48db-894d-58cebe499d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-e7f813eb-89f9-4560-8fbe-3beec74b1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-82675fbb-b5ca-4c2f-a6b8-743d6682dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-bcf1d0d7-84f7-4f80-ac33-ef2f0ca290ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9b625c4d-cd03-4ba7-a26c-84ed83231949,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-f6dd6062-df61-4c31-90de-3ed6d75bf948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146152540-172.17.0.20-1598194376456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-0da85378-1ecd-419c-809b-24db432957ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-1bdc6718-4b31-4deb-b97d-50e6be69b493,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-eb9e3e5d-ffbf-48db-894d-58cebe499d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-e7f813eb-89f9-4560-8fbe-3beec74b1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-82675fbb-b5ca-4c2f-a6b8-743d6682dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-bcf1d0d7-84f7-4f80-ac33-ef2f0ca290ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9b625c4d-cd03-4ba7-a26c-84ed83231949,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-f6dd6062-df61-4c31-90de-3ed6d75bf948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399302524-172.17.0.20-1598194533958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-537c4954-a44d-4225-8783-550a92b296ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1e9c04a8-7d6b-4ff1-a87e-d92cec071351,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-ced559ed-fc19-4a57-8a8b-8d8e8e007f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-45b39e13-af16-41ca-8415-84162d504513,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-d24b64ca-a4fa-46b3-acb0-5e98d1275e47,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-257bfc5f-c1b4-4cc4-8645-1fc46ae718be,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-eeb70257-0fa7-498d-a69b-5d96dfbb2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-7e64fc12-51dd-436e-8c93-526fa8253242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399302524-172.17.0.20-1598194533958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-537c4954-a44d-4225-8783-550a92b296ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1e9c04a8-7d6b-4ff1-a87e-d92cec071351,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-ced559ed-fc19-4a57-8a8b-8d8e8e007f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-45b39e13-af16-41ca-8415-84162d504513,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-d24b64ca-a4fa-46b3-acb0-5e98d1275e47,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-257bfc5f-c1b4-4cc4-8645-1fc46ae718be,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-eeb70257-0fa7-498d-a69b-5d96dfbb2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-7e64fc12-51dd-436e-8c93-526fa8253242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973165510-172.17.0.20-1598194610015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-1d8fc167-4020-4d50-ae9a-adb24ea658b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-855d7709-d284-4920-9efc-0e9ef116435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-5687edae-0611-4b9f-b7a6-a9b504cce0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-81055d6b-9c27-46cc-958d-424e467fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-6ff5e468-0599-48d1-9f5b-ff0c36f17a48,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-4d2c8fb8-12dc-4b49-971e-86e03e53a5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-81da3126-d55c-439d-bec5-4615115c57c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-d5a796ce-8382-4292-aa37-ffb8d031ffa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973165510-172.17.0.20-1598194610015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-1d8fc167-4020-4d50-ae9a-adb24ea658b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-855d7709-d284-4920-9efc-0e9ef116435b,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-5687edae-0611-4b9f-b7a6-a9b504cce0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-81055d6b-9c27-46cc-958d-424e467fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-6ff5e468-0599-48d1-9f5b-ff0c36f17a48,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-4d2c8fb8-12dc-4b49-971e-86e03e53a5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-81da3126-d55c-439d-bec5-4615115c57c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-d5a796ce-8382-4292-aa37-ffb8d031ffa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673426595-172.17.0.20-1598194659072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-e5b9ef48-9812-4b4a-b537-bf53225b2017,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1260c3b5-e9d9-4c92-8b58-88d7218b2f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-90f3c96e-f00a-4331-afcb-43dd11f815a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-a462dbc3-8e5e-454c-afc5-6ef760906e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-05c5d3da-842b-4227-8a71-d02cee34d679,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-f8e37c59-6177-4200-8acd-928ef868f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-8ed5b0cc-b244-49b3-876e-c7e8d50a7a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-a59b772f-1559-4493-afca-cebbe47d9396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673426595-172.17.0.20-1598194659072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33739,DS-e5b9ef48-9812-4b4a-b537-bf53225b2017,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1260c3b5-e9d9-4c92-8b58-88d7218b2f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-90f3c96e-f00a-4331-afcb-43dd11f815a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-a462dbc3-8e5e-454c-afc5-6ef760906e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-05c5d3da-842b-4227-8a71-d02cee34d679,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-f8e37c59-6177-4200-8acd-928ef868f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-8ed5b0cc-b244-49b3-876e-c7e8d50a7a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-a59b772f-1559-4493-afca-cebbe47d9396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529210235-172.17.0.20-1598194836734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33051,DS-37fc0c29-999f-490f-b0a1-3670dd75b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-c10133c9-25f9-450b-9dc5-a85b9307a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-f0422311-99bc-455e-ac15-5ffe7cbc1758,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-90216697-d92f-4356-b180-1eca00a56ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1f193931-ff48-4037-8a01-8a26edcf17ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-86cba14d-1706-4db2-824c-30f4db92e539,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-e28c3d25-6379-45c1-b686-8a467458a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-ff5c1a4d-cdfa-47e0-895f-a718a8a01a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529210235-172.17.0.20-1598194836734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33051,DS-37fc0c29-999f-490f-b0a1-3670dd75b9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-c10133c9-25f9-450b-9dc5-a85b9307a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-f0422311-99bc-455e-ac15-5ffe7cbc1758,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-90216697-d92f-4356-b180-1eca00a56ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1f193931-ff48-4037-8a01-8a26edcf17ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-86cba14d-1706-4db2-824c-30f4db92e539,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-e28c3d25-6379-45c1-b686-8a467458a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-ff5c1a4d-cdfa-47e0-895f-a718a8a01a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243097240-172.17.0.20-1598194925297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-6a5f3582-2eb2-40db-9216-64f7670d88b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-0b39660f-86c3-41d6-84b7-02a8639ba927,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-4fb6fc45-2327-4072-a7af-27719662cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-4918c1f0-284e-4473-8478-745b474a55b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-d4e4bb88-efd1-4ff5-9558-bc7f519c3e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-22683a9d-34d9-4795-b626-927af17edd65,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-abe2d54e-7895-4c62-ae71-ae968d330e55,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-e93bcdc6-225a-4d66-b5fe-a744f8cf015c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243097240-172.17.0.20-1598194925297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-6a5f3582-2eb2-40db-9216-64f7670d88b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-0b39660f-86c3-41d6-84b7-02a8639ba927,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-4fb6fc45-2327-4072-a7af-27719662cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-4918c1f0-284e-4473-8478-745b474a55b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-d4e4bb88-efd1-4ff5-9558-bc7f519c3e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-22683a9d-34d9-4795-b626-927af17edd65,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-abe2d54e-7895-4c62-ae71-ae968d330e55,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-e93bcdc6-225a-4d66-b5fe-a744f8cf015c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509034312-172.17.0.20-1598195292687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-6e8ff149-89ea-4c02-be0b-0aa3409abcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-b8351c74-cb55-4246-8251-24c17d0dee80,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d14c6176-75e5-4316-9677-bc0dfce57e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-9915f858-37d9-41a8-a1c9-f7b959affd20,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-3d063509-3529-43fc-b8f2-2268c0ea8210,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-634b0b81-8090-4c9c-854e-f4c107c6702e,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-a8afd9bf-686b-49d1-99cc-e2679cc3ed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-28337683-0f1b-42a7-81c6-3ea753efa478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509034312-172.17.0.20-1598195292687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-6e8ff149-89ea-4c02-be0b-0aa3409abcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-b8351c74-cb55-4246-8251-24c17d0dee80,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d14c6176-75e5-4316-9677-bc0dfce57e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-9915f858-37d9-41a8-a1c9-f7b959affd20,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-3d063509-3529-43fc-b8f2-2268c0ea8210,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-634b0b81-8090-4c9c-854e-f4c107c6702e,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-a8afd9bf-686b-49d1-99cc-e2679cc3ed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-28337683-0f1b-42a7-81c6-3ea753efa478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242389929-172.17.0.20-1598195347491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-7a045506-bb1c-47d8-850a-fd46db6bf0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-5497c84d-c3ff-46c0-a7da-6ddab7fe7539,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-52ec75f7-7fca-442d-8aac-fefe51a95977,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-657284de-5e7a-40ec-8973-9237b732f07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2119643f-efdd-4402-b789-281caac963e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-0dc7b9f9-7586-470c-8280-42801720443f,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-b2379504-1033-42dc-965e-61e99f7a81c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-7d636541-9fa5-4f74-9a07-6913458c29af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242389929-172.17.0.20-1598195347491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-7a045506-bb1c-47d8-850a-fd46db6bf0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-5497c84d-c3ff-46c0-a7da-6ddab7fe7539,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-52ec75f7-7fca-442d-8aac-fefe51a95977,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-657284de-5e7a-40ec-8973-9237b732f07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2119643f-efdd-4402-b789-281caac963e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-0dc7b9f9-7586-470c-8280-42801720443f,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-b2379504-1033-42dc-965e-61e99f7a81c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-7d636541-9fa5-4f74-9a07-6913458c29af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564318945-172.17.0.20-1598196107436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-e3e39fb8-2528-4c0d-9a73-fb783a5cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-48510b97-b3ca-4cf0-8305-f9e024aa53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-8deaf361-28ce-427e-80e6-2d02f03874c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-21a6b59b-51b9-4bac-9228-16e4d29256a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-0eae4eed-b3db-414e-a3cc-d2b540d228f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-eab63555-22c6-42a5-b815-3be36f9341c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-c0af2333-e57a-4dce-80a8-03bf45b27c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a28ca4be-dd9f-4c6e-9a0e-3ca5ba94662a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564318945-172.17.0.20-1598196107436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-e3e39fb8-2528-4c0d-9a73-fb783a5cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-48510b97-b3ca-4cf0-8305-f9e024aa53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-8deaf361-28ce-427e-80e6-2d02f03874c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-21a6b59b-51b9-4bac-9228-16e4d29256a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-0eae4eed-b3db-414e-a3cc-d2b540d228f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-eab63555-22c6-42a5-b815-3be36f9341c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-c0af2333-e57a-4dce-80a8-03bf45b27c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a28ca4be-dd9f-4c6e-9a0e-3ca5ba94662a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857598573-172.17.0.20-1598196465805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-29bbea28-db5f-4bab-853a-20e02ad1108e,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-2f578be6-f5ec-4b42-8f7b-d8bfc10e2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-a98f7618-7431-4dec-88f5-8046986921a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f68c8a02-2c0a-4b78-a944-2643c37b433c,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-0ab136ab-e382-4f95-8daf-240cb44bd41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-d23ba275-d92d-47a7-9605-92a94fcff091,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7fa04d1a-199f-4862-86f8-cfcdb5813b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4b51c165-4668-4bcb-99d4-3a23435e2edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857598573-172.17.0.20-1598196465805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-29bbea28-db5f-4bab-853a-20e02ad1108e,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-2f578be6-f5ec-4b42-8f7b-d8bfc10e2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-a98f7618-7431-4dec-88f5-8046986921a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f68c8a02-2c0a-4b78-a944-2643c37b433c,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-0ab136ab-e382-4f95-8daf-240cb44bd41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-d23ba275-d92d-47a7-9605-92a94fcff091,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7fa04d1a-199f-4862-86f8-cfcdb5813b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4b51c165-4668-4bcb-99d4-3a23435e2edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190214232-172.17.0.20-1598197181694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-583a9192-57fc-4e7b-93b2-0cb061d8c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d7624ab9-b156-4e38-b5c7-d3ce4376e74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-3897b527-f518-4e7f-ba32-08e2da53e195,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-310f5b7b-9659-4151-a16d-c13d31e2e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-bd46a1b6-aa32-40f2-b86b-b44078360112,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-c157cff7-88d4-4feb-b160-9ebe0884817e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-16522cc2-f7f7-493d-9b65-81f18fbf572a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-fa87d863-e378-40b5-a61e-250ebb8ba5b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190214232-172.17.0.20-1598197181694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39035,DS-583a9192-57fc-4e7b-93b2-0cb061d8c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d7624ab9-b156-4e38-b5c7-d3ce4376e74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-3897b527-f518-4e7f-ba32-08e2da53e195,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-310f5b7b-9659-4151-a16d-c13d31e2e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-bd46a1b6-aa32-40f2-b86b-b44078360112,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-c157cff7-88d4-4feb-b160-9ebe0884817e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-16522cc2-f7f7-493d-9b65-81f18fbf572a,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-fa87d863-e378-40b5-a61e-250ebb8ba5b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257556910-172.17.0.20-1598197551391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-4e66c98b-07c3-425f-96da-ae8b276f837c,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-69d7194f-8a62-46da-9d39-18c6ccc892fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-78e3a451-bbd3-42fc-ba4b-53fef32cd9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-f6f6535d-d294-4aa1-a9a7-6971cde9bfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a5615256-1b14-461e-89f9-084019d15d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-6cc6ffe5-4810-494e-8bef-d2c46354b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-4a1763d7-047f-451c-adc1-1b161967b003,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-b09ae4dd-d2e1-4c05-826a-51ede646bcc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257556910-172.17.0.20-1598197551391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-4e66c98b-07c3-425f-96da-ae8b276f837c,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-69d7194f-8a62-46da-9d39-18c6ccc892fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-78e3a451-bbd3-42fc-ba4b-53fef32cd9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-f6f6535d-d294-4aa1-a9a7-6971cde9bfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a5615256-1b14-461e-89f9-084019d15d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-6cc6ffe5-4810-494e-8bef-d2c46354b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-4a1763d7-047f-451c-adc1-1b161967b003,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-b09ae4dd-d2e1-4c05-826a-51ede646bcc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914991282-172.17.0.20-1598197651794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4a11df7c-6845-4673-b9b9-3bd64cb68809,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-27cdd1bf-d9a7-4cb9-9412-5066e88145e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-34cdf9e7-f4b5-4cfa-a276-05e370e00215,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-35452fe7-e91c-4723-ad9b-a6e5bd38d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-9e261115-84b6-4c10-9ba3-985e38abd1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-a1f581e7-b3b7-4977-8017-6fccb537b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-a040c48f-4990-4f05-a5ac-66024c4e4385,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-22d0519d-49e5-41f4-8438-945fa063689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914991282-172.17.0.20-1598197651794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4a11df7c-6845-4673-b9b9-3bd64cb68809,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-27cdd1bf-d9a7-4cb9-9412-5066e88145e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-34cdf9e7-f4b5-4cfa-a276-05e370e00215,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-35452fe7-e91c-4723-ad9b-a6e5bd38d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-9e261115-84b6-4c10-9ba3-985e38abd1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-a1f581e7-b3b7-4977-8017-6fccb537b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-a040c48f-4990-4f05-a5ac-66024c4e4385,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-22d0519d-49e5-41f4-8438-945fa063689f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456998812-172.17.0.20-1598197786631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-726b8102-1fad-4780-886d-5a14441d3443,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-a7fc4186-d718-492e-ab31-2dddf5f196c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-d5f7bbc3-e4ae-46bd-bde3-781cb7b7237a,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-29c1e77b-a895-4186-b8a9-e630551fbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-949ebae8-d075-47a8-af82-b652c7f3cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-8243b818-d2ae-43e4-ac7e-aee55b45d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-943a0bec-6e67-43fa-bfd9-014710670bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-9a17004c-1961-482c-9f1a-f47d16870c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456998812-172.17.0.20-1598197786631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46067,DS-726b8102-1fad-4780-886d-5a14441d3443,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-a7fc4186-d718-492e-ab31-2dddf5f196c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-d5f7bbc3-e4ae-46bd-bde3-781cb7b7237a,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-29c1e77b-a895-4186-b8a9-e630551fbe64,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-949ebae8-d075-47a8-af82-b652c7f3cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-8243b818-d2ae-43e4-ac7e-aee55b45d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-943a0bec-6e67-43fa-bfd9-014710670bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-9a17004c-1961-482c-9f1a-f47d16870c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306167842-172.17.0.20-1598198519107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41518,DS-f29a04d8-1df7-4d04-b82d-6562ea4dd9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-889a2fa3-8b7f-4ad9-b066-64884399f7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-476a8058-f036-4b0e-bd14-78b2445e801d,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-35a066c5-6595-45ee-b92e-20dd57b37eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-ffd35f95-41c9-4ca0-9502-1f834441bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-64a2d088-b20f-4903-a049-b6cfe495db89,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-a156ce17-27bc-4513-bc64-bed1879caa27,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-c247b724-26d4-43cc-9ad2-f875b3220145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306167842-172.17.0.20-1598198519107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41518,DS-f29a04d8-1df7-4d04-b82d-6562ea4dd9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-889a2fa3-8b7f-4ad9-b066-64884399f7be,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-476a8058-f036-4b0e-bd14-78b2445e801d,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-35a066c5-6595-45ee-b92e-20dd57b37eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-ffd35f95-41c9-4ca0-9502-1f834441bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-64a2d088-b20f-4903-a049-b6cfe495db89,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-a156ce17-27bc-4513-bc64-bed1879caa27,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-c247b724-26d4-43cc-9ad2-f875b3220145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633723005-172.17.0.20-1598198887594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-baa6a6bf-0537-4af0-8cac-93c78b05db85,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-e1abcb14-490b-4f3a-ab07-55cc73236d56,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-cefefc4f-bcc6-4b5b-8712-edd9312bd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-d91b5fca-50ef-407d-bb54-614e2d210f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-ddcbc6b7-9d27-465c-960e-53b987246438,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-64c520f1-f762-4625-bc1f-aeadebe9f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-fcbae504-df67-4c6f-8820-8df148d94fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-7a59a8f3-97da-4aec-bdfa-e82853e95656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633723005-172.17.0.20-1598198887594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-baa6a6bf-0537-4af0-8cac-93c78b05db85,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-e1abcb14-490b-4f3a-ab07-55cc73236d56,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-cefefc4f-bcc6-4b5b-8712-edd9312bd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-d91b5fca-50ef-407d-bb54-614e2d210f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-ddcbc6b7-9d27-465c-960e-53b987246438,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-64c520f1-f762-4625-bc1f-aeadebe9f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-fcbae504-df67-4c6f-8820-8df148d94fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-7a59a8f3-97da-4aec-bdfa-e82853e95656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149380632-172.17.0.20-1598199182650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-592ba00e-96e1-41d9-981a-076596013eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-3b21f4eb-20bb-4ce0-a61e-64742988afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-0db6522f-c3db-4fd5-a1fe-9071bf56b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-63e13662-5630-40b0-9095-c142f55702ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-16736878-90be-4a1e-9fbe-d9b19ace96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-722ed661-298c-480d-9083-c30082dbd4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-36467d92-c93b-4110-9fa0-fa5df7003268,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d4d58a94-c9f3-43b1-b23f-716c89d36920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149380632-172.17.0.20-1598199182650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-592ba00e-96e1-41d9-981a-076596013eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-3b21f4eb-20bb-4ce0-a61e-64742988afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-0db6522f-c3db-4fd5-a1fe-9071bf56b92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-63e13662-5630-40b0-9095-c142f55702ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-16736878-90be-4a1e-9fbe-d9b19ace96cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-722ed661-298c-480d-9083-c30082dbd4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-36467d92-c93b-4110-9fa0-fa5df7003268,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d4d58a94-c9f3-43b1-b23f-716c89d36920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176458444-172.17.0.20-1598199205227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-33ad4000-ca9b-4cc6-bfa5-a87575a31148,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-08dfbf0f-aba4-4d81-8ce5-4fc55c2c090f,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4487fd09-7509-44af-b9ce-e51d8c2a7985,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a5bfc0bb-8f25-4bda-8e2d-69c0b2ee9188,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-3cde3852-8012-48e8-837c-d9c6373086ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-8ac4564c-388e-4683-8e2f-28e596fc6188,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-41cf35a6-7093-41f1-afab-ae19926fe998,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f95df836-99f8-4d9c-b0ca-cf83c25de107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176458444-172.17.0.20-1598199205227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-33ad4000-ca9b-4cc6-bfa5-a87575a31148,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-08dfbf0f-aba4-4d81-8ce5-4fc55c2c090f,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4487fd09-7509-44af-b9ce-e51d8c2a7985,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a5bfc0bb-8f25-4bda-8e2d-69c0b2ee9188,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-3cde3852-8012-48e8-837c-d9c6373086ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-8ac4564c-388e-4683-8e2f-28e596fc6188,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-41cf35a6-7093-41f1-afab-ae19926fe998,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f95df836-99f8-4d9c-b0ca-cf83c25de107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249807098-172.17.0.20-1598199228892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-84bd10d0-fb56-4585-80fa-420224370d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-229b8b42-f937-472e-bc84-de2cf9b14ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-6f140f3a-99e4-4784-8c79-5207e23140c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a9b93a72-30ea-4075-be09-3a34abce3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1bf925dc-b0b2-4ca8-b54d-4d2740a96dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-7adecb0c-b136-4c94-9418-d50fc99105d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-58179c32-35c0-4faf-b68b-44fc8663ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-f1125cfc-a413-4193-b6cc-7e268430d6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249807098-172.17.0.20-1598199228892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45435,DS-84bd10d0-fb56-4585-80fa-420224370d25,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-229b8b42-f937-472e-bc84-de2cf9b14ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-6f140f3a-99e4-4784-8c79-5207e23140c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a9b93a72-30ea-4075-be09-3a34abce3a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1bf925dc-b0b2-4ca8-b54d-4d2740a96dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-7adecb0c-b136-4c94-9418-d50fc99105d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-58179c32-35c0-4faf-b68b-44fc8663ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-f1125cfc-a413-4193-b6cc-7e268430d6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324300584-172.17.0.20-1598199495463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-67706db9-f229-4fec-a11f-bcdc3b6050d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-defe8052-25a7-4f14-b7dc-0270164b6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-0a4e7847-7827-4fbb-85aa-e1fab2cf10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3a0e6959-79d6-4434-a96b-6a1c66fa5e28,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-f39f87dc-7aeb-4932-98f2-a5745a8bd898,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-035ac9ca-c54d-494d-a62e-43255112cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-a5bd966d-99a4-4885-b685-ee864db9eead,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-42202928-e096-484f-9157-70a891956af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324300584-172.17.0.20-1598199495463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46585,DS-67706db9-f229-4fec-a11f-bcdc3b6050d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-defe8052-25a7-4f14-b7dc-0270164b6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-0a4e7847-7827-4fbb-85aa-e1fab2cf10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3a0e6959-79d6-4434-a96b-6a1c66fa5e28,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-f39f87dc-7aeb-4932-98f2-a5745a8bd898,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-035ac9ca-c54d-494d-a62e-43255112cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-a5bd966d-99a4-4885-b685-ee864db9eead,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-42202928-e096-484f-9157-70a891956af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318562174-172.17.0.20-1598199647579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-5ac5d811-eced-4dc0-aa1e-5fdbca7fc390,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-390bfb2f-46f5-454c-a9f2-ac49fd4be055,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-7f23cb34-551c-4f22-aef4-0e1b525d8bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-89dec83c-f176-4d7b-83a2-dd524859fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-211ef556-4578-4ae7-af11-5473a26ab2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8492f06f-f8b1-4f54-af8b-81a058c09d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-bdf7b291-7086-4d22-bc1f-298ec4006b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-842e0bc0-88be-4621-b2a7-bbe3b50a4a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318562174-172.17.0.20-1598199647579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-5ac5d811-eced-4dc0-aa1e-5fdbca7fc390,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-390bfb2f-46f5-454c-a9f2-ac49fd4be055,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-7f23cb34-551c-4f22-aef4-0e1b525d8bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-89dec83c-f176-4d7b-83a2-dd524859fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-211ef556-4578-4ae7-af11-5473a26ab2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8492f06f-f8b1-4f54-af8b-81a058c09d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-bdf7b291-7086-4d22-bc1f-298ec4006b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-842e0bc0-88be-4621-b2a7-bbe3b50a4a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6067
