reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859996263-172.17.0.5-1598117535820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38504,DS-0ed75652-0c48-4e14-b456-64a1078dffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e00f3b02-9b3e-44c7-800d-a1bbfb35528d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c687ed20-f312-49ec-bc0a-8713b925b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-586d673d-163f-407c-ab1f-6b5a5211ffc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-6656189d-27a2-4800-bd33-f6e9ab27b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d082fe6c-bd3c-43d1-b09f-57cb06e5e983,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-07bebaef-675e-43b9-8093-2adb3a626662,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-7f55d2d6-93bd-490c-bba8-e9df8221b60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859996263-172.17.0.5-1598117535820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38504,DS-0ed75652-0c48-4e14-b456-64a1078dffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e00f3b02-9b3e-44c7-800d-a1bbfb35528d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c687ed20-f312-49ec-bc0a-8713b925b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-586d673d-163f-407c-ab1f-6b5a5211ffc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-6656189d-27a2-4800-bd33-f6e9ab27b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d082fe6c-bd3c-43d1-b09f-57cb06e5e983,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-07bebaef-675e-43b9-8093-2adb3a626662,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-7f55d2d6-93bd-490c-bba8-e9df8221b60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103762793-172.17.0.5-1598117919423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-2863b877-13f9-44db-ab39-4c323805a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-f94f69b4-62c5-4bd1-8ebe-0ed9bd21f0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f59e11c7-5bf0-45a0-890f-e78d18ee3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-b371a0d9-8219-400c-ab02-ded92553aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-b9a2054b-e14f-4007-852c-d0e0fc52b141,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-ff897448-5eb7-4300-9046-df6c3c46f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c8130320-af9a-4b9a-a715-c136307df4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2b75c59f-cab8-4bce-823e-5ca4fb54976f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103762793-172.17.0.5-1598117919423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-2863b877-13f9-44db-ab39-4c323805a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-f94f69b4-62c5-4bd1-8ebe-0ed9bd21f0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-f59e11c7-5bf0-45a0-890f-e78d18ee3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-b371a0d9-8219-400c-ab02-ded92553aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-b9a2054b-e14f-4007-852c-d0e0fc52b141,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-ff897448-5eb7-4300-9046-df6c3c46f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c8130320-af9a-4b9a-a715-c136307df4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2b75c59f-cab8-4bce-823e-5ca4fb54976f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713029469-172.17.0.5-1598118320198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-84e608b1-188b-4da2-8713-2d58c60de9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-c0d3aaa8-2e16-4154-9b8b-6546ee65a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-87216852-3acf-4e2c-9dd3-9d6d41835689,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-085af478-d68c-49dd-ab51-1ff28c4622d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-4c498e87-4564-4e90-8f2d-c6387ea23109,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3c0df935-5e0f-4a12-abd5-a66a46e8f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-6eb17990-a0b4-4f7d-b23b-75b1e24c76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-acfff679-693b-4aa0-b098-afa1b4faef80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713029469-172.17.0.5-1598118320198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-84e608b1-188b-4da2-8713-2d58c60de9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-c0d3aaa8-2e16-4154-9b8b-6546ee65a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-87216852-3acf-4e2c-9dd3-9d6d41835689,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-085af478-d68c-49dd-ab51-1ff28c4622d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-4c498e87-4564-4e90-8f2d-c6387ea23109,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-3c0df935-5e0f-4a12-abd5-a66a46e8f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-6eb17990-a0b4-4f7d-b23b-75b1e24c76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-acfff679-693b-4aa0-b098-afa1b4faef80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730072872-172.17.0.5-1598118425505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-c295c3b9-f693-45f4-8156-cdd883dca1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-c3874b6f-2517-4a21-9734-06baaf986e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-6b4d4534-8899-4610-968f-920d95c97f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-18f102b3-ce44-4aea-aea6-c7811e994c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-072dd931-bade-4ca0-9213-fd86703bd1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-814238eb-e122-4324-a950-4c39617b9f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-34d75b21-25d0-4952-8569-c7ba01799d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-6e26a727-8cd7-4eef-9100-30ec21e6757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730072872-172.17.0.5-1598118425505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-c295c3b9-f693-45f4-8156-cdd883dca1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-c3874b6f-2517-4a21-9734-06baaf986e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-6b4d4534-8899-4610-968f-920d95c97f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-18f102b3-ce44-4aea-aea6-c7811e994c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-072dd931-bade-4ca0-9213-fd86703bd1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-814238eb-e122-4324-a950-4c39617b9f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-34d75b21-25d0-4952-8569-c7ba01799d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-6e26a727-8cd7-4eef-9100-30ec21e6757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686913666-172.17.0.5-1598118707593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36865,DS-9e52a7b3-c76f-4da7-85e2-1c93d9efd081,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-73e04172-4c1a-4dfd-b9b9-62cecb4b774d,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-25105ca0-8151-41df-9bf2-5c9685b6846f,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-c88d2feb-ecdf-4739-91eb-0edb0fc57e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-3e233601-d0ed-4d50-9993-84f8669c87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-3e3efe7c-06ca-430c-8f1c-9acec3066d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-f584d228-8c4d-4305-9ac6-8663fa3f95b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-7db7ef62-6ac4-4277-a879-8ce7bbd3b271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686913666-172.17.0.5-1598118707593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36865,DS-9e52a7b3-c76f-4da7-85e2-1c93d9efd081,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-73e04172-4c1a-4dfd-b9b9-62cecb4b774d,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-25105ca0-8151-41df-9bf2-5c9685b6846f,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-c88d2feb-ecdf-4739-91eb-0edb0fc57e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-3e233601-d0ed-4d50-9993-84f8669c87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-3e3efe7c-06ca-430c-8f1c-9acec3066d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-f584d228-8c4d-4305-9ac6-8663fa3f95b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-7db7ef62-6ac4-4277-a879-8ce7bbd3b271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023203005-172.17.0.5-1598118817447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-205d8466-fa19-460a-a489-a792663d9088,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-2594699c-aa52-4c07-ac63-e7dfd8c3bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-2ba63d73-4ad9-42e6-b1f4-94c30ce6e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-b5da18ea-bc93-4b26-b2a9-de983e64e250,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-234f824c-b4ba-431e-a439-cac7747d6e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-4a98b1c6-14a4-4321-8410-d3419fe9fb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-22da6975-b412-41c6-a9f4-016b4778e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a9b4494d-e1b6-423a-a7b9-f3127c70b495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023203005-172.17.0.5-1598118817447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-205d8466-fa19-460a-a489-a792663d9088,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-2594699c-aa52-4c07-ac63-e7dfd8c3bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-2ba63d73-4ad9-42e6-b1f4-94c30ce6e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-b5da18ea-bc93-4b26-b2a9-de983e64e250,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-234f824c-b4ba-431e-a439-cac7747d6e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-4a98b1c6-14a4-4321-8410-d3419fe9fb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-22da6975-b412-41c6-a9f4-016b4778e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-a9b4494d-e1b6-423a-a7b9-f3127c70b495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139988587-172.17.0.5-1598118930670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-d9c7407b-df06-4044-922d-dd3f858193f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f8e1e19d-e022-4b54-a407-3d3c231cc1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-9204e56a-6f03-4ec9-be50-d1e4a306387d,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-683d20a0-6c0b-45e5-873d-31bdda999969,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-68a1cbe5-9c28-4b3a-9141-09101e700735,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0174905f-fc26-4075-8c71-027b182ca18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-d2066d6b-0f8f-4d43-900f-47f5a1c97e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-ff94f08b-9f7f-4429-99ec-1722c9599a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139988587-172.17.0.5-1598118930670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-d9c7407b-df06-4044-922d-dd3f858193f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f8e1e19d-e022-4b54-a407-3d3c231cc1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-9204e56a-6f03-4ec9-be50-d1e4a306387d,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-683d20a0-6c0b-45e5-873d-31bdda999969,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-68a1cbe5-9c28-4b3a-9141-09101e700735,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0174905f-fc26-4075-8c71-027b182ca18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-d2066d6b-0f8f-4d43-900f-47f5a1c97e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-ff94f08b-9f7f-4429-99ec-1722c9599a67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019471871-172.17.0.5-1598119281539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-c9ca4e34-a11d-4ec1-a73b-aa91c00b614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-eba3042a-97ce-4a46-95ae-8bef31bddfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-80bda442-3cde-4246-8a73-f7067b2527cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-232cc705-5e17-4eb6-bb17-ba3d23105f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-200209f6-8d30-4e3c-b357-661d83a61354,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-fc2727de-f262-4710-97d5-e0ce5dbf63ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0f608746-7a61-4b8d-9546-946f15e61f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-32590627-2230-439f-8983-b4ca1b8f6401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019471871-172.17.0.5-1598119281539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46186,DS-c9ca4e34-a11d-4ec1-a73b-aa91c00b614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-eba3042a-97ce-4a46-95ae-8bef31bddfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-80bda442-3cde-4246-8a73-f7067b2527cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-232cc705-5e17-4eb6-bb17-ba3d23105f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-200209f6-8d30-4e3c-b357-661d83a61354,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-fc2727de-f262-4710-97d5-e0ce5dbf63ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0f608746-7a61-4b8d-9546-946f15e61f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-32590627-2230-439f-8983-b4ca1b8f6401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710071035-172.17.0.5-1598119726845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-e09053ae-cf54-4264-acca-a51ea0e9dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-949a4f7b-68a7-4cc1-8045-81c2286082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-fb9a2f12-b357-495e-8f83-c2140a36ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-dc8c3d2c-437b-4004-b4a6-d621e40730c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-dd45d0d1-c311-43a8-845c-2d6113c6b84e,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-efb0f1ff-e0ab-443b-8576-41718f9a5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-f916f28f-fcd4-422f-af04-b53e28afc1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-4be73af1-c86e-4bc8-9c23-5742bab5e070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710071035-172.17.0.5-1598119726845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-e09053ae-cf54-4264-acca-a51ea0e9dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-949a4f7b-68a7-4cc1-8045-81c2286082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-fb9a2f12-b357-495e-8f83-c2140a36ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-dc8c3d2c-437b-4004-b4a6-d621e40730c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-dd45d0d1-c311-43a8-845c-2d6113c6b84e,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-efb0f1ff-e0ab-443b-8576-41718f9a5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-f916f28f-fcd4-422f-af04-b53e28afc1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-4be73af1-c86e-4bc8-9c23-5742bab5e070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968629191-172.17.0.5-1598120321271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-e389b7ca-74d1-4447-99bf-5ead4c3158fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-19db3844-d1e1-47b4-9df4-1b1aaa6a290f,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-ac972ee5-dd1e-4870-a4c8-1cc63195ae1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-1b44cee4-2c74-4433-a063-27ee1fec4cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-3aa23a7a-e24a-4999-8fde-2a9faf6c51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-cb9ac1fa-4aeb-4b63-88b3-73bbce6d50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-8af534cf-a8b9-4d12-b497-47ccfd390067,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-4201f6b6-9d29-406e-9f0f-aece187f2ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968629191-172.17.0.5-1598120321271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-e389b7ca-74d1-4447-99bf-5ead4c3158fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-19db3844-d1e1-47b4-9df4-1b1aaa6a290f,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-ac972ee5-dd1e-4870-a4c8-1cc63195ae1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-1b44cee4-2c74-4433-a063-27ee1fec4cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-3aa23a7a-e24a-4999-8fde-2a9faf6c51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-cb9ac1fa-4aeb-4b63-88b3-73bbce6d50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-8af534cf-a8b9-4d12-b497-47ccfd390067,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-4201f6b6-9d29-406e-9f0f-aece187f2ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578565696-172.17.0.5-1598120388062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-18c8aef6-b47a-47aa-822d-5ae8ef92947b,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-f3baabf8-aeed-4a82-b5b1-21d3f24981c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-10f3a68b-f193-45af-b844-fe6b96de5612,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-0c82ade7-916a-4b18-a50b-750f837d9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-ad49a996-0cf8-4ca9-80bf-c52e03f02a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-c17115df-5775-4b70-a5d7-ceedf389e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-01ddde54-4797-49dd-9e65-c0f477343e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-aa4cbf0c-af84-4e1b-9789-ec866ef007ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578565696-172.17.0.5-1598120388062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-18c8aef6-b47a-47aa-822d-5ae8ef92947b,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-f3baabf8-aeed-4a82-b5b1-21d3f24981c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-10f3a68b-f193-45af-b844-fe6b96de5612,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-0c82ade7-916a-4b18-a50b-750f837d9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-ad49a996-0cf8-4ca9-80bf-c52e03f02a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-c17115df-5775-4b70-a5d7-ceedf389e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-01ddde54-4797-49dd-9e65-c0f477343e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-aa4cbf0c-af84-4e1b-9789-ec866ef007ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076311859-172.17.0.5-1598120583884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-b05a96d8-5d2e-48e5-8a0d-ee57d83a1f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-1c0ec2e9-ad76-48cc-84a5-e92171085060,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-c86c1b31-cb5d-4ae7-88cd-a9ec22a08e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-b7a56ece-4f3a-4829-a1da-0c9eceaeb07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-3267f0ff-b252-4a4a-ba1d-b0fc82c60c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-e17df7fb-03e1-458a-87f3-e39a0122610a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-3b5a1b3b-5a10-4539-9b30-205fc0b3f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5cb58e95-7bae-4265-94d2-21f9edc1e2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076311859-172.17.0.5-1598120583884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-b05a96d8-5d2e-48e5-8a0d-ee57d83a1f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-1c0ec2e9-ad76-48cc-84a5-e92171085060,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-c86c1b31-cb5d-4ae7-88cd-a9ec22a08e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-b7a56ece-4f3a-4829-a1da-0c9eceaeb07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-3267f0ff-b252-4a4a-ba1d-b0fc82c60c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-e17df7fb-03e1-458a-87f3-e39a0122610a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-3b5a1b3b-5a10-4539-9b30-205fc0b3f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-5cb58e95-7bae-4265-94d2-21f9edc1e2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621989587-172.17.0.5-1598120993774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39367,DS-4ebf6677-1a4a-4df2-94bb-e3f42c99463a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-f8cfad5a-5048-40a9-a3b1-0a403c685b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-8ff8101c-b525-413f-9e49-d0720b551bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-5d9e3929-547f-43cd-88c7-03c28062d2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-d70e9ebd-85ab-49dd-9a52-732e7902fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-1143bc5b-4d8b-434a-9f0f-3379d51a624c,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b5f28126-2c4f-4721-a8bc-4fa677ca0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-6f334a4b-78b3-4a74-a66a-4e147048529d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621989587-172.17.0.5-1598120993774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39367,DS-4ebf6677-1a4a-4df2-94bb-e3f42c99463a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-f8cfad5a-5048-40a9-a3b1-0a403c685b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-8ff8101c-b525-413f-9e49-d0720b551bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-5d9e3929-547f-43cd-88c7-03c28062d2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-d70e9ebd-85ab-49dd-9a52-732e7902fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-1143bc5b-4d8b-434a-9f0f-3379d51a624c,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b5f28126-2c4f-4721-a8bc-4fa677ca0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-6f334a4b-78b3-4a74-a66a-4e147048529d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852516936-172.17.0.5-1598121787177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-66e688af-783a-4d0a-b5f5-3e20cc89183d,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d3a46c5e-4c33-49d3-aa61-a906bc6b766c,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-975e2e41-0488-4bec-94d0-38bd8fe414c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-9e89c5a8-6505-4503-b8ee-b6e42fd499bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-dde50478-758f-4641-9d97-d36855a995d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-798e09bf-da53-40bf-a5c0-ff0c7e0323a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-272b6a25-a442-4e0e-b16a-251cb638b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-264f6673-1abb-4d17-b15d-bc60ce4da7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852516936-172.17.0.5-1598121787177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-66e688af-783a-4d0a-b5f5-3e20cc89183d,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d3a46c5e-4c33-49d3-aa61-a906bc6b766c,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-975e2e41-0488-4bec-94d0-38bd8fe414c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-9e89c5a8-6505-4503-b8ee-b6e42fd499bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-dde50478-758f-4641-9d97-d36855a995d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-798e09bf-da53-40bf-a5c0-ff0c7e0323a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-272b6a25-a442-4e0e-b16a-251cb638b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-264f6673-1abb-4d17-b15d-bc60ce4da7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600335517-172.17.0.5-1598121994516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-ddff961a-d21f-4646-807a-f53d61e9a020,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-652069c6-aa55-4227-ae41-84517616e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-dad0b105-cf5a-45a9-bf0c-ccd09a57f965,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-98c544d6-71a1-4415-83e4-a408563668db,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-87a3ea51-ff12-45d0-a99d-693c8ec78838,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-b4b4d558-c2ae-4d40-83cd-dd0d19b8a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-5684c4cb-ba82-4fc9-9eaf-1b5938b604c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c2041ccf-18d4-4bdf-a66f-8019f5f9649c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600335517-172.17.0.5-1598121994516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-ddff961a-d21f-4646-807a-f53d61e9a020,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-652069c6-aa55-4227-ae41-84517616e48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-dad0b105-cf5a-45a9-bf0c-ccd09a57f965,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-98c544d6-71a1-4415-83e4-a408563668db,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-87a3ea51-ff12-45d0-a99d-693c8ec78838,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-b4b4d558-c2ae-4d40-83cd-dd0d19b8a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-5684c4cb-ba82-4fc9-9eaf-1b5938b604c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c2041ccf-18d4-4bdf-a66f-8019f5f9649c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831816196-172.17.0.5-1598122217695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-a61f404e-0077-4505-9b4f-9e4d647ea3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-ef6700dd-5419-4fc8-9d02-2cb48f19f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-dafb008d-474c-43e6-ad72-f8fdc3058a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-912f26fe-20de-4f7d-b74f-b8daafd6232e,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ed173693-d1ed-4319-9075-b4bac8240e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-c2902b48-1755-49ee-8d07-51d58dbd0389,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-d4bdd64d-1ae9-40a2-ac3f-728a11dcb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-05305673-e0a5-4f1a-bbec-89ea5cd79723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831816196-172.17.0.5-1598122217695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-a61f404e-0077-4505-9b4f-9e4d647ea3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-ef6700dd-5419-4fc8-9d02-2cb48f19f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-dafb008d-474c-43e6-ad72-f8fdc3058a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-912f26fe-20de-4f7d-b74f-b8daafd6232e,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ed173693-d1ed-4319-9075-b4bac8240e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-c2902b48-1755-49ee-8d07-51d58dbd0389,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-d4bdd64d-1ae9-40a2-ac3f-728a11dcb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-05305673-e0a5-4f1a-bbec-89ea5cd79723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158486402-172.17.0.5-1598122296044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-176932bc-30a6-4da7-8c99-39a29c9fdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-643ff992-85bc-4c44-9b34-0eee197ed9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-4bcff261-2cf5-46fb-8e72-ea13c1584df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-44d072c8-aa15-4ca4-b806-45c86d11e202,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-8cf5d43e-076f-4d65-8cb6-a6332d4b1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-380d3372-d254-4734-a488-12adcef164ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-9a0386c8-82c0-4d55-8c63-44619ed736f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-b7962082-c036-40bc-aec6-cfe609b0129a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158486402-172.17.0.5-1598122296044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-176932bc-30a6-4da7-8c99-39a29c9fdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-643ff992-85bc-4c44-9b34-0eee197ed9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-4bcff261-2cf5-46fb-8e72-ea13c1584df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-44d072c8-aa15-4ca4-b806-45c86d11e202,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-8cf5d43e-076f-4d65-8cb6-a6332d4b1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-380d3372-d254-4734-a488-12adcef164ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-9a0386c8-82c0-4d55-8c63-44619ed736f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-b7962082-c036-40bc-aec6-cfe609b0129a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882791816-172.17.0.5-1598122560507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-ef28161b-e825-40d2-9c83-da0b0d92616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-61b61bea-5abd-4ee6-b258-ac8f1d13d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-ea4321aa-7594-4df5-9789-3c83c394dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-4eb0999d-d96a-4353-ba33-697b84ef4a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-ddd87a31-09d5-4c9f-9d73-a45e83cd7bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-af782197-6dc3-41e9-a64e-842a3aad6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-2ea56732-21d7-4046-9fd5-65b16bbcae20,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-5210c94b-87c7-4ea8-ac2c-39f2470729df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882791816-172.17.0.5-1598122560507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-ef28161b-e825-40d2-9c83-da0b0d92616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-61b61bea-5abd-4ee6-b258-ac8f1d13d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-ea4321aa-7594-4df5-9789-3c83c394dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-4eb0999d-d96a-4353-ba33-697b84ef4a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-ddd87a31-09d5-4c9f-9d73-a45e83cd7bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-af782197-6dc3-41e9-a64e-842a3aad6a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-2ea56732-21d7-4046-9fd5-65b16bbcae20,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-5210c94b-87c7-4ea8-ac2c-39f2470729df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5373
