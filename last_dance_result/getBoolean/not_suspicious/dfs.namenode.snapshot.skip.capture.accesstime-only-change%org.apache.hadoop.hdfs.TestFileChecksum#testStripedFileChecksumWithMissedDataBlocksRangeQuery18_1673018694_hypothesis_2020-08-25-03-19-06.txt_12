reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948687747-172.17.0.6-1598325752623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-d50ea94b-11d7-42bd-a403-79644409b4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-8ba454c4-11df-4be5-8213-c19916de4939,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-8afc0871-7775-49c0-ba3b-32cd370aa51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-e52e8f9b-d5d9-471c-874f-49c19c509f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-d8597d82-abd5-4ab4-8eaa-0bee6f6ac257,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-6805660b-3ee0-4af1-b3a7-7625d3cd8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-9b6effb6-21bd-40b9-8c00-31384c4c1827,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-cd490486-2931-459c-8dcd-e0f1785a47ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948687747-172.17.0.6-1598325752623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-d50ea94b-11d7-42bd-a403-79644409b4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-8ba454c4-11df-4be5-8213-c19916de4939,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-8afc0871-7775-49c0-ba3b-32cd370aa51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-e52e8f9b-d5d9-471c-874f-49c19c509f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-d8597d82-abd5-4ab4-8eaa-0bee6f6ac257,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-6805660b-3ee0-4af1-b3a7-7625d3cd8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-9b6effb6-21bd-40b9-8c00-31384c4c1827,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-cd490486-2931-459c-8dcd-e0f1785a47ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535158469-172.17.0.6-1598325829360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-4b23d11a-846e-455f-bb14-5e4980e17c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-70acb8f8-b982-4358-9a42-fc34768a24c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-4e66908d-c2a6-497d-962b-4725d834cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-a995db96-04b0-408c-98f8-351c93003218,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-bd36801c-3800-443d-aaee-35c3fe72e4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-f9464de7-9c61-4d1e-bc01-2477f47ea99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-cd91cc7f-d257-4455-bb24-16c37172c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-285ab927-e6ef-478d-9bce-98d1edf940ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535158469-172.17.0.6-1598325829360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-4b23d11a-846e-455f-bb14-5e4980e17c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-70acb8f8-b982-4358-9a42-fc34768a24c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-4e66908d-c2a6-497d-962b-4725d834cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-a995db96-04b0-408c-98f8-351c93003218,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-bd36801c-3800-443d-aaee-35c3fe72e4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-f9464de7-9c61-4d1e-bc01-2477f47ea99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-cd91cc7f-d257-4455-bb24-16c37172c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-285ab927-e6ef-478d-9bce-98d1edf940ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15182642-172.17.0.6-1598325867521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-7814562d-e3f6-4846-a70b-f97a537ec670,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-26b831e5-97a6-46c7-88d3-a4ed5b766e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-96346ce6-a5b2-4d74-966c-5397c95bf259,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-32b59f46-66a8-4d02-aab1-102596c09bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-d1d4137c-9ba7-4d7c-968e-0a26355366cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-3678313f-b18a-4798-a8ee-26316436539c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-b36894bc-a433-4bbe-9f12-227918df09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-95b44802-a4b7-4ab9-88fe-b849feae1ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15182642-172.17.0.6-1598325867521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-7814562d-e3f6-4846-a70b-f97a537ec670,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-26b831e5-97a6-46c7-88d3-a4ed5b766e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-96346ce6-a5b2-4d74-966c-5397c95bf259,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-32b59f46-66a8-4d02-aab1-102596c09bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-d1d4137c-9ba7-4d7c-968e-0a26355366cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-3678313f-b18a-4798-a8ee-26316436539c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-b36894bc-a433-4bbe-9f12-227918df09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-95b44802-a4b7-4ab9-88fe-b849feae1ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134938913-172.17.0.6-1598326997156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-0076ff84-fb41-4420-be67-5b8a327e48de,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-fa1767d6-a991-4e9f-9031-5f46244502a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-15167d55-d2c6-44b5-9428-66fa6ab8bc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-cc1cec66-cdf7-44a9-aad8-211aef3cf6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-2c1ceeef-8f92-437b-9674-ad8efb1f4a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-451fb6d2-a046-4b3e-867a-ff65c3aefe67,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-44a5ff5e-b0f8-46cd-bfdb-5da0eeb68468,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-c26838ca-2aaf-4deb-81b9-bb68e5400cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134938913-172.17.0.6-1598326997156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36972,DS-0076ff84-fb41-4420-be67-5b8a327e48de,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-fa1767d6-a991-4e9f-9031-5f46244502a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-15167d55-d2c6-44b5-9428-66fa6ab8bc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-cc1cec66-cdf7-44a9-aad8-211aef3cf6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-2c1ceeef-8f92-437b-9674-ad8efb1f4a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-451fb6d2-a046-4b3e-867a-ff65c3aefe67,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-44a5ff5e-b0f8-46cd-bfdb-5da0eeb68468,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-c26838ca-2aaf-4deb-81b9-bb68e5400cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79955414-172.17.0.6-1598327341327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-79efc1c9-feb3-425a-abd3-4588f3937f48,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-9e68b624-87f4-4cc0-a340-21dd11066485,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-5c72dd06-817f-4312-aa2f-7f865f3ddffd,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-3527a3e8-0a7b-4b8b-ba98-25b5b0ede3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-d3595955-d1b3-4fa2-8da2-34f765fcc822,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-ae61cc80-0ff5-49ab-a11e-615b1ae18a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-48eb81d1-c03f-484a-b181-ac5a17a905aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-2c93bf0e-42ed-4b60-b764-8ad44dbf116f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79955414-172.17.0.6-1598327341327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-79efc1c9-feb3-425a-abd3-4588f3937f48,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-9e68b624-87f4-4cc0-a340-21dd11066485,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-5c72dd06-817f-4312-aa2f-7f865f3ddffd,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-3527a3e8-0a7b-4b8b-ba98-25b5b0ede3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-d3595955-d1b3-4fa2-8da2-34f765fcc822,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-ae61cc80-0ff5-49ab-a11e-615b1ae18a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-48eb81d1-c03f-484a-b181-ac5a17a905aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-2c93bf0e-42ed-4b60-b764-8ad44dbf116f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662985736-172.17.0.6-1598327426828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-807348a7-b334-4ec4-bafb-edce004ad7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-87935976-4994-402b-9db7-93460ebcb003,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-bdaaba67-edd7-408b-9e0b-bd4cea03f338,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-bd306ca0-0c66-4db0-8764-f9e79f5dd3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-162e9270-4a86-458c-bae0-e83d0948c417,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-5f6dca29-9c9d-41dc-b155-1c2ae6246f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-0622eb5e-2104-4dd2-a838-85482f45b465,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-7d4b8d01-da64-4d43-b8fc-6775dc375535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662985736-172.17.0.6-1598327426828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-807348a7-b334-4ec4-bafb-edce004ad7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-87935976-4994-402b-9db7-93460ebcb003,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-bdaaba67-edd7-408b-9e0b-bd4cea03f338,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-bd306ca0-0c66-4db0-8764-f9e79f5dd3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-162e9270-4a86-458c-bae0-e83d0948c417,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-5f6dca29-9c9d-41dc-b155-1c2ae6246f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-0622eb5e-2104-4dd2-a838-85482f45b465,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-7d4b8d01-da64-4d43-b8fc-6775dc375535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98607265-172.17.0.6-1598328353247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-5aa3e3b7-e078-4c2c-9958-d95b187a086c,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-869e7763-0db6-4685-8237-c28d5bf0c60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-71031023-b96c-4b8b-b2c9-e9cfd2a8f187,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c8237a41-03fd-4a30-bf4b-ec1568c14c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-d9d4fb5d-9db9-4784-957c-896b8db1f0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-44f0c0af-0ef4-4b3a-889a-e1a39ac9b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-1527817b-d1f2-471b-b75b-ef02ff596649,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4d594618-f61b-4414-8143-4b7f8009ac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98607265-172.17.0.6-1598328353247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-5aa3e3b7-e078-4c2c-9958-d95b187a086c,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-869e7763-0db6-4685-8237-c28d5bf0c60b,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-71031023-b96c-4b8b-b2c9-e9cfd2a8f187,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c8237a41-03fd-4a30-bf4b-ec1568c14c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-d9d4fb5d-9db9-4784-957c-896b8db1f0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-44f0c0af-0ef4-4b3a-889a-e1a39ac9b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-1527817b-d1f2-471b-b75b-ef02ff596649,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4d594618-f61b-4414-8143-4b7f8009ac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422246285-172.17.0.6-1598328677623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-7e699a23-52c3-4da3-8d81-400a05c0f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-1be3ff3f-adcd-4a95-8164-05a6d694d3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-5b2ff592-76e0-4381-8867-cefd2fd66659,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-d3205576-1214-4d60-8b77-7732bf03537a,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3c6c2da5-a7cf-4fc8-ae98-9cbc18917d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-454a41d7-4021-41e9-9530-7c18b90e0346,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-495a5a42-08aa-40fc-99bf-1021f566f922,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4893f75a-dfac-41ca-9c26-125c22cfaa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422246285-172.17.0.6-1598328677623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-7e699a23-52c3-4da3-8d81-400a05c0f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-1be3ff3f-adcd-4a95-8164-05a6d694d3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-5b2ff592-76e0-4381-8867-cefd2fd66659,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-d3205576-1214-4d60-8b77-7732bf03537a,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3c6c2da5-a7cf-4fc8-ae98-9cbc18917d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-454a41d7-4021-41e9-9530-7c18b90e0346,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-495a5a42-08aa-40fc-99bf-1021f566f922,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4893f75a-dfac-41ca-9c26-125c22cfaa60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846168511-172.17.0.6-1598328941907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45918,DS-0008001b-390a-44f6-995b-d262b26c7463,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-65b63b24-e210-44ba-aa2e-0eb179d84a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-1c5ce6ea-d863-4cc1-bcb2-3ddf8c878309,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-27ad3899-39f4-4348-9157-abf2a17ed1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-797d4027-a5dc-40e3-b42e-97e1972ed76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-ccb52d67-ceb9-4899-a1bc-fd420e357d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-21979599-c402-487b-8428-5300a2ec322f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-3723af79-58da-4a1c-8e32-ce1bb07cb5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1846168511-172.17.0.6-1598328941907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45918,DS-0008001b-390a-44f6-995b-d262b26c7463,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-65b63b24-e210-44ba-aa2e-0eb179d84a82,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-1c5ce6ea-d863-4cc1-bcb2-3ddf8c878309,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-27ad3899-39f4-4348-9157-abf2a17ed1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-797d4027-a5dc-40e3-b42e-97e1972ed76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-ccb52d67-ceb9-4899-a1bc-fd420e357d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-21979599-c402-487b-8428-5300a2ec322f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-3723af79-58da-4a1c-8e32-ce1bb07cb5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653376394-172.17.0.6-1598329012586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-a46379a0-c8af-4e98-a3d7-5a0bef0617a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-75edf664-5e31-4802-b577-b7ba0bd5a367,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-412dfc93-6f71-4ea6-b079-1392ccc892e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-d5273794-fe0a-4857-8c70-84e29f70e942,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-91ac45d5-ded9-49b1-bcb4-115a5eb9bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-3cc7304e-19ca-486f-b620-0c663af081de,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-8ff35801-78f1-4879-8211-ab0516be7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-fba18494-2fab-4eef-a645-6fc634f664c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653376394-172.17.0.6-1598329012586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-a46379a0-c8af-4e98-a3d7-5a0bef0617a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-75edf664-5e31-4802-b577-b7ba0bd5a367,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-412dfc93-6f71-4ea6-b079-1392ccc892e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-d5273794-fe0a-4857-8c70-84e29f70e942,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-91ac45d5-ded9-49b1-bcb4-115a5eb9bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-3cc7304e-19ca-486f-b620-0c663af081de,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-8ff35801-78f1-4879-8211-ab0516be7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-fba18494-2fab-4eef-a645-6fc634f664c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648213596-172.17.0.6-1598329073956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-c78076a9-795c-4c6b-84aa-e73db042e199,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-92f1c524-04f4-41f8-97c8-11f92880609c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-62618733-8d28-4935-9514-3d0384deeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-385142dc-5303-4bd2-99a5-8b2c38ccd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-bae9504b-da04-4c6a-807a-060c17ca62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-1a66e8a3-8449-49c2-b8ee-8a62d77b372e,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-66b31ffa-6872-499b-86db-e5e4da19875f,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-333e3d7c-ff64-45b7-b96b-ec89d0838b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648213596-172.17.0.6-1598329073956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-c78076a9-795c-4c6b-84aa-e73db042e199,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-92f1c524-04f4-41f8-97c8-11f92880609c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-62618733-8d28-4935-9514-3d0384deeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-385142dc-5303-4bd2-99a5-8b2c38ccd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-bae9504b-da04-4c6a-807a-060c17ca62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-1a66e8a3-8449-49c2-b8ee-8a62d77b372e,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-66b31ffa-6872-499b-86db-e5e4da19875f,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-333e3d7c-ff64-45b7-b96b-ec89d0838b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851989970-172.17.0.6-1598329992507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-4199331a-16cc-41fe-877f-be71874f42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-17f500d6-9119-4cee-b535-8ed1472dfa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-cded94b1-3931-4aae-9e75-6e77f9275ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-a876b205-6208-46cb-a974-6f04b2f84702,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-547a7118-3bbc-4493-9711-c5a194c09359,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-7d1f71a3-0eee-4a4c-8f80-ba18ef957d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b59d7031-dbcc-4593-a010-dd7f8495a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-1c78852f-3328-48c1-b2ad-4d73ec0565a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851989970-172.17.0.6-1598329992507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-4199331a-16cc-41fe-877f-be71874f42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-17f500d6-9119-4cee-b535-8ed1472dfa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-cded94b1-3931-4aae-9e75-6e77f9275ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-a876b205-6208-46cb-a974-6f04b2f84702,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-547a7118-3bbc-4493-9711-c5a194c09359,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-7d1f71a3-0eee-4a4c-8f80-ba18ef957d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b59d7031-dbcc-4593-a010-dd7f8495a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-1c78852f-3328-48c1-b2ad-4d73ec0565a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078571384-172.17.0.6-1598330238987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-25ff33e5-e8fe-4730-be47-93b44a7fb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-b2c13b73-ac7c-449c-a3ee-598f1ddd378f,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-4f211b22-f1cd-4040-86f8-9e8ec5b6e612,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a8cb63bd-6a72-43c1-9d3d-1aba194ac3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-caeedecc-c73e-40b4-b47e-ab704cafa426,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-0bf85937-db78-4db5-a0fb-eb8bbfe41c75,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-cfc7a562-8912-498b-8260-0ada0d889580,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-014834dd-cd0e-4b7b-bf48-1bb2b573c1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078571384-172.17.0.6-1598330238987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-25ff33e5-e8fe-4730-be47-93b44a7fb0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-b2c13b73-ac7c-449c-a3ee-598f1ddd378f,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-4f211b22-f1cd-4040-86f8-9e8ec5b6e612,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a8cb63bd-6a72-43c1-9d3d-1aba194ac3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-caeedecc-c73e-40b4-b47e-ab704cafa426,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-0bf85937-db78-4db5-a0fb-eb8bbfe41c75,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-cfc7a562-8912-498b-8260-0ada0d889580,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-014834dd-cd0e-4b7b-bf48-1bb2b573c1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280711699-172.17.0.6-1598330564319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-b4329d9f-e4e0-4caa-8e70-3c04d7e3fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-c5971d2b-b3c8-4221-8515-eac658cd64e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-d4b62c91-26f9-44ec-a3a2-31c80f316f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-35b5fa11-ed74-4569-84f7-16f91126d1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-b44cae0f-8b78-497c-988f-6f21a854d5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-50e6592e-7b11-432b-ad95-4fb967c296da,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-ddf1b26c-7c42-4093-9f73-759bddaac780,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-66fbb665-3a3c-4072-979c-39f2b01cc4f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280711699-172.17.0.6-1598330564319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-b4329d9f-e4e0-4caa-8e70-3c04d7e3fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-c5971d2b-b3c8-4221-8515-eac658cd64e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-d4b62c91-26f9-44ec-a3a2-31c80f316f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-35b5fa11-ed74-4569-84f7-16f91126d1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-b44cae0f-8b78-497c-988f-6f21a854d5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-50e6592e-7b11-432b-ad95-4fb967c296da,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-ddf1b26c-7c42-4093-9f73-759bddaac780,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-66fbb665-3a3c-4072-979c-39f2b01cc4f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5173
