reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421870852-172.17.0.4-1598469350191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-85402dd6-ed86-43b4-b60e-402bb33c5d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-db7e640b-5a36-477c-8ce5-810e792a6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-9611bc81-151a-48d1-80c4-dc241b40a93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-c4dec629-48a9-4d21-8858-211e3e66613d,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-18c26e7d-818d-4584-986e-ba8d0b35be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-a60a7a52-4719-4986-b616-586dbf711065,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-f73b3934-cbf1-46e7-b1d7-301e0da2f272,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-5a419d3c-8f05-4dce-8658-165047d20c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421870852-172.17.0.4-1598469350191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-85402dd6-ed86-43b4-b60e-402bb33c5d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-db7e640b-5a36-477c-8ce5-810e792a6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-9611bc81-151a-48d1-80c4-dc241b40a93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-c4dec629-48a9-4d21-8858-211e3e66613d,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-18c26e7d-818d-4584-986e-ba8d0b35be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-a60a7a52-4719-4986-b616-586dbf711065,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-f73b3934-cbf1-46e7-b1d7-301e0da2f272,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-5a419d3c-8f05-4dce-8658-165047d20c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354019346-172.17.0.4-1598469880619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-63b34059-268d-44d5-8192-9f431025e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-42aeb083-a55c-4a47-88f2-237660cf1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-a7cff2d3-619d-42b8-a6af-2b905e319587,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-73736a7d-4d50-4fe2-bbc9-12e7fd89a997,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-a7f332ba-57a2-4f92-835d-530ca7649db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6f78552e-6866-407f-b7b3-ff042c4f9f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-1d3bcd59-3f6e-487b-968c-522d237fbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-b90e1384-db6e-4257-a80a-1ba35b91f416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354019346-172.17.0.4-1598469880619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45138,DS-63b34059-268d-44d5-8192-9f431025e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-42aeb083-a55c-4a47-88f2-237660cf1b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-a7cff2d3-619d-42b8-a6af-2b905e319587,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-73736a7d-4d50-4fe2-bbc9-12e7fd89a997,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-a7f332ba-57a2-4f92-835d-530ca7649db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6f78552e-6866-407f-b7b3-ff042c4f9f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-1d3bcd59-3f6e-487b-968c-522d237fbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-b90e1384-db6e-4257-a80a-1ba35b91f416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149128868-172.17.0.4-1598470403644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36783,DS-9957bd38-ad1a-477f-9f59-dfe49594540c,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-b041a67e-3aac-4393-9d7b-1ec16de8437d,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-0e3fe320-0d44-4ede-a607-f4e802977add,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-5009b069-f18e-4ef4-9c40-7082f6872491,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-37279078-df6c-469f-9ee1-71fdd428efee,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-ac0236c1-25be-4532-9769-37027c728f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-577300ae-dad6-455f-acae-3bee311bacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-b5fe16b4-a006-4abf-b21f-57eeaf2d06a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149128868-172.17.0.4-1598470403644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36783,DS-9957bd38-ad1a-477f-9f59-dfe49594540c,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-b041a67e-3aac-4393-9d7b-1ec16de8437d,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-0e3fe320-0d44-4ede-a607-f4e802977add,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-5009b069-f18e-4ef4-9c40-7082f6872491,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-37279078-df6c-469f-9ee1-71fdd428efee,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-ac0236c1-25be-4532-9769-37027c728f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-577300ae-dad6-455f-acae-3bee311bacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-b5fe16b4-a006-4abf-b21f-57eeaf2d06a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704520888-172.17.0.4-1598470576155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-69629cb8-e1bb-448d-a01b-6e6186e92e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8054eb55-4b82-4913-9ac0-067a6cf1f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-74c80538-bba8-4d02-b024-d3a706df3658,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-33cf112c-da9f-400a-97d7-091e89d4ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-493ce858-3b0b-4bb8-a958-a594f91da81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-df24b59c-b350-42cd-ac37-46278a3fe5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-e9cefcad-d245-4e5e-a6b7-0818d2fe6b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ae6e53e4-a51f-4feb-a4a2-a5b40ba66bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704520888-172.17.0.4-1598470576155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-69629cb8-e1bb-448d-a01b-6e6186e92e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8054eb55-4b82-4913-9ac0-067a6cf1f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-74c80538-bba8-4d02-b024-d3a706df3658,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-33cf112c-da9f-400a-97d7-091e89d4ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-493ce858-3b0b-4bb8-a958-a594f91da81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-df24b59c-b350-42cd-ac37-46278a3fe5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-e9cefcad-d245-4e5e-a6b7-0818d2fe6b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ae6e53e4-a51f-4feb-a4a2-a5b40ba66bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704365719-172.17.0.4-1598471691923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f6d1487f-e753-465f-b720-fc5a0d39179a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-765709c3-6a24-4d92-a25b-77b087396af6,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a3c09594-3506-4fd3-bcbe-e980b7d89e58,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-f024386a-c55a-41ea-923a-9303a09ccee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-9fbca3f8-f9f6-4c27-9e3c-eb179a9bf72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-674bb743-774a-4a5f-b0b0-e9807ae54ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-0eca8503-0fb8-49db-90b3-3dda25c8ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-1dc74410-0b79-40d0-a74c-3177d9033927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704365719-172.17.0.4-1598471691923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f6d1487f-e753-465f-b720-fc5a0d39179a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-765709c3-6a24-4d92-a25b-77b087396af6,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a3c09594-3506-4fd3-bcbe-e980b7d89e58,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-f024386a-c55a-41ea-923a-9303a09ccee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-9fbca3f8-f9f6-4c27-9e3c-eb179a9bf72b,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-674bb743-774a-4a5f-b0b0-e9807ae54ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-0eca8503-0fb8-49db-90b3-3dda25c8ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-1dc74410-0b79-40d0-a74c-3177d9033927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533632685-172.17.0.4-1598471758572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-b32d2b0f-090b-4446-8d8b-229c287f2992,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-21049fda-af97-4a4e-addc-b60f1c7cf06a,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-1fc072f2-737c-4020-bc7e-c0a4ad94242e,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-4df206f3-b2c0-405b-88f1-49641bcc35f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-f1fa1e92-08a3-4e30-9f26-e3d8695e93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c28b11e1-c6bd-4403-9ba0-3b9a8e85ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-468dd4a9-8f44-4141-860d-203d3f610692,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-91faa79c-5905-4b41-8c32-752692af9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533632685-172.17.0.4-1598471758572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-b32d2b0f-090b-4446-8d8b-229c287f2992,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-21049fda-af97-4a4e-addc-b60f1c7cf06a,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-1fc072f2-737c-4020-bc7e-c0a4ad94242e,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-4df206f3-b2c0-405b-88f1-49641bcc35f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-f1fa1e92-08a3-4e30-9f26-e3d8695e93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c28b11e1-c6bd-4403-9ba0-3b9a8e85ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-468dd4a9-8f44-4141-860d-203d3f610692,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-91faa79c-5905-4b41-8c32-752692af9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747428846-172.17.0.4-1598472030108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-28aaf214-4b03-478e-a0c3-0643c2e56615,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-53c741ca-cdd8-4a96-82b2-cd46e0569fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f064c078-41e4-4bb0-a596-8e42ab52370a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-7255b1a0-c43d-4c29-9171-9c516369f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-32f2065d-5f5d-464f-8497-a912a5eee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-d02e4245-a289-42b6-acd0-fe39390906c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-9ba3ac20-5135-4f04-a94c-9b772d5a37f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-f3d923f1-2841-4442-b77e-6d07da5d1a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747428846-172.17.0.4-1598472030108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-28aaf214-4b03-478e-a0c3-0643c2e56615,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-53c741ca-cdd8-4a96-82b2-cd46e0569fba,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f064c078-41e4-4bb0-a596-8e42ab52370a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-7255b1a0-c43d-4c29-9171-9c516369f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-32f2065d-5f5d-464f-8497-a912a5eee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-d02e4245-a289-42b6-acd0-fe39390906c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-9ba3ac20-5135-4f04-a94c-9b772d5a37f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-f3d923f1-2841-4442-b77e-6d07da5d1a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555069940-172.17.0.4-1598472143046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-83f8b91a-1aec-47f7-bd99-592847a4a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-a91028ab-44b7-4754-8eee-403603dd14cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-f003c75e-c4cb-482a-b22f-b4077551da55,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-868cd801-ce22-4549-a772-b0de6259a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f7a1c039-6b0f-478f-8817-624e79d5c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-b946a39d-871e-44cb-bec5-2e325599f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-870b74a1-4ec1-4be4-b788-d146f95987d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-68137e20-9b23-40da-93b0-21686c7b8e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555069940-172.17.0.4-1598472143046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-83f8b91a-1aec-47f7-bd99-592847a4a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-a91028ab-44b7-4754-8eee-403603dd14cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-f003c75e-c4cb-482a-b22f-b4077551da55,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-868cd801-ce22-4549-a772-b0de6259a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f7a1c039-6b0f-478f-8817-624e79d5c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-b946a39d-871e-44cb-bec5-2e325599f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-870b74a1-4ec1-4be4-b788-d146f95987d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-68137e20-9b23-40da-93b0-21686c7b8e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211051942-172.17.0.4-1598472625417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-2fdb7c58-1e55-469c-9807-237e7a844d41,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-18cbafdd-2236-401a-a822-2ab56e4aa16b,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-2204bf08-827b-4848-a45c-b97b4d4251e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-e3fa8fa5-0874-46da-81d8-3eb4264ceeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fa9f7633-9f96-44f8-b081-298bedead793,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-86506ef5-0d4d-4da0-a4e4-d905a6b9ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-1543dd51-5d84-410c-8d9b-59516def6edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-3803f85a-5713-47b5-b70b-fece31d0e6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211051942-172.17.0.4-1598472625417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-2fdb7c58-1e55-469c-9807-237e7a844d41,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-18cbafdd-2236-401a-a822-2ab56e4aa16b,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-2204bf08-827b-4848-a45c-b97b4d4251e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-e3fa8fa5-0874-46da-81d8-3eb4264ceeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fa9f7633-9f96-44f8-b081-298bedead793,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-86506ef5-0d4d-4da0-a4e4-d905a6b9ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-1543dd51-5d84-410c-8d9b-59516def6edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-3803f85a-5713-47b5-b70b-fece31d0e6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282988410-172.17.0.4-1598472661008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-fdf03445-0a1f-44ce-a2e7-3909a2c3506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-6e80433a-bbe4-4501-9475-0420d54432c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b7d97945-ce8f-42f9-a02d-368af7c1ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-0728e6b0-ec27-456a-93f4-f94389eb9903,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-3d0f3ffd-accb-4565-955a-830f26f01045,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-90f09b04-bd04-4623-9fc3-3a732c35a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-2ddd4852-2dcb-498e-8baa-51304ac9a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-c05300a0-cb18-4edd-810a-ecd4e3f71f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282988410-172.17.0.4-1598472661008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-fdf03445-0a1f-44ce-a2e7-3909a2c3506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-6e80433a-bbe4-4501-9475-0420d54432c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b7d97945-ce8f-42f9-a02d-368af7c1ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-0728e6b0-ec27-456a-93f4-f94389eb9903,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-3d0f3ffd-accb-4565-955a-830f26f01045,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-90f09b04-bd04-4623-9fc3-3a732c35a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-2ddd4852-2dcb-498e-8baa-51304ac9a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-c05300a0-cb18-4edd-810a-ecd4e3f71f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283816129-172.17.0.4-1598472728626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-bfea9cd7-63b5-46e2-a54e-6801178fd9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-22e5e1ff-9207-4ac4-91f6-16ff85b4ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-81167822-e0d4-4f2d-86e1-af31ba436536,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-e495a62d-3c5e-4f6f-b6d2-5355acb2c188,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-cbdfe985-0968-4cd9-b713-e025d57b65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-ec6b50ba-9383-49db-861e-26ce52d8fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-dedb9760-528c-455c-9650-ad4ca1df1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-23fa6a71-cc82-41d8-8061-58983144480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283816129-172.17.0.4-1598472728626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-bfea9cd7-63b5-46e2-a54e-6801178fd9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-22e5e1ff-9207-4ac4-91f6-16ff85b4ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-81167822-e0d4-4f2d-86e1-af31ba436536,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-e495a62d-3c5e-4f6f-b6d2-5355acb2c188,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-cbdfe985-0968-4cd9-b713-e025d57b65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-ec6b50ba-9383-49db-861e-26ce52d8fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-dedb9760-528c-455c-9650-ad4ca1df1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-23fa6a71-cc82-41d8-8061-58983144480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386067826-172.17.0.4-1598472793442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-64ccbe09-7d67-4368-adff-d504223646e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-3401ab04-6100-4834-bfab-61271a4da83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-9ee5c9b7-398a-4b26-8f45-c5c73062a457,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-32e6d982-f2a6-4ba8-96c3-caef691a69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-c19b2201-f716-498d-a5a5-b7bf12936e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-57e9de72-f273-49dd-b060-c845c1f8e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-8f32f9ea-f46b-41e2-8044-c8ae25050041,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-c893bb60-c73c-49a4-a308-c81faad72305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386067826-172.17.0.4-1598472793442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-64ccbe09-7d67-4368-adff-d504223646e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-3401ab04-6100-4834-bfab-61271a4da83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-9ee5c9b7-398a-4b26-8f45-c5c73062a457,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-32e6d982-f2a6-4ba8-96c3-caef691a69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-c19b2201-f716-498d-a5a5-b7bf12936e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-57e9de72-f273-49dd-b060-c845c1f8e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-8f32f9ea-f46b-41e2-8044-c8ae25050041,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-c893bb60-c73c-49a4-a308-c81faad72305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52562105-172.17.0.4-1598473091978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-d0b6fc88-a2da-49fc-a02e-705def158ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-9c150428-abbd-44a6-85c4-c484d73fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-53ad946e-d73e-488d-98a7-c06789d0c1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c3db12cf-3cd5-4aeb-93a5-f7dd024bf101,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-f43c76a3-81be-42e7-acae-1c193096c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-0d757d67-0a18-4516-9d31-2de548d1338d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e0ce10e3-1db5-4d4b-a42f-a3d3d48337d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-73d8ad2a-58ff-40e6-afe5-2dc819fd6f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52562105-172.17.0.4-1598473091978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-d0b6fc88-a2da-49fc-a02e-705def158ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-9c150428-abbd-44a6-85c4-c484d73fed77,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-53ad946e-d73e-488d-98a7-c06789d0c1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c3db12cf-3cd5-4aeb-93a5-f7dd024bf101,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-f43c76a3-81be-42e7-acae-1c193096c9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-0d757d67-0a18-4516-9d31-2de548d1338d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e0ce10e3-1db5-4d4b-a42f-a3d3d48337d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-73d8ad2a-58ff-40e6-afe5-2dc819fd6f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699930670-172.17.0.4-1598473328362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42015,DS-6a9a1413-d4bb-4b17-8ea3-3d588e1ad628,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-232740cf-05ea-4010-a5ef-77d5fd7f48a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c7bc63d2-678f-4f79-be3e-2491d0e50f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-3b850f46-cdb5-49b6-9bc9-d0b3d064c022,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-70a9150d-53f7-4bb0-8962-dfdf4b784ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-275c7ae7-82a7-4c2d-aec3-dd1e5f61e4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-daac21a8-dd25-4f81-afea-ea9c2acde975,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-d61abef0-47d9-44eb-a1a1-ab37815b59ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699930670-172.17.0.4-1598473328362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42015,DS-6a9a1413-d4bb-4b17-8ea3-3d588e1ad628,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-232740cf-05ea-4010-a5ef-77d5fd7f48a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c7bc63d2-678f-4f79-be3e-2491d0e50f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-3b850f46-cdb5-49b6-9bc9-d0b3d064c022,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-70a9150d-53f7-4bb0-8962-dfdf4b784ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-275c7ae7-82a7-4c2d-aec3-dd1e5f61e4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-daac21a8-dd25-4f81-afea-ea9c2acde975,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-d61abef0-47d9-44eb-a1a1-ab37815b59ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371543537-172.17.0.4-1598473361602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-2026d28b-018a-4e4e-bbc9-285dc77c711c,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-b92daf23-896f-4f63-80cb-eeb5cd9dfd58,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a8edf84b-e527-4dfb-be42-80c078faeda7,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-cdc80e23-7d64-4ebd-aaa0-c318b5c68c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-443bcff4-a108-44ad-98d6-19d7e0378e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-64691ae2-7e24-4010-9eb1-28730079307c,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-3402c44d-4626-4e1a-a33c-e2c571fb1ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-cfb8c3d9-c7e2-4a55-885a-e70027f875bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371543537-172.17.0.4-1598473361602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45490,DS-2026d28b-018a-4e4e-bbc9-285dc77c711c,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-b92daf23-896f-4f63-80cb-eeb5cd9dfd58,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a8edf84b-e527-4dfb-be42-80c078faeda7,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-cdc80e23-7d64-4ebd-aaa0-c318b5c68c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-443bcff4-a108-44ad-98d6-19d7e0378e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-64691ae2-7e24-4010-9eb1-28730079307c,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-3402c44d-4626-4e1a-a33c-e2c571fb1ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-cfb8c3d9-c7e2-4a55-885a-e70027f875bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122286783-172.17.0.4-1598473540282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-cd8cc311-d0ad-4e81-b0b6-3eb6c01a3542,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6d1cbcf2-1099-4265-b1b7-649d5dcc89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-41868643-5620-4e8e-87ea-6889fbe3b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-d1fdcbd5-6574-41dd-9c53-ba993bdab0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a11472cb-17e5-48d6-89e0-bf6d450d9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-180928a6-13d7-4c6b-af07-e6706061bd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-925f45fc-a40f-4613-a1e2-c4d0b9d8f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-a0e11c62-987a-4b00-ac13-6c0bcb20d10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122286783-172.17.0.4-1598473540282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-cd8cc311-d0ad-4e81-b0b6-3eb6c01a3542,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6d1cbcf2-1099-4265-b1b7-649d5dcc89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-41868643-5620-4e8e-87ea-6889fbe3b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-d1fdcbd5-6574-41dd-9c53-ba993bdab0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-a11472cb-17e5-48d6-89e0-bf6d450d9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-180928a6-13d7-4c6b-af07-e6706061bd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-925f45fc-a40f-4613-a1e2-c4d0b9d8f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-a0e11c62-987a-4b00-ac13-6c0bcb20d10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142617937-172.17.0.4-1598473769715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-95a30681-bac6-4bde-8ded-d3c258a11ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-5895831f-8a70-47a8-bbcd-726d5aa831db,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-33b8908c-41fa-4e4d-a16e-029c20d24552,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-67cbe6cf-d96c-40ae-847f-18db61d0bb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c80c8c51-e625-4ba8-96cb-1a8002380e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-84f60fa9-3e6b-4628-b136-0b580f2742ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b211775c-5596-4e84-a95e-2f174b9fd6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-bd0d8d14-6b79-4d5a-ba5a-d2457f9a287a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142617937-172.17.0.4-1598473769715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-95a30681-bac6-4bde-8ded-d3c258a11ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-5895831f-8a70-47a8-bbcd-726d5aa831db,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-33b8908c-41fa-4e4d-a16e-029c20d24552,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-67cbe6cf-d96c-40ae-847f-18db61d0bb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c80c8c51-e625-4ba8-96cb-1a8002380e65,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-84f60fa9-3e6b-4628-b136-0b580f2742ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b211775c-5596-4e84-a95e-2f174b9fd6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-bd0d8d14-6b79-4d5a-ba5a-d2457f9a287a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864175490-172.17.0.4-1598473870047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-97ef59c1-d735-478c-a46e-4e1e6b2670ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-1ccb4e9e-cb2d-4d53-90e0-685f91bace1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-8fbb8a7e-33b3-4da3-9ae1-491c106ca745,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-f459e529-3e3d-4403-a346-3525b84afd36,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-75364bf8-e461-483a-ae4e-942155c39f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-fa8820cd-e6b6-49c2-9530-7682d81769dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-3464d25e-52c3-44ff-99de-7effc157eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-693f0545-8a09-4b6a-b901-fd03c3880e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864175490-172.17.0.4-1598473870047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-97ef59c1-d735-478c-a46e-4e1e6b2670ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-1ccb4e9e-cb2d-4d53-90e0-685f91bace1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-8fbb8a7e-33b3-4da3-9ae1-491c106ca745,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-f459e529-3e3d-4403-a346-3525b84afd36,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-75364bf8-e461-483a-ae4e-942155c39f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-fa8820cd-e6b6-49c2-9530-7682d81769dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-3464d25e-52c3-44ff-99de-7effc157eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-693f0545-8a09-4b6a-b901-fd03c3880e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456421374-172.17.0.4-1598474027215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-058c6a28-31e7-47f1-a056-7a39e36478b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-6a6e99a7-c91b-4e40-891f-6817d82db723,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-3986bfce-f475-4de4-aa49-35832b57814b,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-efabf0eb-d9c8-4ffa-928c-3c4171e964df,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-1214055a-d9b4-4ced-90d4-12b2c75d28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e7c1b3be-571b-49b2-92ae-94fb7354f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-97fe63b0-b7f4-4fc4-9575-1aa0a3bd15a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-ef6b3efb-736b-4c60-b431-6644174a32b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456421374-172.17.0.4-1598474027215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-058c6a28-31e7-47f1-a056-7a39e36478b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-6a6e99a7-c91b-4e40-891f-6817d82db723,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-3986bfce-f475-4de4-aa49-35832b57814b,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-efabf0eb-d9c8-4ffa-928c-3c4171e964df,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-1214055a-d9b4-4ced-90d4-12b2c75d28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e7c1b3be-571b-49b2-92ae-94fb7354f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-97fe63b0-b7f4-4fc4-9575-1aa0a3bd15a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-ef6b3efb-736b-4c60-b431-6644174a32b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522721590-172.17.0.4-1598474202890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-93f17ca1-7c56-43f8-952c-760f4a5e291a,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-16bf9f24-b8b6-49c4-9aa8-e6983687faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-2872e11f-9786-4b5a-ba27-e6550d4d6810,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-25816b73-e968-4e56-9659-d840c3225106,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-08601d7e-6fea-4880-a182-0e015ea286c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-3d10a685-8217-42f0-9f2d-a6779a80a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-aa0d4f72-f97d-4fa9-8174-b254ae4e37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-a17fa997-ff7d-4c09-bdd3-e89decb33aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522721590-172.17.0.4-1598474202890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-93f17ca1-7c56-43f8-952c-760f4a5e291a,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-16bf9f24-b8b6-49c4-9aa8-e6983687faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-2872e11f-9786-4b5a-ba27-e6550d4d6810,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-25816b73-e968-4e56-9659-d840c3225106,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-08601d7e-6fea-4880-a182-0e015ea286c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-3d10a685-8217-42f0-9f2d-a6779a80a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-aa0d4f72-f97d-4fa9-8174-b254ae4e37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-a17fa997-ff7d-4c09-bdd3-e89decb33aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4960
