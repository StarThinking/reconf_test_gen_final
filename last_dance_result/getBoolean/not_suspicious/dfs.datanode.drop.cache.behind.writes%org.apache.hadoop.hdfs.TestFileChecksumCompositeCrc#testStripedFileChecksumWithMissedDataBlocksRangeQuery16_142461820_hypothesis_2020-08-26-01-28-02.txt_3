reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114953018-172.17.0.12-1598405434970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46497,DS-92ac9c20-1d7b-4fa2-9fe7-b7a8a231190e,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-a897f165-b8e1-4f72-9f7a-2d1647e9eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-90b9086f-6707-466b-bc43-ba7a4566acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-6f291ed9-cbee-4e45-ba65-6adf3215c204,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f2a6dbd8-b224-45a6-97fd-17f6431f38f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-f7af8770-1d76-47c9-9001-9c2f15272613,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fce2d92c-3dc9-4469-93e4-c58e1d11b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-4979abd6-f38a-45f1-8f41-4fce048f994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114953018-172.17.0.12-1598405434970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46497,DS-92ac9c20-1d7b-4fa2-9fe7-b7a8a231190e,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-a897f165-b8e1-4f72-9f7a-2d1647e9eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-90b9086f-6707-466b-bc43-ba7a4566acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-6f291ed9-cbee-4e45-ba65-6adf3215c204,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f2a6dbd8-b224-45a6-97fd-17f6431f38f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-f7af8770-1d76-47c9-9001-9c2f15272613,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fce2d92c-3dc9-4469-93e4-c58e1d11b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-4979abd6-f38a-45f1-8f41-4fce048f994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891103364-172.17.0.12-1598405670739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-139156b8-9ecf-4b89-ae05-a2ff39f325f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-52131a6a-e4de-4a28-8d69-c643fac9c980,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-79edf3f3-ca37-4807-8114-a5cc3c4bc651,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-8ca182d6-167f-438b-877d-3bf168731816,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-5f199b5c-58dc-42e2-a225-10d72ed53fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-0e00c3b6-a774-4a97-b2ec-9cdef3d5d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-0d8f4a09-096d-48da-99f2-4eec242bc927,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-fae742a8-547f-4011-8817-9ee142c8b402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891103364-172.17.0.12-1598405670739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-139156b8-9ecf-4b89-ae05-a2ff39f325f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-52131a6a-e4de-4a28-8d69-c643fac9c980,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-79edf3f3-ca37-4807-8114-a5cc3c4bc651,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-8ca182d6-167f-438b-877d-3bf168731816,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-5f199b5c-58dc-42e2-a225-10d72ed53fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-0e00c3b6-a774-4a97-b2ec-9cdef3d5d26a,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-0d8f4a09-096d-48da-99f2-4eec242bc927,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-fae742a8-547f-4011-8817-9ee142c8b402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794673063-172.17.0.12-1598405735493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-5b01e25d-e760-406b-9065-0114360f2698,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-fd025222-0604-46f2-9bdc-6bfcf0688a61,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-a22184fe-7577-4763-9595-f5aff0c1c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-d97da64c-bb52-402a-bb6d-8fa43991e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-c8abe4c7-1a02-4c12-af6d-788c36fe6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-ce58953d-28ab-4e22-a345-71d231ac0220,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-de1ca1e0-83bd-480f-b3b0-4f24cb3fa720,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-1bb0a354-0039-47fc-9344-1d4ad9c0538e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794673063-172.17.0.12-1598405735493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-5b01e25d-e760-406b-9065-0114360f2698,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-fd025222-0604-46f2-9bdc-6bfcf0688a61,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-a22184fe-7577-4763-9595-f5aff0c1c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-d97da64c-bb52-402a-bb6d-8fa43991e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-c8abe4c7-1a02-4c12-af6d-788c36fe6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-ce58953d-28ab-4e22-a345-71d231ac0220,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-de1ca1e0-83bd-480f-b3b0-4f24cb3fa720,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-1bb0a354-0039-47fc-9344-1d4ad9c0538e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86273819-172.17.0.12-1598406255810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-1bb217db-3b93-43bc-9ef2-4f7763b88bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-49cc4193-c651-458f-8df3-40f55b4e08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-a1c8bd61-d290-4463-8b2e-04ceeec09e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-9ed73215-24af-4f4a-89ec-096a248b1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-1dbf442f-44e7-4c15-97f9-112fa370bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-e3aefb75-364b-4349-9b22-744b55044eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-63c7fac2-4d63-45c2-8cc1-0f03d750ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-81c9aec1-95ee-4a1b-aa3f-66846a31a078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86273819-172.17.0.12-1598406255810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-1bb217db-3b93-43bc-9ef2-4f7763b88bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-49cc4193-c651-458f-8df3-40f55b4e08ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-a1c8bd61-d290-4463-8b2e-04ceeec09e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-9ed73215-24af-4f4a-89ec-096a248b1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-1dbf442f-44e7-4c15-97f9-112fa370bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-e3aefb75-364b-4349-9b22-744b55044eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-63c7fac2-4d63-45c2-8cc1-0f03d750ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-81c9aec1-95ee-4a1b-aa3f-66846a31a078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533462573-172.17.0.12-1598406784446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-36981f46-10cb-468c-916c-277c8ef6bece,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-f20439a5-104a-42c2-a447-ebebd68845dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-ecf11bab-02a0-49d4-b4e2-f49e3f7668cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d548f069-850a-4076-8283-44b09a29e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-30c12dd2-2fb1-4025-b5aa-b2c51a33ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-8771cb8b-8c30-4db1-9694-7894c2195757,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-6b379121-0360-4ce6-aea4-3a47dbec318d,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e286430b-3163-46e7-8442-e1af90ee8d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533462573-172.17.0.12-1598406784446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35284,DS-36981f46-10cb-468c-916c-277c8ef6bece,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-f20439a5-104a-42c2-a447-ebebd68845dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-ecf11bab-02a0-49d4-b4e2-f49e3f7668cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d548f069-850a-4076-8283-44b09a29e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-30c12dd2-2fb1-4025-b5aa-b2c51a33ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-8771cb8b-8c30-4db1-9694-7894c2195757,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-6b379121-0360-4ce6-aea4-3a47dbec318d,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e286430b-3163-46e7-8442-e1af90ee8d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750706560-172.17.0.12-1598406939185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-e2d1b7c6-b76f-4b98-9fce-b10fcf535824,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a0cc9ccd-51d0-4475-9124-3b40636c77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-9735a091-14ac-47d7-a81a-e4bdffb85901,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-8b6fdb86-0c68-4beb-bcaf-db97fd4804d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-be58326f-53d0-43ee-b671-8e91d5430916,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-9be4b67a-19a9-4b8c-a420-461bd4a6b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-516fa5b1-433a-4ec0-a985-5bcd3f153e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-af0fc52f-29d7-4abc-8a7a-b1d0c172f7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750706560-172.17.0.12-1598406939185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-e2d1b7c6-b76f-4b98-9fce-b10fcf535824,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a0cc9ccd-51d0-4475-9124-3b40636c77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-9735a091-14ac-47d7-a81a-e4bdffb85901,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-8b6fdb86-0c68-4beb-bcaf-db97fd4804d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-be58326f-53d0-43ee-b671-8e91d5430916,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-9be4b67a-19a9-4b8c-a420-461bd4a6b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-516fa5b1-433a-4ec0-a985-5bcd3f153e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-af0fc52f-29d7-4abc-8a7a-b1d0c172f7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084028605-172.17.0.12-1598407011331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33282,DS-58289777-8d47-4508-ba78-123dced2edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a7072c5d-c7f1-4bbc-82ec-5227174b7932,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b4364195-5790-4f96-95ea-1444ab4eb392,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-cb535d61-8ef8-4ca7-bd86-b87ec03994d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-c3c3af46-bb09-4f95-9aed-d64b7bc76f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6b021516-6956-4907-a494-54e8cbb35ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-4c50fa11-49ae-4dd2-b431-827ee41cc2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7f3d1eb5-144b-44e6-a33d-e437e5021536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084028605-172.17.0.12-1598407011331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33282,DS-58289777-8d47-4508-ba78-123dced2edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a7072c5d-c7f1-4bbc-82ec-5227174b7932,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b4364195-5790-4f96-95ea-1444ab4eb392,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-cb535d61-8ef8-4ca7-bd86-b87ec03994d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-c3c3af46-bb09-4f95-9aed-d64b7bc76f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6b021516-6956-4907-a494-54e8cbb35ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-4c50fa11-49ae-4dd2-b431-827ee41cc2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7f3d1eb5-144b-44e6-a33d-e437e5021536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767681438-172.17.0.12-1598407353326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-ed938339-fdd4-47d5-a9d9-4fc395be1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-ac89fe58-1080-4a2a-8306-6255ffd6ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-da73e756-c01f-415e-82ef-ebd8609f5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-443599bc-b460-429d-b791-3b0d8934ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-fe121834-e751-4dd0-b041-0054f46ab336,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-3962ad9a-801a-443f-af85-edcddef54273,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-85cfdaad-784e-4db9-8b8b-20a8cdb8a500,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-76c4e323-42ea-4605-94ab-4a5d4bcfa3ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767681438-172.17.0.12-1598407353326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-ed938339-fdd4-47d5-a9d9-4fc395be1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-ac89fe58-1080-4a2a-8306-6255ffd6ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-da73e756-c01f-415e-82ef-ebd8609f5c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-443599bc-b460-429d-b791-3b0d8934ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-fe121834-e751-4dd0-b041-0054f46ab336,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-3962ad9a-801a-443f-af85-edcddef54273,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-85cfdaad-784e-4db9-8b8b-20a8cdb8a500,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-76c4e323-42ea-4605-94ab-4a5d4bcfa3ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839486964-172.17.0.12-1598407525194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-59195688-c2a9-4676-bbdf-d73eaae2e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b673b2bb-9a22-495b-a3ef-136b6d23f232,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-226e37ab-5f9e-4962-a020-8af68703fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-4112b642-c421-4c7a-8c85-104a659a9314,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-acffadf3-6a70-42fa-a210-31c3c0d5306d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-668a9158-45eb-4ada-9843-b35bd48ef3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-dac88c38-4347-44b4-ba28-4537450186ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-ff343c5c-109f-4756-8b14-74c4e29ebcc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839486964-172.17.0.12-1598407525194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-59195688-c2a9-4676-bbdf-d73eaae2e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b673b2bb-9a22-495b-a3ef-136b6d23f232,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-226e37ab-5f9e-4962-a020-8af68703fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-4112b642-c421-4c7a-8c85-104a659a9314,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-acffadf3-6a70-42fa-a210-31c3c0d5306d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-668a9158-45eb-4ada-9843-b35bd48ef3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-dac88c38-4347-44b4-ba28-4537450186ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-ff343c5c-109f-4756-8b14-74c4e29ebcc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205573290-172.17.0.12-1598407669538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-6d4c3617-8317-485c-b826-2b34e024b545,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-fd494793-160f-45ae-8af8-0055037f70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-48a8b77f-b1b1-4e58-a8a8-f0a8a8544e70,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-16d5a052-6978-4cc6-8e61-e712ecf5738d,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f06d8db0-9fe2-4c60-a71f-d6d4a24f75ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-018091a1-ac59-4901-a998-f3eaf0df0ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-d3d042fd-e4bd-458a-a9db-98d8914ce321,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-a41dd6a7-acc9-4dfe-8ca8-06478b3cacb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205573290-172.17.0.12-1598407669538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-6d4c3617-8317-485c-b826-2b34e024b545,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-fd494793-160f-45ae-8af8-0055037f70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-48a8b77f-b1b1-4e58-a8a8-f0a8a8544e70,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-16d5a052-6978-4cc6-8e61-e712ecf5738d,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-f06d8db0-9fe2-4c60-a71f-d6d4a24f75ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-018091a1-ac59-4901-a998-f3eaf0df0ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-d3d042fd-e4bd-458a-a9db-98d8914ce321,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-a41dd6a7-acc9-4dfe-8ca8-06478b3cacb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097022453-172.17.0.12-1598408049557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-10e72a47-bf77-41a5-8e97-d0b00165acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-eb2c726a-d721-4564-8855-8e19d2459642,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-3825cd6e-dd87-40ad-b135-2f7eb1499d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-7d1bcb15-0506-4aeb-9347-c22c0f83f17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-1b46ee5b-5310-4eab-8797-c784c7bc656a,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-28680705-4b8c-4df8-b7cc-53d52c835a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-2f6a50e3-5475-4dc7-8a5f-a724408f2183,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-0dc95a2e-94f8-4ec8-86a9-3d9a8ef9f1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097022453-172.17.0.12-1598408049557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-10e72a47-bf77-41a5-8e97-d0b00165acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-eb2c726a-d721-4564-8855-8e19d2459642,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-3825cd6e-dd87-40ad-b135-2f7eb1499d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-7d1bcb15-0506-4aeb-9347-c22c0f83f17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-1b46ee5b-5310-4eab-8797-c784c7bc656a,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-28680705-4b8c-4df8-b7cc-53d52c835a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-2f6a50e3-5475-4dc7-8a5f-a724408f2183,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-0dc95a2e-94f8-4ec8-86a9-3d9a8ef9f1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499156889-172.17.0.12-1598408147810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-774ed79a-6a4a-4c64-976d-d0f64b2dddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-882c7dd5-a741-46aa-bcc3-bb07c474ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-3164c607-c7d4-450f-8f3e-1eaf0bdce7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-516e2937-411e-41c6-a634-4a417a561a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-a89e21f9-9f6f-4b59-abe4-9d0a43301d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-55040ded-177e-48b1-a1ef-73aae50179c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-0b912385-851b-4e5b-b4a2-f842ce9b9ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-97191180-e1bf-4272-9523-cc6d28edd16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499156889-172.17.0.12-1598408147810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-774ed79a-6a4a-4c64-976d-d0f64b2dddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-882c7dd5-a741-46aa-bcc3-bb07c474ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-3164c607-c7d4-450f-8f3e-1eaf0bdce7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-516e2937-411e-41c6-a634-4a417a561a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-a89e21f9-9f6f-4b59-abe4-9d0a43301d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-55040ded-177e-48b1-a1ef-73aae50179c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-0b912385-851b-4e5b-b4a2-f842ce9b9ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-97191180-e1bf-4272-9523-cc6d28edd16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802537285-172.17.0.12-1598408479692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-e88002f2-594d-4c08-a1dc-e1892e9ce450,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-931caf6d-b295-4926-9e05-f661690f68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-918526d2-a16d-4240-b51e-9d5abefcf713,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-7c953464-2149-4005-b421-8ceca8c5ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19294945-9bcd-48db-8439-019485e6a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-2c3ff127-1cd0-4140-a983-94b0e90b1e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-6108543b-6f39-4850-b732-a5750e2d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-955df076-4311-4c0f-8d96-a560342834a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802537285-172.17.0.12-1598408479692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-e88002f2-594d-4c08-a1dc-e1892e9ce450,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-931caf6d-b295-4926-9e05-f661690f68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-918526d2-a16d-4240-b51e-9d5abefcf713,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-7c953464-2149-4005-b421-8ceca8c5ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19294945-9bcd-48db-8439-019485e6a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-2c3ff127-1cd0-4140-a983-94b0e90b1e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-6108543b-6f39-4850-b732-a5750e2d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-955df076-4311-4c0f-8d96-a560342834a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665438282-172.17.0.12-1598408857781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-138b9ab9-ba1a-4df7-9de8-b8c593b95eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-cf63cd35-9e24-46ec-96e4-036f7e204665,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e732995b-8687-4e8f-82c5-6c5f67f99c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-103c337e-5845-48dd-a760-aeb39582c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-08df0b2f-f469-46fd-b77b-78bd986997c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-ad03b2f8-b869-4555-9c40-63bea835b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-33f59ffa-b532-45b9-a2a5-c3620548da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-841130e4-d35d-4489-9d5b-b660072aa1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665438282-172.17.0.12-1598408857781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-138b9ab9-ba1a-4df7-9de8-b8c593b95eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-cf63cd35-9e24-46ec-96e4-036f7e204665,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-e732995b-8687-4e8f-82c5-6c5f67f99c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-103c337e-5845-48dd-a760-aeb39582c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-08df0b2f-f469-46fd-b77b-78bd986997c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-ad03b2f8-b869-4555-9c40-63bea835b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-33f59ffa-b532-45b9-a2a5-c3620548da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-841130e4-d35d-4489-9d5b-b660072aa1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689702124-172.17.0.12-1598409166619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-b0569140-3bbb-4226-b6bf-24ce59743f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-be337a24-8c9d-410f-9003-d52402c5ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-4b0f6d0f-225b-4016-9c92-b1bf4616db62,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-0641faa5-8dfd-499c-a173-5a049a1eaa29,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-4ca34d6b-3d12-4ea2-9e7c-9a23c002d937,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-7fa12e86-928a-495f-9216-55ba59d46f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-e3eddd6d-3f66-41b8-85d6-d2477ced84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-1d85aa80-c036-44e2-ac1d-99de190bebf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689702124-172.17.0.12-1598409166619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39120,DS-b0569140-3bbb-4226-b6bf-24ce59743f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-be337a24-8c9d-410f-9003-d52402c5ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-4b0f6d0f-225b-4016-9c92-b1bf4616db62,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-0641faa5-8dfd-499c-a173-5a049a1eaa29,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-4ca34d6b-3d12-4ea2-9e7c-9a23c002d937,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-7fa12e86-928a-495f-9216-55ba59d46f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-e3eddd6d-3f66-41b8-85d6-d2477ced84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-1d85aa80-c036-44e2-ac1d-99de190bebf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958396459-172.17.0.12-1598409305100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-dba014d8-3b69-4767-8da9-32fc817a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-76bd002f-d0a5-4dee-8711-30c271ef3880,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-0565dd4f-22cd-4ddb-85b4-ea86dea7ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-89a83acd-63d5-4f25-9bca-6437e7752757,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-6db27cf4-c184-4922-9d20-bcdde0579b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-92ab669d-8e49-42e7-9032-928a123b5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-acca5c59-8474-4587-8eb3-ae0ca82cc76a,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-6b6f7cf8-aa31-4394-be71-4eafdc157c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958396459-172.17.0.12-1598409305100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-dba014d8-3b69-4767-8da9-32fc817a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-76bd002f-d0a5-4dee-8711-30c271ef3880,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-0565dd4f-22cd-4ddb-85b4-ea86dea7ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-89a83acd-63d5-4f25-9bca-6437e7752757,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-6db27cf4-c184-4922-9d20-bcdde0579b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-92ab669d-8e49-42e7-9032-928a123b5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-acca5c59-8474-4587-8eb3-ae0ca82cc76a,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-6b6f7cf8-aa31-4394-be71-4eafdc157c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789007476-172.17.0.12-1598409827943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35592,DS-6f34fa94-2ece-4232-a209-871b25207d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-7dc1abbd-c369-4b71-8d24-6b0d72c6b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ef80d4e5-0a30-424e-93f7-546403261e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-58d21771-9026-4932-9189-410412002bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-e1291d24-b095-43a3-a2d4-cd3f1cdbb42e,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-27706f1c-6375-4a3a-b822-89efdcba68ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-0dc13c05-e95b-4155-8cd8-c1026f241d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-bc098cb1-a5dd-443c-926c-e15c9fb85970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789007476-172.17.0.12-1598409827943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35592,DS-6f34fa94-2ece-4232-a209-871b25207d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-7dc1abbd-c369-4b71-8d24-6b0d72c6b77c,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ef80d4e5-0a30-424e-93f7-546403261e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-58d21771-9026-4932-9189-410412002bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-e1291d24-b095-43a3-a2d4-cd3f1cdbb42e,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-27706f1c-6375-4a3a-b822-89efdcba68ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-0dc13c05-e95b-4155-8cd8-c1026f241d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-bc098cb1-a5dd-443c-926c-e15c9fb85970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633700907-172.17.0.12-1598409930034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-e5ccaedf-f5d3-42d3-b1eb-d2be8fba72e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5d1e6d15-8953-4ef7-88e8-a91b17e69f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-988dd4c1-7184-43d1-a8b5-cd6b3fd556af,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-89e81eae-d6b6-4dc4-9626-3f0e72fc082e,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-ed07eec8-4671-42e1-809c-b21cf9da3567,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-2109cf12-d1c6-4c9c-9c07-94864614fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-794ad406-94d1-46de-b719-8ad8ca81c166,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-da3e80ee-386e-4e65-89b1-14bc7e63fed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633700907-172.17.0.12-1598409930034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-e5ccaedf-f5d3-42d3-b1eb-d2be8fba72e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5d1e6d15-8953-4ef7-88e8-a91b17e69f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-988dd4c1-7184-43d1-a8b5-cd6b3fd556af,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-89e81eae-d6b6-4dc4-9626-3f0e72fc082e,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-ed07eec8-4671-42e1-809c-b21cf9da3567,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-2109cf12-d1c6-4c9c-9c07-94864614fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-794ad406-94d1-46de-b719-8ad8ca81c166,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-da3e80ee-386e-4e65-89b1-14bc7e63fed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351227653-172.17.0.12-1598409959326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-984c7646-7c55-477e-b291-2f0cd7a68cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-9c274369-d327-419f-84d5-d335a0ad1ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-22ff1de2-a91d-43a7-b631-c7de69110c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0c8c6809-cab9-4f15-97c6-956c1db72be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-c5420786-918d-4582-80dd-1537a30844e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-e4194d93-b410-4502-9946-82f2718c067c,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-8f8ef622-eaab-407b-a459-df8044fceec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9c39ab1d-4ddf-428b-a57e-09286461eed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351227653-172.17.0.12-1598409959326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-984c7646-7c55-477e-b291-2f0cd7a68cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-9c274369-d327-419f-84d5-d335a0ad1ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-22ff1de2-a91d-43a7-b631-c7de69110c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-0c8c6809-cab9-4f15-97c6-956c1db72be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-c5420786-918d-4582-80dd-1537a30844e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-e4194d93-b410-4502-9946-82f2718c067c,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-8f8ef622-eaab-407b-a459-df8044fceec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-9c39ab1d-4ddf-428b-a57e-09286461eed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464955486-172.17.0.12-1598410060121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-a315f960-05ef-4892-a8b4-eab4b2a2eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1a7a5ff8-2222-4734-af3f-7c4d16aca6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9efff867-b8fb-405f-8b88-6a2304daea82,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-d5965a00-ee3c-4a6e-880a-0d3f94f0f698,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-b8682e7b-b240-4419-9a98-a9c2c9b389dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-bbe79789-ea30-4134-8968-edcd7b486dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-3eed3406-5a97-4a07-bbd8-3ae9417f9d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-7c7c9812-6ee7-4cb2-8fd4-78a869faf3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464955486-172.17.0.12-1598410060121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-a315f960-05ef-4892-a8b4-eab4b2a2eae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1a7a5ff8-2222-4734-af3f-7c4d16aca6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9efff867-b8fb-405f-8b88-6a2304daea82,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-d5965a00-ee3c-4a6e-880a-0d3f94f0f698,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-b8682e7b-b240-4419-9a98-a9c2c9b389dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-bbe79789-ea30-4134-8968-edcd7b486dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-3eed3406-5a97-4a07-bbd8-3ae9417f9d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-7c7c9812-6ee7-4cb2-8fd4-78a869faf3bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893915559-172.17.0.12-1598410166823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-56ed81a4-b466-4eed-b03c-2d4e3eed84a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-148a7be2-71e0-406c-9dc0-458ec092dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-2cf26cc3-6736-4c80-8aa4-1584cbd92482,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-6b00a923-fd8e-4ee5-bd39-917e84400065,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-49f48cc5-9443-4903-8769-2cc4d78f61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-8b66488f-8f64-4e21-94cd-e5a2ba5d6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-c668017f-a392-4e5d-bbce-0b52eaf202d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-c57a8a4c-1209-47a5-833c-1f4b76bdb9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893915559-172.17.0.12-1598410166823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-56ed81a4-b466-4eed-b03c-2d4e3eed84a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-148a7be2-71e0-406c-9dc0-458ec092dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-2cf26cc3-6736-4c80-8aa4-1584cbd92482,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-6b00a923-fd8e-4ee5-bd39-917e84400065,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-49f48cc5-9443-4903-8769-2cc4d78f61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-8b66488f-8f64-4e21-94cd-e5a2ba5d6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-c668017f-a392-4e5d-bbce-0b52eaf202d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-c57a8a4c-1209-47a5-833c-1f4b76bdb9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216302801-172.17.0.12-1598410231716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-2d7194a7-c88d-47d6-a6b0-6687bc8ec714,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-e21eef50-a767-4d32-8eaf-4ac7fa5cbfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-ffddb459-4ffe-4fa6-ab81-29d1a7afd640,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-16918ed9-7887-4eaf-87e0-7fc4c543a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-439187a1-cde3-4e9e-b6b8-d7fd0fb7e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-d1696d72-e9e4-4de1-bfbe-ecafeb60e707,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-2ca19371-2975-4a0a-850b-2e668f5b377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-0fd2e519-e2ab-4909-897e-85508a974219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216302801-172.17.0.12-1598410231716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-2d7194a7-c88d-47d6-a6b0-6687bc8ec714,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-e21eef50-a767-4d32-8eaf-4ac7fa5cbfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-ffddb459-4ffe-4fa6-ab81-29d1a7afd640,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-16918ed9-7887-4eaf-87e0-7fc4c543a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-439187a1-cde3-4e9e-b6b8-d7fd0fb7e6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-d1696d72-e9e4-4de1-bfbe-ecafeb60e707,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-2ca19371-2975-4a0a-850b-2e668f5b377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-0fd2e519-e2ab-4909-897e-85508a974219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644058967-172.17.0.12-1598410295707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-85d4009b-98af-4b04-930c-6a6980ca5381,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-ba2b0e26-fa3f-463d-86e3-47662231b908,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-40bd2bfe-1f4b-4756-8954-57f9e3785e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-5796f95e-95d1-492f-a652-f3a706d634a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-1f95438b-25df-4bd7-970a-31dd5410df05,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a74b4ada-8fcc-43eb-99d5-5ce71401a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-a1ec1126-8fdc-4638-9a5c-fa662be2ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-f7e6c9c3-47c3-4db5-984e-6a46a7af1460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644058967-172.17.0.12-1598410295707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-85d4009b-98af-4b04-930c-6a6980ca5381,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-ba2b0e26-fa3f-463d-86e3-47662231b908,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-40bd2bfe-1f4b-4756-8954-57f9e3785e51,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-5796f95e-95d1-492f-a652-f3a706d634a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-1f95438b-25df-4bd7-970a-31dd5410df05,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a74b4ada-8fcc-43eb-99d5-5ce71401a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-a1ec1126-8fdc-4638-9a5c-fa662be2ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-f7e6c9c3-47c3-4db5-984e-6a46a7af1460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5065
