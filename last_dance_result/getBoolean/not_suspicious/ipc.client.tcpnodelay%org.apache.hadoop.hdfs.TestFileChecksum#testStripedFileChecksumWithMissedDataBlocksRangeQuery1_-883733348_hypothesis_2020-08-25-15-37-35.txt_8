reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500706454-172.17.0.9-1598369940125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37938,DS-cce0d1ec-f63b-43aa-8e5b-ca8e4e21d520,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-939b0e4d-aa76-4506-a5ef-71dabdf64503,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-20484eef-03d4-486a-a9a1-ab343d9b8690,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-b7f2590b-379d-4526-86f8-7059309a5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2bb6da9c-4c87-47d4-9d05-0f57f7958067,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-77502a74-c5aa-4eb4-8c2a-59e6842d7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-c0d79219-bb0a-437d-884d-d0322a72f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-97bfcc43-615f-4c25-853a-01ed9de0dce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500706454-172.17.0.9-1598369940125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37938,DS-cce0d1ec-f63b-43aa-8e5b-ca8e4e21d520,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-939b0e4d-aa76-4506-a5ef-71dabdf64503,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-20484eef-03d4-486a-a9a1-ab343d9b8690,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-b7f2590b-379d-4526-86f8-7059309a5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2bb6da9c-4c87-47d4-9d05-0f57f7958067,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-77502a74-c5aa-4eb4-8c2a-59e6842d7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-c0d79219-bb0a-437d-884d-d0322a72f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-97bfcc43-615f-4c25-853a-01ed9de0dce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952242124-172.17.0.9-1598370098702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-af507ec4-5105-4d40-ae2f-f51c7a940d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-5a056df4-6d3e-4718-b112-4d7f26b4f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-ec05cf95-2aea-4da8-b823-46e730a486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-f3e60352-38b6-4b7a-aefb-6d4c02e0bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-6143f8a8-6bca-48af-b3f0-fb7d3a3fe0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-ef8c5abc-3943-47bc-88b6-b261ea651a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-537de872-aba6-4b1e-89f1-26ecb7c58722,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-7b17b8e4-3b36-444c-9e94-4330e8d131eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952242124-172.17.0.9-1598370098702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-af507ec4-5105-4d40-ae2f-f51c7a940d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-5a056df4-6d3e-4718-b112-4d7f26b4f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-ec05cf95-2aea-4da8-b823-46e730a486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-f3e60352-38b6-4b7a-aefb-6d4c02e0bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-6143f8a8-6bca-48af-b3f0-fb7d3a3fe0af,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-ef8c5abc-3943-47bc-88b6-b261ea651a25,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-537de872-aba6-4b1e-89f1-26ecb7c58722,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-7b17b8e4-3b36-444c-9e94-4330e8d131eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933409325-172.17.0.9-1598370247130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-19055b56-f63a-40c2-bcab-ecec3573b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-f2fc3292-cd77-4aab-a6ec-74e2b645af1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-3cbf2308-85ea-480a-8f64-b09af3da8672,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-74a003ea-2e8a-46e9-a147-7d7dbddad7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-f8ba6f43-a3d4-4314-a63e-f4926e88edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-317adbe5-1017-407e-86f7-628291b7ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-7d4d16f3-fc39-41ff-9a6f-7ba3cda1d968,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e4d50d43-8336-4d9d-9248-b9a5dab3e13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933409325-172.17.0.9-1598370247130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-19055b56-f63a-40c2-bcab-ecec3573b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-f2fc3292-cd77-4aab-a6ec-74e2b645af1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-3cbf2308-85ea-480a-8f64-b09af3da8672,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-74a003ea-2e8a-46e9-a147-7d7dbddad7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-f8ba6f43-a3d4-4314-a63e-f4926e88edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-317adbe5-1017-407e-86f7-628291b7ed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-7d4d16f3-fc39-41ff-9a6f-7ba3cda1d968,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e4d50d43-8336-4d9d-9248-b9a5dab3e13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906417734-172.17.0.9-1598370453783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-286c6c9c-4157-44ba-82f6-c1ae638fdf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7aea5cc4-31c3-4478-97a7-95c1d5132f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-f209c043-073a-4620-8757-1db3896ce796,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-1250d2eb-d1e2-406e-8cba-abc55ed712ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-2be6759c-c975-4a77-89dc-2df70b58868d,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-41cb5616-0426-4ad8-9964-040c736731cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-792343f9-3f71-4579-8aeb-fb668be4df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a187b51-a0dd-4214-829e-76023b4096b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906417734-172.17.0.9-1598370453783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-286c6c9c-4157-44ba-82f6-c1ae638fdf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7aea5cc4-31c3-4478-97a7-95c1d5132f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-f209c043-073a-4620-8757-1db3896ce796,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-1250d2eb-d1e2-406e-8cba-abc55ed712ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-2be6759c-c975-4a77-89dc-2df70b58868d,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-41cb5616-0426-4ad8-9964-040c736731cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-792343f9-3f71-4579-8aeb-fb668be4df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a187b51-a0dd-4214-829e-76023b4096b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135485254-172.17.0.9-1598371057233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-a9e326ab-def0-47c7-a657-894a393df0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6b688e06-af09-4e3c-bd9b-68e5200880ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ea0238b3-554b-4641-a408-a13fd64ca250,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-1bdb127b-6736-4cb2-962d-cb84adf217b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-cd9c817d-5727-4993-878e-ff144a829d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-0f2d1fa7-54ee-4b6f-a030-b4a1410b2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-d86638c2-dad3-4d52-b2cd-dcec27703da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9b6c3b47-059a-4ee9-a500-9eee69e4942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135485254-172.17.0.9-1598371057233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-a9e326ab-def0-47c7-a657-894a393df0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6b688e06-af09-4e3c-bd9b-68e5200880ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ea0238b3-554b-4641-a408-a13fd64ca250,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-1bdb127b-6736-4cb2-962d-cb84adf217b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-cd9c817d-5727-4993-878e-ff144a829d72,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-0f2d1fa7-54ee-4b6f-a030-b4a1410b2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-d86638c2-dad3-4d52-b2cd-dcec27703da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9b6c3b47-059a-4ee9-a500-9eee69e4942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88998603-172.17.0.9-1598371325193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-107bf938-3a27-432a-9ca3-63b359bfd82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f2f5aa2d-5e0d-495b-a122-517e49e6ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-7c82fa66-0fbb-4005-95ce-ddb15adcd092,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8f75159f-7a7a-4bfc-8443-97a537be3613,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-275673af-6836-4fb0-adb9-d01f314c30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-7a5b0573-7230-481a-ac82-0309f43048ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-dd993050-33ae-42b8-a3e1-fc63e81c41a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-2eddb683-3dfe-413a-ac85-ada0e7758249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88998603-172.17.0.9-1598371325193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-107bf938-3a27-432a-9ca3-63b359bfd82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f2f5aa2d-5e0d-495b-a122-517e49e6ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-7c82fa66-0fbb-4005-95ce-ddb15adcd092,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8f75159f-7a7a-4bfc-8443-97a537be3613,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-275673af-6836-4fb0-adb9-d01f314c30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-7a5b0573-7230-481a-ac82-0309f43048ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-dd993050-33ae-42b8-a3e1-fc63e81c41a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-2eddb683-3dfe-413a-ac85-ada0e7758249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758787396-172.17.0.9-1598371479074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-0d30040e-4ca4-422e-b456-656bdbf15b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-b328ecf4-6ecc-4105-813d-6995c1cc42a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-f2a69eca-a893-436c-8a4a-572746ea2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-e8a19576-8ba4-4d78-b3fb-dc217851f5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-aa5129b3-869b-4a1a-9bbc-bf535d765019,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-e7e91148-ad8e-438e-9bb7-9e2b34a345ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-9a667c20-d18c-4584-9b31-64f064c0db91,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-e5ed8051-f2e5-467d-b082-066b677196a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758787396-172.17.0.9-1598371479074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-0d30040e-4ca4-422e-b456-656bdbf15b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-b328ecf4-6ecc-4105-813d-6995c1cc42a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-f2a69eca-a893-436c-8a4a-572746ea2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-e8a19576-8ba4-4d78-b3fb-dc217851f5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-aa5129b3-869b-4a1a-9bbc-bf535d765019,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-e7e91148-ad8e-438e-9bb7-9e2b34a345ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-9a667c20-d18c-4584-9b31-64f064c0db91,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-e5ed8051-f2e5-467d-b082-066b677196a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391611385-172.17.0.9-1598371628878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-99be299d-b260-44db-8cfb-e6353c20499a,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-68835e70-2f72-4ac7-a297-d4938134fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8776c4b8-b92d-44f7-a0d9-886785fbec91,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-69eefdd4-4f43-4166-a443-ce89342781bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-0ea9aa1c-46e5-4c25-a058-e47077b19841,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-f71f2bee-6441-40e4-80da-f9dee04c6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-fd693f43-8f90-4e2b-abbe-bab928b2580b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-7f039486-634a-4951-9b01-4f89a55161b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391611385-172.17.0.9-1598371628878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-99be299d-b260-44db-8cfb-e6353c20499a,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-68835e70-2f72-4ac7-a297-d4938134fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8776c4b8-b92d-44f7-a0d9-886785fbec91,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-69eefdd4-4f43-4166-a443-ce89342781bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-0ea9aa1c-46e5-4c25-a058-e47077b19841,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-f71f2bee-6441-40e4-80da-f9dee04c6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-fd693f43-8f90-4e2b-abbe-bab928b2580b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-7f039486-634a-4951-9b01-4f89a55161b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699183875-172.17.0.9-1598372020348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-5f832697-60c1-4586-be81-baf5a51bc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-ed970b95-88bb-4257-acc6-f697ab1d6d52,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-04e8ceaf-d0d0-4abf-9d49-a915e4eeb62c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-433c151b-9586-4123-8690-98e917492743,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-8cbc46d1-ec6d-41e6-8cc7-1ccbbbfc646f,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-90325a33-52a5-4429-ab56-e120ff452c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-07f822dc-27c8-4a3e-84ea-909233b59782,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cacd704d-59df-425c-b402-664393b7ef0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699183875-172.17.0.9-1598372020348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-5f832697-60c1-4586-be81-baf5a51bc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-ed970b95-88bb-4257-acc6-f697ab1d6d52,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-04e8ceaf-d0d0-4abf-9d49-a915e4eeb62c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-433c151b-9586-4123-8690-98e917492743,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-8cbc46d1-ec6d-41e6-8cc7-1ccbbbfc646f,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-90325a33-52a5-4429-ab56-e120ff452c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-07f822dc-27c8-4a3e-84ea-909233b59782,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cacd704d-59df-425c-b402-664393b7ef0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731833011-172.17.0.9-1598372235346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-a9ac8e64-8d68-4b53-ac79-019be364c25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-994b35a5-a660-4ccf-92bd-4dbee95df3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-67c88659-c45f-4f51-9499-26b413e4200b,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-2d6dc6be-725b-4e04-8ce7-79213a172b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a985b1e2-5448-4c64-a52f-8609bf5b7fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b643bf07-c67d-45b3-984a-c2dc49c23aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4e58e258-71bb-4599-924f-89b58f5f24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-4e98c6da-90d9-4000-8b32-a2c210a581aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731833011-172.17.0.9-1598372235346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37236,DS-a9ac8e64-8d68-4b53-ac79-019be364c25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-994b35a5-a660-4ccf-92bd-4dbee95df3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-67c88659-c45f-4f51-9499-26b413e4200b,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-2d6dc6be-725b-4e04-8ce7-79213a172b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a985b1e2-5448-4c64-a52f-8609bf5b7fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b643bf07-c67d-45b3-984a-c2dc49c23aad,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-4e58e258-71bb-4599-924f-89b58f5f24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-4e98c6da-90d9-4000-8b32-a2c210a581aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927158505-172.17.0.9-1598372634518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-13494f4e-3707-415a-804c-b881df0c131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-2fa146f4-0f70-4032-bbea-4f0fb2feee40,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-af363032-651e-4d08-a9c9-a9bca3d5354c,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b93688f1-bd01-44ea-9074-b51259056509,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-735086da-bd97-4513-af3f-889b778f65e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-f794e1a8-9c05-4858-9fa2-8ab1b699cf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-e47e2e77-bbc6-4d28-959c-787008e551c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-22f81837-1828-4570-b06d-dbcdc98fb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927158505-172.17.0.9-1598372634518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-13494f4e-3707-415a-804c-b881df0c131a,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-2fa146f4-0f70-4032-bbea-4f0fb2feee40,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-af363032-651e-4d08-a9c9-a9bca3d5354c,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b93688f1-bd01-44ea-9074-b51259056509,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-735086da-bd97-4513-af3f-889b778f65e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-f794e1a8-9c05-4858-9fa2-8ab1b699cf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-e47e2e77-bbc6-4d28-959c-787008e551c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-22f81837-1828-4570-b06d-dbcdc98fb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576548474-172.17.0.9-1598373222025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-84c9121c-900d-4c14-99ec-7d14f67eb2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-b7ba55e9-f44a-4bbd-9ab3-9e3561c374f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-478a2bcc-3b42-48fe-b1ed-cf279f0bd1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-0d0fffdc-6a20-4cbd-99a0-b015e816a040,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-cb788ca8-a528-4006-86ec-96600362ceda,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-f8eab952-e75e-48c3-a8e6-c7f987b13384,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-22514492-e92a-41e9-89ca-e4996bfd335f,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-4dfeeb38-a0fd-4311-a8fb-2429f16f75bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576548474-172.17.0.9-1598373222025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-84c9121c-900d-4c14-99ec-7d14f67eb2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-b7ba55e9-f44a-4bbd-9ab3-9e3561c374f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-478a2bcc-3b42-48fe-b1ed-cf279f0bd1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-0d0fffdc-6a20-4cbd-99a0-b015e816a040,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-cb788ca8-a528-4006-86ec-96600362ceda,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-f8eab952-e75e-48c3-a8e6-c7f987b13384,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-22514492-e92a-41e9-89ca-e4996bfd335f,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-4dfeeb38-a0fd-4311-a8fb-2429f16f75bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400990397-172.17.0.9-1598373332487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-2982784f-d249-480b-b1fa-782f6169e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-193b0c56-ce53-4a18-8ee3-01c8af8b70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-15bdd3ee-f465-4a94-814f-80eb0db4e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-a9701ae6-a9c2-439f-aeb3-76ab5ff48590,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-64b2553a-f58d-4337-9982-7426b121f733,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-1e4972ec-8c63-411b-b03b-06b83537a253,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-dd646a49-6aa4-4e37-b414-ccc940da3507,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-48a3765a-e8fc-4f1e-82fa-1398ad838fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400990397-172.17.0.9-1598373332487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-2982784f-d249-480b-b1fa-782f6169e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-193b0c56-ce53-4a18-8ee3-01c8af8b70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-15bdd3ee-f465-4a94-814f-80eb0db4e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-a9701ae6-a9c2-439f-aeb3-76ab5ff48590,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-64b2553a-f58d-4337-9982-7426b121f733,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-1e4972ec-8c63-411b-b03b-06b83537a253,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-dd646a49-6aa4-4e37-b414-ccc940da3507,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-48a3765a-e8fc-4f1e-82fa-1398ad838fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30161865-172.17.0.9-1598373691302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-e4553bc6-349a-48b3-a05e-459edcd3873e,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-83596f86-e277-44d8-b118-cd34e0546e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-07813ffd-4ee4-4a0b-abb8-aa4996e47daf,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-868b93f8-0fb9-450e-85b9-3c1fe35f6d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-d0c3950b-ffcf-44ac-b642-015d7e71c099,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6fe7dee9-d93f-49a0-b05d-6ed591bc3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-1949f5eb-d233-42ff-9931-bc795b181de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-782a874e-2bad-40f9-8773-d214fe836908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30161865-172.17.0.9-1598373691302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-e4553bc6-349a-48b3-a05e-459edcd3873e,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-83596f86-e277-44d8-b118-cd34e0546e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-07813ffd-4ee4-4a0b-abb8-aa4996e47daf,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-868b93f8-0fb9-450e-85b9-3c1fe35f6d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-d0c3950b-ffcf-44ac-b642-015d7e71c099,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6fe7dee9-d93f-49a0-b05d-6ed591bc3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-1949f5eb-d233-42ff-9931-bc795b181de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-782a874e-2bad-40f9-8773-d214fe836908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427016430-172.17.0.9-1598373960195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-2632ec32-3c53-47cc-bc39-270eda7a836b,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-e0e7b6e0-42de-4489-b2ad-9e4cc8aaf60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-e1c7a956-6b56-4557-81de-63755c877012,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-1682ed45-98ec-4b23-8658-9eefa758219b,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-ce28f3a9-99cf-4a6b-8630-1397d448af87,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-11bc8828-0f79-4061-a9a1-9f163ac29fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-68772d3f-3a75-4223-911b-77502881e553,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-502c96f7-eef2-4229-887d-924698606962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427016430-172.17.0.9-1598373960195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-2632ec32-3c53-47cc-bc39-270eda7a836b,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-e0e7b6e0-42de-4489-b2ad-9e4cc8aaf60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-e1c7a956-6b56-4557-81de-63755c877012,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-1682ed45-98ec-4b23-8658-9eefa758219b,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-ce28f3a9-99cf-4a6b-8630-1397d448af87,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-11bc8828-0f79-4061-a9a1-9f163ac29fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-68772d3f-3a75-4223-911b-77502881e553,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-502c96f7-eef2-4229-887d-924698606962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171945468-172.17.0.9-1598374465416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-eb331f22-bb56-43df-9353-365e79d5380c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-54ce7f8c-ba7f-4f79-88db-51c17c54efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-2317030f-d9cf-4520-96a9-95f55a83b9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-37540dd9-f579-45fa-a381-9704093870fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-d549d3d7-79ee-4553-8d68-e750c2bcf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-6be7fd31-2fe6-46b0-9617-30e923f11d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-b4370074-75d7-40d6-9324-8a4742a86c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-1eef1850-f0dd-407b-b45f-54638ca47036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171945468-172.17.0.9-1598374465416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-eb331f22-bb56-43df-9353-365e79d5380c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-54ce7f8c-ba7f-4f79-88db-51c17c54efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-2317030f-d9cf-4520-96a9-95f55a83b9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-37540dd9-f579-45fa-a381-9704093870fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-d549d3d7-79ee-4553-8d68-e750c2bcf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-6be7fd31-2fe6-46b0-9617-30e923f11d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-b4370074-75d7-40d6-9324-8a4742a86c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-1eef1850-f0dd-407b-b45f-54638ca47036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600198752-172.17.0.9-1598374536438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-09aa8639-d149-42b9-b948-c403e2605d94,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2b455045-d541-449c-8b5b-f62e7c7c3615,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-97e17cc7-6d07-4bb4-bdd2-83c493731861,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-ca4ac763-9a7c-40d2-9b16-b710e7ac7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-82298b14-b5b6-474f-b532-e5d1408ed3be,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-34c6d8cd-4879-4213-86c1-1a4c7fed78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-f04397c7-36ef-42e7-bdc9-ec5f02d5817f,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-ca92bf60-edb8-4019-856f-403bbdafa104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600198752-172.17.0.9-1598374536438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-09aa8639-d149-42b9-b948-c403e2605d94,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2b455045-d541-449c-8b5b-f62e7c7c3615,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-97e17cc7-6d07-4bb4-bdd2-83c493731861,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-ca4ac763-9a7c-40d2-9b16-b710e7ac7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-82298b14-b5b6-474f-b532-e5d1408ed3be,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-34c6d8cd-4879-4213-86c1-1a4c7fed78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-f04397c7-36ef-42e7-bdc9-ec5f02d5817f,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-ca92bf60-edb8-4019-856f-403bbdafa104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655942774-172.17.0.9-1598374721189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-50cb85df-5a24-4b03-8eac-f87b3347c6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-f770d053-fe78-492e-af1a-ea5628a5298c,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1db88a0b-71bc-4491-9ad2-6b0828bd97f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-a5a936c8-bfbc-4ab7-9b24-df66d904b837,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-d992647b-d563-405b-a5ae-936c534f7165,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-d18301a1-0dbe-4d3b-8c88-7052ee2952bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-370ea421-5c82-432a-bbe8-b2aa244d85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-0833c935-bef9-4365-9d3d-c905c85f74f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655942774-172.17.0.9-1598374721189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-50cb85df-5a24-4b03-8eac-f87b3347c6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-f770d053-fe78-492e-af1a-ea5628a5298c,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1db88a0b-71bc-4491-9ad2-6b0828bd97f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-a5a936c8-bfbc-4ab7-9b24-df66d904b837,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-d992647b-d563-405b-a5ae-936c534f7165,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-d18301a1-0dbe-4d3b-8c88-7052ee2952bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-370ea421-5c82-432a-bbe8-b2aa244d85ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-0833c935-bef9-4365-9d3d-c905c85f74f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514569345-172.17.0.9-1598374963795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-57c25cd4-df6f-4b4c-863e-642b36186e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-6a05a372-1b59-462f-8ea7-ec7adee9a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2393cc00-7e24-4f8d-bb16-646efb71cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-30a05f05-5c47-4fff-910a-35724fb4170e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-5bfeb776-63bb-413e-9c7e-f0c544da1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-9fdbd9a1-a315-452f-80a6-fba5ebf65f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-05171335-74e0-4597-a8eb-9b19a25dc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-3c3ab9e2-dc15-4381-bbae-5e8a3dd7d771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514569345-172.17.0.9-1598374963795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-57c25cd4-df6f-4b4c-863e-642b36186e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-6a05a372-1b59-462f-8ea7-ec7adee9a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-2393cc00-7e24-4f8d-bb16-646efb71cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-30a05f05-5c47-4fff-910a-35724fb4170e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-5bfeb776-63bb-413e-9c7e-f0c544da1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-9fdbd9a1-a315-452f-80a6-fba5ebf65f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-05171335-74e0-4597-a8eb-9b19a25dc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-3c3ab9e2-dc15-4381-bbae-5e8a3dd7d771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849296437-172.17.0.9-1598375031008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-6590871d-1404-499d-b7a1-b26451e9f980,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-48eea990-1909-4dc4-8977-002bf8e8863d,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-a6669c69-4f57-4188-8be1-1b9f089edc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-fcf2fc65-ac86-44ed-bafd-417b71a080ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d75ef5fb-24a7-4075-9504-4354850e2006,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-71e3e6c9-8418-445a-90a4-d2ce16700f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b46df6ab-2dbd-47fd-86bc-2447d2f6287f,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-e8c17e78-63dc-4fd9-9e3e-7101ab4e12fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849296437-172.17.0.9-1598375031008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-6590871d-1404-499d-b7a1-b26451e9f980,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-48eea990-1909-4dc4-8977-002bf8e8863d,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-a6669c69-4f57-4188-8be1-1b9f089edc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-fcf2fc65-ac86-44ed-bafd-417b71a080ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d75ef5fb-24a7-4075-9504-4354850e2006,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-71e3e6c9-8418-445a-90a4-d2ce16700f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b46df6ab-2dbd-47fd-86bc-2447d2f6287f,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-e8c17e78-63dc-4fd9-9e3e-7101ab4e12fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037056144-172.17.0.9-1598375111453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-9abeab4d-3b16-4ed4-a103-5ef176897b01,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-1afc7ebd-9ebb-4873-97dc-a2da9af6a091,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-2cac142d-d079-4fb4-a7c8-499690b8f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-40367af7-1e9d-41ca-9950-2d07c7b647c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-ecbbe2d0-4e65-4322-b13a-262b753b7145,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-dd58dd09-295b-489e-ab43-a70be4e28e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-68f10201-2aa4-46c7-88cb-c0fb67718548,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0e36189d-32e8-440d-8be1-b78ce4a04e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037056144-172.17.0.9-1598375111453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-9abeab4d-3b16-4ed4-a103-5ef176897b01,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-1afc7ebd-9ebb-4873-97dc-a2da9af6a091,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-2cac142d-d079-4fb4-a7c8-499690b8f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-40367af7-1e9d-41ca-9950-2d07c7b647c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-ecbbe2d0-4e65-4322-b13a-262b753b7145,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-dd58dd09-295b-489e-ab43-a70be4e28e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-68f10201-2aa4-46c7-88cb-c0fb67718548,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-0e36189d-32e8-440d-8be1-b78ce4a04e36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5667
