reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892518255-172.17.0.14-1598399677095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-ee9e2258-b19f-4bc4-a173-296fe6196564,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-3144186d-4af6-46b8-b314-8d603c9477f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-cc6cef60-07fc-4bbe-a428-d29c45e42270,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-deabda99-b711-48d2-bce8-4bedd486135d,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e694180e-fbf0-4c23-bd52-766704f091dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-8f558fd7-8f7e-45b7-ab79-4871fd9874df,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-65e523e9-3e3b-401c-b3e8-32c69f79e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-1eec313e-e472-465a-8e2f-2fb88c36da6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892518255-172.17.0.14-1598399677095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-ee9e2258-b19f-4bc4-a173-296fe6196564,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-3144186d-4af6-46b8-b314-8d603c9477f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-cc6cef60-07fc-4bbe-a428-d29c45e42270,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-deabda99-b711-48d2-bce8-4bedd486135d,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e694180e-fbf0-4c23-bd52-766704f091dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-8f558fd7-8f7e-45b7-ab79-4871fd9874df,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-65e523e9-3e3b-401c-b3e8-32c69f79e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-1eec313e-e472-465a-8e2f-2fb88c36da6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850815355-172.17.0.14-1598400267410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-a455e8b7-88ed-49cb-9fd1-a8b3337faa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-e72ca065-1c86-4886-954d-e8654686a866,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-d9596896-61b6-4af0-9a44-80ce7f6993f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-259425e2-dcde-4237-997e-46c45d3458af,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-7887ae6a-83fe-4d1f-aa83-a30466bf1995,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-09cee807-cfb9-48a6-a0cd-c9e38db303eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a7baa30d-8ef3-4f5e-8bed-b2dc3e0150b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-aa38bca6-3432-4c6f-a625-48928e08d0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850815355-172.17.0.14-1598400267410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-a455e8b7-88ed-49cb-9fd1-a8b3337faa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-e72ca065-1c86-4886-954d-e8654686a866,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-d9596896-61b6-4af0-9a44-80ce7f6993f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-259425e2-dcde-4237-997e-46c45d3458af,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-7887ae6a-83fe-4d1f-aa83-a30466bf1995,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-09cee807-cfb9-48a6-a0cd-c9e38db303eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a7baa30d-8ef3-4f5e-8bed-b2dc3e0150b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-aa38bca6-3432-4c6f-a625-48928e08d0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072425507-172.17.0.14-1598400303156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-d53cd268-520e-4a34-803f-655ce0adb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-4eabf6c0-a75e-4d62-9d85-0700922ff5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ee979efb-48b1-4f0a-954e-a54aa97e7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-77739668-0578-45c4-a9c9-61b57bc34015,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-5f94fbed-e827-4447-a830-12110345afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-dcdcf0ff-a559-414b-85ce-0d6e3117d324,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-26aeecb4-fb3e-47b2-8edc-e54561799e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b9508073-5b7c-4a09-a32e-eaf0fec08043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072425507-172.17.0.14-1598400303156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-d53cd268-520e-4a34-803f-655ce0adb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-4eabf6c0-a75e-4d62-9d85-0700922ff5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ee979efb-48b1-4f0a-954e-a54aa97e7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-77739668-0578-45c4-a9c9-61b57bc34015,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-5f94fbed-e827-4447-a830-12110345afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-dcdcf0ff-a559-414b-85ce-0d6e3117d324,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-26aeecb4-fb3e-47b2-8edc-e54561799e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b9508073-5b7c-4a09-a32e-eaf0fec08043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533420893-172.17.0.14-1598400347698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-882424f8-a23f-4084-a012-1b9ccce37138,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-efd42fdc-41d1-4191-ad43-b3352c17711e,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-e5e9f50f-72a9-4f8c-9f65-cea47483fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-59aaf30d-a7ef-4f1d-a37b-18c5f694f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-9c19a715-b930-4d64-aefb-5bce229e6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-2f2288c1-24cf-4d2a-b30c-89aec2383207,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-038b98af-55e8-44c6-b314-d41411499573,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-40fbf208-c049-4214-ba3b-c0abbbe2f5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533420893-172.17.0.14-1598400347698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-882424f8-a23f-4084-a012-1b9ccce37138,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-efd42fdc-41d1-4191-ad43-b3352c17711e,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-e5e9f50f-72a9-4f8c-9f65-cea47483fdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-59aaf30d-a7ef-4f1d-a37b-18c5f694f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-9c19a715-b930-4d64-aefb-5bce229e6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-2f2288c1-24cf-4d2a-b30c-89aec2383207,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-038b98af-55e8-44c6-b314-d41411499573,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-40fbf208-c049-4214-ba3b-c0abbbe2f5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535450234-172.17.0.14-1598400497370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-23edd9de-ec99-4279-9d21-b285a70ca484,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-b95f9784-ab21-41a6-9588-a0b97ed8046f,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-d5a38147-7328-4c39-914d-258a0ddabc00,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a5224e37-63b0-43c6-8426-1f0f7e01d809,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-571f8e1d-339f-41f9-9c37-eb5e4cd75363,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-5f5ae0ef-d39e-4e52-89c9-33fdb78991a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-f85f3ca8-5423-4f4f-a658-883f4fd14549,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-83fb89dc-c97a-4f47-bee6-86c063c96b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535450234-172.17.0.14-1598400497370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-23edd9de-ec99-4279-9d21-b285a70ca484,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-b95f9784-ab21-41a6-9588-a0b97ed8046f,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-d5a38147-7328-4c39-914d-258a0ddabc00,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a5224e37-63b0-43c6-8426-1f0f7e01d809,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-571f8e1d-339f-41f9-9c37-eb5e4cd75363,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-5f5ae0ef-d39e-4e52-89c9-33fdb78991a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-f85f3ca8-5423-4f4f-a658-883f4fd14549,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-83fb89dc-c97a-4f47-bee6-86c063c96b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061234231-172.17.0.14-1598400828796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37655,DS-134e7d6c-c041-423b-b4b2-b41dad554384,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1ec93b4a-39af-4fee-951b-3b617c134db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-b1ca11f8-2a5e-4ca9-8497-b926b3e469ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-dcafc65a-2b50-4411-b710-be270e7216e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-3fbed7e8-d7c4-4ccf-ac7e-b31add8ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ea28029f-d462-40ad-b6f4-aefafd5f6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-78161ecc-5bb5-4e25-9bf6-3afbe46dfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-fe23b241-23fd-4c35-b54d-35089ad940e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061234231-172.17.0.14-1598400828796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37655,DS-134e7d6c-c041-423b-b4b2-b41dad554384,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1ec93b4a-39af-4fee-951b-3b617c134db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-b1ca11f8-2a5e-4ca9-8497-b926b3e469ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-dcafc65a-2b50-4411-b710-be270e7216e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-3fbed7e8-d7c4-4ccf-ac7e-b31add8ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-ea28029f-d462-40ad-b6f4-aefafd5f6e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-78161ecc-5bb5-4e25-9bf6-3afbe46dfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-fe23b241-23fd-4c35-b54d-35089ad940e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409244955-172.17.0.14-1598401458803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-75b06611-572b-4524-a977-7ff9b47210a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-331d7028-8454-4a2b-aadf-92f720bebe99,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-67a56aab-ff5c-4f06-b3bd-037ed3a6d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-c1f1b915-8ced-4f14-865d-104caca2631c,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-2e7bce26-2d7c-4117-af33-ca20052dbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5bea7bbc-5b75-4086-9d95-2f5a73952fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-0d8de88d-dcb8-4d78-85fe-cc225ad07e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-194c8c72-0bc0-4e8f-9edc-9ea87eff07ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409244955-172.17.0.14-1598401458803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-75b06611-572b-4524-a977-7ff9b47210a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-331d7028-8454-4a2b-aadf-92f720bebe99,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-67a56aab-ff5c-4f06-b3bd-037ed3a6d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-c1f1b915-8ced-4f14-865d-104caca2631c,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-2e7bce26-2d7c-4117-af33-ca20052dbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5bea7bbc-5b75-4086-9d95-2f5a73952fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-0d8de88d-dcb8-4d78-85fe-cc225ad07e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-194c8c72-0bc0-4e8f-9edc-9ea87eff07ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124694097-172.17.0.14-1598401537412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-33ba461c-3bbb-4b83-8e06-b08a1cf15f19,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-422bef09-2c2e-41a0-a74f-5505a311c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-e392ca86-ccf4-4a52-87f5-1b908b6830c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-1c8f95c1-ae5e-4eb9-9fc9-79a23188d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-48669c88-63f0-4c17-824b-1d6964ab65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-4cc4abeb-0a5e-45eb-841e-0ff478e8da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-44ac14b2-9e26-4f73-81e5-eab29073560a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-5f716f3a-e6b7-4538-9371-cd09ca4f3131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124694097-172.17.0.14-1598401537412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-33ba461c-3bbb-4b83-8e06-b08a1cf15f19,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-422bef09-2c2e-41a0-a74f-5505a311c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-e392ca86-ccf4-4a52-87f5-1b908b6830c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-1c8f95c1-ae5e-4eb9-9fc9-79a23188d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-48669c88-63f0-4c17-824b-1d6964ab65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-4cc4abeb-0a5e-45eb-841e-0ff478e8da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-44ac14b2-9e26-4f73-81e5-eab29073560a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-5f716f3a-e6b7-4538-9371-cd09ca4f3131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507363888-172.17.0.14-1598402181876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-516e8353-8919-4cb9-ac52-0c900842db21,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1dac01f0-8e7a-4155-ba04-937cfa65f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-ba9b0fc1-7b9d-469f-a31e-6911f3f82048,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-5dece18d-dfa0-4a0b-84bb-2e2c7e5565d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-ed0a30fb-0448-4743-82ca-9543a350281b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-042c966a-a0a1-4f3f-90db-81017ebd75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-2de4fb34-b575-4554-badd-f07a303bce85,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-95e0fb3a-bc63-4313-a09d-75f8a68d66a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507363888-172.17.0.14-1598402181876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-516e8353-8919-4cb9-ac52-0c900842db21,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1dac01f0-8e7a-4155-ba04-937cfa65f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-ba9b0fc1-7b9d-469f-a31e-6911f3f82048,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-5dece18d-dfa0-4a0b-84bb-2e2c7e5565d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-ed0a30fb-0448-4743-82ca-9543a350281b,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-042c966a-a0a1-4f3f-90db-81017ebd75ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-2de4fb34-b575-4554-badd-f07a303bce85,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-95e0fb3a-bc63-4313-a09d-75f8a68d66a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86641095-172.17.0.14-1598402216638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-618e8d3d-95ac-4446-b381-76125d3e0b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-fe08505d-982f-4b3c-bca2-83b09f9b8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-f4c733c5-e37d-4c8d-a50d-72801c4b058f,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-9ad72fb9-7c98-4b41-a231-463f1e549c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-6afdb50c-91d5-471a-aa3f-0dbaf121c536,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-5803d2a7-8bbb-4c6c-bfee-5601a04ef0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-22e09ef4-92b8-42cf-99bc-e1003408e745,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-1e3db8e6-6d5d-4d48-ae4e-67021f5b9b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86641095-172.17.0.14-1598402216638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-618e8d3d-95ac-4446-b381-76125d3e0b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-fe08505d-982f-4b3c-bca2-83b09f9b8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-f4c733c5-e37d-4c8d-a50d-72801c4b058f,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-9ad72fb9-7c98-4b41-a231-463f1e549c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-6afdb50c-91d5-471a-aa3f-0dbaf121c536,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-5803d2a7-8bbb-4c6c-bfee-5601a04ef0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-22e09ef4-92b8-42cf-99bc-e1003408e745,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-1e3db8e6-6d5d-4d48-ae4e-67021f5b9b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507006285-172.17.0.14-1598402257112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-bbdb2e2f-649e-4723-9a68-17e1ff153514,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-83c31719-058e-467e-8393-f1411e8b6bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0cbe4cf7-e32d-4f91-9cbb-dd2e50ff0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-a0f06236-01f6-40da-8e6d-d3a155f09b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-5dc454c4-9395-47b4-bd4a-eea63bf11f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-982e8fb3-db63-4943-a6cc-a2a13303894c,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-487f5c0f-e2ee-4e36-b4ec-ad297df20efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-275a076b-13dc-42fb-bd0a-a00079c1f447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507006285-172.17.0.14-1598402257112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-bbdb2e2f-649e-4723-9a68-17e1ff153514,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-83c31719-058e-467e-8393-f1411e8b6bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0cbe4cf7-e32d-4f91-9cbb-dd2e50ff0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-a0f06236-01f6-40da-8e6d-d3a155f09b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-5dc454c4-9395-47b4-bd4a-eea63bf11f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-982e8fb3-db63-4943-a6cc-a2a13303894c,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-487f5c0f-e2ee-4e36-b4ec-ad297df20efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-275a076b-13dc-42fb-bd0a-a00079c1f447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615576352-172.17.0.14-1598402294459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-99d8816c-e38a-4dfb-b361-3fa0d2d460ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-9134ce88-f534-41bc-9065-6919cacd7539,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-615e299f-79e3-4e95-bc6e-01ae115779d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-90689fe4-fd5b-4ee0-ab18-7a226706ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-1610b333-6109-4fbe-85e3-fdc6122d5108,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-4459aff9-2ced-480d-aec1-857bda7b1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-d87fa48e-0630-415e-b3ac-1a44ac01257f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-f37ccc96-df82-4cd6-b3ab-85f45d7415ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615576352-172.17.0.14-1598402294459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-99d8816c-e38a-4dfb-b361-3fa0d2d460ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-9134ce88-f534-41bc-9065-6919cacd7539,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-615e299f-79e3-4e95-bc6e-01ae115779d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-90689fe4-fd5b-4ee0-ab18-7a226706ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-1610b333-6109-4fbe-85e3-fdc6122d5108,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-4459aff9-2ced-480d-aec1-857bda7b1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-d87fa48e-0630-415e-b3ac-1a44ac01257f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-f37ccc96-df82-4cd6-b3ab-85f45d7415ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178600224-172.17.0.14-1598402524057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-2f675ea5-385a-456f-807a-7b62b70a4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-a90cd1fb-2686-4342-90ff-791ccfb58531,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d2ddbecb-82bd-4aa7-81ee-a5b34408da9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-57ecf910-b463-4801-8f47-0da27e1342d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-8093b02c-7e21-41c5-9bd2-6008fb4826c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-b9cc712c-8712-47b5-940a-206d6a5e62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-fc18289d-6cb6-4288-846a-9efd0e6a5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-7a5dd355-70a5-42dc-9582-4b1dee460880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178600224-172.17.0.14-1598402524057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-2f675ea5-385a-456f-807a-7b62b70a4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-a90cd1fb-2686-4342-90ff-791ccfb58531,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d2ddbecb-82bd-4aa7-81ee-a5b34408da9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-57ecf910-b463-4801-8f47-0da27e1342d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-8093b02c-7e21-41c5-9bd2-6008fb4826c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-b9cc712c-8712-47b5-940a-206d6a5e62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-fc18289d-6cb6-4288-846a-9efd0e6a5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-7a5dd355-70a5-42dc-9582-4b1dee460880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45173201-172.17.0.14-1598402674314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-5808f064-f18f-4c6a-8611-81096b571271,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-fcdd9ea7-343d-4d66-8bc9-611fdfeb241d,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e784b5a7-c50d-4909-aae2-c703410f6435,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-9a0c7ee2-5bf2-49d3-8671-33936a187bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-572c4bbd-361b-4411-b4d6-de7a9e0438e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-ecf63bb4-8646-42c2-8e3b-96eba5090f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-186b16a8-e656-4b42-b09f-babc81434954,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-e1cdc29b-29af-48d6-9e75-d3bb1048312e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45173201-172.17.0.14-1598402674314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-5808f064-f18f-4c6a-8611-81096b571271,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-fcdd9ea7-343d-4d66-8bc9-611fdfeb241d,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e784b5a7-c50d-4909-aae2-c703410f6435,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-9a0c7ee2-5bf2-49d3-8671-33936a187bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-572c4bbd-361b-4411-b4d6-de7a9e0438e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-ecf63bb4-8646-42c2-8e3b-96eba5090f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-186b16a8-e656-4b42-b09f-babc81434954,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-e1cdc29b-29af-48d6-9e75-d3bb1048312e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662673424-172.17.0.14-1598403967775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-2750f6f7-dec4-475e-8d02-d9aa84647828,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-e4c9e94e-dd1c-489c-a719-5a782d9d23d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5082a75f-7ad2-4fa7-95cc-3e52fa21936d,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-a7faaa63-2de8-4515-9d32-6981f8fc175c,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-8633737a-2259-49dd-a01a-de4a1e15bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-2490ee45-76dc-4811-a0b9-94c2f64da757,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-16ab7ab2-a5b7-4b87-8220-bdaca060ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-a08126b9-70af-433e-bb1b-1b8c13b62fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662673424-172.17.0.14-1598403967775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-2750f6f7-dec4-475e-8d02-d9aa84647828,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-e4c9e94e-dd1c-489c-a719-5a782d9d23d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5082a75f-7ad2-4fa7-95cc-3e52fa21936d,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-a7faaa63-2de8-4515-9d32-6981f8fc175c,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-8633737a-2259-49dd-a01a-de4a1e15bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-2490ee45-76dc-4811-a0b9-94c2f64da757,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-16ab7ab2-a5b7-4b87-8220-bdaca060ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-a08126b9-70af-433e-bb1b-1b8c13b62fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280094049-172.17.0.14-1598404234858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-4343a54b-6140-4b78-aec1-b6f1c2738a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c01d5611-601c-4b1f-9e70-45e10c0863e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-ed7e27b1-bb38-4ea2-880a-0b169dae8eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e2c09e15-88c2-4f71-b470-d19d7edf3652,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-156419d3-221a-4173-9329-9469d023e931,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-222a30ed-dc12-40c9-8860-c9e23897f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0f5aec91-bad8-42d7-8d00-5323d8d223b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-47364efa-120e-46e5-ad3e-46332346086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280094049-172.17.0.14-1598404234858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-4343a54b-6140-4b78-aec1-b6f1c2738a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c01d5611-601c-4b1f-9e70-45e10c0863e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-ed7e27b1-bb38-4ea2-880a-0b169dae8eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e2c09e15-88c2-4f71-b470-d19d7edf3652,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-156419d3-221a-4173-9329-9469d023e931,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-222a30ed-dc12-40c9-8860-c9e23897f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0f5aec91-bad8-42d7-8d00-5323d8d223b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-47364efa-120e-46e5-ad3e-46332346086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897627709-172.17.0.14-1598404548976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-fa4cc6c2-15fe-4ce8-8058-9be944ddb34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-0e60fbdd-1e70-4e68-8afc-876ab012beb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-b16991af-f10d-4f68-a2b6-ce4acecc90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-2e892d6e-12be-406a-b1a5-31537d5e5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e147d0df-8197-49b2-bc47-179c14fa10f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ae41cac7-0846-4821-9e80-15f5f6232f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-0f677662-a8e8-4013-9979-356e1d8dd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-eb977c94-d5a4-4eed-b76a-6f7f6ca53cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897627709-172.17.0.14-1598404548976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-fa4cc6c2-15fe-4ce8-8058-9be944ddb34f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-0e60fbdd-1e70-4e68-8afc-876ab012beb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-b16991af-f10d-4f68-a2b6-ce4acecc90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-2e892d6e-12be-406a-b1a5-31537d5e5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e147d0df-8197-49b2-bc47-179c14fa10f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ae41cac7-0846-4821-9e80-15f5f6232f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-0f677662-a8e8-4013-9979-356e1d8dd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-eb977c94-d5a4-4eed-b76a-6f7f6ca53cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265546915-172.17.0.14-1598404779996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-d1f40fc7-8e44-4d23-8998-6a206a0fd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-c660d4f3-62a5-4f22-b54f-f21de3855986,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-3d6a15c6-8712-4480-80c5-38b6c49efaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6894dcd6-83df-48ad-ac84-2ddad54e98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-0faf8c2a-fc39-4673-b9b7-0c748f01cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-3f091474-8a40-43c0-b00f-7f2535326904,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-66e1f097-81a5-42c9-95c9-d3b91cf88f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-07b118d7-afa8-49bd-8af2-786d26c9edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265546915-172.17.0.14-1598404779996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-d1f40fc7-8e44-4d23-8998-6a206a0fd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-c660d4f3-62a5-4f22-b54f-f21de3855986,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-3d6a15c6-8712-4480-80c5-38b6c49efaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6894dcd6-83df-48ad-ac84-2ddad54e98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-0faf8c2a-fc39-4673-b9b7-0c748f01cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-3f091474-8a40-43c0-b00f-7f2535326904,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-66e1f097-81a5-42c9-95c9-d3b91cf88f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-07b118d7-afa8-49bd-8af2-786d26c9edd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777636081-172.17.0.14-1598404815106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-2bd7686e-9a49-4a55-a331-e897dff76c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-88c47b2b-b733-45e0-9976-b12047e428a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-96fea436-802c-426a-8994-a352ac6907e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-febdce7a-63cc-43f7-b7f2-7eee2be33e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-62f49f33-1589-4559-9af6-9a926f1e306f,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-97cff195-5233-4877-a045-eca8a4ddc045,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-c67cef40-7197-4c3d-ae35-7b02e689b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-eb7e3276-ae72-442d-9af0-e8adda714e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777636081-172.17.0.14-1598404815106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-2bd7686e-9a49-4a55-a331-e897dff76c48,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-88c47b2b-b733-45e0-9976-b12047e428a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-96fea436-802c-426a-8994-a352ac6907e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-febdce7a-63cc-43f7-b7f2-7eee2be33e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-62f49f33-1589-4559-9af6-9a926f1e306f,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-97cff195-5233-4877-a045-eca8a4ddc045,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-c67cef40-7197-4c3d-ae35-7b02e689b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-eb7e3276-ae72-442d-9af0-e8adda714e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5538
