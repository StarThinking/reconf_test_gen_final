reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512212732-172.17.0.11-1598361717009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-aa5629fe-d531-4e1e-88f1-f6506ba3f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0cf0489a-d8a6-4c34-a807-61592695ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-b3fda8dd-b9c9-45ce-8d0e-5b2f817025ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-901dc50c-3f45-42f5-8ab8-3013dbc539c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-2bf07600-5406-4883-ab0b-7a049481651d,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-3a8d24bb-7279-4dcf-9b50-b9a55c657512,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-e99e569d-647f-4d2d-b4fb-7f55c5a4a073,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-566df0d7-6b48-4434-9d74-9b375fc9539e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512212732-172.17.0.11-1598361717009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-aa5629fe-d531-4e1e-88f1-f6506ba3f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0cf0489a-d8a6-4c34-a807-61592695ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-b3fda8dd-b9c9-45ce-8d0e-5b2f817025ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-901dc50c-3f45-42f5-8ab8-3013dbc539c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-2bf07600-5406-4883-ab0b-7a049481651d,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-3a8d24bb-7279-4dcf-9b50-b9a55c657512,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-e99e569d-647f-4d2d-b4fb-7f55c5a4a073,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-566df0d7-6b48-4434-9d74-9b375fc9539e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255087611-172.17.0.11-1598361782022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-3f329953-9570-4708-9618-8f6cbe1975e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-94027592-1aa9-42cc-ac78-a0536d8da400,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-0fd9ece1-14b5-4366-a596-3efd27f1a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-7ae85b5a-9970-4f1e-9d18-dfc747e5e319,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1057419c-3d2b-4ec7-b8fd-34c7a2fa078a,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-09f62ce7-cce0-4bff-8b4d-5c6495339f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-dbf88b60-6d65-41f0-a5dc-037ed1dd4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-57fadc35-721e-4815-9890-7589864b94f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255087611-172.17.0.11-1598361782022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-3f329953-9570-4708-9618-8f6cbe1975e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-94027592-1aa9-42cc-ac78-a0536d8da400,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-0fd9ece1-14b5-4366-a596-3efd27f1a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-7ae85b5a-9970-4f1e-9d18-dfc747e5e319,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-1057419c-3d2b-4ec7-b8fd-34c7a2fa078a,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-09f62ce7-cce0-4bff-8b4d-5c6495339f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-dbf88b60-6d65-41f0-a5dc-037ed1dd4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-57fadc35-721e-4815-9890-7589864b94f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335103097-172.17.0.11-1598362171388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-00b78770-77cb-4183-be6d-6981bd28755c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-47b3692c-f057-460e-a9e9-bb8cccad7144,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-9e832e70-0a02-462f-94b9-ca18a0933fff,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-a356b37a-94d1-454c-99c3-c3c784216a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-75fb8364-8c59-46e1-ab49-bf9a70ca3264,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-b924e009-271f-4000-ba0c-239ef1f0181c,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-7fdb4537-9afa-48f5-b6a4-a87b30e2c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-1250b3ab-2a40-4fd6-a6e0-ccd9dc81410a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335103097-172.17.0.11-1598362171388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-00b78770-77cb-4183-be6d-6981bd28755c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-47b3692c-f057-460e-a9e9-bb8cccad7144,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-9e832e70-0a02-462f-94b9-ca18a0933fff,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-a356b37a-94d1-454c-99c3-c3c784216a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-75fb8364-8c59-46e1-ab49-bf9a70ca3264,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-b924e009-271f-4000-ba0c-239ef1f0181c,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-7fdb4537-9afa-48f5-b6a4-a87b30e2c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-1250b3ab-2a40-4fd6-a6e0-ccd9dc81410a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275255012-172.17.0.11-1598362347227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-391c0952-c933-48a1-b554-68a96103f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b87fdc50-4401-49ae-ac68-3dcc3f75ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3c4bdb8e-3d92-44c5-97cc-633f298a6d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-550d6a38-f9e9-4d5d-bc04-4114c98cd47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-edd96b3b-ec1b-4887-af17-daacf3241ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-7c89c321-e2a6-47ed-b3ff-f4e1804633f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-743a1a95-393d-40c7-b637-b315232f9fde,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-c166b86b-1c8e-4129-ba8f-377ce77aeb77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275255012-172.17.0.11-1598362347227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-391c0952-c933-48a1-b554-68a96103f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-b87fdc50-4401-49ae-ac68-3dcc3f75ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3c4bdb8e-3d92-44c5-97cc-633f298a6d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-550d6a38-f9e9-4d5d-bc04-4114c98cd47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-edd96b3b-ec1b-4887-af17-daacf3241ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-7c89c321-e2a6-47ed-b3ff-f4e1804633f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-743a1a95-393d-40c7-b637-b315232f9fde,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-c166b86b-1c8e-4129-ba8f-377ce77aeb77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374098008-172.17.0.11-1598363081649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-e02cb525-ef56-479e-890d-711059c66149,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-3ae8b01c-a43a-4dc6-b56b-d530486553e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-edf0bd3b-320c-4542-b043-cceee8eead94,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-167c2eae-74d5-4bd7-9798-b5da714d23b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-a1637d7f-e6ac-46b4-b7eb-056faa2dba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-40ad18b1-a203-4565-b969-69677aa8f068,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-189608e4-ec02-4e5a-8587-c294d95f6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-27f00b4f-c5ea-4e97-b9b1-a1d333f96d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374098008-172.17.0.11-1598363081649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-e02cb525-ef56-479e-890d-711059c66149,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-3ae8b01c-a43a-4dc6-b56b-d530486553e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-edf0bd3b-320c-4542-b043-cceee8eead94,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-167c2eae-74d5-4bd7-9798-b5da714d23b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-a1637d7f-e6ac-46b4-b7eb-056faa2dba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-40ad18b1-a203-4565-b969-69677aa8f068,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-189608e4-ec02-4e5a-8587-c294d95f6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-27f00b4f-c5ea-4e97-b9b1-a1d333f96d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084168677-172.17.0.11-1598363218212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38884,DS-38f04604-b36a-4bb7-ab2e-1ab45fe20049,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-0fa40578-1f3e-4058-87cb-05ad2748ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-49d48a19-e7ac-4a3f-8b1a-6b3866caf999,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-42dbbab5-d3bb-4cf8-ba7c-ac147b0c502b,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-048b448e-e301-4262-a3e9-3db32dbe28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-f413d3ae-22e9-4ef5-a423-3bec69b06cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-d517baff-b710-43e7-8575-0cabb8a54c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-8d98ce41-61a7-48c2-b704-c6133918cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084168677-172.17.0.11-1598363218212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38884,DS-38f04604-b36a-4bb7-ab2e-1ab45fe20049,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-0fa40578-1f3e-4058-87cb-05ad2748ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-49d48a19-e7ac-4a3f-8b1a-6b3866caf999,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-42dbbab5-d3bb-4cf8-ba7c-ac147b0c502b,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-048b448e-e301-4262-a3e9-3db32dbe28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-f413d3ae-22e9-4ef5-a423-3bec69b06cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-d517baff-b710-43e7-8575-0cabb8a54c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-8d98ce41-61a7-48c2-b704-c6133918cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306000819-172.17.0.11-1598364269550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-87b8013b-e3ec-4b9f-8705-117795854698,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9c7af7a8-f0f9-44ba-a328-1050d99529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-a749e453-fd32-4645-b94a-45700d37b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-6f985c83-31d7-4332-89f5-a8a338568bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-d23c5638-fbd1-4d52-8ce6-08d8f4843bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-419dbea3-e075-4efc-90f8-2bc9d7b66a57,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-8e96f493-0ad1-4681-ba57-d7988c64b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-f73bad96-3a6e-426a-bea1-2c5eb5778a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306000819-172.17.0.11-1598364269550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-87b8013b-e3ec-4b9f-8705-117795854698,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9c7af7a8-f0f9-44ba-a328-1050d99529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-a749e453-fd32-4645-b94a-45700d37b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-6f985c83-31d7-4332-89f5-a8a338568bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-d23c5638-fbd1-4d52-8ce6-08d8f4843bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-419dbea3-e075-4efc-90f8-2bc9d7b66a57,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-8e96f493-0ad1-4681-ba57-d7988c64b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-f73bad96-3a6e-426a-bea1-2c5eb5778a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884126042-172.17.0.11-1598364387030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-7bb32e2b-389b-47e9-b3fa-6ad8f2eba8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-73b8224a-507d-44d3-8b72-66255c1c91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-8fe764e1-40be-41ac-826d-c34725e4be78,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-cfdf22a9-53d0-4b17-b3c1-7c3a9e726eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-ac43040c-9f1b-40c3-8252-67a5ef3d3951,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-5c1916b1-3025-4067-b008-b2e5461f7601,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-0880808c-9c64-4ffa-959f-f3e7705013b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-f444fe66-4ebf-473b-a672-1336208f3dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884126042-172.17.0.11-1598364387030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-7bb32e2b-389b-47e9-b3fa-6ad8f2eba8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-73b8224a-507d-44d3-8b72-66255c1c91ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-8fe764e1-40be-41ac-826d-c34725e4be78,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-cfdf22a9-53d0-4b17-b3c1-7c3a9e726eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-ac43040c-9f1b-40c3-8252-67a5ef3d3951,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-5c1916b1-3025-4067-b008-b2e5461f7601,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-0880808c-9c64-4ffa-959f-f3e7705013b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-f444fe66-4ebf-473b-a672-1336208f3dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763425157-172.17.0.11-1598364802324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-a1340086-9ad6-4f64-a631-97fe97c710a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-dfcb4b4d-0cc1-4d31-8507-843c28dcba61,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-496e9218-358c-4850-9887-8de47ebd8141,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-19b5b79c-9248-4ef4-8a14-f15ccfe32c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-40449e21-5860-4b84-97a7-b4b3abebb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-1e1cd062-48c4-4adc-aabf-bc4a53d7dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-63e82583-a62b-46b0-9a00-2aa3e600f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-12d3640d-e570-4070-9814-1f626424ea93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763425157-172.17.0.11-1598364802324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-a1340086-9ad6-4f64-a631-97fe97c710a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-dfcb4b4d-0cc1-4d31-8507-843c28dcba61,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-496e9218-358c-4850-9887-8de47ebd8141,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-19b5b79c-9248-4ef4-8a14-f15ccfe32c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-40449e21-5860-4b84-97a7-b4b3abebb3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-1e1cd062-48c4-4adc-aabf-bc4a53d7dfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-63e82583-a62b-46b0-9a00-2aa3e600f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-12d3640d-e570-4070-9814-1f626424ea93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593416063-172.17.0.11-1598364956786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-20d1523d-b379-4d6c-9ea9-1104cb466808,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-1a31bae0-3df5-473b-9246-e3a4ed45e896,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-49a838b0-1994-4ada-a17d-cdbbcf78beff,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-368a8bed-4c3d-42ec-bbf4-cf2e10af9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-2bb0adcf-f927-4d72-a82c-7ca07cfdc28f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-6f3f60ab-6d8e-4de5-b1a2-dff2d43f1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-51159ec9-70e9-43a5-80db-97039af6ad60,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a87d1e80-023f-4abc-ac4e-96850301a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593416063-172.17.0.11-1598364956786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-20d1523d-b379-4d6c-9ea9-1104cb466808,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-1a31bae0-3df5-473b-9246-e3a4ed45e896,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-49a838b0-1994-4ada-a17d-cdbbcf78beff,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-368a8bed-4c3d-42ec-bbf4-cf2e10af9cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-2bb0adcf-f927-4d72-a82c-7ca07cfdc28f,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-6f3f60ab-6d8e-4de5-b1a2-dff2d43f1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-51159ec9-70e9-43a5-80db-97039af6ad60,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a87d1e80-023f-4abc-ac4e-96850301a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579263947-172.17.0.11-1598365187949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-84cfcf59-0f53-4be5-a97e-2e2b5b825753,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-3c2398ba-f3fe-412f-8ee7-b7180fe440d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-453f8848-85b6-48d5-8610-e6a055edfe75,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b973464e-bae9-4868-9f73-e2e94ae41a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-c3ffedfb-6f73-4020-bddf-b1523feb961d,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-68ffcaff-03b7-47a3-941e-7d3bba55eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-e557dcc2-47d6-4d53-a6e4-ff757b6217be,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-6f8c7a23-a06d-4b92-9872-c42d14c27caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579263947-172.17.0.11-1598365187949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-84cfcf59-0f53-4be5-a97e-2e2b5b825753,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-3c2398ba-f3fe-412f-8ee7-b7180fe440d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-453f8848-85b6-48d5-8610-e6a055edfe75,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b973464e-bae9-4868-9f73-e2e94ae41a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-c3ffedfb-6f73-4020-bddf-b1523feb961d,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-68ffcaff-03b7-47a3-941e-7d3bba55eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-e557dcc2-47d6-4d53-a6e4-ff757b6217be,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-6f8c7a23-a06d-4b92-9872-c42d14c27caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469090867-172.17.0.11-1598365431306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44860,DS-7b1943f2-53b6-48db-b6b6-99bc4273bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-2a52c101-d0b4-4c01-ad98-6b9151ed6353,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-6351556c-9b66-4675-8906-3f8de73a7343,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-550303b0-df07-4606-a052-7345a6b20942,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-d3d3ecf9-71cf-4102-9069-0c01b318f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-4597149a-7362-44d9-8bdf-969bc1bcf032,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-8a1abe8b-9f20-4a3e-bda0-3135cec5871a,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-2152d2c3-aa73-4059-a2e5-42305d74f61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469090867-172.17.0.11-1598365431306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44860,DS-7b1943f2-53b6-48db-b6b6-99bc4273bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-2a52c101-d0b4-4c01-ad98-6b9151ed6353,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-6351556c-9b66-4675-8906-3f8de73a7343,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-550303b0-df07-4606-a052-7345a6b20942,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-d3d3ecf9-71cf-4102-9069-0c01b318f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-4597149a-7362-44d9-8bdf-969bc1bcf032,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-8a1abe8b-9f20-4a3e-bda0-3135cec5871a,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-2152d2c3-aa73-4059-a2e5-42305d74f61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44331413-172.17.0.11-1598365527591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-7efee979-25a5-428e-afe0-bb7417251827,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-8c0d88d8-3ed0-4d3e-8d79-bf95b71b47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-c45e9b94-7b2d-4f61-a6d5-7f2fa864e086,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-07d17db3-32d5-46a0-8740-9a43adef13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-94ad6a7e-a783-47a1-9568-f819fff14a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-8bba8a02-b203-4b04-8ea9-a55ed0ca105d,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-d51eed98-863f-4bd2-92d7-9510b5b12856,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-996b2fc6-f597-46a9-aa27-8dcbf1dd626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44331413-172.17.0.11-1598365527591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-7efee979-25a5-428e-afe0-bb7417251827,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-8c0d88d8-3ed0-4d3e-8d79-bf95b71b47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-c45e9b94-7b2d-4f61-a6d5-7f2fa864e086,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-07d17db3-32d5-46a0-8740-9a43adef13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-94ad6a7e-a783-47a1-9568-f819fff14a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-8bba8a02-b203-4b04-8ea9-a55ed0ca105d,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-d51eed98-863f-4bd2-92d7-9510b5b12856,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-996b2fc6-f597-46a9-aa27-8dcbf1dd626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5125
