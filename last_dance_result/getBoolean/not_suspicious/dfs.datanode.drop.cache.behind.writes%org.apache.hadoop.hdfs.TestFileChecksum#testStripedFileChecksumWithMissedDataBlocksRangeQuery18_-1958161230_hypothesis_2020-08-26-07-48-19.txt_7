reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048061212-172.17.0.3-1598428354790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-7101681f-2fce-4d5d-8577-c80b66fb35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-dc7e3fd7-901d-4d80-833d-a8eb1a463a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-957cd1c5-fc21-4789-a3d1-302c136190e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-0578c858-930c-4012-b7d4-be887fb7dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-a225d745-4c57-4711-96fe-1a79d0b01a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-bce6b1f5-7095-43b4-aa40-2547a7de3907,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-07aeef6f-2b90-4669-b1b7-01be26d1f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-da7f8fee-4ecb-4315-a8f0-1565a515dc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048061212-172.17.0.3-1598428354790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-7101681f-2fce-4d5d-8577-c80b66fb35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-dc7e3fd7-901d-4d80-833d-a8eb1a463a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-957cd1c5-fc21-4789-a3d1-302c136190e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-0578c858-930c-4012-b7d4-be887fb7dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-a225d745-4c57-4711-96fe-1a79d0b01a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-bce6b1f5-7095-43b4-aa40-2547a7de3907,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-07aeef6f-2b90-4669-b1b7-01be26d1f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-da7f8fee-4ecb-4315-a8f0-1565a515dc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047513207-172.17.0.3-1598428447869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-97f42a8c-4f90-42b3-b910-99e34e215a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-342df38c-46a5-4997-ac79-2341123a9869,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-bda790e0-afaa-4d57-9ce4-2879622f304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-aac455a7-98b1-4c49-81f6-fb2655e3f227,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-7a01bd68-a08c-4caa-805d-f353a491100b,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-a6980a4d-249d-495a-981f-deb3a96322ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-32cc61af-5500-401e-ac86-e004d47facd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-5d25dd59-373f-42fb-9e10-77e029e80520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047513207-172.17.0.3-1598428447869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-97f42a8c-4f90-42b3-b910-99e34e215a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-342df38c-46a5-4997-ac79-2341123a9869,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-bda790e0-afaa-4d57-9ce4-2879622f304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-aac455a7-98b1-4c49-81f6-fb2655e3f227,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-7a01bd68-a08c-4caa-805d-f353a491100b,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-a6980a4d-249d-495a-981f-deb3a96322ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-32cc61af-5500-401e-ac86-e004d47facd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-5d25dd59-373f-42fb-9e10-77e029e80520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851895578-172.17.0.3-1598428780467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-4b84b6f7-a6cb-4387-a155-59537adf9efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-000789c0-78b7-4c46-a08c-c6ab0d684991,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-616703e0-583b-48b8-a63e-de08ab3ea821,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-7aaa7987-651c-458c-a397-9a72d7a24782,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-df9315d6-1433-4b23-b136-b12be0254698,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ae6636c0-1cd1-4b45-adc2-25dc19e81579,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-2f6dd852-e7f4-42e4-b035-bb918ef8ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-5517d3ca-1c32-4458-8937-2c213dcad330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851895578-172.17.0.3-1598428780467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-4b84b6f7-a6cb-4387-a155-59537adf9efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-000789c0-78b7-4c46-a08c-c6ab0d684991,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-616703e0-583b-48b8-a63e-de08ab3ea821,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-7aaa7987-651c-458c-a397-9a72d7a24782,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-df9315d6-1433-4b23-b136-b12be0254698,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ae6636c0-1cd1-4b45-adc2-25dc19e81579,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-2f6dd852-e7f4-42e4-b035-bb918ef8ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-5517d3ca-1c32-4458-8937-2c213dcad330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073450717-172.17.0.3-1598429536772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-afabedd7-99a6-4928-ad45-b2b5b0805d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-fca85b60-1195-4bd1-8c6d-9dcdd208b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-f0df8176-1095-4b8d-80ef-768bd8e9a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-014a3eb4-52a7-48a2-aa63-19183d7f1062,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-42efb52b-f5c8-4745-a6a4-7d6c5358f008,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-85d8ca42-33ba-4165-acdb-d08e1763efba,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-507926d3-5d95-442b-ad17-ba734a785311,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-6f7dba1c-af30-4445-a626-4b1b28847f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073450717-172.17.0.3-1598429536772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-afabedd7-99a6-4928-ad45-b2b5b0805d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-fca85b60-1195-4bd1-8c6d-9dcdd208b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-f0df8176-1095-4b8d-80ef-768bd8e9a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-014a3eb4-52a7-48a2-aa63-19183d7f1062,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-42efb52b-f5c8-4745-a6a4-7d6c5358f008,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-85d8ca42-33ba-4165-acdb-d08e1763efba,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-507926d3-5d95-442b-ad17-ba734a785311,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-6f7dba1c-af30-4445-a626-4b1b28847f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728736869-172.17.0.3-1598430266033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-a2bed684-4ed1-4d2e-b1b5-d8246a30c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-bc1fae56-4df7-47d8-b650-483723aac9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-722fc6ad-074f-41d6-9dc3-8e91319a71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-a5140859-d475-4a16-b044-1e1ec9a6b652,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-bff08959-bb8b-48e6-bccc-dcedef135dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-605c9ea0-5e38-432f-b597-91dd5af524b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-17870bde-279d-4a39-8d7a-7e6a34f99290,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-be55d9cc-297c-4235-83de-f2a589f803c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728736869-172.17.0.3-1598430266033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-a2bed684-4ed1-4d2e-b1b5-d8246a30c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-bc1fae56-4df7-47d8-b650-483723aac9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-722fc6ad-074f-41d6-9dc3-8e91319a71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-a5140859-d475-4a16-b044-1e1ec9a6b652,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-bff08959-bb8b-48e6-bccc-dcedef135dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-605c9ea0-5e38-432f-b597-91dd5af524b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-17870bde-279d-4a39-8d7a-7e6a34f99290,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-be55d9cc-297c-4235-83de-f2a589f803c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339050519-172.17.0.3-1598430935433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-5ec8ad93-60f1-496b-932b-62e412a06ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-10b06294-f76e-443e-abc5-b0714ce39067,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e63b1efe-5b88-4a5f-8c4c-75e33f75871d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-a3f10272-b3e3-41db-8935-25c36e0964f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-1fa52cde-2c43-47eb-ab2d-288d63a99b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-36302710-285f-41bc-ba85-fec53bb49ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ff417388-45ee-4213-972f-43c7b443749b,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-dc4d928c-817e-4367-a11a-5dae1a3ce8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339050519-172.17.0.3-1598430935433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-5ec8ad93-60f1-496b-932b-62e412a06ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-10b06294-f76e-443e-abc5-b0714ce39067,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e63b1efe-5b88-4a5f-8c4c-75e33f75871d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-a3f10272-b3e3-41db-8935-25c36e0964f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-1fa52cde-2c43-47eb-ab2d-288d63a99b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-36302710-285f-41bc-ba85-fec53bb49ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ff417388-45ee-4213-972f-43c7b443749b,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-dc4d928c-817e-4367-a11a-5dae1a3ce8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688100977-172.17.0.3-1598431506217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-72e0523a-aef6-4db1-aeae-d1c9e4f527ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-44da923d-7b02-467e-b323-91763b4d7a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-8d94bd58-04d7-4c6a-8f76-0fe4b595d689,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-b293d5d1-4ea7-4399-a91d-a010d30dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-95296448-3088-45b6-863b-69bcb0285474,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-ad2cb2a1-bd34-49b5-9b87-46263e076884,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-d3622de9-7f12-4560-a7fe-8ef3f890b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-21caaeab-b4f3-4714-b576-2e6e8c79f8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688100977-172.17.0.3-1598431506217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-72e0523a-aef6-4db1-aeae-d1c9e4f527ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-44da923d-7b02-467e-b323-91763b4d7a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-8d94bd58-04d7-4c6a-8f76-0fe4b595d689,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-b293d5d1-4ea7-4399-a91d-a010d30dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-95296448-3088-45b6-863b-69bcb0285474,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-ad2cb2a1-bd34-49b5-9b87-46263e076884,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-d3622de9-7f12-4560-a7fe-8ef3f890b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-21caaeab-b4f3-4714-b576-2e6e8c79f8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185762547-172.17.0.3-1598431664687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-cd712f11-1674-4e6a-8024-2d42bcc1d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-e8b5dfb4-0b3d-4705-92ad-2af795db249c,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0bc07ff2-a886-4ef3-b278-d762e3d2ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-bc4aee0f-37b0-4f3b-93a6-20b4d68afd59,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-6fa6fd93-1cbb-49e7-a105-0b8bd88b75a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-529eb0e3-93a7-49ce-a24d-de14379aa07c,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-a9cab4cf-d375-4868-9e38-795a0e8d4c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-63dd2581-eef3-4528-94e3-a04a2b2a2224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185762547-172.17.0.3-1598431664687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-cd712f11-1674-4e6a-8024-2d42bcc1d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-e8b5dfb4-0b3d-4705-92ad-2af795db249c,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-0bc07ff2-a886-4ef3-b278-d762e3d2ddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-bc4aee0f-37b0-4f3b-93a6-20b4d68afd59,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-6fa6fd93-1cbb-49e7-a105-0b8bd88b75a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-529eb0e3-93a7-49ce-a24d-de14379aa07c,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-a9cab4cf-d375-4868-9e38-795a0e8d4c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-63dd2581-eef3-4528-94e3-a04a2b2a2224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134434035-172.17.0.3-1598431866962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-00fcbe66-6121-4caf-ab4e-03562f554927,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-34cee188-cee5-4545-80bc-7fd76137f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-7841510a-b0d3-4d22-a617-f1198666dd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-40fd51ca-8a7e-4e40-9d7e-5e5e7374fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1bc6d4b6-9ea0-4d69-a1e9-456897f1f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-d3033c9b-bf46-474c-ac05-b4966d29c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-95d2328f-f08b-4256-bdbd-afb972e42ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-da719b61-70f2-4f86-b532-381903efcef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134434035-172.17.0.3-1598431866962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-00fcbe66-6121-4caf-ab4e-03562f554927,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-34cee188-cee5-4545-80bc-7fd76137f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-7841510a-b0d3-4d22-a617-f1198666dd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-40fd51ca-8a7e-4e40-9d7e-5e5e7374fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1bc6d4b6-9ea0-4d69-a1e9-456897f1f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-d3033c9b-bf46-474c-ac05-b4966d29c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-95d2328f-f08b-4256-bdbd-afb972e42ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-da719b61-70f2-4f86-b532-381903efcef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256100129-172.17.0.3-1598432198063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-3389be15-9118-484a-a570-1a868ccb58a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-ad0f6912-f7d0-4ee4-a93d-e8be45967790,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-8f670bbc-86e1-4d54-b3e1-95b0192c61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-3eb2ff2e-6248-4432-aec5-920c7c4316a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-76535cd7-9586-4b8f-8aba-4222ae4e3053,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-4461d614-6ed2-4257-ac75-3f0ee06b0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-e6a0e2b9-e4b9-48c9-b5fe-d5adc81d5b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-fbe78b8d-d677-4fbd-a524-eb51a95f2900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256100129-172.17.0.3-1598432198063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-3389be15-9118-484a-a570-1a868ccb58a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-ad0f6912-f7d0-4ee4-a93d-e8be45967790,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-8f670bbc-86e1-4d54-b3e1-95b0192c61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-3eb2ff2e-6248-4432-aec5-920c7c4316a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-76535cd7-9586-4b8f-8aba-4222ae4e3053,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-4461d614-6ed2-4257-ac75-3f0ee06b0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-e6a0e2b9-e4b9-48c9-b5fe-d5adc81d5b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-fbe78b8d-d677-4fbd-a524-eb51a95f2900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146719520-172.17.0.3-1598432347970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-498e2946-ad79-4b6e-9a31-e9756aa14cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-c4a2b437-2498-49a4-9500-d596aeed1256,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-55ddad24-6713-4801-8bbb-89a49da589f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-1f556343-b95c-4bd3-bf1a-781c7ab4530b,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-cdc3d7b7-113c-4770-892a-be62eee89d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-7ebada8f-f757-45ed-8c23-0d7755b70e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-2ea6d3f4-9c5c-4f05-bc28-6cb31c4a0228,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-52a01d37-9d9d-4031-b929-ffa6abbdf2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146719520-172.17.0.3-1598432347970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-498e2946-ad79-4b6e-9a31-e9756aa14cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-c4a2b437-2498-49a4-9500-d596aeed1256,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-55ddad24-6713-4801-8bbb-89a49da589f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-1f556343-b95c-4bd3-bf1a-781c7ab4530b,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-cdc3d7b7-113c-4770-892a-be62eee89d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-7ebada8f-f757-45ed-8c23-0d7755b70e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-2ea6d3f4-9c5c-4f05-bc28-6cb31c4a0228,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-52a01d37-9d9d-4031-b929-ffa6abbdf2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755007068-172.17.0.3-1598432384350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-8049f972-3c4f-4a74-96de-8ff374590bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-f1d63688-912c-45c8-8752-a5c339aa4479,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-553f7d3f-d521-407f-9041-8d0fbb173c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-05f1bf68-d3bf-4222-961d-11a1e44b9aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-f3c5242e-d2d6-4342-8be0-f1bc6a67f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-b932ab02-6e2d-467e-ad31-c5db471df59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-e1262ac8-460f-4587-80e3-01c221f1988d,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-566d5340-3a0d-4617-8cbe-89953d80deb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755007068-172.17.0.3-1598432384350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-8049f972-3c4f-4a74-96de-8ff374590bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-f1d63688-912c-45c8-8752-a5c339aa4479,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-553f7d3f-d521-407f-9041-8d0fbb173c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-05f1bf68-d3bf-4222-961d-11a1e44b9aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-f3c5242e-d2d6-4342-8be0-f1bc6a67f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-b932ab02-6e2d-467e-ad31-c5db471df59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-e1262ac8-460f-4587-80e3-01c221f1988d,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-566d5340-3a0d-4617-8cbe-89953d80deb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824263646-172.17.0.3-1598432519085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39806,DS-6f90e9df-5763-424b-83c9-bf588dc091e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-a219ea34-bc06-4790-9930-74490c94db1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-b1129644-a518-4719-90bc-0ec2dc5c0268,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-56250201-2387-4ab5-96d2-d8b3609b0900,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-ce2d9c52-ee7a-43e8-bc7f-217bc6c32c84,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-35f5e9c9-dd24-49e8-aa7f-322d11d41452,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-278c72ad-3c78-4827-8caa-ebe5199fba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-7fca779b-3a63-4d23-b12a-71a40b01e00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824263646-172.17.0.3-1598432519085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39806,DS-6f90e9df-5763-424b-83c9-bf588dc091e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-a219ea34-bc06-4790-9930-74490c94db1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-b1129644-a518-4719-90bc-0ec2dc5c0268,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-56250201-2387-4ab5-96d2-d8b3609b0900,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-ce2d9c52-ee7a-43e8-bc7f-217bc6c32c84,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-35f5e9c9-dd24-49e8-aa7f-322d11d41452,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-278c72ad-3c78-4827-8caa-ebe5199fba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-7fca779b-3a63-4d23-b12a-71a40b01e00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31766771-172.17.0.3-1598432622680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-4af87d9f-5696-44a6-ace0-af832c6126d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-2e041897-7900-44ea-97ce-92a155708d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c89b63e8-0ad5-4998-8ca8-f05a686d0669,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-04e500e0-8be3-436b-8f5a-ca7ad25f2da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-849f1ae9-dfcc-4a7c-af3b-df83a56babab,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a31ad488-c4c3-431f-a6c6-36b4df9121f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-a79ab8ba-9a37-481d-92f7-8321d1258c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-19a7f272-9e18-46e2-b387-906b11dd5563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31766771-172.17.0.3-1598432622680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-4af87d9f-5696-44a6-ace0-af832c6126d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-2e041897-7900-44ea-97ce-92a155708d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c89b63e8-0ad5-4998-8ca8-f05a686d0669,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-04e500e0-8be3-436b-8f5a-ca7ad25f2da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-849f1ae9-dfcc-4a7c-af3b-df83a56babab,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a31ad488-c4c3-431f-a6c6-36b4df9121f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-a79ab8ba-9a37-481d-92f7-8321d1258c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-19a7f272-9e18-46e2-b387-906b11dd5563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5159
