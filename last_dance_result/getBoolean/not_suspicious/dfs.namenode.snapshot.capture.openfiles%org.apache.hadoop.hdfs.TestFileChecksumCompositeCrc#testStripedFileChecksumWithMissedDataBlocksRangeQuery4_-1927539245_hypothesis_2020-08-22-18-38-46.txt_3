reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975201571-172.17.0.14-1598121926237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-19693a04-2b60-437c-8778-4fb66c4a8af1,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-ee03ce88-6c54-4231-828c-4ded754bfbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-975f9b3a-099a-4291-8ead-fe0f4e22101f,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-2aeaa90d-f7a6-45be-8da2-4115fb37f720,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-b851ef9c-1c24-4335-aaf9-0e7e90802018,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-cd3dea57-b89b-41f3-8183-3d9a00a8aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-227027e6-4667-454a-82cf-69cdfd61790e,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-da8ef222-8d44-4394-9f7e-dd8ad8027258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975201571-172.17.0.14-1598121926237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-19693a04-2b60-437c-8778-4fb66c4a8af1,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-ee03ce88-6c54-4231-828c-4ded754bfbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-975f9b3a-099a-4291-8ead-fe0f4e22101f,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-2aeaa90d-f7a6-45be-8da2-4115fb37f720,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-b851ef9c-1c24-4335-aaf9-0e7e90802018,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-cd3dea57-b89b-41f3-8183-3d9a00a8aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-227027e6-4667-454a-82cf-69cdfd61790e,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-da8ef222-8d44-4394-9f7e-dd8ad8027258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975056639-172.17.0.14-1598122562986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-954ab0bf-b6c0-45e9-b79e-29087fa859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-18f27c60-4a45-4ed1-9de3-b55d5fa6a364,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-444afe0a-e359-4a01-988b-304a5a7c28b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-4853c14f-d0ae-409e-b45c-60108fd50142,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-1213c475-e7a9-4f94-9f1e-8339f832c69d,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-6f4996a0-222e-45be-9e18-dfa59dd9e008,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-47d70aa3-8aa4-4350-846c-e5bed9a35b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e3c94e8b-3514-4644-a8b4-4d6e9602bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975056639-172.17.0.14-1598122562986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-954ab0bf-b6c0-45e9-b79e-29087fa859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-18f27c60-4a45-4ed1-9de3-b55d5fa6a364,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-444afe0a-e359-4a01-988b-304a5a7c28b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-4853c14f-d0ae-409e-b45c-60108fd50142,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-1213c475-e7a9-4f94-9f1e-8339f832c69d,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-6f4996a0-222e-45be-9e18-dfa59dd9e008,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-47d70aa3-8aa4-4350-846c-e5bed9a35b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e3c94e8b-3514-4644-a8b4-4d6e9602bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009568064-172.17.0.14-1598122920828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-5b5eb1ec-22f4-41a7-8aec-6b395d35ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ccb92f5b-7f4d-4ca3-85b0-d921449a3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-adae94c3-b2d2-4fbb-b9b9-4797c6eef21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-19040449-c43a-4d9f-b245-b5e26154083b,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-57177ad8-9167-4679-9596-5fa1bf16b605,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-a837febd-7485-4a50-888a-47ae4550eda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-320b1c46-683f-4597-9e8d-5e02ce59c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-7ea9191d-6ae3-48c1-940c-d34e2ed6d584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009568064-172.17.0.14-1598122920828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-5b5eb1ec-22f4-41a7-8aec-6b395d35ace6,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-ccb92f5b-7f4d-4ca3-85b0-d921449a3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-adae94c3-b2d2-4fbb-b9b9-4797c6eef21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-19040449-c43a-4d9f-b245-b5e26154083b,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-57177ad8-9167-4679-9596-5fa1bf16b605,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-a837febd-7485-4a50-888a-47ae4550eda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-320b1c46-683f-4597-9e8d-5e02ce59c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-7ea9191d-6ae3-48c1-940c-d34e2ed6d584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979982044-172.17.0.14-1598123008016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-9209402b-a292-4748-81a6-1afe7ad008c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-d0526ca2-9434-49d7-b7f5-75451220e408,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-f4a60f2b-0778-4ec0-a987-07b074fadab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f88220c6-9778-4c9d-9515-08fa71441a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b7ea8e94-0665-42c7-ac3b-a0e5522a1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-9f7cec1f-d4e9-4192-81b8-6fdc6e33c658,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-09b43faa-20cc-4192-bb9f-92e06583a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-0071ad15-2da6-444a-9f7b-766d4f34165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979982044-172.17.0.14-1598123008016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-9209402b-a292-4748-81a6-1afe7ad008c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-d0526ca2-9434-49d7-b7f5-75451220e408,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-f4a60f2b-0778-4ec0-a987-07b074fadab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f88220c6-9778-4c9d-9515-08fa71441a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-b7ea8e94-0665-42c7-ac3b-a0e5522a1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-9f7cec1f-d4e9-4192-81b8-6fdc6e33c658,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-09b43faa-20cc-4192-bb9f-92e06583a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-0071ad15-2da6-444a-9f7b-766d4f34165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611821479-172.17.0.14-1598123144503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-e6434620-d756-4ec2-9e6f-509a4d78757f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-25fcfa89-0abd-43db-8615-bd88e759004f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-e497deeb-c644-45a0-b730-9915bffd4474,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a197de1e-c488-4681-8508-b6843a2c973a,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-35d00251-3842-4755-a410-250d2de79b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-45ee6fd8-48eb-4c5b-b27c-7571c16cbc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-8026b4e7-405e-4c6a-9d4a-cd9171487850,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-f81fd07a-9bb2-4742-93b1-f1f1c41bc60b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611821479-172.17.0.14-1598123144503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-e6434620-d756-4ec2-9e6f-509a4d78757f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-25fcfa89-0abd-43db-8615-bd88e759004f,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-e497deeb-c644-45a0-b730-9915bffd4474,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a197de1e-c488-4681-8508-b6843a2c973a,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-35d00251-3842-4755-a410-250d2de79b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-45ee6fd8-48eb-4c5b-b27c-7571c16cbc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-8026b4e7-405e-4c6a-9d4a-cd9171487850,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-f81fd07a-9bb2-4742-93b1-f1f1c41bc60b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329511128-172.17.0.14-1598123239187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-1fa309ea-5454-47e3-baf8-7eb1cee0426f,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-94322d10-d328-47f7-8d79-17ad5d8a2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-cc96697d-de13-4539-8887-e3c024d1e056,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-18278c99-9213-4942-a779-d095e166e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-4f1c2909-8aa9-4290-aa83-be95b6491cac,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-149c6b85-b8ab-47e9-a740-26389ea53ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-1b9c3d96-8b52-4e3c-ac37-49755d450444,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-eda1d4c2-7710-4e41-8e70-9005530d72d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329511128-172.17.0.14-1598123239187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-1fa309ea-5454-47e3-baf8-7eb1cee0426f,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-94322d10-d328-47f7-8d79-17ad5d8a2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-cc96697d-de13-4539-8887-e3c024d1e056,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-18278c99-9213-4942-a779-d095e166e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-4f1c2909-8aa9-4290-aa83-be95b6491cac,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-149c6b85-b8ab-47e9-a740-26389ea53ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-1b9c3d96-8b52-4e3c-ac37-49755d450444,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-eda1d4c2-7710-4e41-8e70-9005530d72d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920753730-172.17.0.14-1598123455841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-44604440-b177-423d-b93f-ff0f410a1177,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-26206a44-17e9-424a-b023-160746fd3060,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-617cf102-5ba3-454b-bf33-54b318738719,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8a33423e-58b9-4bb6-a822-111c0e67a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-b50a25d9-bbbb-4518-802e-71b96d23777b,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-cf243f37-1544-4ca6-bd3b-2a793e99cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-3f90530d-7075-4828-b082-98545fc69745,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-313dfd33-f1a9-44fd-88b6-983defe15426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920753730-172.17.0.14-1598123455841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-44604440-b177-423d-b93f-ff0f410a1177,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-26206a44-17e9-424a-b023-160746fd3060,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-617cf102-5ba3-454b-bf33-54b318738719,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8a33423e-58b9-4bb6-a822-111c0e67a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-b50a25d9-bbbb-4518-802e-71b96d23777b,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-cf243f37-1544-4ca6-bd3b-2a793e99cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-3f90530d-7075-4828-b082-98545fc69745,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-313dfd33-f1a9-44fd-88b6-983defe15426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836329169-172.17.0.14-1598123543671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-b0260faa-24e7-4ed7-a102-16c7db79f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7598356b-8e6b-460b-bcd3-4bc1906e3c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1e4c42d3-0750-4974-a0d0-460ef01d0ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-842d23f0-9b6a-4ab5-8c2f-e4a3ba6aa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-d9982f6f-f5a5-49c9-b075-fb44c56ac2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-3c7fa952-b234-47a2-8965-90cd4179cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-134a5974-e02c-4078-b4da-a3922a48b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-23b48ce7-3432-46c1-bab3-e0e707173997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836329169-172.17.0.14-1598123543671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-b0260faa-24e7-4ed7-a102-16c7db79f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7598356b-8e6b-460b-bcd3-4bc1906e3c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-1e4c42d3-0750-4974-a0d0-460ef01d0ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-842d23f0-9b6a-4ab5-8c2f-e4a3ba6aa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-d9982f6f-f5a5-49c9-b075-fb44c56ac2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-3c7fa952-b234-47a2-8965-90cd4179cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-134a5974-e02c-4078-b4da-a3922a48b2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-23b48ce7-3432-46c1-bab3-e0e707173997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496885695-172.17.0.14-1598123691752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41660,DS-adb54dfc-fc9d-4831-9c35-59e9bcfae0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ad807313-4928-483d-b961-07971287374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c6f45171-4433-4590-b7c2-0bb4b0148f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-e62d83bd-9e98-477e-9a94-4ec8e697835a,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-4ef4cb3f-62c8-4c7b-a27a-e1cc21ef3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-58e1612a-6242-4f8d-b588-0981eda30926,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-933e7ead-9020-4734-bccb-af3d861763d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-ec1718fe-d7a3-4b2c-8215-78167a0d2606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496885695-172.17.0.14-1598123691752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41660,DS-adb54dfc-fc9d-4831-9c35-59e9bcfae0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ad807313-4928-483d-b961-07971287374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c6f45171-4433-4590-b7c2-0bb4b0148f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-e62d83bd-9e98-477e-9a94-4ec8e697835a,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-4ef4cb3f-62c8-4c7b-a27a-e1cc21ef3fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-58e1612a-6242-4f8d-b588-0981eda30926,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-933e7ead-9020-4734-bccb-af3d861763d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-ec1718fe-d7a3-4b2c-8215-78167a0d2606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523997724-172.17.0.14-1598123767290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-9536a32a-42a1-44f2-976b-9ee213b7d188,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-b10ffda6-3dbb-4491-90d5-95189d36bf28,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-922c9f08-6190-48b8-9a89-e92891c1ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-3400ecc0-99ed-48a2-9091-c4a971988955,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-a060b623-45e6-41fc-8277-f576c09626e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-37454df8-ff97-429f-9adf-ce31097fabdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-ac31219b-4067-4134-bf10-9653729bea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f0b40573-9337-4670-bb58-b7b8c2060af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523997724-172.17.0.14-1598123767290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-9536a32a-42a1-44f2-976b-9ee213b7d188,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-b10ffda6-3dbb-4491-90d5-95189d36bf28,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-922c9f08-6190-48b8-9a89-e92891c1ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-3400ecc0-99ed-48a2-9091-c4a971988955,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-a060b623-45e6-41fc-8277-f576c09626e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-37454df8-ff97-429f-9adf-ce31097fabdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-ac31219b-4067-4134-bf10-9653729bea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f0b40573-9337-4670-bb58-b7b8c2060af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641710193-172.17.0.14-1598124174764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-fe1beb4c-ed57-4dda-817d-55ee796d6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-6cc56deb-752a-4b82-bbc0-f0266a757863,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-326dece7-3790-4717-bef5-908b4ab3bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3cfc7b18-d74a-4c00-b2df-1b1a0787cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-61883204-997b-450f-8750-106e038fe08e,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1e2402a6-d4ef-468d-8f0e-d1217c9a10ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-21f8a17f-e4e9-453f-aecc-288e43dcc7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-099d3f82-59a7-40f5-931b-18d110b4bd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641710193-172.17.0.14-1598124174764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-fe1beb4c-ed57-4dda-817d-55ee796d6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-6cc56deb-752a-4b82-bbc0-f0266a757863,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-326dece7-3790-4717-bef5-908b4ab3bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3cfc7b18-d74a-4c00-b2df-1b1a0787cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-61883204-997b-450f-8750-106e038fe08e,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1e2402a6-d4ef-468d-8f0e-d1217c9a10ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-21f8a17f-e4e9-453f-aecc-288e43dcc7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-099d3f82-59a7-40f5-931b-18d110b4bd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672226718-172.17.0.14-1598124956731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-48b6f6c8-bb11-459b-889e-72fe111736b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-08963433-69f4-40ad-8751-6ba45b1e785c,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-6382a51f-ac1e-4cb0-a4a6-341c10c9ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-9aedce64-3701-4d1a-9101-6a32487b8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-02b89c92-847a-4716-9226-690dc17b54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-cb599c5c-af31-4d31-bcd1-0e7f998906be,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3f56eb76-b0d6-48a3-abcf-dd8d4fbcf899,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-7ffb7057-32ad-4c00-b520-6384f4d36174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672226718-172.17.0.14-1598124956731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-48b6f6c8-bb11-459b-889e-72fe111736b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-08963433-69f4-40ad-8751-6ba45b1e785c,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-6382a51f-ac1e-4cb0-a4a6-341c10c9ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-9aedce64-3701-4d1a-9101-6a32487b8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-02b89c92-847a-4716-9226-690dc17b54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-cb599c5c-af31-4d31-bcd1-0e7f998906be,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3f56eb76-b0d6-48a3-abcf-dd8d4fbcf899,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-7ffb7057-32ad-4c00-b520-6384f4d36174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293542923-172.17.0.14-1598125874711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-f73a4b25-e633-4205-8984-6c992e2bd234,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b0aace2f-0367-4dd0-abd2-f72901a2c186,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-234370f2-adfc-4a73-8d51-46bf78f60891,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-792d15d1-ee42-462f-8d64-96512b5338fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-1066003b-fbed-4b63-8f27-ed04df98d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-bb34458a-ff25-48a8-9524-11c92a442f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-11b64b1c-e009-4172-a598-b590159b6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-50d2c299-7b52-435f-bb52-ad7d27eb8e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293542923-172.17.0.14-1598125874711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34963,DS-f73a4b25-e633-4205-8984-6c992e2bd234,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b0aace2f-0367-4dd0-abd2-f72901a2c186,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-234370f2-adfc-4a73-8d51-46bf78f60891,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-792d15d1-ee42-462f-8d64-96512b5338fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-1066003b-fbed-4b63-8f27-ed04df98d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-bb34458a-ff25-48a8-9524-11c92a442f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-11b64b1c-e009-4172-a598-b590159b6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-50d2c299-7b52-435f-bb52-ad7d27eb8e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580917999-172.17.0.14-1598126024006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-457199e3-d1ee-44fb-99e3-1e1d3a3713b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-7f7aad06-9e62-4231-9f7f-a463ac750842,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-0c604e77-8926-4690-b4b5-a7c339caffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d6c9851c-aae7-497f-8ef9-aef88f19e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-078fa219-6c31-4dac-b626-275ed6ffe62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-bd93f67d-449f-4264-b189-6d6fe2d3e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-225e1e30-095f-4b42-a33f-ee1e84b43669,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-88517d14-9f3f-4b23-ba4e-58b6517f44b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580917999-172.17.0.14-1598126024006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-457199e3-d1ee-44fb-99e3-1e1d3a3713b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-7f7aad06-9e62-4231-9f7f-a463ac750842,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-0c604e77-8926-4690-b4b5-a7c339caffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d6c9851c-aae7-497f-8ef9-aef88f19e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-078fa219-6c31-4dac-b626-275ed6ffe62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-bd93f67d-449f-4264-b189-6d6fe2d3e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-225e1e30-095f-4b42-a33f-ee1e84b43669,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-88517d14-9f3f-4b23-ba4e-58b6517f44b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4913
