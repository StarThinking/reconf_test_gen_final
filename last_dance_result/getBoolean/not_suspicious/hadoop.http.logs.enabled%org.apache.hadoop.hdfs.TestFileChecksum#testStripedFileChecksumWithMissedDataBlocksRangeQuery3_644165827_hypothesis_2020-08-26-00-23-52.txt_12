reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574208384-172.17.0.18-1598401766219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-625e7420-b3ae-4c57-a515-1adfc33bccff,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-9584f873-8efb-41ee-83e8-82452c35a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-5e45c99e-ad01-4d51-ad62-864a2a39c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-83146b7d-699b-483f-a88c-909fc9ecbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-3173cbe3-efa5-407e-9825-7871ebec183a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-b771a05b-b68c-4aba-b7b3-c1a9947c21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e4143aef-519d-4d78-8a38-3ecb7b47db59,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-97c535db-cf77-45f9-9d9c-279f4a7ed5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574208384-172.17.0.18-1598401766219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-625e7420-b3ae-4c57-a515-1adfc33bccff,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-9584f873-8efb-41ee-83e8-82452c35a3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-5e45c99e-ad01-4d51-ad62-864a2a39c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-83146b7d-699b-483f-a88c-909fc9ecbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-3173cbe3-efa5-407e-9825-7871ebec183a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-b771a05b-b68c-4aba-b7b3-c1a9947c21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e4143aef-519d-4d78-8a38-3ecb7b47db59,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-97c535db-cf77-45f9-9d9c-279f4a7ed5c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106578870-172.17.0.18-1598401844127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-134d979b-9080-43e6-9159-1dbf0f5ea3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-74a6d8a8-9b65-4af1-8082-086b89f4d791,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-0667e1de-a737-4e44-b12f-607714f7af79,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-e81e30ef-761d-4145-9f0d-b656116af765,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-49da4356-e7bb-4d90-b29f-38e45ac4af09,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-9268128a-7113-466c-9c8e-ca8b45362bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-1753c3f6-b6cd-4032-8e8c-3b9a3465cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-2a29b1ff-899c-4814-9522-4e69b67ffc01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106578870-172.17.0.18-1598401844127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-134d979b-9080-43e6-9159-1dbf0f5ea3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-74a6d8a8-9b65-4af1-8082-086b89f4d791,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-0667e1de-a737-4e44-b12f-607714f7af79,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-e81e30ef-761d-4145-9f0d-b656116af765,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-49da4356-e7bb-4d90-b29f-38e45ac4af09,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-9268128a-7113-466c-9c8e-ca8b45362bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-1753c3f6-b6cd-4032-8e8c-3b9a3465cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-2a29b1ff-899c-4814-9522-4e69b67ffc01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203134042-172.17.0.18-1598402401547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39133,DS-83fbee0f-448e-4a01-a85e-97200b09c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-8310110b-e165-42df-b39b-3d8a2c315460,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-96e70b87-1ce8-40cf-849e-0a1530bf0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-09bf5ed7-9943-4aef-8068-3a90a3b9675f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-0f8bc000-9f5e-4a47-a347-aaae987b3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-5cfd675c-84ef-4c1b-be45-e5d670e78627,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d0f8f454-28b0-45c6-9365-bcb41846b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-6529da43-1974-4f4c-9eee-d21bba72a536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203134042-172.17.0.18-1598402401547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39133,DS-83fbee0f-448e-4a01-a85e-97200b09c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-8310110b-e165-42df-b39b-3d8a2c315460,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-96e70b87-1ce8-40cf-849e-0a1530bf0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-09bf5ed7-9943-4aef-8068-3a90a3b9675f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-0f8bc000-9f5e-4a47-a347-aaae987b3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-5cfd675c-84ef-4c1b-be45-e5d670e78627,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d0f8f454-28b0-45c6-9365-bcb41846b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-6529da43-1974-4f4c-9eee-d21bba72a536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121317549-172.17.0.18-1598402487147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-a96dce49-5ed2-4230-a2b9-4875c0c5aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-64d81730-1c3a-4594-a82c-3c77ed72ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-17e3d92b-e27d-457b-a7f7-62664dba7a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f7302936-fec9-4498-9e5e-4840727514ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-0c244f33-7d56-4970-89cc-a0250a81d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-26d0065f-38bb-4540-9835-49253189a42a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-9d51f3db-d801-4eb8-a3aa-2ed1eb42f869,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-1affce44-acb7-4466-982b-ddae23e82f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121317549-172.17.0.18-1598402487147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-a96dce49-5ed2-4230-a2b9-4875c0c5aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-64d81730-1c3a-4594-a82c-3c77ed72ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-17e3d92b-e27d-457b-a7f7-62664dba7a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f7302936-fec9-4498-9e5e-4840727514ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-0c244f33-7d56-4970-89cc-a0250a81d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-26d0065f-38bb-4540-9835-49253189a42a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-9d51f3db-d801-4eb8-a3aa-2ed1eb42f869,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-1affce44-acb7-4466-982b-ddae23e82f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656231172-172.17.0.18-1598403194585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-416ce3b9-725f-44f3-8480-1127f0c5b19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-04601460-f48d-4ebd-ae3a-7459a78d6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-5b7c2b80-3e1a-4e28-b933-be678ee40d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-dd55205c-3029-46b1-a42c-25c87a9cb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e0904a73-d0d5-4086-a1cc-0ac694014d27,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-8338d168-c6d3-4a6b-b465-f0e49874e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f992ae32-d9fd-46a9-b8c2-ae8a76835b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-6a1c044b-6431-41b6-87f9-40b45997aa64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656231172-172.17.0.18-1598403194585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-416ce3b9-725f-44f3-8480-1127f0c5b19f,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-04601460-f48d-4ebd-ae3a-7459a78d6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-5b7c2b80-3e1a-4e28-b933-be678ee40d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-dd55205c-3029-46b1-a42c-25c87a9cb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e0904a73-d0d5-4086-a1cc-0ac694014d27,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-8338d168-c6d3-4a6b-b465-f0e49874e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f992ae32-d9fd-46a9-b8c2-ae8a76835b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-6a1c044b-6431-41b6-87f9-40b45997aa64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547586513-172.17.0.18-1598403346209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-a04f1e4f-7d00-435a-8a70-0fa770e96de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0d017988-bdcf-4bf2-b3f5-20c4c65e2276,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-08702a8b-7611-41fa-8156-ad350c8b7247,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-1c4cd407-2af7-4940-b7d7-52d6e505882c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-8ad5ab07-fae6-4c8d-b370-1cba9915b761,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-13c07aa5-fbe8-46ee-bc46-6824a6ec8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-8dcf2392-9f2b-4524-8362-cbf0878595b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-67830afd-b7fd-4bcf-a485-d4e655a46685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547586513-172.17.0.18-1598403346209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39707,DS-a04f1e4f-7d00-435a-8a70-0fa770e96de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0d017988-bdcf-4bf2-b3f5-20c4c65e2276,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-08702a8b-7611-41fa-8156-ad350c8b7247,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-1c4cd407-2af7-4940-b7d7-52d6e505882c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-8ad5ab07-fae6-4c8d-b370-1cba9915b761,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-13c07aa5-fbe8-46ee-bc46-6824a6ec8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-8dcf2392-9f2b-4524-8362-cbf0878595b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-67830afd-b7fd-4bcf-a485-d4e655a46685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656264611-172.17.0.18-1598403989781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-8529a05c-f9eb-4c8c-94a4-8c0217247ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-ab3314ad-0485-4ab6-bbe2-5343c0637e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-eecb45a5-b1f9-467b-842c-7c16f196efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b4f8e934-9dcc-41f7-a9c0-5938e911d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-3c4f40ca-1a59-49b4-b460-d231a417f0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-972b8b26-166e-46b9-bd5b-a4acd671dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-c74d507a-3aeb-45f3-9098-fcf9da2938b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-46d7f201-789b-4519-aa58-bfa4a75995eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656264611-172.17.0.18-1598403989781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-8529a05c-f9eb-4c8c-94a4-8c0217247ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-ab3314ad-0485-4ab6-bbe2-5343c0637e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-eecb45a5-b1f9-467b-842c-7c16f196efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b4f8e934-9dcc-41f7-a9c0-5938e911d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-3c4f40ca-1a59-49b4-b460-d231a417f0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-972b8b26-166e-46b9-bd5b-a4acd671dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-c74d507a-3aeb-45f3-9098-fcf9da2938b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-46d7f201-789b-4519-aa58-bfa4a75995eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987436685-172.17.0.18-1598404157180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-39c1803f-757e-486a-89bd-a9650100af23,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-4da04cf1-fb83-4cef-943b-44658d8e62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-2ff13d63-030b-421f-8c1f-55e6eb88fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-f32fc758-1646-448f-92b7-e022f2958281,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-5efc1e1a-44d1-4749-8841-05f69dd97147,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-248f754a-3232-4da9-abee-0b6a0787f287,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-ec8b9958-0ace-47cd-a7a9-964a14bc0124,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-2dd7ab78-a676-49ee-88ed-2c03e1369f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987436685-172.17.0.18-1598404157180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36486,DS-39c1803f-757e-486a-89bd-a9650100af23,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-4da04cf1-fb83-4cef-943b-44658d8e62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-2ff13d63-030b-421f-8c1f-55e6eb88fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-f32fc758-1646-448f-92b7-e022f2958281,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-5efc1e1a-44d1-4749-8841-05f69dd97147,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-248f754a-3232-4da9-abee-0b6a0787f287,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-ec8b9958-0ace-47cd-a7a9-964a14bc0124,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-2dd7ab78-a676-49ee-88ed-2c03e1369f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268696895-172.17.0.18-1598404680906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-ef2b0181-59d5-4458-bb6c-a4dcc37cb423,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-58844bb4-b5c9-48e0-b846-1f87b26a916d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-3345d80a-5eab-4df0-ae35-dcfadaac7dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-5fafaccf-9c55-4ebd-bb3f-25ea727e4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-2f3010a3-285f-4e61-8ace-ba3fef3690e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-55b97ab6-4012-417d-bf3a-4d0c3c6b3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-26fc565f-c773-40f2-8689-17d0a5f2c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f8f5d7c5-c68c-41e9-9520-ccf56f98e3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268696895-172.17.0.18-1598404680906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-ef2b0181-59d5-4458-bb6c-a4dcc37cb423,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-58844bb4-b5c9-48e0-b846-1f87b26a916d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-3345d80a-5eab-4df0-ae35-dcfadaac7dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-5fafaccf-9c55-4ebd-bb3f-25ea727e4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-2f3010a3-285f-4e61-8ace-ba3fef3690e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-55b97ab6-4012-417d-bf3a-4d0c3c6b3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-26fc565f-c773-40f2-8689-17d0a5f2c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f8f5d7c5-c68c-41e9-9520-ccf56f98e3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669464823-172.17.0.18-1598405092613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-026478bf-24ca-4190-87a9-3abaa5261eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-56926823-3f40-4303-bce9-70f03d3ff4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-18e10527-f2fe-458e-be9f-0ca5b21b48f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-253dde4c-b49e-4527-9932-b773b91f6379,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-17ec6f6d-7309-4e2b-a84f-9696d9369911,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-0f5de45a-1514-4217-9752-5930b825166d,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5a4a9d04-a3d4-4496-9354-6cbf39004787,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-92567571-6edf-494b-a484-842c0780e208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669464823-172.17.0.18-1598405092613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44832,DS-026478bf-24ca-4190-87a9-3abaa5261eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-56926823-3f40-4303-bce9-70f03d3ff4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-18e10527-f2fe-458e-be9f-0ca5b21b48f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-253dde4c-b49e-4527-9932-b773b91f6379,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-17ec6f6d-7309-4e2b-a84f-9696d9369911,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-0f5de45a-1514-4217-9752-5930b825166d,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5a4a9d04-a3d4-4496-9354-6cbf39004787,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-92567571-6edf-494b-a484-842c0780e208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642467001-172.17.0.18-1598405629250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-0849178c-88a3-4e70-b0a5-f31f7af46944,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-56d8bf3a-073f-4869-a03c-e925321c114a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-fedc8531-edc1-40aa-83f5-39cc45f68495,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-01cee229-20b4-4d8d-9812-bcdf4a80b272,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-b77c411a-6a41-40ea-be15-c1ac22055f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-53a7f6e3-585b-475f-9bc9-28d3c0a666db,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-c75526fc-00c6-48cb-8a52-0329d422e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-77a10805-6a38-4022-9acd-38dbc5b1296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642467001-172.17.0.18-1598405629250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-0849178c-88a3-4e70-b0a5-f31f7af46944,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-56d8bf3a-073f-4869-a03c-e925321c114a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-fedc8531-edc1-40aa-83f5-39cc45f68495,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-01cee229-20b4-4d8d-9812-bcdf4a80b272,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-b77c411a-6a41-40ea-be15-c1ac22055f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-53a7f6e3-585b-475f-9bc9-28d3c0a666db,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-c75526fc-00c6-48cb-8a52-0329d422e1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-77a10805-6a38-4022-9acd-38dbc5b1296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366561405-172.17.0.18-1598406235528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-f5345df5-7820-445f-9b4c-fd9f674412ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-58f11823-9e5e-44f7-bd45-55f73811784b,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-a19a0c88-5001-4393-bcc8-5c9f164b21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-7e103266-5225-4c60-bfb6-fb8a3868ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-c9188f0b-2335-4eb6-b36b-6875c84c3ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6983ce37-e128-4364-a4bd-6e093cbf7e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-14c55ce7-4550-4a68-835b-a6f9d5d754ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-05712fe5-25f9-4fff-b302-4f3a47f64147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366561405-172.17.0.18-1598406235528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-f5345df5-7820-445f-9b4c-fd9f674412ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-58f11823-9e5e-44f7-bd45-55f73811784b,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-a19a0c88-5001-4393-bcc8-5c9f164b21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-7e103266-5225-4c60-bfb6-fb8a3868ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-c9188f0b-2335-4eb6-b36b-6875c84c3ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6983ce37-e128-4364-a4bd-6e093cbf7e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-14c55ce7-4550-4a68-835b-a6f9d5d754ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-05712fe5-25f9-4fff-b302-4f3a47f64147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142470699-172.17.0.18-1598406274610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-511f4049-641d-4bab-b300-d84ef98199f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-d687b5fd-798e-426f-9fb2-7152f5071ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-708ff8b6-2496-43ce-9baa-940cc4952fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-a5078c29-8e05-40d5-96fe-84746fd6d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-7fdd2ac5-d20c-4bb5-8b8a-97c02de54533,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-9c942cde-8a28-4722-87b7-f202ba8d1988,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2398b565-6bc3-4bd0-b099-95140fcbce94,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-e8ba3fc1-bc70-4f05-8915-d2039e1d1d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142470699-172.17.0.18-1598406274610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-511f4049-641d-4bab-b300-d84ef98199f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-d687b5fd-798e-426f-9fb2-7152f5071ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-708ff8b6-2496-43ce-9baa-940cc4952fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-a5078c29-8e05-40d5-96fe-84746fd6d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-7fdd2ac5-d20c-4bb5-8b8a-97c02de54533,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-9c942cde-8a28-4722-87b7-f202ba8d1988,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-2398b565-6bc3-4bd0-b099-95140fcbce94,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-e8ba3fc1-bc70-4f05-8915-d2039e1d1d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839647058-172.17.0.18-1598406608600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45805,DS-cb4c8b17-7de4-4426-a328-d3fb33c6fbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-968e532e-d694-4ab9-9830-7cd7bf96938e,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-ce10d594-2a5b-48a4-bf39-3c1dfb5f9704,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-647f6e39-259d-4307-b6d0-7c1e739e16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-5202509e-3d24-4782-b994-514b80c771de,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-d9984ea8-3352-41a8-8083-823c14900b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-14fe1f5c-025a-47a6-a6c0-9576c22cd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e9eb134b-6ee2-4096-b717-8a327a363643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839647058-172.17.0.18-1598406608600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45805,DS-cb4c8b17-7de4-4426-a328-d3fb33c6fbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-968e532e-d694-4ab9-9830-7cd7bf96938e,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-ce10d594-2a5b-48a4-bf39-3c1dfb5f9704,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-647f6e39-259d-4307-b6d0-7c1e739e16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-5202509e-3d24-4782-b994-514b80c771de,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-d9984ea8-3352-41a8-8083-823c14900b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-14fe1f5c-025a-47a6-a6c0-9576c22cd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e9eb134b-6ee2-4096-b717-8a327a363643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868786682-172.17.0.18-1598406899738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-42190ba8-2132-4d77-9d8b-55431d015226,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-c8ecaefa-f8d4-42b9-92a8-ebd05a1f725f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-60d039f6-bf30-4906-8e29-b3a419b2b999,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-91ff02ea-43ea-453f-83ea-93287c6a0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-99c0e582-90f1-4abf-9870-1e37fb0b67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-3aa26356-fd55-40b1-8165-01ced45a7690,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-ccec1084-d5cd-4437-8e53-4e032c0e980c,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-9798b572-9bc2-4a2d-9ad5-ed71ce29ae44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868786682-172.17.0.18-1598406899738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-42190ba8-2132-4d77-9d8b-55431d015226,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-c8ecaefa-f8d4-42b9-92a8-ebd05a1f725f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-60d039f6-bf30-4906-8e29-b3a419b2b999,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-91ff02ea-43ea-453f-83ea-93287c6a0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-99c0e582-90f1-4abf-9870-1e37fb0b67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-3aa26356-fd55-40b1-8165-01ced45a7690,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-ccec1084-d5cd-4437-8e53-4e032c0e980c,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-9798b572-9bc2-4a2d-9ad5-ed71ce29ae44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091422462-172.17.0.18-1598406935338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-3cbb7a07-db83-4745-ad44-d1821ccae1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-7bdbbcb4-7458-409a-bc0b-ff7aebc97d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-02413490-2dc6-4db1-a47d-31cb02f7069a,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-7dba4770-dfe6-4f10-981e-c53d375c058a,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-fdb905ce-9bbb-488c-b021-afc2c8359d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8e0336dd-e6a0-4478-b14d-17aeeb5cc014,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-eef9b0b9-1603-455e-9cd6-b6dbaeecc716,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-348b59e0-4d36-4ced-9c08-dd23fa0a6f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091422462-172.17.0.18-1598406935338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-3cbb7a07-db83-4745-ad44-d1821ccae1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-7bdbbcb4-7458-409a-bc0b-ff7aebc97d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-02413490-2dc6-4db1-a47d-31cb02f7069a,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-7dba4770-dfe6-4f10-981e-c53d375c058a,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-fdb905ce-9bbb-488c-b021-afc2c8359d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8e0336dd-e6a0-4478-b14d-17aeeb5cc014,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-eef9b0b9-1603-455e-9cd6-b6dbaeecc716,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-348b59e0-4d36-4ced-9c08-dd23fa0a6f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5671
