reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187980101-172.17.0.10-1598348024976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-d795b11f-47bd-4501-a121-10529adbdf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-fd04833a-1fa2-4749-bde4-f7a11813b5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-93d35af2-109c-4ca5-a4cf-0a932a000332,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-5bc8e469-3b3d-4b5f-b017-b3d0d28feaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-7d1177e2-167c-45cd-bc2b-98f9f3e94099,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ab3a24a8-cf2c-4830-b0c7-40d9d86506b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-6fedd8d2-a0d8-405e-aab7-f075739c0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-28cbe5ae-97f6-46bf-99da-249b59f36403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187980101-172.17.0.10-1598348024976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-d795b11f-47bd-4501-a121-10529adbdf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-fd04833a-1fa2-4749-bde4-f7a11813b5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-93d35af2-109c-4ca5-a4cf-0a932a000332,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-5bc8e469-3b3d-4b5f-b017-b3d0d28feaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-7d1177e2-167c-45cd-bc2b-98f9f3e94099,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ab3a24a8-cf2c-4830-b0c7-40d9d86506b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-6fedd8d2-a0d8-405e-aab7-f075739c0a81,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-28cbe5ae-97f6-46bf-99da-249b59f36403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400122940-172.17.0.10-1598348065753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-ad26a1d6-134a-4bb1-9585-b20c4ae6ec93,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-549cb0c1-fcd0-41a9-adca-a075f4ab5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-2ddeecfb-f02b-4aa6-8109-9d826be046f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-07cf7bfd-aeb5-48d7-9862-d62d092387a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5b101906-8696-415f-9050-72305fd3acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-07d05bd4-644f-4abc-9cf3-129dd8792cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-817b591d-60f1-458b-84f4-4ca3faf3eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-057193aa-b9b0-47e3-801c-26fc68cde5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400122940-172.17.0.10-1598348065753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-ad26a1d6-134a-4bb1-9585-b20c4ae6ec93,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-549cb0c1-fcd0-41a9-adca-a075f4ab5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-2ddeecfb-f02b-4aa6-8109-9d826be046f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-07cf7bfd-aeb5-48d7-9862-d62d092387a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5b101906-8696-415f-9050-72305fd3acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-07d05bd4-644f-4abc-9cf3-129dd8792cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-817b591d-60f1-458b-84f4-4ca3faf3eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-057193aa-b9b0-47e3-801c-26fc68cde5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404611792-172.17.0.10-1598348570260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-50ff2a8f-6feb-4112-afd6-a3dce58993b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-9b4df091-9e74-4ae6-9350-a166e27ba8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-664ab2c3-5d6f-489f-b7b5-fec827988be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-c73df773-aec5-48f7-bb05-91fc5632abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-7cb562c1-6102-4a00-b689-7480f3df72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-dffa7941-8eb0-475a-bcec-dc947e2ca3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-7ca11d28-f8c0-486c-b88e-09302295d134,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-2ad87e57-10e8-446d-8824-5d0b8ae3030b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404611792-172.17.0.10-1598348570260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-50ff2a8f-6feb-4112-afd6-a3dce58993b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-9b4df091-9e74-4ae6-9350-a166e27ba8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-664ab2c3-5d6f-489f-b7b5-fec827988be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-c73df773-aec5-48f7-bb05-91fc5632abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-7cb562c1-6102-4a00-b689-7480f3df72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-dffa7941-8eb0-475a-bcec-dc947e2ca3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-7ca11d28-f8c0-486c-b88e-09302295d134,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-2ad87e57-10e8-446d-8824-5d0b8ae3030b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074213305-172.17.0.10-1598349395905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34936,DS-c902ac2f-8350-40e3-80c8-4b5362120fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-28fd09b6-3d0e-47f9-8297-9724e6dbdf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-f0fe7d1c-8052-45a6-b220-9e9f633b0fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-4347104f-3d55-408a-b679-a111c1994cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-ff51d378-7441-4b75-84ac-c35b0ca88f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d9606dce-81b7-4416-85fc-0b640bdebdea,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-757cb125-c280-4a1c-95fe-324e7b994af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-611faa75-d2bd-4618-9653-61b51b419515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074213305-172.17.0.10-1598349395905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34936,DS-c902ac2f-8350-40e3-80c8-4b5362120fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-28fd09b6-3d0e-47f9-8297-9724e6dbdf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-f0fe7d1c-8052-45a6-b220-9e9f633b0fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-4347104f-3d55-408a-b679-a111c1994cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-ff51d378-7441-4b75-84ac-c35b0ca88f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d9606dce-81b7-4416-85fc-0b640bdebdea,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-757cb125-c280-4a1c-95fe-324e7b994af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-611faa75-d2bd-4618-9653-61b51b419515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747460710-172.17.0.10-1598350850725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-a4716d79-b94f-479f-984c-8fea988ef9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3ff9a4c3-d0c8-4f67-a7ff-2ddec30d0456,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-af39a2b1-60cc-4307-92a2-ddf02e11ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-371a42e6-1131-49b4-91ee-4dae3e1285ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-9a6069ac-c7ab-4968-b4fe-a412b72b458e,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-f6265de2-6389-4322-82fd-55e97b48d8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-11f8ee10-edb9-440e-a2d8-d524cf8a0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-e235cae4-d342-4198-a038-355db8b04039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747460710-172.17.0.10-1598350850725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-a4716d79-b94f-479f-984c-8fea988ef9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-3ff9a4c3-d0c8-4f67-a7ff-2ddec30d0456,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-af39a2b1-60cc-4307-92a2-ddf02e11ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-371a42e6-1131-49b4-91ee-4dae3e1285ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-9a6069ac-c7ab-4968-b4fe-a412b72b458e,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-f6265de2-6389-4322-82fd-55e97b48d8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-11f8ee10-edb9-440e-a2d8-d524cf8a0e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-e235cae4-d342-4198-a038-355db8b04039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525629448-172.17.0.10-1598351504409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-b0eea850-8d75-457f-b5d8-bbf988af1345,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-dbc42477-6064-4c1c-8c7a-1b5b85e10fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-29e254ab-6c24-4248-a9ee-0b14c467d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-8f191448-5099-4ce8-9a67-8a1eaaaa248f,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-8bfb82b4-4a9c-43df-9fbd-4a75af80110e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-e4fd043a-4b7e-48e5-97c0-8d9af756284d,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-16a6e1cf-f888-4ac8-ad29-91af31d136fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-c4468510-026f-48d4-9583-a670fe9f1a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525629448-172.17.0.10-1598351504409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40790,DS-b0eea850-8d75-457f-b5d8-bbf988af1345,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-dbc42477-6064-4c1c-8c7a-1b5b85e10fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-29e254ab-6c24-4248-a9ee-0b14c467d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-8f191448-5099-4ce8-9a67-8a1eaaaa248f,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-8bfb82b4-4a9c-43df-9fbd-4a75af80110e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-e4fd043a-4b7e-48e5-97c0-8d9af756284d,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-16a6e1cf-f888-4ac8-ad29-91af31d136fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-c4468510-026f-48d4-9583-a670fe9f1a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525985336-172.17.0.10-1598351546646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-e7299248-67b3-404f-aaf9-a68990dbee60,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-ed0577f7-8adc-4f05-9cd6-68e678690f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-94c62668-4ab8-4cc5-aca8-c5baec1cd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-395f70ae-92c1-44e7-82c9-512e34037008,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-692b9eb0-7f63-4076-8a7f-35a14ad13ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-283030d3-9d18-4fb2-8ded-123ce8710c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-7b4fa5c3-0482-433c-b817-79f2364109fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-406ed910-3956-45ce-b783-0f8e44b514e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525985336-172.17.0.10-1598351546646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-e7299248-67b3-404f-aaf9-a68990dbee60,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-ed0577f7-8adc-4f05-9cd6-68e678690f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-94c62668-4ab8-4cc5-aca8-c5baec1cd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-395f70ae-92c1-44e7-82c9-512e34037008,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-692b9eb0-7f63-4076-8a7f-35a14ad13ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-283030d3-9d18-4fb2-8ded-123ce8710c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-7b4fa5c3-0482-433c-b817-79f2364109fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-406ed910-3956-45ce-b783-0f8e44b514e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389009081-172.17.0.10-1598351861162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-5b1430f2-f5bb-44ff-a25f-c9ee6d8571e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-44fa201d-9979-49a4-b32c-81137f088d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-d2cf9480-0ab4-4f9b-86cd-49d42ae1446e,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-0ae17c8a-52ca-4dd2-8da7-dda654ccd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-a2fc5cbf-ac2c-459a-917d-e5a7674e7350,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-bcf6a90b-b078-40a5-bff2-04f123d22365,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-66b1ba36-d87f-41db-aa0e-df23867fbd13,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-fdd9ebcb-c7c5-4ac6-a8c4-626f145ffe93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389009081-172.17.0.10-1598351861162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-5b1430f2-f5bb-44ff-a25f-c9ee6d8571e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-44fa201d-9979-49a4-b32c-81137f088d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-d2cf9480-0ab4-4f9b-86cd-49d42ae1446e,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-0ae17c8a-52ca-4dd2-8da7-dda654ccd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-a2fc5cbf-ac2c-459a-917d-e5a7674e7350,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-bcf6a90b-b078-40a5-bff2-04f123d22365,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-66b1ba36-d87f-41db-aa0e-df23867fbd13,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-fdd9ebcb-c7c5-4ac6-a8c4-626f145ffe93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5213
