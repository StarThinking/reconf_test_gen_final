reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168967877-172.17.0.9-1598114522511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-1e5751b2-9522-4410-8a76-03d90f65be60,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-88c68e71-f85d-4de4-ae0b-c83907c23b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-0466bced-10ff-44ad-89e7-bca71aa1c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e57db076-1517-4c35-a94c-0ec4dda94b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a897c414-7bcb-497b-a776-a5fd1f29e395,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-fc11f341-faa9-4f1a-99c5-eb6ef0802b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-09f6c44f-4e32-4935-b63c-59b2b6b32cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-a25e6297-e69f-4811-a04a-040da117f150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168967877-172.17.0.9-1598114522511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-1e5751b2-9522-4410-8a76-03d90f65be60,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-88c68e71-f85d-4de4-ae0b-c83907c23b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-0466bced-10ff-44ad-89e7-bca71aa1c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e57db076-1517-4c35-a94c-0ec4dda94b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a897c414-7bcb-497b-a776-a5fd1f29e395,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-fc11f341-faa9-4f1a-99c5-eb6ef0802b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-09f6c44f-4e32-4935-b63c-59b2b6b32cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-a25e6297-e69f-4811-a04a-040da117f150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855986681-172.17.0.9-1598114862722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-c0033136-2965-4d81-9e8f-b184382e616b,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-2bc1eb4c-cedd-4da4-bf22-2774d757a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-d67768a6-9fb5-45f1-b6a8-3138013fc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b9f15944-6c75-4d41-a7a6-be620664d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-6be94200-49a0-4821-97c6-9c4c1a9008e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-bb0026ea-1743-4173-9922-7bb224d9d419,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-70e332f9-c29e-4bfb-b971-dfc1f1b14ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-083025dd-c484-4cce-aa58-8413d71f3ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855986681-172.17.0.9-1598114862722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-c0033136-2965-4d81-9e8f-b184382e616b,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-2bc1eb4c-cedd-4da4-bf22-2774d757a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-d67768a6-9fb5-45f1-b6a8-3138013fc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b9f15944-6c75-4d41-a7a6-be620664d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-6be94200-49a0-4821-97c6-9c4c1a9008e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-bb0026ea-1743-4173-9922-7bb224d9d419,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-70e332f9-c29e-4bfb-b971-dfc1f1b14ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-083025dd-c484-4cce-aa58-8413d71f3ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158892973-172.17.0.9-1598115319485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-241b9753-38d2-403a-bfd7-1633035dca99,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-e3e32824-3e80-4f8b-ba46-e6591e4c1485,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-3e0667e1-8b20-422c-b267-f39fab2c5519,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7742a013-f12e-4afb-9241-cd3ce02fc723,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-201d4311-732a-49fc-af4c-ccfa2c84b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-6d631fa1-bb48-48dd-890b-ee47797e17ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-82be3008-31c9-4b51-9d5a-9289904456ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-4a182f2b-05c4-4866-87db-d355d4ac0bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158892973-172.17.0.9-1598115319485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-241b9753-38d2-403a-bfd7-1633035dca99,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-e3e32824-3e80-4f8b-ba46-e6591e4c1485,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-3e0667e1-8b20-422c-b267-f39fab2c5519,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7742a013-f12e-4afb-9241-cd3ce02fc723,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-201d4311-732a-49fc-af4c-ccfa2c84b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-6d631fa1-bb48-48dd-890b-ee47797e17ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-82be3008-31c9-4b51-9d5a-9289904456ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-4a182f2b-05c4-4866-87db-d355d4ac0bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960072570-172.17.0.9-1598115422970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-6076fd77-c90a-42b3-9b49-38b0f3a7a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-14bb7d74-9950-426e-833d-8bc8d8cfe841,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-49f42d78-fb47-42c9-88e0-405a2c673f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e0f28df8-3b57-40bb-ac78-d9645b2cc395,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-908bdf38-baee-4eda-95cf-7e8e08913b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-acada831-689e-4a49-bc00-e751fb937847,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-34a86e91-c832-4f9b-8283-c35cd2860cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-818cc376-9835-4c72-934a-cb1b67d4d8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960072570-172.17.0.9-1598115422970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-6076fd77-c90a-42b3-9b49-38b0f3a7a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-14bb7d74-9950-426e-833d-8bc8d8cfe841,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-49f42d78-fb47-42c9-88e0-405a2c673f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e0f28df8-3b57-40bb-ac78-d9645b2cc395,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-908bdf38-baee-4eda-95cf-7e8e08913b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-acada831-689e-4a49-bc00-e751fb937847,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-34a86e91-c832-4f9b-8283-c35cd2860cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-818cc376-9835-4c72-934a-cb1b67d4d8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171532346-172.17.0.9-1598115598918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-f4f5f72b-8bfd-499d-ba8e-ed8d71224f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-094b17de-c911-4630-a3b2-d29438ab90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-35ef6ba3-08e0-4f3b-932a-3739bdaa9124,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-8e8d4940-50ed-4ef2-839d-cdbd0732fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-c62b0421-d76c-422b-9c19-e0e7c9ebb462,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0d82ab56-803c-48ca-8dd3-b9e1631ba230,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-f009fb78-2380-4c74-99d4-e5b0322ffb24,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9b8e9bee-cd4c-4b4b-93f4-11bd5693fa0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171532346-172.17.0.9-1598115598918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-f4f5f72b-8bfd-499d-ba8e-ed8d71224f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-094b17de-c911-4630-a3b2-d29438ab90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-35ef6ba3-08e0-4f3b-932a-3739bdaa9124,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-8e8d4940-50ed-4ef2-839d-cdbd0732fc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-c62b0421-d76c-422b-9c19-e0e7c9ebb462,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0d82ab56-803c-48ca-8dd3-b9e1631ba230,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-f009fb78-2380-4c74-99d4-e5b0322ffb24,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9b8e9bee-cd4c-4b4b-93f4-11bd5693fa0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747413690-172.17.0.9-1598115707412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-eed8e0bb-2bf5-4dad-8f6c-a0edaacfc180,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-7e6c8e56-9033-480f-b357-7f3d2fd617d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e18dc0c0-105d-418f-9f7a-7e0a7342f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-297619e8-b4c4-4310-9acb-8a2288ab0a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-661acad1-cb95-4941-94d7-5547b7e99f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-8a7d48be-a354-4027-8fdf-a61aa2899f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-41377a0a-cc9d-4255-b433-81064252234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-f9cb742e-3b99-4a52-ac66-fb38cff8f479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747413690-172.17.0.9-1598115707412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-eed8e0bb-2bf5-4dad-8f6c-a0edaacfc180,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-7e6c8e56-9033-480f-b357-7f3d2fd617d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e18dc0c0-105d-418f-9f7a-7e0a7342f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-297619e8-b4c4-4310-9acb-8a2288ab0a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-661acad1-cb95-4941-94d7-5547b7e99f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-8a7d48be-a354-4027-8fdf-a61aa2899f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-41377a0a-cc9d-4255-b433-81064252234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-f9cb742e-3b99-4a52-ac66-fb38cff8f479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081119446-172.17.0.9-1598115749686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-3557a0aa-9a14-4f6b-a30f-cffc16aa7796,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-262a139f-32e3-4971-b82d-e6f21316cf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-e80ebbfe-7a8f-4220-b13a-19120c42b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-a0c46cfd-4e30-497a-8ff3-8339ddd883c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-6a04795c-12ae-4601-b5df-cf09d6f2cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-85485c55-1ef7-4613-989a-014c5504f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-01534c63-3af1-4680-a606-a4e54909220f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-935a7936-f3a1-4a48-b23f-19141dacd8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081119446-172.17.0.9-1598115749686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43217,DS-3557a0aa-9a14-4f6b-a30f-cffc16aa7796,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-262a139f-32e3-4971-b82d-e6f21316cf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-e80ebbfe-7a8f-4220-b13a-19120c42b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-a0c46cfd-4e30-497a-8ff3-8339ddd883c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-6a04795c-12ae-4601-b5df-cf09d6f2cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-85485c55-1ef7-4613-989a-014c5504f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-01534c63-3af1-4680-a606-a4e54909220f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-935a7936-f3a1-4a48-b23f-19141dacd8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343574964-172.17.0.9-1598116153716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-8ba080ff-4a95-463e-950c-681e59c34fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-e4ec8329-22a8-4e41-be7d-ed4915a47a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-0a75a158-38e4-405e-bd7b-9d3cb3d6ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-54363432-9f15-4824-9be3-30d739b80ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9503ac06-0a35-4f50-b6e7-01c1906133d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-424b9cbe-cae9-4ae3-97e8-8c6a7805b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c6fef590-db0d-4406-b5f7-a01736e74ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-43ef704d-9a46-464d-b891-c5d31ef73548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343574964-172.17.0.9-1598116153716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-8ba080ff-4a95-463e-950c-681e59c34fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-e4ec8329-22a8-4e41-be7d-ed4915a47a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-0a75a158-38e4-405e-bd7b-9d3cb3d6ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-54363432-9f15-4824-9be3-30d739b80ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9503ac06-0a35-4f50-b6e7-01c1906133d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-424b9cbe-cae9-4ae3-97e8-8c6a7805b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c6fef590-db0d-4406-b5f7-a01736e74ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-43ef704d-9a46-464d-b891-c5d31ef73548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089721503-172.17.0.9-1598116535032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34497,DS-e739f424-5684-4acb-babc-51ba41bafa53,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-4aa718f7-bafa-452c-8e5c-60c288958ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-75d0a496-e5fd-4284-b1de-2b74c2b79cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-dd72f870-2219-4d04-9291-7dd931b2c013,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-3866e8fc-e0e3-4f84-8d3e-c979721443e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-b955cf16-3554-4bce-9546-2e3ae9b35c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-68933b72-b77c-46fa-b9f6-c1f622fe3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-7a969589-ee8c-4653-b8a9-1c12e2e0f018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089721503-172.17.0.9-1598116535032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34497,DS-e739f424-5684-4acb-babc-51ba41bafa53,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-4aa718f7-bafa-452c-8e5c-60c288958ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-75d0a496-e5fd-4284-b1de-2b74c2b79cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-dd72f870-2219-4d04-9291-7dd931b2c013,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-3866e8fc-e0e3-4f84-8d3e-c979721443e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-b955cf16-3554-4bce-9546-2e3ae9b35c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-68933b72-b77c-46fa-b9f6-c1f622fe3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-7a969589-ee8c-4653-b8a9-1c12e2e0f018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658736484-172.17.0.9-1598116636970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-3361faf6-df12-48d0-b040-5e41031c22ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-5c8bf529-2246-49d5-acc5-f87f41fcef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-bca80266-2729-4a0c-87be-fc294c6611cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2a3c08e4-c2c9-40de-be62-289cf705ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-0fd99510-554c-4c0c-8696-b9fa3dd622a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d8cd3355-d472-4bd0-8a8a-ed9803c4d836,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4a8f9b40-ed98-464b-a2b8-a97d71328e18,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-336abbb0-a207-45c6-aab8-06808d041a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658736484-172.17.0.9-1598116636970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36394,DS-3361faf6-df12-48d0-b040-5e41031c22ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-5c8bf529-2246-49d5-acc5-f87f41fcef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-bca80266-2729-4a0c-87be-fc294c6611cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2a3c08e4-c2c9-40de-be62-289cf705ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-0fd99510-554c-4c0c-8696-b9fa3dd622a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d8cd3355-d472-4bd0-8a8a-ed9803c4d836,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-4a8f9b40-ed98-464b-a2b8-a97d71328e18,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-336abbb0-a207-45c6-aab8-06808d041a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289105694-172.17.0.9-1598117120655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-2acfd1bd-a4b3-477d-aeb4-250c64aeebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-b0141f20-11a7-4d29-b7a1-96bfce1dfd12,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-3acd97f7-fafb-4a54-9f70-2c6f553b163e,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-251b88a4-6fe9-4b6f-89eb-b05bb503d751,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-47a8f6aa-ac51-4065-ba40-7018758d8dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-645c5696-3fa9-4963-96ab-79c471311c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-4e8b20b7-44ed-40f5-b57f-190bbde6141f,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-57b81913-83f5-4cb6-9342-521f7c9acd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289105694-172.17.0.9-1598117120655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-2acfd1bd-a4b3-477d-aeb4-250c64aeebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-b0141f20-11a7-4d29-b7a1-96bfce1dfd12,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-3acd97f7-fafb-4a54-9f70-2c6f553b163e,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-251b88a4-6fe9-4b6f-89eb-b05bb503d751,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-47a8f6aa-ac51-4065-ba40-7018758d8dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-645c5696-3fa9-4963-96ab-79c471311c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-4e8b20b7-44ed-40f5-b57f-190bbde6141f,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-57b81913-83f5-4cb6-9342-521f7c9acd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976058338-172.17.0.9-1598117317841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-be7fc518-78cb-4df3-86d4-4df5d72a0008,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-eb31ec5f-86ee-404c-8f9b-01df09d398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-870f7c3d-5622-4504-b52f-484d50082aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-bb9185eb-c391-426f-b0d4-20cf90e1600c,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-29f7bd24-789a-4a51-b6c3-721bc61a317e,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-aefd02a1-9442-4027-b3bf-eb275c819f94,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-af291de5-29b1-4d09-a44e-bac3c7dccfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-9f4de426-85ee-4128-9c7c-6787e853e49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976058338-172.17.0.9-1598117317841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-be7fc518-78cb-4df3-86d4-4df5d72a0008,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-eb31ec5f-86ee-404c-8f9b-01df09d398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-870f7c3d-5622-4504-b52f-484d50082aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-bb9185eb-c391-426f-b0d4-20cf90e1600c,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-29f7bd24-789a-4a51-b6c3-721bc61a317e,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-aefd02a1-9442-4027-b3bf-eb275c819f94,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-af291de5-29b1-4d09-a44e-bac3c7dccfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-9f4de426-85ee-4128-9c7c-6787e853e49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082225714-172.17.0.9-1598117530150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43488,DS-90ae7238-a1dd-4585-bfc0-14ac6e4204a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-90617fa5-437c-473e-9430-83f47443d958,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-4eda162c-3960-4779-a7eb-4331daa2df21,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-49e38421-4670-4d7b-a7d7-1c16ab16e502,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-22a2b0b8-0879-40f7-beee-d5dc26d7a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-76218c17-b15b-454b-9bf3-7863ff047dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-dd650c29-774e-4f4f-89cd-0229094895c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-0fdb36b1-6fe1-44a0-97dd-aca1d14e0284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082225714-172.17.0.9-1598117530150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43488,DS-90ae7238-a1dd-4585-bfc0-14ac6e4204a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-90617fa5-437c-473e-9430-83f47443d958,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-4eda162c-3960-4779-a7eb-4331daa2df21,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-49e38421-4670-4d7b-a7d7-1c16ab16e502,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-22a2b0b8-0879-40f7-beee-d5dc26d7a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-76218c17-b15b-454b-9bf3-7863ff047dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-dd650c29-774e-4f4f-89cd-0229094895c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-0fdb36b1-6fe1-44a0-97dd-aca1d14e0284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616431633-172.17.0.9-1598117897764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-b336e057-043c-4fd5-9e87-baf5c22fc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-b348eb80-9510-4fd6-97c5-191e32bf75aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-5006cc9f-cfd8-4461-8f8c-35590710ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d489a7bc-9fd2-46ba-b0c4-047533f14ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-b9963537-72b5-48aa-a600-1130c0306d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-78635bec-e378-4997-81dd-5acf90cb3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-836fb530-d275-483d-8fde-6678677f1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-180fdcb3-41e7-4571-9992-4c4638809a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616431633-172.17.0.9-1598117897764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-b336e057-043c-4fd5-9e87-baf5c22fc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-b348eb80-9510-4fd6-97c5-191e32bf75aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-5006cc9f-cfd8-4461-8f8c-35590710ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d489a7bc-9fd2-46ba-b0c4-047533f14ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-b9963537-72b5-48aa-a600-1130c0306d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-78635bec-e378-4997-81dd-5acf90cb3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-836fb530-d275-483d-8fde-6678677f1ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-180fdcb3-41e7-4571-9992-4c4638809a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52469130-172.17.0.9-1598118140631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-baf5b3f2-133a-4d38-901f-2778f38a298b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-dd6d2ae1-726d-4e0a-b531-53a8193b4549,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-fd23d585-9609-4e93-835a-635f57ccfde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-fcd82308-353d-4033-b2cc-85c9a3d7f9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c65d1fe3-b053-4c47-988d-d97997478e01,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-dc6bad20-2a55-4a28-b43e-37dc4c3e8fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-155f7766-981c-4882-875b-f987081c550c,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b7fd3000-74bd-485e-98fd-d8b9dc37c337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52469130-172.17.0.9-1598118140631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-baf5b3f2-133a-4d38-901f-2778f38a298b,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-dd6d2ae1-726d-4e0a-b531-53a8193b4549,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-fd23d585-9609-4e93-835a-635f57ccfde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-fcd82308-353d-4033-b2cc-85c9a3d7f9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c65d1fe3-b053-4c47-988d-d97997478e01,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-dc6bad20-2a55-4a28-b43e-37dc4c3e8fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-155f7766-981c-4882-875b-f987081c550c,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-b7fd3000-74bd-485e-98fd-d8b9dc37c337,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175944204-172.17.0.9-1598118488202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-9f4da04d-e36c-452b-aec6-f96f9190ea58,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6d591e11-feca-4bb5-aa3d-fb52e11c952c,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-69e42f6d-c7bb-4281-998e-dd7e97437a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-7f6c5659-2a3a-441c-b8cc-818d37836cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-d3d4ace6-9ba8-452b-9cd5-ad2bf4388401,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-6cce28db-7e37-4057-b416-d38ae41714c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-1fc3bde1-a1f6-4dae-872f-a7f03e6bf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-929afd96-f83d-41bf-9d80-47ef6e4ffc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175944204-172.17.0.9-1598118488202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-9f4da04d-e36c-452b-aec6-f96f9190ea58,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6d591e11-feca-4bb5-aa3d-fb52e11c952c,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-69e42f6d-c7bb-4281-998e-dd7e97437a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-7f6c5659-2a3a-441c-b8cc-818d37836cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-d3d4ace6-9ba8-452b-9cd5-ad2bf4388401,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-6cce28db-7e37-4057-b416-d38ae41714c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-1fc3bde1-a1f6-4dae-872f-a7f03e6bf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-929afd96-f83d-41bf-9d80-47ef6e4ffc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265543531-172.17.0.9-1598118814943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-9e3ab51e-26d8-4e83-ab32-9cb44239cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-fd640996-5d57-4667-90aa-d50225e63142,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-b206e9cb-f2b4-4256-b4b5-21f6eae47e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-e2e95994-adb9-4066-b328-0a2b5deeb162,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-42b3a7c7-b291-4ba1-a15d-39d8c11da9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-d78645bc-4024-49a8-a387-cefa43801148,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-773d38cd-6dad-4ce0-82be-a30996d01455,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-89b35d16-6a86-4d64-ac41-0b0f9ef85eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265543531-172.17.0.9-1598118814943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-9e3ab51e-26d8-4e83-ab32-9cb44239cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-fd640996-5d57-4667-90aa-d50225e63142,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-b206e9cb-f2b4-4256-b4b5-21f6eae47e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-e2e95994-adb9-4066-b328-0a2b5deeb162,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-42b3a7c7-b291-4ba1-a15d-39d8c11da9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-d78645bc-4024-49a8-a387-cefa43801148,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-773d38cd-6dad-4ce0-82be-a30996d01455,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-89b35d16-6a86-4d64-ac41-0b0f9ef85eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808582846-172.17.0.9-1598119346055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-f2da9c34-aa8d-4461-9474-5885282cd452,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-f5852431-499f-4e5b-b74b-3b4c0dadc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-6f173d62-52ad-4b63-8687-f35588a8cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-d2497f52-9ba8-450e-8e1e-8666f0cc42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-43aa729d-cfe8-445a-b2aa-64d91a2b323e,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-9c0a9f16-5c9d-45fd-94eb-35b6dd121f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-d721e6cc-68d5-4365-88f7-65d54e1d3866,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-203c0e32-bd6a-47b7-b4fd-d39af7095584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808582846-172.17.0.9-1598119346055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-f2da9c34-aa8d-4461-9474-5885282cd452,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-f5852431-499f-4e5b-b74b-3b4c0dadc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-6f173d62-52ad-4b63-8687-f35588a8cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-d2497f52-9ba8-450e-8e1e-8666f0cc42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-43aa729d-cfe8-445a-b2aa-64d91a2b323e,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-9c0a9f16-5c9d-45fd-94eb-35b6dd121f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-d721e6cc-68d5-4365-88f7-65d54e1d3866,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-203c0e32-bd6a-47b7-b4fd-d39af7095584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5358
