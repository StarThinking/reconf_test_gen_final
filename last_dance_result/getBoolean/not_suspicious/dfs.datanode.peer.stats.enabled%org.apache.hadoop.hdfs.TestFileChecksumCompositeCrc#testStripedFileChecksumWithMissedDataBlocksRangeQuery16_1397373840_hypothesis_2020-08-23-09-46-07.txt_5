reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786803325-172.17.0.7-1598176220673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34899,DS-74fce27c-51d8-45bc-a6dc-42ed2ecca47c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-c21e613c-d82b-469c-9e4e-71c66b70b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-66ff7087-0f8b-430d-9616-0258be3169a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-0de09344-3a05-4bcb-a2d1-a5b5158c82d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-d6544c88-fb9b-4003-8ede-12514de6b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-72e61845-9a5f-4cea-8e15-11d30bf61419,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-1186535b-f27c-417f-a5da-d80413c3ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-d31767ad-fa83-48b5-bff0-61813d72dc3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786803325-172.17.0.7-1598176220673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34899,DS-74fce27c-51d8-45bc-a6dc-42ed2ecca47c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-c21e613c-d82b-469c-9e4e-71c66b70b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-66ff7087-0f8b-430d-9616-0258be3169a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-0de09344-3a05-4bcb-a2d1-a5b5158c82d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-d6544c88-fb9b-4003-8ede-12514de6b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-72e61845-9a5f-4cea-8e15-11d30bf61419,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-1186535b-f27c-417f-a5da-d80413c3ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-d31767ad-fa83-48b5-bff0-61813d72dc3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698437064-172.17.0.7-1598176894665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-31a26545-d4a0-43cf-89e8-27542c906797,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a4e70894-9899-43b8-aa6f-0dff9687ac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-38c38830-ad1b-459c-868a-5b96ab3e1c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-28c702c1-28e3-42fd-a6a3-28bc74373fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-48a91d6c-680e-4559-837e-fe6a7c6fbebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-b4991253-a5a0-475b-9c6e-bc9396388c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-bc16c9a1-f78d-47a9-b0af-eddfcbe994a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-62e630ba-467d-4779-9e44-cee643bbea00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698437064-172.17.0.7-1598176894665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-31a26545-d4a0-43cf-89e8-27542c906797,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a4e70894-9899-43b8-aa6f-0dff9687ac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-38c38830-ad1b-459c-868a-5b96ab3e1c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-28c702c1-28e3-42fd-a6a3-28bc74373fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-48a91d6c-680e-4559-837e-fe6a7c6fbebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-b4991253-a5a0-475b-9c6e-bc9396388c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-bc16c9a1-f78d-47a9-b0af-eddfcbe994a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-62e630ba-467d-4779-9e44-cee643bbea00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246300775-172.17.0.7-1598176946442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-c1d92592-fe4f-42e8-8ff2-f858d072b108,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-75c5bac7-3317-4f07-a01a-701b0e4dc5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-7a43cb98-b867-4e27-8405-70b3ed48b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0b777717-e73f-4b6f-90bc-698e2abd1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-779d9953-1945-4e4a-9de6-9feb4eca1f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-7360b31b-2a6a-4fea-9404-48209b6c5d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-040b8225-2eb8-40c2-8874-dfa01f5f5e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-f7eb177c-a92c-4d9f-85ff-0089a6249846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246300775-172.17.0.7-1598176946442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-c1d92592-fe4f-42e8-8ff2-f858d072b108,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-75c5bac7-3317-4f07-a01a-701b0e4dc5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-7a43cb98-b867-4e27-8405-70b3ed48b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0b777717-e73f-4b6f-90bc-698e2abd1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-779d9953-1945-4e4a-9de6-9feb4eca1f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-7360b31b-2a6a-4fea-9404-48209b6c5d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-040b8225-2eb8-40c2-8874-dfa01f5f5e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-f7eb177c-a92c-4d9f-85ff-0089a6249846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200983969-172.17.0.7-1598178601041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-5f3b1ef5-0892-47a0-88d1-af1ad8e3ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-80c89f41-69c3-428a-8eb3-059776eecf79,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-f3a20726-c1bf-45c4-a1ec-76488ca80e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-fccbbdad-fec7-4267-a36c-862d870066e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-cf34bc08-476c-417b-a877-ebda9fda24bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-be8020d8-a3d9-4960-8348-86953be05ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-0dd47b5a-4656-4f1a-8399-169d8c468df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b6c0e5f4-b1f6-4313-8e5f-138d087518b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200983969-172.17.0.7-1598178601041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-5f3b1ef5-0892-47a0-88d1-af1ad8e3ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-80c89f41-69c3-428a-8eb3-059776eecf79,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-f3a20726-c1bf-45c4-a1ec-76488ca80e61,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-fccbbdad-fec7-4267-a36c-862d870066e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-cf34bc08-476c-417b-a877-ebda9fda24bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-be8020d8-a3d9-4960-8348-86953be05ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-0dd47b5a-4656-4f1a-8399-169d8c468df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b6c0e5f4-b1f6-4313-8e5f-138d087518b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372314980-172.17.0.7-1598178976913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-d36e4bae-7764-4a0b-b6ec-6c521349b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5d0f978e-dc34-49b2-b269-c324e9c719bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-abaca5ac-4d9f-4928-a16b-abba0dc63e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-98fb5ec5-6969-4b1a-a1b3-7b9efa11ef15,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-87ef774d-f0f3-4256-8382-74dee150335a,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-9e3284eb-7e0d-4628-aa7c-351a7286bc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-59aeaa12-b6fb-41c0-9ac3-0f2405af0fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-a379c15d-7b49-450e-a49a-3c4a5ecc3d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372314980-172.17.0.7-1598178976913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-d36e4bae-7764-4a0b-b6ec-6c521349b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5d0f978e-dc34-49b2-b269-c324e9c719bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-abaca5ac-4d9f-4928-a16b-abba0dc63e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-98fb5ec5-6969-4b1a-a1b3-7b9efa11ef15,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-87ef774d-f0f3-4256-8382-74dee150335a,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-9e3284eb-7e0d-4628-aa7c-351a7286bc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-59aeaa12-b6fb-41c0-9ac3-0f2405af0fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-a379c15d-7b49-450e-a49a-3c4a5ecc3d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266629565-172.17.0.7-1598179018866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-f7e7ed05-a088-462f-9958-fea8552180f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-7dd55fdd-7d47-45b4-9848-6c7a8152836c,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-d0690382-e549-4244-9ccb-9f264ff0efb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-de45b7cd-406f-460b-aca7-df7238f4fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-7b147784-a66f-4f35-86fb-9629993c0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-7237d635-a032-436f-9206-000002e15b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-c170108b-6650-4f73-ac24-b6d5abbfbe26,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f08abbd2-4b36-4cd3-88d0-774095d36b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266629565-172.17.0.7-1598179018866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-f7e7ed05-a088-462f-9958-fea8552180f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-7dd55fdd-7d47-45b4-9848-6c7a8152836c,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-d0690382-e549-4244-9ccb-9f264ff0efb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-de45b7cd-406f-460b-aca7-df7238f4fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-7b147784-a66f-4f35-86fb-9629993c0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-7237d635-a032-436f-9206-000002e15b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-c170108b-6650-4f73-ac24-b6d5abbfbe26,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f08abbd2-4b36-4cd3-88d0-774095d36b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626569969-172.17.0.7-1598179058182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-727785c0-b6b9-4e4c-b0a7-8db54fd800a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-45819eb7-06a8-43f5-9284-9d163661a4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-8c86a789-4ca1-41a1-b274-50537d31498e,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-db656c7d-818f-4760-bdfa-540ac44970d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-1f8ad77b-02ee-4e04-9c45-570afc7c134a,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-48c5c610-8368-49fa-9348-3958464a2c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-93f8bd7c-32a1-42e0-a2d7-fc86ae6a6133,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5540d89b-68d8-49f6-8818-e81d812ee8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626569969-172.17.0.7-1598179058182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-727785c0-b6b9-4e4c-b0a7-8db54fd800a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-45819eb7-06a8-43f5-9284-9d163661a4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-8c86a789-4ca1-41a1-b274-50537d31498e,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-db656c7d-818f-4760-bdfa-540ac44970d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-1f8ad77b-02ee-4e04-9c45-570afc7c134a,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-48c5c610-8368-49fa-9348-3958464a2c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-93f8bd7c-32a1-42e0-a2d7-fc86ae6a6133,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5540d89b-68d8-49f6-8818-e81d812ee8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23316114-172.17.0.7-1598179352882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-5fb59e67-52c0-4534-8fc7-af70c7292abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-892e611d-49c7-4b3a-88ff-bc44a1fbb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-ac073a40-8f0a-4364-bf37-0670046480dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4b3b02d0-b538-446d-9411-3444aad1be18,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8a988397-e69e-4aeb-bc6e-cc3bf142ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-b112ea88-4988-44cf-b82d-a8183653abc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-167dcd4a-3a1f-4748-9cbe-06082c338220,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-85220827-d19d-4718-b3b0-87dece6c92b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23316114-172.17.0.7-1598179352882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-5fb59e67-52c0-4534-8fc7-af70c7292abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-892e611d-49c7-4b3a-88ff-bc44a1fbb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-ac073a40-8f0a-4364-bf37-0670046480dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4b3b02d0-b538-446d-9411-3444aad1be18,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-8a988397-e69e-4aeb-bc6e-cc3bf142ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-b112ea88-4988-44cf-b82d-a8183653abc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-167dcd4a-3a1f-4748-9cbe-06082c338220,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-85220827-d19d-4718-b3b0-87dece6c92b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453102304-172.17.0.7-1598179526283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-9747065a-8692-4163-a33e-d06e333ae27c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-ddfc9ef9-4353-4e38-9531-07b758fd7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-9a283597-6e79-4be1-b8a9-14392dd452de,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-6d4b4ce1-19db-4de4-b537-de587daf1610,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-1c334331-210e-445b-8e8b-e1eadcd9dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-f2728584-c86a-4eb1-b413-1ae2c866697e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-7645be46-f1f4-4687-86c3-08f44ef01c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-4b81c3ff-cf22-4dd8-a02d-cee1e9d82633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453102304-172.17.0.7-1598179526283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-9747065a-8692-4163-a33e-d06e333ae27c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-ddfc9ef9-4353-4e38-9531-07b758fd7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-9a283597-6e79-4be1-b8a9-14392dd452de,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-6d4b4ce1-19db-4de4-b537-de587daf1610,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-1c334331-210e-445b-8e8b-e1eadcd9dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-f2728584-c86a-4eb1-b413-1ae2c866697e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-7645be46-f1f4-4687-86c3-08f44ef01c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-4b81c3ff-cf22-4dd8-a02d-cee1e9d82633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037688861-172.17.0.7-1598179649152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-0329e6e1-3e32-4840-b7f0-dbe11f51efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-36c3ccab-5e1d-4b23-b8b7-5e63048bb1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-21c4a479-909b-40c3-8fab-98612c2d4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-531e8932-efa3-493d-b9b2-2b9a35a54685,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-86dbb8e7-9a78-4ce2-a882-9736efdad366,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-6e20ca9d-7fdd-44f1-b29e-bcff348e13d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-6902b9cc-776c-4e0a-8903-ec92df0252d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-cfbf6223-3cf2-499b-9ecd-8cd44cc08e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037688861-172.17.0.7-1598179649152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33010,DS-0329e6e1-3e32-4840-b7f0-dbe11f51efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-36c3ccab-5e1d-4b23-b8b7-5e63048bb1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-21c4a479-909b-40c3-8fab-98612c2d4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-531e8932-efa3-493d-b9b2-2b9a35a54685,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-86dbb8e7-9a78-4ce2-a882-9736efdad366,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-6e20ca9d-7fdd-44f1-b29e-bcff348e13d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-6902b9cc-776c-4e0a-8903-ec92df0252d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-cfbf6223-3cf2-499b-9ecd-8cd44cc08e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116089587-172.17.0.7-1598179823187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-286bd9b9-81c5-447f-a7dc-f8061c7a13d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-bd5115be-d48f-4352-928e-fc4828bc1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-0294e5a9-dfee-40d0-a6f9-47f14a0298c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-aa9d864d-ed25-4e70-aab5-eee3d6c43d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-bd845509-719e-47da-96ed-8f63a5a46b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-1dd3efae-92c8-4974-b481-1d82b12541d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-8cce8a0b-08fb-4d0c-8143-0f0104584bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-8b2c88e9-c033-4be2-879c-357cfa621960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116089587-172.17.0.7-1598179823187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-286bd9b9-81c5-447f-a7dc-f8061c7a13d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-bd5115be-d48f-4352-928e-fc4828bc1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-0294e5a9-dfee-40d0-a6f9-47f14a0298c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-aa9d864d-ed25-4e70-aab5-eee3d6c43d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-bd845509-719e-47da-96ed-8f63a5a46b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-1dd3efae-92c8-4974-b481-1d82b12541d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-8cce8a0b-08fb-4d0c-8143-0f0104584bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-8b2c88e9-c033-4be2-879c-357cfa621960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69640036-172.17.0.7-1598179950219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-71c6246c-39bb-461e-a453-ede54d0ae674,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-91671066-5d56-4181-a535-7db3729a2682,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0d9d28fc-725c-4e1e-aff4-644b58729554,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-0f61bab5-5333-48e1-8bd2-70e46902ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-ef41e1ec-73fc-47f3-a6ef-3aab1fbb1555,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-572d4833-9384-422c-b767-9e6aae427827,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-dc23dd09-9846-4601-b88b-d6dc9bbb3533,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-8ae6d147-c105-49c2-82da-efd587ac4d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69640036-172.17.0.7-1598179950219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-71c6246c-39bb-461e-a453-ede54d0ae674,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-91671066-5d56-4181-a535-7db3729a2682,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0d9d28fc-725c-4e1e-aff4-644b58729554,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-0f61bab5-5333-48e1-8bd2-70e46902ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-ef41e1ec-73fc-47f3-a6ef-3aab1fbb1555,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-572d4833-9384-422c-b767-9e6aae427827,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-dc23dd09-9846-4601-b88b-d6dc9bbb3533,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-8ae6d147-c105-49c2-82da-efd587ac4d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559620321-172.17.0.7-1598179998289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-ee5c7a55-4155-4e7c-bf80-6440953ceff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-5f6ad75f-85b5-4264-8ea9-fd90cf4dc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-b113ee88-8e85-4950-b1b5-73dd34a7c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-06ab98c0-4a9b-42e1-9c9a-8d92587f4996,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-5e6fcd92-ffe0-49a3-bc1b-605bc7d0ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-9e8d4606-6b8f-4f0c-9826-ed3f004f9093,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-f7cbc31a-f7c3-4b6e-9631-3e61086197e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-85f4532b-4927-403e-b1bb-3ada04ad6502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559620321-172.17.0.7-1598179998289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-ee5c7a55-4155-4e7c-bf80-6440953ceff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-5f6ad75f-85b5-4264-8ea9-fd90cf4dc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-b113ee88-8e85-4950-b1b5-73dd34a7c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-06ab98c0-4a9b-42e1-9c9a-8d92587f4996,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-5e6fcd92-ffe0-49a3-bc1b-605bc7d0ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-9e8d4606-6b8f-4f0c-9826-ed3f004f9093,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-f7cbc31a-f7c3-4b6e-9631-3e61086197e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-85f4532b-4927-403e-b1bb-3ada04ad6502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920863853-172.17.0.7-1598180241237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-5050532a-015e-48e1-8b18-3394285ae92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-eed1255f-3717-4d80-82a2-99d83eb63aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-a16be3e3-e59e-4463-a4e0-04f290c69a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-50ee88d5-b3ba-444c-9e48-b14c62db17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-6627d326-35b4-407c-b36a-b9cb0d926501,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-99e021c6-12e2-400b-bf58-2b926575bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-f277e19d-83ca-4942-9a02-c3d16a1f0784,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-9f126ea2-4e4d-48d0-bdfd-b871d9587c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920863853-172.17.0.7-1598180241237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-5050532a-015e-48e1-8b18-3394285ae92c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-eed1255f-3717-4d80-82a2-99d83eb63aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-a16be3e3-e59e-4463-a4e0-04f290c69a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-50ee88d5-b3ba-444c-9e48-b14c62db17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-6627d326-35b4-407c-b36a-b9cb0d926501,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-99e021c6-12e2-400b-bf58-2b926575bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-f277e19d-83ca-4942-9a02-c3d16a1f0784,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-9f126ea2-4e4d-48d0-bdfd-b871d9587c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184796594-172.17.0.7-1598180763957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-beba5daf-5047-4c07-9232-db14843b3673,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-534718e1-114e-4b3f-90e1-98ed04f1c023,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-80c7e850-00aa-45ac-bb86-f2482869e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6e721cee-8ac5-4a50-b8f7-6a9940deadb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f0e4ecc9-974f-4983-b927-129eb1a6092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-16a317b8-aa34-46b9-8557-6e14b3e40da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-69b72db1-4684-408d-996a-686c29d75648,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-f129484d-4f3f-42c9-861d-dd2e154c8ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184796594-172.17.0.7-1598180763957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-beba5daf-5047-4c07-9232-db14843b3673,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-534718e1-114e-4b3f-90e1-98ed04f1c023,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-80c7e850-00aa-45ac-bb86-f2482869e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6e721cee-8ac5-4a50-b8f7-6a9940deadb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f0e4ecc9-974f-4983-b927-129eb1a6092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-16a317b8-aa34-46b9-8557-6e14b3e40da3,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-69b72db1-4684-408d-996a-686c29d75648,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-f129484d-4f3f-42c9-861d-dd2e154c8ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298924573-172.17.0.7-1598181474445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-034fd64f-a9fc-45e9-a3f2-8eafa285dcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-86b17dbe-2e6b-4c8e-ae78-aeaad129a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-37be73f2-98a2-4fba-83d5-f2dcb0696f37,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-2a0ef14b-9524-427d-b20f-f399faeed823,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-26dce30a-d91e-47d4-8392-8f5f2eb81c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-38dbaf76-dc8e-4ce2-9618-8373e836562a,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-53272c3f-d2c8-4551-85a4-2f01ab55d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-3d19a352-3ab9-45f2-b169-1bcb979393b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298924573-172.17.0.7-1598181474445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-034fd64f-a9fc-45e9-a3f2-8eafa285dcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-86b17dbe-2e6b-4c8e-ae78-aeaad129a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-37be73f2-98a2-4fba-83d5-f2dcb0696f37,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-2a0ef14b-9524-427d-b20f-f399faeed823,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-26dce30a-d91e-47d4-8392-8f5f2eb81c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-38dbaf76-dc8e-4ce2-9618-8373e836562a,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-53272c3f-d2c8-4551-85a4-2f01ab55d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-3d19a352-3ab9-45f2-b169-1bcb979393b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046540485-172.17.0.7-1598181957512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-a813f24e-6fc7-4511-8203-b371dd4bf191,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-b0fdb6eb-85c5-4125-a506-125e0ff92cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d6a50201-d07c-4788-8a3d-cf856c87dc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d3074061-f4e8-4e33-ac61-ff5ad9647078,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-cedb3421-2a6a-4153-87e5-d1e0ec409772,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-81da7021-ff5b-4ea4-b65f-7fe607a7c873,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-d5d3150f-548d-40e0-9a1c-8389e31eded3,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-21290843-f9e2-4074-9411-a133ae5eeef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046540485-172.17.0.7-1598181957512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42541,DS-a813f24e-6fc7-4511-8203-b371dd4bf191,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-b0fdb6eb-85c5-4125-a506-125e0ff92cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d6a50201-d07c-4788-8a3d-cf856c87dc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d3074061-f4e8-4e33-ac61-ff5ad9647078,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-cedb3421-2a6a-4153-87e5-d1e0ec409772,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-81da7021-ff5b-4ea4-b65f-7fe607a7c873,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-d5d3150f-548d-40e0-9a1c-8389e31eded3,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-21290843-f9e2-4074-9411-a133ae5eeef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6540
