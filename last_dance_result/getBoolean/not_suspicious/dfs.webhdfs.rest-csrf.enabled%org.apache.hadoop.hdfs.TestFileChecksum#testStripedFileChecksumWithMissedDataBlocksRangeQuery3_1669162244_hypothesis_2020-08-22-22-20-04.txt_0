reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770674225-172.17.0.10-1598134893640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-931ec261-80e7-42fb-aa84-d92208e70be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-56355432-7966-46ad-994f-02ba965ab3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a0291dcc-421d-480f-b40f-4a97b0f7103b,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-6f2303ac-55a6-4e25-bca1-57c6551b07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-6d6f1538-47ed-4949-ad1e-59846e061d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-bbf544d2-b9b5-4b6d-9a1f-cf1f210c8873,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a2401a21-5c67-40d4-96cd-5e3c1f49b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ce5926ac-3ef4-4e38-ad53-76b1386fdea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770674225-172.17.0.10-1598134893640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-931ec261-80e7-42fb-aa84-d92208e70be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-56355432-7966-46ad-994f-02ba965ab3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a0291dcc-421d-480f-b40f-4a97b0f7103b,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-6f2303ac-55a6-4e25-bca1-57c6551b07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-6d6f1538-47ed-4949-ad1e-59846e061d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-bbf544d2-b9b5-4b6d-9a1f-cf1f210c8873,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a2401a21-5c67-40d4-96cd-5e3c1f49b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ce5926ac-3ef4-4e38-ad53-76b1386fdea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9752919-172.17.0.10-1598134994591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36409,DS-e6e7b723-1edf-44bd-b554-643bcfda49fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-6e7f9261-b344-4a09-9d6c-25ed08345007,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-a35a6dff-feb7-475b-afa6-de144653639d,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-fdbd1863-7db7-44fb-89fb-1e88a95e8064,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4732a636-5310-46ee-be63-c36028b2bf82,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-2d5fbfe6-4797-430e-9d93-d6acdc17f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-dba6d4cd-7390-48d7-ab5d-d8b45dcb9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-087bcd92-a3c4-4ab6-b60f-48418e3e2b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9752919-172.17.0.10-1598134994591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36409,DS-e6e7b723-1edf-44bd-b554-643bcfda49fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-6e7f9261-b344-4a09-9d6c-25ed08345007,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-a35a6dff-feb7-475b-afa6-de144653639d,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-fdbd1863-7db7-44fb-89fb-1e88a95e8064,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4732a636-5310-46ee-be63-c36028b2bf82,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-2d5fbfe6-4797-430e-9d93-d6acdc17f46a,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-dba6d4cd-7390-48d7-ab5d-d8b45dcb9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-087bcd92-a3c4-4ab6-b60f-48418e3e2b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331802072-172.17.0.10-1598135588518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-3ecc08aa-294b-4381-b7f5-f6070510d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-07c32ee9-f492-400e-9f6b-469d7db72709,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-023a7107-e8c7-46a3-aab1-1e3ca313a968,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-f621a9d3-f6c7-41b8-bd23-fc28fba11ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-1c8acad4-9ba7-45ee-932a-f775483374ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-8d6ac2a9-1822-4dba-b94b-abcd1aada164,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3309fd6a-3ff4-4050-a9af-a71ade7e4b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-bd233826-631f-4b04-a83f-0c2414599296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331802072-172.17.0.10-1598135588518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-3ecc08aa-294b-4381-b7f5-f6070510d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-07c32ee9-f492-400e-9f6b-469d7db72709,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-023a7107-e8c7-46a3-aab1-1e3ca313a968,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-f621a9d3-f6c7-41b8-bd23-fc28fba11ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-1c8acad4-9ba7-45ee-932a-f775483374ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-8d6ac2a9-1822-4dba-b94b-abcd1aada164,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3309fd6a-3ff4-4050-a9af-a71ade7e4b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-bd233826-631f-4b04-a83f-0c2414599296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071197327-172.17.0.10-1598136641634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-2a67fe21-9b32-4c22-b15f-5af13569294f,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-855d436f-8149-4b00-b50b-c502a4079bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-00a9a1b6-d734-47f7-aff3-8870e7d6507a,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-a7bad643-aaa0-453c-81c8-664e961e85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-d277ed29-ad3f-4878-8d98-f731abf512a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-0805f7c8-87c8-4e96-ac2e-112fe116591e,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-5e0b2dc3-4c24-4557-a305-af245518efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-22cc26ea-8e80-4993-8771-fd695c60336d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071197327-172.17.0.10-1598136641634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-2a67fe21-9b32-4c22-b15f-5af13569294f,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-855d436f-8149-4b00-b50b-c502a4079bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-00a9a1b6-d734-47f7-aff3-8870e7d6507a,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-a7bad643-aaa0-453c-81c8-664e961e85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-d277ed29-ad3f-4878-8d98-f731abf512a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-0805f7c8-87c8-4e96-ac2e-112fe116591e,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-5e0b2dc3-4c24-4557-a305-af245518efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-22cc26ea-8e80-4993-8771-fd695c60336d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77682763-172.17.0.10-1598136711735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-6af62f6a-d891-4b39-af7f-36e2e6ee0636,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-6fe22f3c-791a-4711-aa89-999fe3f515e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-aefa9b88-728b-47f8-8338-f0c59db2f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-5e9d067b-45fc-4084-9232-3b34a8e182f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-fd132313-ffdb-4810-aae2-08c95917b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-1ba4daec-4c85-4906-8905-01d8a4e1b680,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-eb023d20-dc6a-4c5c-9e62-d80fcd3de3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-d35d1970-a044-4fd5-be1d-e23af185aa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77682763-172.17.0.10-1598136711735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-6af62f6a-d891-4b39-af7f-36e2e6ee0636,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-6fe22f3c-791a-4711-aa89-999fe3f515e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-aefa9b88-728b-47f8-8338-f0c59db2f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-5e9d067b-45fc-4084-9232-3b34a8e182f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-fd132313-ffdb-4810-aae2-08c95917b5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-1ba4daec-4c85-4906-8905-01d8a4e1b680,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-eb023d20-dc6a-4c5c-9e62-d80fcd3de3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-d35d1970-a044-4fd5-be1d-e23af185aa25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494357025-172.17.0.10-1598137223063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-1349420a-f164-4780-9f28-8da77c27ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-5cbe4189-6fd7-4d3a-a6d3-ed3e914a8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-56995ac6-ff30-409d-9a54-98caccb629ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-6305cd64-5f88-4b04-acf1-26fe28904eed,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-0b73751a-ab96-4e36-93c1-600f6ada5536,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-fb767fe2-582d-4b46-bf74-b2dcce5e2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-2a41d87d-5bbd-47aa-893b-7dd2d4c88051,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-766534e0-6794-4666-805e-b657cf916f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494357025-172.17.0.10-1598137223063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-1349420a-f164-4780-9f28-8da77c27ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-5cbe4189-6fd7-4d3a-a6d3-ed3e914a8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-56995ac6-ff30-409d-9a54-98caccb629ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-6305cd64-5f88-4b04-acf1-26fe28904eed,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-0b73751a-ab96-4e36-93c1-600f6ada5536,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-fb767fe2-582d-4b46-bf74-b2dcce5e2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-2a41d87d-5bbd-47aa-893b-7dd2d4c88051,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-766534e0-6794-4666-805e-b657cf916f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678866775-172.17.0.10-1598137504173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-6ef749a6-3d9a-486a-8f55-998969bef1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-a02e92f8-3ab2-4c60-82a9-7f8ee4362c31,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-394a09eb-e704-4be8-b5ff-dde4ae231148,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-b8d44b83-ecc2-41c6-b3ab-0466b2b93efe,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-3d7f8d6d-23aa-4c1a-ab3b-cab07302dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-490d0293-390f-4590-a586-2496ceedd1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-6f219aef-65ee-4121-80d9-76645a801496,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b2333f75-4c9c-4ca4-968f-d9c7dc28d290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678866775-172.17.0.10-1598137504173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-6ef749a6-3d9a-486a-8f55-998969bef1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-a02e92f8-3ab2-4c60-82a9-7f8ee4362c31,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-394a09eb-e704-4be8-b5ff-dde4ae231148,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-b8d44b83-ecc2-41c6-b3ab-0466b2b93efe,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-3d7f8d6d-23aa-4c1a-ab3b-cab07302dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-490d0293-390f-4590-a586-2496ceedd1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-6f219aef-65ee-4121-80d9-76645a801496,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b2333f75-4c9c-4ca4-968f-d9c7dc28d290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145845989-172.17.0.10-1598137687307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-f779ec97-d85c-4448-b373-a0456c40d5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-073ed0e1-65ec-4c06-aa73-023b585a073b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-2508da34-3d95-43a5-b2f4-f7480de6d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7076f473-db0a-486a-a512-045521f266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-c9f86b9c-bbd7-434c-b04c-743225c98c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-1d2d7b19-b2d3-4850-831f-48ad1cd82de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-90433740-aa8f-4e61-aa01-ac5e67e0db56,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-3c84a31c-c37b-4624-b02f-9e3ba5d91a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145845989-172.17.0.10-1598137687307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-f779ec97-d85c-4448-b373-a0456c40d5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-073ed0e1-65ec-4c06-aa73-023b585a073b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-2508da34-3d95-43a5-b2f4-f7480de6d5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-7076f473-db0a-486a-a512-045521f266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-c9f86b9c-bbd7-434c-b04c-743225c98c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-1d2d7b19-b2d3-4850-831f-48ad1cd82de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-90433740-aa8f-4e61-aa01-ac5e67e0db56,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-3c84a31c-c37b-4624-b02f-9e3ba5d91a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147203733-172.17.0.10-1598137756955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46000,DS-04986372-0c13-4d40-be9b-731b312fce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-16f87875-3f51-4c9d-ba86-a5ae60906622,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d77a50f2-8a44-4efd-add6-f6dc0a7bf4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-03560b17-b0ef-437d-bc62-e30b1d5542af,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-bae0e010-761b-4a25-a912-b2e0cd59d9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-183bfc9b-2b1b-4d7b-bbc3-966087cf93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-fd238bfd-61fd-40c8-a15f-77070ca98a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-f3353ae5-0c00-4fc9-b438-c010265ed88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147203733-172.17.0.10-1598137756955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46000,DS-04986372-0c13-4d40-be9b-731b312fce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-16f87875-3f51-4c9d-ba86-a5ae60906622,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d77a50f2-8a44-4efd-add6-f6dc0a7bf4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-03560b17-b0ef-437d-bc62-e30b1d5542af,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-bae0e010-761b-4a25-a912-b2e0cd59d9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-183bfc9b-2b1b-4d7b-bbc3-966087cf93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-fd238bfd-61fd-40c8-a15f-77070ca98a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-f3353ae5-0c00-4fc9-b438-c010265ed88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013741221-172.17.0.10-1598137945090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-c94bd340-5987-4c9e-a59e-218d1104ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-9f0acba0-7be3-435c-9ab0-497bbfe23f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-d4700edf-70e2-4cb1-b3d9-90f6914b0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-44863338-8b28-4f5e-8477-51acb7d726be,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-1e3c83ee-6f08-4a93-89ac-a8aabda38755,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e4bca1e0-e831-4a72-9edd-d833779496a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-78d40590-62be-4e70-b34b-eacdf4a60b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7d052984-c5f4-4748-9ac8-18cde1059815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013741221-172.17.0.10-1598137945090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-c94bd340-5987-4c9e-a59e-218d1104ba84,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-9f0acba0-7be3-435c-9ab0-497bbfe23f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-d4700edf-70e2-4cb1-b3d9-90f6914b0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-44863338-8b28-4f5e-8477-51acb7d726be,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-1e3c83ee-6f08-4a93-89ac-a8aabda38755,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e4bca1e0-e831-4a72-9edd-d833779496a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-78d40590-62be-4e70-b34b-eacdf4a60b25,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7d052984-c5f4-4748-9ac8-18cde1059815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750444830-172.17.0.10-1598138140261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-93307bac-96fc-4ee9-8be9-961f2151fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-79569ce4-7225-4083-9779-85e4f4dc0e22,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-d53efad2-2051-4033-9dfc-2a186dadd468,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-83758a05-7a52-44c7-a17e-42faa400bc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-8ce8ffd5-343c-47b9-866c-90838c8b513d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-53758d95-3b4a-4cab-be44-601002a22872,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-30b144b5-2c2b-49d1-a760-df456d0376b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-6a566e1c-117f-4686-8b6f-e0c125421aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750444830-172.17.0.10-1598138140261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-93307bac-96fc-4ee9-8be9-961f2151fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-79569ce4-7225-4083-9779-85e4f4dc0e22,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-d53efad2-2051-4033-9dfc-2a186dadd468,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-83758a05-7a52-44c7-a17e-42faa400bc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-8ce8ffd5-343c-47b9-866c-90838c8b513d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-53758d95-3b4a-4cab-be44-601002a22872,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-30b144b5-2c2b-49d1-a760-df456d0376b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-6a566e1c-117f-4686-8b6f-e0c125421aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526731491-172.17.0.10-1598138576796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-5dc86fad-2e6b-420c-9738-a8dfde0e03dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-a18636a7-028b-4ae6-ad37-ad6962ec3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-a82d60a5-d7a4-4c08-8e82-4246259a7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-a6a1ffce-2468-4e0a-9f46-4ebdb4228284,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-b45dba7a-ec0d-498a-a5b8-fa5bf5d96508,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-fe6eaa9d-e0f5-4ebf-aa53-d6d81a464b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-69c577d5-188b-4a2f-b44d-07580c2eb567,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-0ba6d531-8423-431c-912f-2f497fcc0b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526731491-172.17.0.10-1598138576796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-5dc86fad-2e6b-420c-9738-a8dfde0e03dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-a18636a7-028b-4ae6-ad37-ad6962ec3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-a82d60a5-d7a4-4c08-8e82-4246259a7d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-a6a1ffce-2468-4e0a-9f46-4ebdb4228284,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-b45dba7a-ec0d-498a-a5b8-fa5bf5d96508,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-fe6eaa9d-e0f5-4ebf-aa53-d6d81a464b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-69c577d5-188b-4a2f-b44d-07580c2eb567,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-0ba6d531-8423-431c-912f-2f497fcc0b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342893979-172.17.0.10-1598138653440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-a97392b4-c5d4-4755-b9b9-507fa3055dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-06b3e3d5-a8d2-4f9c-b8a7-8e7e0ef3f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-ec3d68de-b327-4181-b12e-2b32c47e4717,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-ab95dc2d-3838-4a4d-9420-1f6bacb74444,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-407cbd08-dc46-46cf-a9d4-1be1c7ed3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-1ea54d96-d70f-4374-a47d-b49732074e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-17153232-03e5-4ea6-b8cf-260e68cc49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-4a1a2cba-d52c-4ae1-a4b6-aa8f5f355115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342893979-172.17.0.10-1598138653440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-a97392b4-c5d4-4755-b9b9-507fa3055dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-06b3e3d5-a8d2-4f9c-b8a7-8e7e0ef3f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-ec3d68de-b327-4181-b12e-2b32c47e4717,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-ab95dc2d-3838-4a4d-9420-1f6bacb74444,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-407cbd08-dc46-46cf-a9d4-1be1c7ed3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-1ea54d96-d70f-4374-a47d-b49732074e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-17153232-03e5-4ea6-b8cf-260e68cc49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-4a1a2cba-d52c-4ae1-a4b6-aa8f5f355115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495185603-172.17.0.10-1598138840551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-bfaf53c5-2401-4b6f-8d27-6b53719932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-321847af-0ea8-433d-b9bd-255106b98262,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b8e9a132-8ca2-44e3-8990-369fabc068c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-a8c02dae-6cc5-4350-a520-bcf323a97740,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a72adf20-c049-43ea-9eb5-a95f3f0e8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-707b1917-319d-4eae-9484-5ac0ae64c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-a65645e1-d1b6-4a3d-8559-df42cbbae124,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-1d04399b-4353-4de1-8798-75fb6905c503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495185603-172.17.0.10-1598138840551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-bfaf53c5-2401-4b6f-8d27-6b53719932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-321847af-0ea8-433d-b9bd-255106b98262,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-b8e9a132-8ca2-44e3-8990-369fabc068c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-a8c02dae-6cc5-4350-a520-bcf323a97740,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-a72adf20-c049-43ea-9eb5-a95f3f0e8d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-707b1917-319d-4eae-9484-5ac0ae64c45a,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-a65645e1-d1b6-4a3d-8559-df42cbbae124,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-1d04399b-4353-4de1-8798-75fb6905c503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108983170-172.17.0.10-1598138987598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-527bb98c-75d7-44ed-80c6-4d3bb2f39d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5ee8443a-ab31-45db-8f61-c8bb1877e197,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-bba480da-195e-4e3d-8859-a269e71a8387,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6aade621-326d-458a-ab35-b4a3e48490b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-100eb2d4-3eb3-4150-b3ec-df1b975f025e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-c9787f0d-f0da-4ba9-8fb4-ce26c92fb604,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-17f7aa17-e8cb-4377-891f-0c4d46ba31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-44289f88-2357-427e-a960-23d83a66f884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108983170-172.17.0.10-1598138987598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-527bb98c-75d7-44ed-80c6-4d3bb2f39d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5ee8443a-ab31-45db-8f61-c8bb1877e197,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-bba480da-195e-4e3d-8859-a269e71a8387,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6aade621-326d-458a-ab35-b4a3e48490b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-100eb2d4-3eb3-4150-b3ec-df1b975f025e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-c9787f0d-f0da-4ba9-8fb4-ce26c92fb604,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-17f7aa17-e8cb-4377-891f-0c4d46ba31f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-44289f88-2357-427e-a960-23d83a66f884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505247581-172.17.0.10-1598139669269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41431,DS-b4713d76-1e21-478f-8532-497ce762a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-5b210fcd-979e-486c-ace7-1819b0180f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-f2d992ff-e321-457e-a6da-819f2b25ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-008af6a1-0b32-4e63-a452-cb9ca8083edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-ce03443e-0224-4f68-b764-bab374745f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-9b0f4bfc-9fd3-43e7-b7bc-03d368d09d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-24900935-cf8d-407e-b4b0-68f1b86468d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-a6642f9c-6698-492b-90f9-f1c91b9bfe61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505247581-172.17.0.10-1598139669269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41431,DS-b4713d76-1e21-478f-8532-497ce762a5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-5b210fcd-979e-486c-ace7-1819b0180f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-f2d992ff-e321-457e-a6da-819f2b25ac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-008af6a1-0b32-4e63-a452-cb9ca8083edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-ce03443e-0224-4f68-b764-bab374745f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-9b0f4bfc-9fd3-43e7-b7bc-03d368d09d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-24900935-cf8d-407e-b4b0-68f1b86468d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-a6642f9c-6698-492b-90f9-f1c91b9bfe61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177095335-172.17.0.10-1598139842109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-94cf38d6-c3d9-4c73-97f7-779e54727633,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9ff5d404-d9e0-4d94-9d5a-857751089c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-fe4583f4-e59a-48e2-80f1-0852ea97e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-baa91e40-3346-4714-a1f8-50b75f59dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-311de308-7acc-4416-b393-bbf7bbd429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-aea4f030-f743-48b5-9027-adba9a990071,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-c3861b70-5cd0-4645-b565-dc4b3255add7,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-38778b4d-d4f8-41c6-8f8f-aa45c8fe97ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177095335-172.17.0.10-1598139842109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-94cf38d6-c3d9-4c73-97f7-779e54727633,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9ff5d404-d9e0-4d94-9d5a-857751089c82,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-fe4583f4-e59a-48e2-80f1-0852ea97e40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-baa91e40-3346-4714-a1f8-50b75f59dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-311de308-7acc-4416-b393-bbf7bbd429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-aea4f030-f743-48b5-9027-adba9a990071,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-c3861b70-5cd0-4645-b565-dc4b3255add7,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-38778b4d-d4f8-41c6-8f8f-aa45c8fe97ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558846434-172.17.0.10-1598139877258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-c0271852-db5f-40e4-b38d-d4ea945f97ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-318de521-10d5-4534-8fa8-aa5a780b538b,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-f0136a11-b89f-4046-8adf-dc8b6ce8f894,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-eeab39e3-dd12-4930-a6fe-9b00ef2e43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-05a50d76-deac-467d-9014-9cd0d6520abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-b9a8f1e2-9a15-43c6-8085-9c1056cd142d,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-fc1428a3-a4e6-4ca7-b0b6-8cee774f4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-0ffccd87-4162-47b2-b43f-aa98162545bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558846434-172.17.0.10-1598139877258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-c0271852-db5f-40e4-b38d-d4ea945f97ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-318de521-10d5-4534-8fa8-aa5a780b538b,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-f0136a11-b89f-4046-8adf-dc8b6ce8f894,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-eeab39e3-dd12-4930-a6fe-9b00ef2e43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-05a50d76-deac-467d-9014-9cd0d6520abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-b9a8f1e2-9a15-43c6-8085-9c1056cd142d,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-fc1428a3-a4e6-4ca7-b0b6-8cee774f4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-0ffccd87-4162-47b2-b43f-aa98162545bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902656294-172.17.0.10-1598140014677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37245,DS-d6ce09cf-9906-4752-9a3d-3dd7a9d4371f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-5a74fb23-c9f1-4e6a-a875-90a9e312fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-7affba1c-3fe0-455b-b1d9-4ce911f15932,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-7e4a2d39-b588-4421-8713-9d4735bb8ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-0c8d833c-d5d7-4960-ac73-082c47c0b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-a7210d9e-c233-4310-b551-ceaf20cfaba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-98d68532-8ac5-4f15-b860-a5c2cf0f1093,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-8411d6f6-30cc-4dc0-b98a-7770e355e265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902656294-172.17.0.10-1598140014677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37245,DS-d6ce09cf-9906-4752-9a3d-3dd7a9d4371f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-5a74fb23-c9f1-4e6a-a875-90a9e312fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-7affba1c-3fe0-455b-b1d9-4ce911f15932,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-7e4a2d39-b588-4421-8713-9d4735bb8ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-0c8d833c-d5d7-4960-ac73-082c47c0b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-a7210d9e-c233-4310-b551-ceaf20cfaba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-98d68532-8ac5-4f15-b860-a5c2cf0f1093,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-8411d6f6-30cc-4dc0-b98a-7770e355e265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924217778-172.17.0.10-1598140264005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-e2148650-4718-44ad-836c-874f4b03dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-e530b099-6914-4aef-9253-6eabc20955e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-ded9a159-ac02-4745-b646-8aeea01b99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-b97a3edc-360e-40b8-9707-1dccd9369357,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-40fadcd0-49b2-4d34-bce7-8fcc2b421597,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-4ea3e3bd-5470-48c8-8fa4-9b9cd132dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-9fdbc363-d8b2-4a06-ab28-12f525666c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-ded0143a-7583-4e4e-bf0e-4955fbeeeb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924217778-172.17.0.10-1598140264005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-e2148650-4718-44ad-836c-874f4b03dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-e530b099-6914-4aef-9253-6eabc20955e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-ded9a159-ac02-4745-b646-8aeea01b99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-b97a3edc-360e-40b8-9707-1dccd9369357,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-40fadcd0-49b2-4d34-bce7-8fcc2b421597,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-4ea3e3bd-5470-48c8-8fa4-9b9cd132dfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-9fdbc363-d8b2-4a06-ab28-12f525666c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-ded0143a-7583-4e4e-bf0e-4955fbeeeb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696829856-172.17.0.10-1598140340447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39660,DS-5b2efb3a-d872-4b76-b140-2afd71112be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eb66c1f4-e668-497d-9fb9-5bc77b7925f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-30acafc4-b378-41e3-8f14-37a67e44e343,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-10435e1a-aeff-4eba-a18b-cb2318992d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-a745703e-6320-484c-9929-be6eb8636c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-afbb673d-fb44-4eee-b24f-1e74b75c933f,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-570786eb-ba72-4c9d-957d-014fa58f5e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-536715d3-97dd-4cda-8ec2-3668f4e9e6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696829856-172.17.0.10-1598140340447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39660,DS-5b2efb3a-d872-4b76-b140-2afd71112be6,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eb66c1f4-e668-497d-9fb9-5bc77b7925f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-30acafc4-b378-41e3-8f14-37a67e44e343,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-10435e1a-aeff-4eba-a18b-cb2318992d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-a745703e-6320-484c-9929-be6eb8636c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-afbb673d-fb44-4eee-b24f-1e74b75c933f,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-570786eb-ba72-4c9d-957d-014fa58f5e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-536715d3-97dd-4cda-8ec2-3668f4e9e6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5551
