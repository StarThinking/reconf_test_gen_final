reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720726051-172.17.0.12-1598146593713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-109d1ee1-e0dc-43dc-80f7-1fbb6f84c5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-7f12fb18-51e5-4750-a6e1-f9a6ed3a0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-f2f84416-1347-4b9b-a747-3c1eaa79a768,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-a132fd47-2d6f-484d-9bd5-5aedfc4de132,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-061852bc-0f7b-4a7e-85e7-e0fae05723ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-1fab3189-1134-413b-b6dd-83f9233fdea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-147c2975-623b-4403-8d91-808c373d65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-9d48589a-7b0e-4882-b4ad-5d1a388abb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720726051-172.17.0.12-1598146593713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-109d1ee1-e0dc-43dc-80f7-1fbb6f84c5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-7f12fb18-51e5-4750-a6e1-f9a6ed3a0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-f2f84416-1347-4b9b-a747-3c1eaa79a768,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-a132fd47-2d6f-484d-9bd5-5aedfc4de132,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-061852bc-0f7b-4a7e-85e7-e0fae05723ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-1fab3189-1134-413b-b6dd-83f9233fdea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-147c2975-623b-4403-8d91-808c373d65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-9d48589a-7b0e-4882-b4ad-5d1a388abb61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629556592-172.17.0.12-1598146628755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-4f57f1e2-a6a0-41fa-9ce9-d34fd2f57b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-dc02c8b3-d06a-46a0-9900-2891c008c952,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-a479e36b-b0fd-4cdd-8b28-640617164279,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-e0da7058-164d-4fa2-8c7e-149681952c41,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-aec87a51-8598-43b8-8171-35d19eb1b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-80dbd1d6-adea-4b51-b113-b57287cddd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-476cacdb-5e25-40ad-b3b8-4429b7ca1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-9979ff87-ff77-441b-b17f-80da8ac868bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629556592-172.17.0.12-1598146628755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-4f57f1e2-a6a0-41fa-9ce9-d34fd2f57b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-dc02c8b3-d06a-46a0-9900-2891c008c952,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-a479e36b-b0fd-4cdd-8b28-640617164279,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-e0da7058-164d-4fa2-8c7e-149681952c41,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-aec87a51-8598-43b8-8171-35d19eb1b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-80dbd1d6-adea-4b51-b113-b57287cddd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-476cacdb-5e25-40ad-b3b8-4429b7ca1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-9979ff87-ff77-441b-b17f-80da8ac868bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612039326-172.17.0.12-1598147083361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-7da4a276-499d-4b11-bb80-47070b2ab5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-8fa859ca-985d-436f-96af-008243b634a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-5800eb9e-6a95-4609-b346-8261d87621b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-001cb927-9eb4-4941-a6d5-35a92047b654,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8caf3411-5e3d-4c3e-aaa3-149c92875a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-504a2e3b-a175-4b91-96ad-73412f7d1d24,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-eb136905-27d6-4e3b-b93e-33fa9c70d05f,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-9556eee8-5a46-4536-826f-cb9e54d5675b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612039326-172.17.0.12-1598147083361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-7da4a276-499d-4b11-bb80-47070b2ab5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-8fa859ca-985d-436f-96af-008243b634a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-5800eb9e-6a95-4609-b346-8261d87621b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-001cb927-9eb4-4941-a6d5-35a92047b654,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8caf3411-5e3d-4c3e-aaa3-149c92875a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-504a2e3b-a175-4b91-96ad-73412f7d1d24,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-eb136905-27d6-4e3b-b93e-33fa9c70d05f,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-9556eee8-5a46-4536-826f-cb9e54d5675b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217076174-172.17.0.12-1598147397766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-c2541750-1590-4609-bb7b-3524d1e92f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-f43b4131-3ab2-4985-83aa-0c0c47b369de,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-40cc0475-75f7-4b9c-b3a5-05a39dab936d,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-08f3c66b-ed52-4440-8aa3-6a9cefec5365,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-82901eeb-d76c-4da3-989c-c79dcf90b388,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-6a7482a9-da63-40bc-aa90-ead58db26406,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c80962c2-4d4a-4c02-91dc-2ec5357cb22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-f84a10c6-d3e2-487f-b730-1fd1fb03401d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217076174-172.17.0.12-1598147397766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-c2541750-1590-4609-bb7b-3524d1e92f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-f43b4131-3ab2-4985-83aa-0c0c47b369de,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-40cc0475-75f7-4b9c-b3a5-05a39dab936d,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-08f3c66b-ed52-4440-8aa3-6a9cefec5365,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-82901eeb-d76c-4da3-989c-c79dcf90b388,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-6a7482a9-da63-40bc-aa90-ead58db26406,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c80962c2-4d4a-4c02-91dc-2ec5357cb22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-f84a10c6-d3e2-487f-b730-1fd1fb03401d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120833750-172.17.0.12-1598147633502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-a1bd9e2a-47e4-4a66-9451-74dc417fa9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-5706095e-5083-4bf3-906f-366b2952529c,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-f6da59a4-4cdd-4919-95e9-fb62de7e5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-8e3150f3-a43f-442b-a34b-9f36048d86c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-0fba2eb4-a2bf-45e0-9b8e-8eb5954dc242,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-9885e7a2-bdd8-4fc2-9cd4-abb9cbfa14ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ef21f4f3-40ae-4560-96f3-54c66fa427a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-8c6231e4-c070-4957-8949-4a8b78193862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120833750-172.17.0.12-1598147633502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-a1bd9e2a-47e4-4a66-9451-74dc417fa9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-5706095e-5083-4bf3-906f-366b2952529c,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-f6da59a4-4cdd-4919-95e9-fb62de7e5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-8e3150f3-a43f-442b-a34b-9f36048d86c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-0fba2eb4-a2bf-45e0-9b8e-8eb5954dc242,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-9885e7a2-bdd8-4fc2-9cd4-abb9cbfa14ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ef21f4f3-40ae-4560-96f3-54c66fa427a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-8c6231e4-c070-4957-8949-4a8b78193862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669547963-172.17.0.12-1598148057706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-3327d55e-c8d3-4164-83b5-d6ccb5f94607,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-7e7e8727-9659-44c9-b862-b5ace9daa442,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-a1361243-07b0-4ecc-85ac-6141cd8c6328,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-749a1aaf-2424-4d90-97d4-537269de8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a5b7573c-0fa2-43fc-8824-90ba93a65523,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-686c6ecf-8422-4f97-bebc-d5db2aeac98c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-13963329-27de-4b3d-ad38-68d491cd1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-295124ba-7260-4643-90a2-4a4c2cd6db57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669547963-172.17.0.12-1598148057706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-3327d55e-c8d3-4164-83b5-d6ccb5f94607,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-7e7e8727-9659-44c9-b862-b5ace9daa442,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-a1361243-07b0-4ecc-85ac-6141cd8c6328,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-749a1aaf-2424-4d90-97d4-537269de8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a5b7573c-0fa2-43fc-8824-90ba93a65523,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-686c6ecf-8422-4f97-bebc-d5db2aeac98c,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-13963329-27de-4b3d-ad38-68d491cd1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-295124ba-7260-4643-90a2-4a4c2cd6db57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820948126-172.17.0.12-1598148489842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-f6fcea2f-1440-43d7-a7ef-208509f06bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-50e24999-45f9-4cbe-ba3c-bd0b4b4ea839,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-8dad82cc-d76f-4e7f-81d5-30f2716e07d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-aa449740-619f-4f8a-a0fc-39722bedb932,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-f9d37e84-e421-442a-8963-cf4c11bc5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-a0f85821-0a26-49a3-a76f-7631bcad792d,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-00ae5986-c940-46dd-85c8-a6dc85a926e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-00ebae8f-bff2-4176-b708-2280a5de21ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820948126-172.17.0.12-1598148489842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-f6fcea2f-1440-43d7-a7ef-208509f06bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-50e24999-45f9-4cbe-ba3c-bd0b4b4ea839,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-8dad82cc-d76f-4e7f-81d5-30f2716e07d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-aa449740-619f-4f8a-a0fc-39722bedb932,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-f9d37e84-e421-442a-8963-cf4c11bc5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-a0f85821-0a26-49a3-a76f-7631bcad792d,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-00ae5986-c940-46dd-85c8-a6dc85a926e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-00ebae8f-bff2-4176-b708-2280a5de21ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589923778-172.17.0.12-1598148716146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-a1d64cfb-7599-43dd-a6f3-07ed9556e84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-c2d9e2ce-4d66-40ba-867c-71900f5345c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b9a5e4f9-9027-4470-8d9e-939e90f8bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7550497a-4d2e-424d-af79-0ad6a86a6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d06e47e5-b656-4264-8691-c714c539bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-5e9c1def-7823-47e7-8733-056d4f9bb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b07226aa-169e-45d1-9542-40c1e0c2c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-752c102b-aab4-40c2-b802-b072e26885e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589923778-172.17.0.12-1598148716146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-a1d64cfb-7599-43dd-a6f3-07ed9556e84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-c2d9e2ce-4d66-40ba-867c-71900f5345c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b9a5e4f9-9027-4470-8d9e-939e90f8bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7550497a-4d2e-424d-af79-0ad6a86a6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-d06e47e5-b656-4264-8691-c714c539bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-5e9c1def-7823-47e7-8733-056d4f9bb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b07226aa-169e-45d1-9542-40c1e0c2c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-752c102b-aab4-40c2-b802-b072e26885e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831057759-172.17.0.12-1598149372175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-530bb736-c77d-43e4-b0d5-765777e3bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-03db1c3d-e45a-4aab-baa9-13241200e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-2c178ae0-b745-4b11-b662-5860d6473163,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-3d799251-e134-496c-972f-dc12a6af4697,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-1941dc73-3eb1-49a0-a1be-7cd8382395dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-a8577812-5162-431d-a8fb-3f9a2f495f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-fff6a054-c81a-4ebc-8650-8147874a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-34b13867-a927-4d90-bc75-f4ab59796950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831057759-172.17.0.12-1598149372175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-530bb736-c77d-43e4-b0d5-765777e3bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-03db1c3d-e45a-4aab-baa9-13241200e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-2c178ae0-b745-4b11-b662-5860d6473163,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-3d799251-e134-496c-972f-dc12a6af4697,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-1941dc73-3eb1-49a0-a1be-7cd8382395dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-a8577812-5162-431d-a8fb-3f9a2f495f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-fff6a054-c81a-4ebc-8650-8147874a6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-34b13867-a927-4d90-bc75-f4ab59796950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214479021-172.17.0.12-1598149477695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-f7938eb5-de0c-406b-a5e2-86003efb3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-975b584e-c46f-47b5-b275-ef2861ab06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-80d5faa1-fa47-4f8a-a3c7-bd13f62b894b,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1b8eeb04-ffd1-4e69-91a4-310cb5847582,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-58e208e9-be9f-443a-8158-384255d883c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-b8819ea1-951c-4955-b71e-0cc12b6d9685,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-19f68df8-5e62-4b21-9e90-b9b63aea5578,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-78c1d1f5-6ecc-480d-a003-79f1cd85040e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214479021-172.17.0.12-1598149477695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43412,DS-f7938eb5-de0c-406b-a5e2-86003efb3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-975b584e-c46f-47b5-b275-ef2861ab06e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-80d5faa1-fa47-4f8a-a3c7-bd13f62b894b,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-1b8eeb04-ffd1-4e69-91a4-310cb5847582,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-58e208e9-be9f-443a-8158-384255d883c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-b8819ea1-951c-4955-b71e-0cc12b6d9685,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-19f68df8-5e62-4b21-9e90-b9b63aea5578,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-78c1d1f5-6ecc-480d-a003-79f1cd85040e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072878246-172.17.0.12-1598149602829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-47d057f1-ba1e-4ca6-b8ab-95cb69d2e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-bfdcc4a2-fe42-4bcc-87f9-ca0f2de5340e,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-1025c67a-0303-44dc-86a0-f957db7635ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-15f91395-1bd0-4357-9ae1-9f37d6a783d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-506ed50f-5214-4c8b-b1f1-9cf0bb2b09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-db3e7463-eb48-4a60-9f77-00c6928de2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-41f5c00a-39b7-479d-928c-56017c1767f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-0691b5f1-23aa-4b96-bec7-a4a5e87dfd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072878246-172.17.0.12-1598149602829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-47d057f1-ba1e-4ca6-b8ab-95cb69d2e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-bfdcc4a2-fe42-4bcc-87f9-ca0f2de5340e,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-1025c67a-0303-44dc-86a0-f957db7635ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-15f91395-1bd0-4357-9ae1-9f37d6a783d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-506ed50f-5214-4c8b-b1f1-9cf0bb2b09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-db3e7463-eb48-4a60-9f77-00c6928de2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-41f5c00a-39b7-479d-928c-56017c1767f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-0691b5f1-23aa-4b96-bec7-a4a5e87dfd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169373794-172.17.0.12-1598150108190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-6f71c6f7-fd17-4884-8279-7661f883d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-965f1310-118f-42b1-8822-d0a6f1f3bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-ca161ccb-8514-4713-8184-2363cf1b2feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-45e2abc3-2948-41d6-9c83-3db0147acf88,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-55208cb6-0522-45c2-933f-d9cfb4eaea50,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-8a0b734f-aacd-4cee-a904-d2f40a9aea98,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-f7a3a98a-8317-434c-84b0-0ab2d8cef583,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-b0423ab1-3595-40d9-84ea-7a39238f0a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169373794-172.17.0.12-1598150108190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-6f71c6f7-fd17-4884-8279-7661f883d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-965f1310-118f-42b1-8822-d0a6f1f3bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-ca161ccb-8514-4713-8184-2363cf1b2feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-45e2abc3-2948-41d6-9c83-3db0147acf88,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-55208cb6-0522-45c2-933f-d9cfb4eaea50,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-8a0b734f-aacd-4cee-a904-d2f40a9aea98,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-f7a3a98a-8317-434c-84b0-0ab2d8cef583,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-b0423ab1-3595-40d9-84ea-7a39238f0a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90111664-172.17.0.12-1598150140600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-3ac8f822-ea41-4a84-9dec-3d5aa9c2ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c7af0f05-7e10-43c3-9ac7-1a4daa3e87c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-9fa24df2-7521-4693-a2c5-961ffdc761ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6011ee04-aa94-4226-a19f-3cdd0f8b6b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-edd984e9-7c20-405e-821c-0d4596c46512,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-9d64a222-3904-4533-a749-26a065051ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-221f157d-fa42-4b05-bb67-41a05bbe04de,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-eacdc3b8-1728-4052-925e-e663acf94a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90111664-172.17.0.12-1598150140600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-3ac8f822-ea41-4a84-9dec-3d5aa9c2ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-c7af0f05-7e10-43c3-9ac7-1a4daa3e87c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-9fa24df2-7521-4693-a2c5-961ffdc761ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6011ee04-aa94-4226-a19f-3cdd0f8b6b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-edd984e9-7c20-405e-821c-0d4596c46512,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-9d64a222-3904-4533-a749-26a065051ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-221f157d-fa42-4b05-bb67-41a05bbe04de,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-eacdc3b8-1728-4052-925e-e663acf94a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411418037-172.17.0.12-1598150218601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44190,DS-9d41e7fd-4404-48f9-9784-9f0e2eda14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-68bdca29-eada-4449-a587-0cb1f459d329,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-0f11aeab-1083-4925-8ba7-9981c8cdfaea,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-00edfc1c-5138-401d-b086-593fe7988a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-c38f1baf-0e49-4076-b442-f26e5c5b9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d4170c21-2c59-46b9-9076-b5d1a435e056,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-100b304c-d38c-4bce-b312-96e2e0c445ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-44c931ff-2c5d-4c2d-a91b-c4365c812b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411418037-172.17.0.12-1598150218601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44190,DS-9d41e7fd-4404-48f9-9784-9f0e2eda14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-68bdca29-eada-4449-a587-0cb1f459d329,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-0f11aeab-1083-4925-8ba7-9981c8cdfaea,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-00edfc1c-5138-401d-b086-593fe7988a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-c38f1baf-0e49-4076-b442-f26e5c5b9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d4170c21-2c59-46b9-9076-b5d1a435e056,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-100b304c-d38c-4bce-b312-96e2e0c445ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-44c931ff-2c5d-4c2d-a91b-c4365c812b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126487150-172.17.0.12-1598150370975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a6326321-6ec1-47f7-abb9-ad56f45580f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-3125f5c5-fb23-4020-ac22-68ea88234c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-69b01a1b-a086-4ea9-b066-a1b883c82f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-98eacf53-4edc-41ba-b4ba-94ac1c51a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-1179c3f2-76fd-4b6c-a623-314396db2899,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-31fdee6f-9933-4881-b414-a205fe5f06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6940beae-e981-47cd-943f-f1d0284aae52,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-8361e81d-6b6f-4624-b2ac-0e6ba30b524f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126487150-172.17.0.12-1598150370975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-a6326321-6ec1-47f7-abb9-ad56f45580f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-3125f5c5-fb23-4020-ac22-68ea88234c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-69b01a1b-a086-4ea9-b066-a1b883c82f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-98eacf53-4edc-41ba-b4ba-94ac1c51a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-1179c3f2-76fd-4b6c-a623-314396db2899,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-31fdee6f-9933-4881-b414-a205fe5f06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6940beae-e981-47cd-943f-f1d0284aae52,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-8361e81d-6b6f-4624-b2ac-0e6ba30b524f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870498377-172.17.0.12-1598150691789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-92923dc9-51a6-4c3b-a5d1-149252b0a27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-7211c0de-788e-4660-94ed-5119b78a8ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-c8beeef2-7a2d-4fab-825a-82b1c15e7dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-182e1b9c-bc8f-492b-8d41-5f59088757c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-274d2415-6fd6-43ab-b208-5f81ed944403,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-8ef10d2f-9143-4518-902d-753f1335f827,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-e6e0bfac-2edc-4810-b2e2-9d498b701506,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6d2f9c81-1521-4abf-af64-6e91d09f6e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870498377-172.17.0.12-1598150691789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-92923dc9-51a6-4c3b-a5d1-149252b0a27a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-7211c0de-788e-4660-94ed-5119b78a8ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-c8beeef2-7a2d-4fab-825a-82b1c15e7dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-182e1b9c-bc8f-492b-8d41-5f59088757c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-274d2415-6fd6-43ab-b208-5f81ed944403,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-8ef10d2f-9143-4518-902d-753f1335f827,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-e6e0bfac-2edc-4810-b2e2-9d498b701506,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6d2f9c81-1521-4abf-af64-6e91d09f6e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283664368-172.17.0.12-1598151239693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-a66317ab-e720-46c4-a91e-c560b68743f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-bd5eb302-8b31-4971-a18a-52d6ff3f24dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-5fe7df0f-0ccf-4feb-9bb8-9d2b32b90b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-da2fe9c3-d0d5-4688-9f2f-a7704c1f9387,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-a2920e50-5ff8-4063-9b9b-7366d8248a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-667b8959-d52a-4941-90b0-65e26ff8ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-6f2dfc1e-7a20-4c13-8d17-7cff0405a461,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-36867992-73de-41fb-a16e-1b3d1a1c6ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283664368-172.17.0.12-1598151239693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-a66317ab-e720-46c4-a91e-c560b68743f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-bd5eb302-8b31-4971-a18a-52d6ff3f24dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-5fe7df0f-0ccf-4feb-9bb8-9d2b32b90b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-da2fe9c3-d0d5-4688-9f2f-a7704c1f9387,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-a2920e50-5ff8-4063-9b9b-7366d8248a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-667b8959-d52a-4941-90b0-65e26ff8ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-6f2dfc1e-7a20-4c13-8d17-7cff0405a461,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-36867992-73de-41fb-a16e-1b3d1a1c6ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147839964-172.17.0.12-1598151386584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-400ea09f-3876-461c-984d-263e59aef713,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-89e6210c-1e69-4c29-b550-93ed09f0be96,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-78662e89-3eaa-4bca-947d-07eae9e5f55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-32708ca4-4fc7-4c44-aabb-8c672df5f998,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-41a44ddc-85f6-4f4c-ad51-bab581972d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-405f1e39-283f-43e0-afb3-3c25e68e1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-7ecc1185-d26c-4253-847d-18bfd66616c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-81c67f63-5ab3-49a6-91e0-5a2fa03b8f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147839964-172.17.0.12-1598151386584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-400ea09f-3876-461c-984d-263e59aef713,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-89e6210c-1e69-4c29-b550-93ed09f0be96,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-78662e89-3eaa-4bca-947d-07eae9e5f55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-32708ca4-4fc7-4c44-aabb-8c672df5f998,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-41a44ddc-85f6-4f4c-ad51-bab581972d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-405f1e39-283f-43e0-afb3-3c25e68e1d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-7ecc1185-d26c-4253-847d-18bfd66616c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-81c67f63-5ab3-49a6-91e0-5a2fa03b8f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034228864-172.17.0.12-1598151421531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-cfa67e64-5f63-4904-8964-993bacf5d955,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-bf3c7268-6d36-469f-acdd-843d5e7dc755,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-1605afc7-85f9-4a46-a3d1-9a084d23b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-8c4ac5d0-5532-410a-baa0-c8543d6c7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-8103db99-f401-4c03-bbbc-3d048a4d101d,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-296fa2b0-8bac-497e-9605-61f33f356020,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-5f75e2c9-d550-4e4d-843b-0d8521014f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ee98a178-5250-4eab-822c-39760c4785ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034228864-172.17.0.12-1598151421531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42259,DS-cfa67e64-5f63-4904-8964-993bacf5d955,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-bf3c7268-6d36-469f-acdd-843d5e7dc755,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-1605afc7-85f9-4a46-a3d1-9a084d23b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-8c4ac5d0-5532-410a-baa0-c8543d6c7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-8103db99-f401-4c03-bbbc-3d048a4d101d,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-296fa2b0-8bac-497e-9605-61f33f356020,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-5f75e2c9-d550-4e4d-843b-0d8521014f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ee98a178-5250-4eab-822c-39760c4785ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5409
