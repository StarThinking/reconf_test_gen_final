reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743356496-172.17.0.7-1598435200959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-958c3c7f-b462-46b8-8fa8-550836c727e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-5e335307-95b7-41ef-b565-a164d9771ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-6ec70da4-f816-4735-abb7-d542f55401ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-fa4c64b6-41ab-4117-8d28-383419a2a535,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-f602ead3-5766-46b5-9bdf-153a742acdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-51dd28e7-6349-4bb7-80de-f88631db3599,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-e86d7670-b5d7-48e7-b3a1-e7f68f05799e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-c97f3ff1-2def-42a7-b96c-f5475472c3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743356496-172.17.0.7-1598435200959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-958c3c7f-b462-46b8-8fa8-550836c727e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-5e335307-95b7-41ef-b565-a164d9771ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-6ec70da4-f816-4735-abb7-d542f55401ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-fa4c64b6-41ab-4117-8d28-383419a2a535,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-f602ead3-5766-46b5-9bdf-153a742acdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-51dd28e7-6349-4bb7-80de-f88631db3599,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-e86d7670-b5d7-48e7-b3a1-e7f68f05799e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-c97f3ff1-2def-42a7-b96c-f5475472c3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865222091-172.17.0.7-1598435403871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-2859c088-9b31-4c0c-a2b0-3f4c7fa3d60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-e73a7cfb-1c5a-4c4d-9589-ba11f13b0950,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f47fdb67-5540-4290-880c-73181320575b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-73c2a140-697e-41b0-82dc-228be9646f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-a7e95e80-5b22-48b7-b662-cab8d9c19520,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-2ee1b207-524a-4c75-af47-5c080a26b1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-26190549-2056-45c8-931b-ae96b109a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-0f5b2fb5-ab03-4739-89bb-b574ddece1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865222091-172.17.0.7-1598435403871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-2859c088-9b31-4c0c-a2b0-3f4c7fa3d60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-e73a7cfb-1c5a-4c4d-9589-ba11f13b0950,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f47fdb67-5540-4290-880c-73181320575b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-73c2a140-697e-41b0-82dc-228be9646f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-a7e95e80-5b22-48b7-b662-cab8d9c19520,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-2ee1b207-524a-4c75-af47-5c080a26b1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-26190549-2056-45c8-931b-ae96b109a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-0f5b2fb5-ab03-4739-89bb-b574ddece1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811172641-172.17.0.7-1598435935605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-81d4b85f-2c36-49b0-9543-c2510a786cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-a3ae180b-a49d-437a-b218-ef0a6f8b1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c749c56d-8b27-4928-899a-f2f20af75ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-fa0a24a8-ad05-4448-80ff-28e13d3c6c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-86f19a1b-0b53-4dba-b2de-c44d91cf7674,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-33eb7fd3-4585-4866-bf46-7401fb977dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-e5f3690f-d18b-43b1-8cc2-b0f487de1065,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-97c77f87-6dee-4deb-8d5e-8d0e0cf04dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811172641-172.17.0.7-1598435935605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-81d4b85f-2c36-49b0-9543-c2510a786cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-a3ae180b-a49d-437a-b218-ef0a6f8b1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c749c56d-8b27-4928-899a-f2f20af75ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-fa0a24a8-ad05-4448-80ff-28e13d3c6c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-86f19a1b-0b53-4dba-b2de-c44d91cf7674,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-33eb7fd3-4585-4866-bf46-7401fb977dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-e5f3690f-d18b-43b1-8cc2-b0f487de1065,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-97c77f87-6dee-4deb-8d5e-8d0e0cf04dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352716419-172.17.0.7-1598436587004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42638,DS-3449c74b-2fb8-4f7f-8d11-fb268ab419f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-55de86c4-1cff-4908-9340-15527876703b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-7b0c01e5-df1a-40ad-bdc5-94257b677390,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-10e2465f-3807-4141-8142-c4c98be2e272,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-0a70b9f4-8b8c-47ec-ad28-208603bfc713,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-204f0baa-9fb9-4e98-955d-40c74ab69a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-64b9e7ac-c034-4ef7-a613-727b674bdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-e6d2d0db-0ec7-4d41-b6b5-831a3c04c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352716419-172.17.0.7-1598436587004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42638,DS-3449c74b-2fb8-4f7f-8d11-fb268ab419f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-55de86c4-1cff-4908-9340-15527876703b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-7b0c01e5-df1a-40ad-bdc5-94257b677390,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-10e2465f-3807-4141-8142-c4c98be2e272,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-0a70b9f4-8b8c-47ec-ad28-208603bfc713,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-204f0baa-9fb9-4e98-955d-40c74ab69a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-64b9e7ac-c034-4ef7-a613-727b674bdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-e6d2d0db-0ec7-4d41-b6b5-831a3c04c071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10234361-172.17.0.7-1598436623629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-3b49d0ff-bcf8-46e9-be33-5fea5d6909c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-e9c28167-94c0-4cb0-841e-85cc617d8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-f302533a-3724-440f-af05-7a2e1ec7f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-e88826d2-2da9-4b02-a688-5bb484d7419d,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-80efd009-da8d-4e34-9ea2-ebed2a06f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-c85b5621-9ab0-45b2-bfc6-86263cac9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-0c1520f0-567f-4b01-8449-7c212b7d8f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-9f8f941b-dd66-4aaf-b834-c4bf9a816f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10234361-172.17.0.7-1598436623629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-3b49d0ff-bcf8-46e9-be33-5fea5d6909c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-e9c28167-94c0-4cb0-841e-85cc617d8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-f302533a-3724-440f-af05-7a2e1ec7f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-e88826d2-2da9-4b02-a688-5bb484d7419d,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-80efd009-da8d-4e34-9ea2-ebed2a06f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-c85b5621-9ab0-45b2-bfc6-86263cac9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-0c1520f0-567f-4b01-8449-7c212b7d8f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-9f8f941b-dd66-4aaf-b834-c4bf9a816f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973625921-172.17.0.7-1598437052457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-0c7d6324-fac8-4ada-a252-bb197d82cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-a5fb36b1-cb18-4f87-b5cb-47754f04e028,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-fdbfddac-a4dc-46b6-a87e-d7eb19b40209,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-3fde0cc2-e1a8-4a05-a2b8-a047b89d4196,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c6102c31-ed34-4cdb-a7a3-59e0b2b4fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-4db3dde6-53e8-4afa-bca9-60e93dbdd709,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-a8863fd3-5af3-4858-aaf1-9fe4eeb85c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-ca081146-a0e7-4a58-84a0-188a80d98c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973625921-172.17.0.7-1598437052457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-0c7d6324-fac8-4ada-a252-bb197d82cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-a5fb36b1-cb18-4f87-b5cb-47754f04e028,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-fdbfddac-a4dc-46b6-a87e-d7eb19b40209,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-3fde0cc2-e1a8-4a05-a2b8-a047b89d4196,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c6102c31-ed34-4cdb-a7a3-59e0b2b4fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-4db3dde6-53e8-4afa-bca9-60e93dbdd709,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-a8863fd3-5af3-4858-aaf1-9fe4eeb85c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-ca081146-a0e7-4a58-84a0-188a80d98c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852369817-172.17.0.7-1598437125717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-84cc7d1c-5c7f-4245-959b-4fc43e92132c,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-6d7da644-74ae-4ec6-bb0a-e2a384d008fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-a77d03c8-196f-433c-9b25-5727be6dd22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-03ba6181-7e97-44c1-a4df-93154a6cd698,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-018f8c18-f68d-4123-8888-c87b53196606,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d7f82a52-0555-441d-8591-e2a41a881af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-1064e6d2-09c1-4bfd-ab82-6c7a17f8de23,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-27e46ff7-a931-4a6d-8881-35fd14f06a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852369817-172.17.0.7-1598437125717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-84cc7d1c-5c7f-4245-959b-4fc43e92132c,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-6d7da644-74ae-4ec6-bb0a-e2a384d008fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-a77d03c8-196f-433c-9b25-5727be6dd22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-03ba6181-7e97-44c1-a4df-93154a6cd698,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-018f8c18-f68d-4123-8888-c87b53196606,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d7f82a52-0555-441d-8591-e2a41a881af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-1064e6d2-09c1-4bfd-ab82-6c7a17f8de23,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-27e46ff7-a931-4a6d-8881-35fd14f06a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028550893-172.17.0.7-1598437394542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-8be26173-83d1-4420-a521-276aa04dd346,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-7551f648-61eb-44eb-af49-6b62114cc216,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-635c41bb-5ff4-49d4-8eec-4af89f3438d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-13d3f2af-9204-4ace-ba19-464253d5e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-d3e7cb78-2d33-434b-bd3c-d4136257f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-a20ee670-914f-4bb1-87ca-cc816e590e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-05c3f3c9-8b00-43e3-a4ef-cc4b563aa6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-107c8f1d-0fb5-43c5-92d1-c46f57617705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028550893-172.17.0.7-1598437394542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-8be26173-83d1-4420-a521-276aa04dd346,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-7551f648-61eb-44eb-af49-6b62114cc216,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-635c41bb-5ff4-49d4-8eec-4af89f3438d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-13d3f2af-9204-4ace-ba19-464253d5e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-d3e7cb78-2d33-434b-bd3c-d4136257f3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-a20ee670-914f-4bb1-87ca-cc816e590e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-05c3f3c9-8b00-43e3-a4ef-cc4b563aa6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-107c8f1d-0fb5-43c5-92d1-c46f57617705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888446531-172.17.0.7-1598437831027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-363556f4-c17d-49a2-92d0-cb2a0c2f0dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-eba030e4-cf30-4f94-b6bc-ef63c8574517,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-445418d7-4353-4856-8de1-1d6bb7e2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-2367cea5-f103-42a4-83f3-044815125678,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-aab5ac17-ba17-483e-a78b-0bbcd07f3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-dfa1f7dd-c7f4-4e8f-a816-599be4116aca,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-2836a411-5fda-4ff9-84ea-2a1bf92208f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-5512b4de-cdcf-4501-805c-29d0454cd97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888446531-172.17.0.7-1598437831027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-363556f4-c17d-49a2-92d0-cb2a0c2f0dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-eba030e4-cf30-4f94-b6bc-ef63c8574517,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-445418d7-4353-4856-8de1-1d6bb7e2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-2367cea5-f103-42a4-83f3-044815125678,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-aab5ac17-ba17-483e-a78b-0bbcd07f3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-dfa1f7dd-c7f4-4e8f-a816-599be4116aca,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-2836a411-5fda-4ff9-84ea-2a1bf92208f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-5512b4de-cdcf-4501-805c-29d0454cd97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325056669-172.17.0.7-1598437949353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-4b7dee72-602a-4e4a-858c-ab7672443ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-4cb63206-b152-4a8a-996f-a0baa8481a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-36994564-0f75-4d12-b3df-1f0c17418c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-48e6def6-ebd7-437a-a039-f4b067566765,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-513053c0-a2f2-44bc-9a95-edc3f307adde,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-5b1ddcd9-7903-42d5-b0e1-79ef2a842142,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-a1a8b52b-bc4b-4af0-b6d7-3fe877f6dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-c0033cfe-56f5-4a65-9dd9-39b26b7ca1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325056669-172.17.0.7-1598437949353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-4b7dee72-602a-4e4a-858c-ab7672443ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-4cb63206-b152-4a8a-996f-a0baa8481a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-36994564-0f75-4d12-b3df-1f0c17418c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-48e6def6-ebd7-437a-a039-f4b067566765,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-513053c0-a2f2-44bc-9a95-edc3f307adde,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-5b1ddcd9-7903-42d5-b0e1-79ef2a842142,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-a1a8b52b-bc4b-4af0-b6d7-3fe877f6dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-c0033cfe-56f5-4a65-9dd9-39b26b7ca1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134156517-172.17.0.7-1598438384238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-35d31bda-de5a-4b15-8233-61e7a058915c,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-baedaeef-e215-40e0-a9a6-33f277f71133,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-175f64cb-da64-48ee-8f17-d9b33dd73463,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-e71e323e-eb79-4c95-a480-4989fd158dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-a4f346f1-d667-43c8-97e6-3e6499a65fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-aab72859-7e5d-4e56-8d79-d739f5bf4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-e2071214-c3ff-4fa0-9fd8-7ad8e3bf8a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1f0e0d35-f995-4e12-ada4-2643bb844aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134156517-172.17.0.7-1598438384238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-35d31bda-de5a-4b15-8233-61e7a058915c,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-baedaeef-e215-40e0-a9a6-33f277f71133,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-175f64cb-da64-48ee-8f17-d9b33dd73463,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-e71e323e-eb79-4c95-a480-4989fd158dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-a4f346f1-d667-43c8-97e6-3e6499a65fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-aab72859-7e5d-4e56-8d79-d739f5bf4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-e2071214-c3ff-4fa0-9fd8-7ad8e3bf8a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1f0e0d35-f995-4e12-ada4-2643bb844aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342840394-172.17.0.7-1598438445242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-62727031-52dd-4872-a7be-3b5ea9225a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-ba78c45c-2c25-4b39-82e8-c99309b9c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-882e496c-6337-47e3-8d51-12162e4e8b32,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-7b93154e-366c-4cd5-812f-0ce0fdac9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-5ad4d4f1-0851-4c33-912b-a5c3b7dcfc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-5212c762-5edd-40d6-bf77-52a8ff79d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-11d6b5ef-9dbc-4d62-9604-88e5f1dc620b,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-6bf9c7fc-266b-4da1-a914-7203590a2c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342840394-172.17.0.7-1598438445242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-62727031-52dd-4872-a7be-3b5ea9225a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-ba78c45c-2c25-4b39-82e8-c99309b9c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-882e496c-6337-47e3-8d51-12162e4e8b32,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-7b93154e-366c-4cd5-812f-0ce0fdac9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-5ad4d4f1-0851-4c33-912b-a5c3b7dcfc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-5212c762-5edd-40d6-bf77-52a8ff79d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-11d6b5ef-9dbc-4d62-9604-88e5f1dc620b,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-6bf9c7fc-266b-4da1-a914-7203590a2c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995271214-172.17.0.7-1598439582964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-fbbc0903-b7eb-4e40-be03-8d5262c87172,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-80e5fd4e-d900-47b4-8445-04eff793cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d6d6ab47-9d64-41b6-a350-b2ec48cbf2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-1e300a0a-a669-45d2-b8db-eccc8e7d8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-7b1ec25e-ca3b-4eda-aa7b-902c9a8e2c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-3bd709f2-d654-4ef6-9ab2-b44bb2ce8074,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-44503bbd-030c-4c67-b05e-e528c95f994b,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-17c10f05-0bb4-4dc2-8dd6-7225f11415cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995271214-172.17.0.7-1598439582964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-fbbc0903-b7eb-4e40-be03-8d5262c87172,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-80e5fd4e-d900-47b4-8445-04eff793cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d6d6ab47-9d64-41b6-a350-b2ec48cbf2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-1e300a0a-a669-45d2-b8db-eccc8e7d8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-7b1ec25e-ca3b-4eda-aa7b-902c9a8e2c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-3bd709f2-d654-4ef6-9ab2-b44bb2ce8074,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-44503bbd-030c-4c67-b05e-e528c95f994b,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-17c10f05-0bb4-4dc2-8dd6-7225f11415cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815044088-172.17.0.7-1598439804271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-8ab86f5a-c708-48c8-8d41-0a9588fa2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-5d401369-9c83-410f-aa9f-5aa72f1e2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-c0f5ea45-365c-4803-8ccc-9fbecd5dc506,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-ae8fa840-7583-42fb-a66d-ede59b46352f,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-faba1356-9156-4a6e-b7ea-a2510ee4ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-7c743221-ee85-4317-86d7-18ef2a7baa02,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-159d0f82-918f-41de-be9d-d8574e0218cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-96425b27-584f-419f-9242-f9c88aa1f283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815044088-172.17.0.7-1598439804271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-8ab86f5a-c708-48c8-8d41-0a9588fa2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-5d401369-9c83-410f-aa9f-5aa72f1e2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-c0f5ea45-365c-4803-8ccc-9fbecd5dc506,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-ae8fa840-7583-42fb-a66d-ede59b46352f,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-faba1356-9156-4a6e-b7ea-a2510ee4ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-7c743221-ee85-4317-86d7-18ef2a7baa02,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-159d0f82-918f-41de-be9d-d8574e0218cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-96425b27-584f-419f-9242-f9c88aa1f283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5268
