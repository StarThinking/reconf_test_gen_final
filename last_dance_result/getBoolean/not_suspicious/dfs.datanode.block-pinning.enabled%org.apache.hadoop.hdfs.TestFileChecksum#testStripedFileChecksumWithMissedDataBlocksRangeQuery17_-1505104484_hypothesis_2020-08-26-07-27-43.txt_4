reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485778680-172.17.0.13-1598426945360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-4a30d1d2-99d1-4b0f-ad6e-fc8c68d0e550,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-53a6b26c-9680-41d5-a28e-9d04335470b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-707ebfc9-1d12-45b2-875e-eb5ce41aab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-a34c4249-33c9-41d7-a989-c9dd3208a264,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-7c7d8828-41e5-4163-957a-c7f774218588,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-15d1c659-48f9-46be-8280-d77b78007597,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-387479bf-a85a-4e0d-a47b-71794d25b705,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-dfcb1e31-eaf3-437a-8c4e-a45e42da5663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485778680-172.17.0.13-1598426945360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-4a30d1d2-99d1-4b0f-ad6e-fc8c68d0e550,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-53a6b26c-9680-41d5-a28e-9d04335470b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-707ebfc9-1d12-45b2-875e-eb5ce41aab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-a34c4249-33c9-41d7-a989-c9dd3208a264,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-7c7d8828-41e5-4163-957a-c7f774218588,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-15d1c659-48f9-46be-8280-d77b78007597,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-387479bf-a85a-4e0d-a47b-71794d25b705,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-dfcb1e31-eaf3-437a-8c4e-a45e42da5663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89817738-172.17.0.13-1598427013755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36864,DS-9e473e9b-f186-4254-a55a-a7189b322872,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-d9f1ddc0-0da0-4f7a-b683-2d5017296a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-766da894-6212-455e-b627-1e4f4aaa2065,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-8b216b23-9ea4-4a9b-a41a-ca55d764d060,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-afad940d-ad93-446b-91ec-716ae12687bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-52be3940-c838-42d5-bb79-5920eee2f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d67da72e-62d2-45ad-8d3b-301b2924940b,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-5ebea4b6-be70-4a3a-a0ac-011c2be9d71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89817738-172.17.0.13-1598427013755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36864,DS-9e473e9b-f186-4254-a55a-a7189b322872,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-d9f1ddc0-0da0-4f7a-b683-2d5017296a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-766da894-6212-455e-b627-1e4f4aaa2065,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-8b216b23-9ea4-4a9b-a41a-ca55d764d060,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-afad940d-ad93-446b-91ec-716ae12687bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-52be3940-c838-42d5-bb79-5920eee2f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d67da72e-62d2-45ad-8d3b-301b2924940b,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-5ebea4b6-be70-4a3a-a0ac-011c2be9d71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139431330-172.17.0.13-1598427049592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-6d7f9183-fa8c-40f2-ac00-5676aa3b8431,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-07a97633-ed26-40db-843f-e3a04040534a,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-c13634e7-57ce-4c9b-93b8-18b6ddbad417,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-694681c1-e20e-495e-a2df-dc248cd87199,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-03798b42-250d-4215-86fc-9afb45eac02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-e9ee9237-e5b1-4fdf-a05c-1d1eee22d005,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-261fd8a8-2bdf-44f8-804b-7ddb05b70aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-5afadeba-939e-4b49-bae1-7de3f1909721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139431330-172.17.0.13-1598427049592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-6d7f9183-fa8c-40f2-ac00-5676aa3b8431,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-07a97633-ed26-40db-843f-e3a04040534a,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-c13634e7-57ce-4c9b-93b8-18b6ddbad417,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-694681c1-e20e-495e-a2df-dc248cd87199,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-03798b42-250d-4215-86fc-9afb45eac02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-e9ee9237-e5b1-4fdf-a05c-1d1eee22d005,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-261fd8a8-2bdf-44f8-804b-7ddb05b70aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-5afadeba-939e-4b49-bae1-7de3f1909721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385739888-172.17.0.13-1598427322002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45519,DS-53ee8294-9d5e-47c0-8df1-cceb8612a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-7985b1a5-6afc-41f7-93e3-2e05499d3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-8655ef82-27d9-4ba9-be07-00f90349a191,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5d8dcbc6-2c76-481f-9f85-141f887ec340,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-143b9605-eece-4238-880e-dec1d006e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f24c6c92-7214-4b69-9ed9-f7da1b55805b,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-1230a931-2aff-41ba-aae0-b36c10639820,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-711d9507-1a16-40ea-8b95-3c70cf256223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385739888-172.17.0.13-1598427322002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45519,DS-53ee8294-9d5e-47c0-8df1-cceb8612a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-7985b1a5-6afc-41f7-93e3-2e05499d3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-8655ef82-27d9-4ba9-be07-00f90349a191,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-5d8dcbc6-2c76-481f-9f85-141f887ec340,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-143b9605-eece-4238-880e-dec1d006e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f24c6c92-7214-4b69-9ed9-f7da1b55805b,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-1230a931-2aff-41ba-aae0-b36c10639820,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-711d9507-1a16-40ea-8b95-3c70cf256223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388334340-172.17.0.13-1598427360169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-7ec81cd7-e18b-4567-9606-9266d080fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2c0b69d7-0f48-48af-b141-b432e96a9118,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-0e62a9a7-c625-4697-a8a8-54166373ecba,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-078cb65a-0cec-4f33-b31c-0d50d2dab3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-9d22ec7a-02ee-4177-9cd2-16c0d5cefdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad7774b1-7c0f-4f67-8a54-31be8c92bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-6c94a752-0677-4d69-affc-f7478ba4b301,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-d3f18783-1583-438b-a275-411a39962fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388334340-172.17.0.13-1598427360169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-7ec81cd7-e18b-4567-9606-9266d080fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2c0b69d7-0f48-48af-b141-b432e96a9118,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-0e62a9a7-c625-4697-a8a8-54166373ecba,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-078cb65a-0cec-4f33-b31c-0d50d2dab3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-9d22ec7a-02ee-4177-9cd2-16c0d5cefdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-ad7774b1-7c0f-4f67-8a54-31be8c92bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-6c94a752-0677-4d69-affc-f7478ba4b301,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-d3f18783-1583-438b-a275-411a39962fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064229447-172.17.0.13-1598427688957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-e66fcf4d-61d8-489c-b445-e8f935e6761e,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-2d3c2ca7-e285-496b-bebe-8f1981c90066,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a1bf1154-16af-4e10-9cd9-7d2efbd0460d,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-bb37777d-cd33-41c6-bb13-c9de391a270a,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-dc519590-2622-4cdb-a4d9-418f63f80ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-492aa6f5-a4bc-465d-8280-2d3383d094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-08b12fbb-6d93-434f-a0e3-a15b83225c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-9f4c9e5e-a657-4e99-a2c0-547d7590264d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064229447-172.17.0.13-1598427688957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-e66fcf4d-61d8-489c-b445-e8f935e6761e,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-2d3c2ca7-e285-496b-bebe-8f1981c90066,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a1bf1154-16af-4e10-9cd9-7d2efbd0460d,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-bb37777d-cd33-41c6-bb13-c9de391a270a,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-dc519590-2622-4cdb-a4d9-418f63f80ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-492aa6f5-a4bc-465d-8280-2d3383d094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-08b12fbb-6d93-434f-a0e3-a15b83225c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-9f4c9e5e-a657-4e99-a2c0-547d7590264d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998129889-172.17.0.13-1598427861491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-e9c2d643-ca42-4495-828d-1e9d15d531a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-a77e053d-a631-491c-9019-4bb88a1b4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-0d8aed0b-a5ca-459f-b9ed-58873b711eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1d0b318c-5458-4f48-a823-3d07e843c8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-7f98b504-cfbb-42e8-ab33-deeec5040bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-18f397da-c24d-498a-b4ac-8a7922e8fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2b5a9a9c-74d4-4df4-a0f2-7eac95a5f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-43f108a2-a8e7-425b-866c-a736e6bbbffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998129889-172.17.0.13-1598427861491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-e9c2d643-ca42-4495-828d-1e9d15d531a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-a77e053d-a631-491c-9019-4bb88a1b4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-0d8aed0b-a5ca-459f-b9ed-58873b711eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1d0b318c-5458-4f48-a823-3d07e843c8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-7f98b504-cfbb-42e8-ab33-deeec5040bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-18f397da-c24d-498a-b4ac-8a7922e8fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-2b5a9a9c-74d4-4df4-a0f2-7eac95a5f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-43f108a2-a8e7-425b-866c-a736e6bbbffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061919104-172.17.0.13-1598427929690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-0693b282-bea6-4e49-83a9-5f594eece5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9180bd5e-47c7-4482-9727-d6f521b85a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-532c3fb8-232d-4d9b-ba4b-17047788aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-baec30f8-5ba3-4346-b82a-6b85172f2b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-66b362b4-18a5-4945-b63b-417cc6dbd10a,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-42708ad8-499d-486f-8d38-f41b72d78773,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-9fe1325e-486c-4791-bcd4-977193bfcabc,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-b79528c4-1a28-45bd-935c-86443c401501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061919104-172.17.0.13-1598427929690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-0693b282-bea6-4e49-83a9-5f594eece5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9180bd5e-47c7-4482-9727-d6f521b85a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-532c3fb8-232d-4d9b-ba4b-17047788aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-baec30f8-5ba3-4346-b82a-6b85172f2b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-66b362b4-18a5-4945-b63b-417cc6dbd10a,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-42708ad8-499d-486f-8d38-f41b72d78773,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-9fe1325e-486c-4791-bcd4-977193bfcabc,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-b79528c4-1a28-45bd-935c-86443c401501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526565468-172.17.0.13-1598428412476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-3e3a298f-3924-4e3e-b090-6050804d132d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-52313a64-6545-4d77-929c-f09cbad4cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-ec327ef8-87e5-41e5-973f-78421dca8445,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-3906f555-dd13-4a90-98d7-ec564aaee858,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-29f62abf-cbe1-432f-a05a-1fb8cd4006d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-0ad794ce-347e-4216-b53d-d2edab4ec90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-2aaf5e1f-31db-4026-9541-8d4127855edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-85c05f56-bd8c-41d0-8304-a6b84d3082e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526565468-172.17.0.13-1598428412476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-3e3a298f-3924-4e3e-b090-6050804d132d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-52313a64-6545-4d77-929c-f09cbad4cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-ec327ef8-87e5-41e5-973f-78421dca8445,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-3906f555-dd13-4a90-98d7-ec564aaee858,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-29f62abf-cbe1-432f-a05a-1fb8cd4006d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-0ad794ce-347e-4216-b53d-d2edab4ec90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-2aaf5e1f-31db-4026-9541-8d4127855edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-85c05f56-bd8c-41d0-8304-a6b84d3082e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761354253-172.17.0.13-1598429058036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-707078a3-557a-4e18-b474-067be65bd405,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-84d30e78-ef0a-472c-821b-4e2147a043d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-fb6e6ed7-1c32-40d7-99fc-e2cae6bca17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-806f00d2-1469-4568-a175-1009e7978d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-fb62b7b1-ce07-4a31-b083-26a7d5ce258d,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-7bbd79a2-8747-4f49-90aa-9e2f62d518c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-83ea7214-13d7-4010-a137-e5cfeac6c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-918d1e7b-8b47-4151-a2f4-dab27140ccb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761354253-172.17.0.13-1598429058036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-707078a3-557a-4e18-b474-067be65bd405,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-84d30e78-ef0a-472c-821b-4e2147a043d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-fb6e6ed7-1c32-40d7-99fc-e2cae6bca17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-806f00d2-1469-4568-a175-1009e7978d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-fb62b7b1-ce07-4a31-b083-26a7d5ce258d,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-7bbd79a2-8747-4f49-90aa-9e2f62d518c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-83ea7214-13d7-4010-a137-e5cfeac6c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-918d1e7b-8b47-4151-a2f4-dab27140ccb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682421032-172.17.0.13-1598429485107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-b1c0ec6b-3016-45f5-914b-1373df3f34bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-fcb8f2eb-d5a7-4172-b5d7-807926756cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-5aaa4be4-1c75-4934-a618-7b2fbc473ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-3ffd3e56-8fd8-40c5-a238-4e4b00e2ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-bef9fd78-7252-4fd8-b3be-4d0b9653583e,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-c2185056-ffe4-476b-aef4-6aa6a80b51e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-140f56a0-2445-480a-98d7-37540f3ffaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-f69d364f-1b4f-4cb1-b4ca-1abf68aaced5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682421032-172.17.0.13-1598429485107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-b1c0ec6b-3016-45f5-914b-1373df3f34bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-fcb8f2eb-d5a7-4172-b5d7-807926756cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-5aaa4be4-1c75-4934-a618-7b2fbc473ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-3ffd3e56-8fd8-40c5-a238-4e4b00e2ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-bef9fd78-7252-4fd8-b3be-4d0b9653583e,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-c2185056-ffe4-476b-aef4-6aa6a80b51e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-140f56a0-2445-480a-98d7-37540f3ffaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-f69d364f-1b4f-4cb1-b4ca-1abf68aaced5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980465948-172.17.0.13-1598430355283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-ff956161-18d4-40de-9da6-d0b8add6df6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-1d624580-03af-4054-b5d1-791c6a9fb6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5f393d3f-ae13-48f6-85fd-1ca1310a014a,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-dc47caf1-cb34-4dc1-ab3f-63b7fcffcb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-dad60e6e-971d-418f-8710-fdb283468037,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-781c0110-b337-4884-bbb6-5835a800ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c8d4f143-466d-460d-b3ca-8a3c3c82b093,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-aca3b45e-845c-4a24-9fa5-88f795111af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980465948-172.17.0.13-1598430355283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-ff956161-18d4-40de-9da6-d0b8add6df6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-1d624580-03af-4054-b5d1-791c6a9fb6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5f393d3f-ae13-48f6-85fd-1ca1310a014a,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-dc47caf1-cb34-4dc1-ab3f-63b7fcffcb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-dad60e6e-971d-418f-8710-fdb283468037,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-781c0110-b337-4884-bbb6-5835a800ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c8d4f143-466d-460d-b3ca-8a3c3c82b093,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-aca3b45e-845c-4a24-9fa5-88f795111af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562523790-172.17.0.13-1598430390133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-81358ecd-ed4e-41cb-8c6d-6cdee06afa16,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-14b70606-5c2d-4341-9dc9-c7d30909573a,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4c5be38a-2c16-4546-ae78-914120dfa01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-bbc28ac4-5d0b-40ba-bd40-ede033672fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-0b943a87-9c86-4d07-a133-8133c68b83da,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-85953d03-18ad-4a9f-a2a5-87b8c4da1ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-e5b309f3-1377-40ea-bca0-eeb568a352c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-40dff8fb-c1a4-43f5-8266-9dad6e401fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562523790-172.17.0.13-1598430390133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-81358ecd-ed4e-41cb-8c6d-6cdee06afa16,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-14b70606-5c2d-4341-9dc9-c7d30909573a,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4c5be38a-2c16-4546-ae78-914120dfa01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-bbc28ac4-5d0b-40ba-bd40-ede033672fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-0b943a87-9c86-4d07-a133-8133c68b83da,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-85953d03-18ad-4a9f-a2a5-87b8c4da1ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-e5b309f3-1377-40ea-bca0-eeb568a352c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-40dff8fb-c1a4-43f5-8266-9dad6e401fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303713119-172.17.0.13-1598430769531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-4d04f25a-7a80-49eb-89fe-d59760aa229c,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-3e59f235-6b18-4f01-9c6a-26e59a038209,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-228a184c-e8c6-46dd-8d0e-37422f7ef37e,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a7253e40-69d2-4257-8fb6-2127aad1a351,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-ad1a69e6-135a-4e4a-a41d-157d3a2bf032,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-1c53c25f-9a38-4b87-827a-aa7b49fb6674,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-cfc28a98-3f50-46de-ae63-496cbb40aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-3e0d7a9d-47db-4233-91ff-32c715b6fd7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303713119-172.17.0.13-1598430769531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-4d04f25a-7a80-49eb-89fe-d59760aa229c,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-3e59f235-6b18-4f01-9c6a-26e59a038209,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-228a184c-e8c6-46dd-8d0e-37422f7ef37e,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a7253e40-69d2-4257-8fb6-2127aad1a351,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-ad1a69e6-135a-4e4a-a41d-157d3a2bf032,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-1c53c25f-9a38-4b87-827a-aa7b49fb6674,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-cfc28a98-3f50-46de-ae63-496cbb40aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-3e0d7a9d-47db-4233-91ff-32c715b6fd7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670819965-172.17.0.13-1598430898498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-08791b2a-9aca-4b25-9ad8-be6932621d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-194cb02e-9f56-4702-b4ab-1ac8b24aca61,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-c42fc4a8-4017-437f-a3d3-8087fed073ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-b907d74d-83f5-4201-8403-717c589457c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-b544b503-0279-45c8-9693-36d98ef6ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f7f708c0-1a5f-493b-af1a-93edc0766b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-ccc64705-d5b3-4ae4-9dc4-880522d3967d,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-822b2787-26c4-465c-ba8f-589d0295c747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670819965-172.17.0.13-1598430898498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-08791b2a-9aca-4b25-9ad8-be6932621d29,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-194cb02e-9f56-4702-b4ab-1ac8b24aca61,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-c42fc4a8-4017-437f-a3d3-8087fed073ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-b907d74d-83f5-4201-8403-717c589457c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-b544b503-0279-45c8-9693-36d98ef6ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f7f708c0-1a5f-493b-af1a-93edc0766b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-ccc64705-d5b3-4ae4-9dc4-880522d3967d,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-822b2787-26c4-465c-ba8f-589d0295c747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229911701-172.17.0.13-1598431134828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-28204358-166b-42e8-a7fa-408cbf175426,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2a26726f-7a29-4c6f-8ec0-18966d23f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-bb5c99ab-527e-4493-9680-43873e117cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-5d17c3e3-2d01-4a80-ba49-62daaa68fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-ba4122ff-4013-435a-bdc9-c1d4c45deb53,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1cb99fb0-d6d3-4b30-9cba-997bbe59c022,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-316d2f0c-c756-43b7-99a8-706327be659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-b8708de1-a2bd-4eb7-9337-bd82a298ee10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229911701-172.17.0.13-1598431134828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33969,DS-28204358-166b-42e8-a7fa-408cbf175426,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2a26726f-7a29-4c6f-8ec0-18966d23f78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-bb5c99ab-527e-4493-9680-43873e117cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-5d17c3e3-2d01-4a80-ba49-62daaa68fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-ba4122ff-4013-435a-bdc9-c1d4c45deb53,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1cb99fb0-d6d3-4b30-9cba-997bbe59c022,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-316d2f0c-c756-43b7-99a8-706327be659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-b8708de1-a2bd-4eb7-9337-bd82a298ee10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078880936-172.17.0.13-1598431271178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-a9926e04-8f25-43fc-ab90-d4d9bb6c3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-3b51851a-0a0d-4c9d-8dd3-aa8405b75f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-a03762e0-d672-4018-8b8c-d8baa23d9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-281dcf00-0d55-48e1-9040-ca7154de1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-c71507ae-f952-4496-881a-59ede1f7d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-58193820-349c-4bce-9458-b1fe152b7c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-79bd9b6e-aaf6-4c29-b6c7-cd8fe6e9da71,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-a1070cb5-1214-470f-9b6d-1746fb4be37b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078880936-172.17.0.13-1598431271178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-a9926e04-8f25-43fc-ab90-d4d9bb6c3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-3b51851a-0a0d-4c9d-8dd3-aa8405b75f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-a03762e0-d672-4018-8b8c-d8baa23d9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-281dcf00-0d55-48e1-9040-ca7154de1e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-c71507ae-f952-4496-881a-59ede1f7d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-58193820-349c-4bce-9458-b1fe152b7c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-79bd9b6e-aaf6-4c29-b6c7-cd8fe6e9da71,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-a1070cb5-1214-470f-9b6d-1746fb4be37b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341914574-172.17.0.13-1598431536853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-9c20eacc-2bbe-498a-902f-4e6775eb9981,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-5715933b-68dd-4058-a95e-d93691a1dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-48c552cd-3fe4-45cc-b714-f15e08577c77,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-840542aa-3f13-4d62-b13e-08a8217e8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-b8bb3e23-07e2-49fe-9795-597fb87ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-06ae2480-d273-448b-81fc-e3f41e2a15ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-89319aee-c3a3-4962-8b47-feb668d4379c,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-c9165b72-6bdc-4fcc-83eb-79b2bd5ce1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341914574-172.17.0.13-1598431536853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-9c20eacc-2bbe-498a-902f-4e6775eb9981,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-5715933b-68dd-4058-a95e-d93691a1dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-48c552cd-3fe4-45cc-b714-f15e08577c77,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-840542aa-3f13-4d62-b13e-08a8217e8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-b8bb3e23-07e2-49fe-9795-597fb87ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-06ae2480-d273-448b-81fc-e3f41e2a15ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-89319aee-c3a3-4962-8b47-feb668d4379c,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-c9165b72-6bdc-4fcc-83eb-79b2bd5ce1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5037
