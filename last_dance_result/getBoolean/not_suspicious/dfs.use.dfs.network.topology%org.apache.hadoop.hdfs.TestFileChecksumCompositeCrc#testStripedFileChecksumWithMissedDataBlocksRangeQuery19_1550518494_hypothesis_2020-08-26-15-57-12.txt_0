reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153578621-172.17.0.2-1598457955860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-f1fb6567-07da-4591-adeb-ebdd74b5041d,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-67dad960-1fd2-4b05-a053-4baf7abe034d,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-e367cde9-faeb-4258-a302-824a795d4273,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-c8aa760c-d5f5-4c67-bad3-bec0ae74d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7d3a2384-cb28-40ba-a6e8-c128937401bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-480e43ac-3b97-4b9d-bb38-2da6bfac961e,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-5c129348-f588-465a-a29f-7b82d9b03143,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-dbb92395-5c3d-4e90-bf94-0cb4313eebd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153578621-172.17.0.2-1598457955860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-f1fb6567-07da-4591-adeb-ebdd74b5041d,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-67dad960-1fd2-4b05-a053-4baf7abe034d,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-e367cde9-faeb-4258-a302-824a795d4273,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-c8aa760c-d5f5-4c67-bad3-bec0ae74d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7d3a2384-cb28-40ba-a6e8-c128937401bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-480e43ac-3b97-4b9d-bb38-2da6bfac961e,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-5c129348-f588-465a-a29f-7b82d9b03143,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-dbb92395-5c3d-4e90-bf94-0cb4313eebd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40014078-172.17.0.2-1598458583293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-7e139a8e-a5b0-4864-90c9-16a603c5d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-7e868cbf-fa75-43cc-ab5e-ffb576e3f160,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-f9b77278-7dda-4589-bff6-8ada5f987310,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-18c44c5d-9f0a-4230-adf5-11414238146d,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-a0b56f8e-d625-4318-bf1d-e14468d65de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-2599e406-897d-4e01-974e-8033a9804786,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-2a8582de-d5db-4dbb-bd01-15552ec21237,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-6dc3d055-5cb6-478f-b48d-10cc17b74822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40014078-172.17.0.2-1598458583293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-7e139a8e-a5b0-4864-90c9-16a603c5d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-7e868cbf-fa75-43cc-ab5e-ffb576e3f160,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-f9b77278-7dda-4589-bff6-8ada5f987310,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-18c44c5d-9f0a-4230-adf5-11414238146d,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-a0b56f8e-d625-4318-bf1d-e14468d65de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-2599e406-897d-4e01-974e-8033a9804786,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-2a8582de-d5db-4dbb-bd01-15552ec21237,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-6dc3d055-5cb6-478f-b48d-10cc17b74822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490278321-172.17.0.2-1598458781434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-1f008ee3-00d2-49ee-b976-815692afa6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-bcc02f44-c7e2-4993-9f26-e46e7fa4912a,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-3ad421e7-10ef-4915-a926-11273c95e720,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-5bc5296c-7573-4228-b397-478c1fdd3341,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b8d4699c-f3e6-4cd8-884b-151e973a7839,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c611a794-5cae-47ab-b5ad-5fec93f6e183,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-4ca1d429-48ed-4f1f-866e-41b6060b4d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-203d76e3-6d2e-43b7-ad21-d4e00590a0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490278321-172.17.0.2-1598458781434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39304,DS-1f008ee3-00d2-49ee-b976-815692afa6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-bcc02f44-c7e2-4993-9f26-e46e7fa4912a,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-3ad421e7-10ef-4915-a926-11273c95e720,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-5bc5296c-7573-4228-b397-478c1fdd3341,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b8d4699c-f3e6-4cd8-884b-151e973a7839,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-c611a794-5cae-47ab-b5ad-5fec93f6e183,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-4ca1d429-48ed-4f1f-866e-41b6060b4d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-203d76e3-6d2e-43b7-ad21-d4e00590a0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374303423-172.17.0.2-1598458913123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-f50cc4a9-57da-4991-b718-3275468bef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-800a4435-86a6-4d46-81a0-44a4de76bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-8dfda57b-012b-4ce5-8ba7-4415b3139388,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-bdaf06f2-6c17-4a11-9f67-887b56ec26cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-b2e86650-5ba1-4a13-9403-88a4b3f968d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-bc4f1aec-e7f8-45c8-a6c1-e61f2098dd62,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-48dee5ce-7e08-4d49-ad24-5ce2eea70922,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2a5cd460-73cc-4af6-ab40-b3c48bf45a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374303423-172.17.0.2-1598458913123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-f50cc4a9-57da-4991-b718-3275468bef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-800a4435-86a6-4d46-81a0-44a4de76bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-8dfda57b-012b-4ce5-8ba7-4415b3139388,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-bdaf06f2-6c17-4a11-9f67-887b56ec26cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-b2e86650-5ba1-4a13-9403-88a4b3f968d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-bc4f1aec-e7f8-45c8-a6c1-e61f2098dd62,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-48dee5ce-7e08-4d49-ad24-5ce2eea70922,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2a5cd460-73cc-4af6-ab40-b3c48bf45a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538701375-172.17.0.2-1598459043112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45472,DS-c4e2120a-2f95-426e-bcaa-9d460bdd5073,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-b2f85655-ee17-4d30-8761-f242f7e6bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-83b7025d-58f6-4d4d-874a-f02cce1985a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-0cb43c5f-2c7e-40c0-b837-c00bc1b071bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-90f48166-57ff-4a35-af46-0816c564d722,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-232b7cfb-33f9-4bf5-9e7c-eb01d3ea68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-70c3990e-bfdf-435c-82ae-d1af7de78099,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2315a3ab-baa2-44f6-8ba1-da03caf421f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538701375-172.17.0.2-1598459043112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45472,DS-c4e2120a-2f95-426e-bcaa-9d460bdd5073,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-b2f85655-ee17-4d30-8761-f242f7e6bd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-83b7025d-58f6-4d4d-874a-f02cce1985a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-0cb43c5f-2c7e-40c0-b837-c00bc1b071bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-90f48166-57ff-4a35-af46-0816c564d722,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-232b7cfb-33f9-4bf5-9e7c-eb01d3ea68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-70c3990e-bfdf-435c-82ae-d1af7de78099,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2315a3ab-baa2-44f6-8ba1-da03caf421f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590667920-172.17.0.2-1598459106312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-ced2008c-e090-46cf-b03e-ac2f616f665f,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-15abcb0d-fc7d-485b-a9ce-7dd8d0541b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-4b3f2f56-52eb-4158-97b8-e34fd8b8ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b82d0455-9cc4-4f80-989b-962e35d6c332,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-9ae8f2df-0022-42f2-8a01-878aebcad00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-cb9814e8-f6a6-4839-9e9b-c34861008dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-c3011d78-4d14-4312-b2d2-b8303f140a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-9841be71-82dd-4757-bf89-ac93a161463b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590667920-172.17.0.2-1598459106312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-ced2008c-e090-46cf-b03e-ac2f616f665f,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-15abcb0d-fc7d-485b-a9ce-7dd8d0541b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-4b3f2f56-52eb-4158-97b8-e34fd8b8ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b82d0455-9cc4-4f80-989b-962e35d6c332,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-9ae8f2df-0022-42f2-8a01-878aebcad00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-cb9814e8-f6a6-4839-9e9b-c34861008dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-c3011d78-4d14-4312-b2d2-b8303f140a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-9841be71-82dd-4757-bf89-ac93a161463b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502830261-172.17.0.2-1598459140828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-126b4c26-5dbf-42ad-83b3-2e743d017db9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-7c0582e8-acde-42db-893f-738171c7c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-fc2311be-92b1-42ce-816c-cf677349ecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-cfbd8ce0-e593-4d50-8ca9-0d4ef75b507d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-0fdefb71-b8e0-45f1-b96a-b89c6854f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-863d7010-b620-4cd0-9517-32ba908e7f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c25bca87-eca1-4e0a-a067-14870da279e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-646f9411-16e4-4ca1-a402-773b6cc1c32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502830261-172.17.0.2-1598459140828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-126b4c26-5dbf-42ad-83b3-2e743d017db9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-7c0582e8-acde-42db-893f-738171c7c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-fc2311be-92b1-42ce-816c-cf677349ecf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-cfbd8ce0-e593-4d50-8ca9-0d4ef75b507d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-0fdefb71-b8e0-45f1-b96a-b89c6854f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-863d7010-b620-4cd0-9517-32ba908e7f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c25bca87-eca1-4e0a-a067-14870da279e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-646f9411-16e4-4ca1-a402-773b6cc1c32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196834705-172.17.0.2-1598459320253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-884d83d0-807c-4859-afdf-92db952cfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-f319b627-1517-413e-b4f3-34e4c9a5fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-79ac1356-a91e-42de-8755-901fd5c863bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-3d2280f9-cb13-4778-9f75-062139b0d709,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-76373697-0a8f-4ad2-8c35-c53cca77ad43,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-1647320c-90f1-415c-a672-cc5ceb70d414,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-fd28bfbe-7743-4cf3-870d-711f14d95c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-806b42c2-93e5-4ce4-8041-4fafa752b9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196834705-172.17.0.2-1598459320253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-884d83d0-807c-4859-afdf-92db952cfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-f319b627-1517-413e-b4f3-34e4c9a5fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-79ac1356-a91e-42de-8755-901fd5c863bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-3d2280f9-cb13-4778-9f75-062139b0d709,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-76373697-0a8f-4ad2-8c35-c53cca77ad43,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-1647320c-90f1-415c-a672-cc5ceb70d414,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-fd28bfbe-7743-4cf3-870d-711f14d95c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-806b42c2-93e5-4ce4-8041-4fafa752b9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814334015-172.17.0.2-1598459738110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-2996de6d-dfa5-4a61-8b84-65eec0b4b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-17159452-9a46-4dfc-9bff-97cc7666a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-4fb5df95-64e1-4f89-91f5-52c6863c2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-4bdd2b09-ce2c-4d2e-b296-151b76f50d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-dbbe30f4-9238-4cd6-94d5-deded3601203,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-6d4da5e2-3ba8-4770-8383-4ffa01b9b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-51c80322-f077-4314-bcb0-265e7d50dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-f12fe8e1-f42d-4766-8a0c-5d439ab369e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814334015-172.17.0.2-1598459738110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41514,DS-2996de6d-dfa5-4a61-8b84-65eec0b4b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-17159452-9a46-4dfc-9bff-97cc7666a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-4fb5df95-64e1-4f89-91f5-52c6863c2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-4bdd2b09-ce2c-4d2e-b296-151b76f50d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-dbbe30f4-9238-4cd6-94d5-deded3601203,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-6d4da5e2-3ba8-4770-8383-4ffa01b9b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-51c80322-f077-4314-bcb0-265e7d50dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-f12fe8e1-f42d-4766-8a0c-5d439ab369e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768597697-172.17.0.2-1598459859971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-a8f749a9-77ae-467c-ab43-099beaed5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-25907eb3-a8e5-4152-861a-3da09d560837,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-1cbf19ed-5d4f-4935-8d15-30b4ba168afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-7e52438d-60da-4347-a3c7-281af4f20201,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-1afb7ab7-c4db-45f6-81d8-cc4776bf986d,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-283e3e57-785f-4553-a1c2-0706eef944a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-fe719451-364b-441e-8588-355129579e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b48c2233-9215-41aa-a872-4b9a285ece62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768597697-172.17.0.2-1598459859971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39960,DS-a8f749a9-77ae-467c-ab43-099beaed5fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-25907eb3-a8e5-4152-861a-3da09d560837,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-1cbf19ed-5d4f-4935-8d15-30b4ba168afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-7e52438d-60da-4347-a3c7-281af4f20201,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-1afb7ab7-c4db-45f6-81d8-cc4776bf986d,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-283e3e57-785f-4553-a1c2-0706eef944a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-fe719451-364b-441e-8588-355129579e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b48c2233-9215-41aa-a872-4b9a285ece62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686170556-172.17.0.2-1598460219916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40489,DS-f63d0a4d-4748-45f6-9d5a-df56228c90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-20a12e1a-6fda-4c3e-82ba-d4df4da9cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-56da0cde-c4ff-4f6c-9455-4fca2608fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-6164eb90-c1ba-4243-91ef-95a8e5b05419,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-e44f9595-e374-44ca-8c58-cbc9086316d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-be76a7e8-9d43-4152-b3f5-fdecdfe3bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-149ea02f-08b8-48bb-9684-8aa75a371c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-74ea4a13-5a8b-4a97-9d29-3928e4c42ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686170556-172.17.0.2-1598460219916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40489,DS-f63d0a4d-4748-45f6-9d5a-df56228c90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-20a12e1a-6fda-4c3e-82ba-d4df4da9cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-56da0cde-c4ff-4f6c-9455-4fca2608fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-6164eb90-c1ba-4243-91ef-95a8e5b05419,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-e44f9595-e374-44ca-8c58-cbc9086316d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-be76a7e8-9d43-4152-b3f5-fdecdfe3bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-149ea02f-08b8-48bb-9684-8aa75a371c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-74ea4a13-5a8b-4a97-9d29-3928e4c42ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584839018-172.17.0.2-1598460353817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-a5927d5c-f3e0-4635-b710-5c3db61b433a,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-9874a533-c64f-4697-ba3f-e310562e8633,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-d20b84ad-77de-482b-bcd5-f225b1ab36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-0d8bdb3c-0958-42d4-b6f4-cd88df7f0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1cdad133-f374-4049-8903-198eded62dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-bb3e2e4c-135e-4e8b-8372-75d3f033d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-6eee67f2-92a9-40bc-8205-1cac287c7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-64fee6d4-e00e-40fe-a71a-9c64b4165fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584839018-172.17.0.2-1598460353817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-a5927d5c-f3e0-4635-b710-5c3db61b433a,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-9874a533-c64f-4697-ba3f-e310562e8633,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-d20b84ad-77de-482b-bcd5-f225b1ab36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-0d8bdb3c-0958-42d4-b6f4-cd88df7f0cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-1cdad133-f374-4049-8903-198eded62dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-bb3e2e4c-135e-4e8b-8372-75d3f033d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-6eee67f2-92a9-40bc-8205-1cac287c7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-64fee6d4-e00e-40fe-a71a-9c64b4165fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393867545-172.17.0.2-1598460387527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-ee2509dc-9c7d-4939-b8d6-9472efe0afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-2853021f-1e9d-4843-b226-953ffda144d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-0b79009c-6e49-45f5-85f3-897149dfc259,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-f4ffa403-8477-4593-aace-0154f743d875,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-b0f0e81e-dcd6-4d2f-95fd-1bf50a47e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-8f55d07a-68cb-4ec0-b08e-b3609a7f5c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-24c2da2e-8586-471b-aa77-38c33af713a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-810c29b3-0ea5-4aba-9705-ff6a15e69612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393867545-172.17.0.2-1598460387527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-ee2509dc-9c7d-4939-b8d6-9472efe0afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-2853021f-1e9d-4843-b226-953ffda144d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-0b79009c-6e49-45f5-85f3-897149dfc259,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-f4ffa403-8477-4593-aace-0154f743d875,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-b0f0e81e-dcd6-4d2f-95fd-1bf50a47e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-8f55d07a-68cb-4ec0-b08e-b3609a7f5c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-24c2da2e-8586-471b-aa77-38c33af713a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-810c29b3-0ea5-4aba-9705-ff6a15e69612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249367018-172.17.0.2-1598460447847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-8c94bb9f-61a4-4b61-aa01-e632cd921f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-f822e839-f6e7-456d-871c-fbb46462ba30,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-98e48cdd-f48f-471e-8882-345ad2f3be32,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-94820bae-7d4f-4388-af62-4895c5da3039,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-f6504234-1f16-492c-ad3a-1d3e13687166,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-ba1fde28-9d61-4914-9912-952271ded751,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-087ca9f1-2832-4a44-b271-f78e7398a633,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-ca51fe34-15a7-4636-806b-3d0899586467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249367018-172.17.0.2-1598460447847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42381,DS-8c94bb9f-61a4-4b61-aa01-e632cd921f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-f822e839-f6e7-456d-871c-fbb46462ba30,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-98e48cdd-f48f-471e-8882-345ad2f3be32,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-94820bae-7d4f-4388-af62-4895c5da3039,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-f6504234-1f16-492c-ad3a-1d3e13687166,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-ba1fde28-9d61-4914-9912-952271ded751,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-087ca9f1-2832-4a44-b271-f78e7398a633,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-ca51fe34-15a7-4636-806b-3d0899586467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198475151-172.17.0.2-1598460481954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-d6e0e9a1-6978-4768-ab0e-01bf07ca6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-392a2d69-ebe2-4482-9f07-0016fabd9659,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-ed7da0fe-329d-4264-bdf4-ba12141cd419,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0abcc56b-e5da-4a5a-9b80-7f03575e19b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-0e959521-467c-4d2d-a152-3526ea16f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-43e7448a-a030-4571-8c54-433da94d4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-6936a261-eca2-4b5b-85f2-58dd0bf7c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-61848daf-8fb9-45bc-ad6c-fd174cc2de50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198475151-172.17.0.2-1598460481954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-d6e0e9a1-6978-4768-ab0e-01bf07ca6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-392a2d69-ebe2-4482-9f07-0016fabd9659,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-ed7da0fe-329d-4264-bdf4-ba12141cd419,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0abcc56b-e5da-4a5a-9b80-7f03575e19b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-0e959521-467c-4d2d-a152-3526ea16f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-43e7448a-a030-4571-8c54-433da94d4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-6936a261-eca2-4b5b-85f2-58dd0bf7c8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-61848daf-8fb9-45bc-ad6c-fd174cc2de50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903074718-172.17.0.2-1598460879269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-54264169-4913-4968-ba56-3b461058d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-0bf2b382-7793-48b8-89a3-8908ba168313,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e20efbd4-6d8d-4ace-919d-cfd5b727ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-7dba14f6-1b98-4870-9fbc-b05092bd330f,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-86c9289f-2330-4713-81db-c1d7fcbe450d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-841a16de-d585-4fa7-95a8-18fd3aee4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-6dd7c72c-4b0f-45e2-a532-824df7d58ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-ff75d703-5eda-47fb-a8e1-9422d50ece4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903074718-172.17.0.2-1598460879269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-54264169-4913-4968-ba56-3b461058d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-0bf2b382-7793-48b8-89a3-8908ba168313,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e20efbd4-6d8d-4ace-919d-cfd5b727ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-7dba14f6-1b98-4870-9fbc-b05092bd330f,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-86c9289f-2330-4713-81db-c1d7fcbe450d,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-841a16de-d585-4fa7-95a8-18fd3aee4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-6dd7c72c-4b0f-45e2-a532-824df7d58ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-ff75d703-5eda-47fb-a8e1-9422d50ece4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106037710-172.17.0.2-1598461015819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-22f0c8fe-c21a-4c87-a349-c734ed1c6118,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-3e6ce0c8-404f-4676-a3ed-5914dc07a29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-4367d000-c548-4c2b-893c-7d244c9c4111,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-3e5b4773-94b9-4e5c-a90a-acbc5052f2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-c5c3ccb5-a7f9-4514-9f54-fefba42ba0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-a0542f20-2c6b-45c8-b30e-788dc63bcc80,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8099f251-dcce-420f-babe-1af21901903c,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-2ff5d48c-1251-4e88-b940-ab5b299c00d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106037710-172.17.0.2-1598461015819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-22f0c8fe-c21a-4c87-a349-c734ed1c6118,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-3e6ce0c8-404f-4676-a3ed-5914dc07a29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-4367d000-c548-4c2b-893c-7d244c9c4111,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-3e5b4773-94b9-4e5c-a90a-acbc5052f2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-c5c3ccb5-a7f9-4514-9f54-fefba42ba0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-a0542f20-2c6b-45c8-b30e-788dc63bcc80,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-8099f251-dcce-420f-babe-1af21901903c,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-2ff5d48c-1251-4e88-b940-ab5b299c00d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190052369-172.17.0.2-1598461188061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-6cab75d3-8a87-4c23-a7fd-849b04f1e368,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-4ddde53f-ddb3-441b-8122-2edc7123ae1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9e1101c8-9f1b-4f63-8357-04394835d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-03506190-1ad3-4b48-a6d0-0a0682535ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-80757cdf-27a1-4ea9-a1c3-eb0402720971,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-52296c1f-9adb-4982-b648-73d0a571578e,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-ee698757-4ea4-4ce0-990b-774878bb946c,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-2eafee22-4c9f-4118-a0e8-f41437ee6a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190052369-172.17.0.2-1598461188061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-6cab75d3-8a87-4c23-a7fd-849b04f1e368,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-4ddde53f-ddb3-441b-8122-2edc7123ae1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9e1101c8-9f1b-4f63-8357-04394835d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-03506190-1ad3-4b48-a6d0-0a0682535ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-80757cdf-27a1-4ea9-a1c3-eb0402720971,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-52296c1f-9adb-4982-b648-73d0a571578e,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-ee698757-4ea4-4ce0-990b-774878bb946c,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-2eafee22-4c9f-4118-a0e8-f41437ee6a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453880219-172.17.0.2-1598461241243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-71f7e719-4aca-46ac-889f-555be75cc160,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-590b1f99-36f2-479e-9f42-27343aa31435,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-e035ce60-1d70-4d4c-a47a-aea9aecdc809,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-c073472f-1242-473f-953f-39d988a18506,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-5b61175e-f964-491e-8cea-d0d409445010,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6cfe82b6-e1f1-4846-8a33-03ac0c9e9f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-cd7de62f-2a8d-4e03-81b1-58c564884ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-72052d63-3815-421d-b07a-b8a7a3e8c587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453880219-172.17.0.2-1598461241243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-71f7e719-4aca-46ac-889f-555be75cc160,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-590b1f99-36f2-479e-9f42-27343aa31435,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-e035ce60-1d70-4d4c-a47a-aea9aecdc809,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-c073472f-1242-473f-953f-39d988a18506,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-5b61175e-f964-491e-8cea-d0d409445010,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6cfe82b6-e1f1-4846-8a33-03ac0c9e9f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-cd7de62f-2a8d-4e03-81b1-58c564884ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-72052d63-3815-421d-b07a-b8a7a3e8c587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758770789-172.17.0.2-1598461364804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-544980a9-8df9-45d5-85c8-188d3a8420e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-b9c8d4ed-219b-411a-a574-0417a75f6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-0713a2f2-8976-4c87-af62-81fcea5695bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-453af22b-791e-40bb-8fe6-920f79d5f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-63efeef3-216b-4970-b9ed-a46ec03ae366,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4acf9a30-fdcd-4e82-813a-54edee48ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-46872a83-b584-4dc8-a0bd-d2a4305ed6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-8c70a991-ab09-41e8-b195-833c6ecf2bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758770789-172.17.0.2-1598461364804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-544980a9-8df9-45d5-85c8-188d3a8420e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-b9c8d4ed-219b-411a-a574-0417a75f6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-0713a2f2-8976-4c87-af62-81fcea5695bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-453af22b-791e-40bb-8fe6-920f79d5f3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-63efeef3-216b-4970-b9ed-a46ec03ae366,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4acf9a30-fdcd-4e82-813a-54edee48ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-46872a83-b584-4dc8-a0bd-d2a4305ed6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-8c70a991-ab09-41e8-b195-833c6ecf2bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937748847-172.17.0.2-1598461782558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-71095aea-5742-47c7-aeaf-7c3b8b1c5e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-fd57acda-6d68-40e8-bb5c-6c2ffdcfa0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-f67697b2-0155-4537-98eb-e7c454ee830c,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-04f4b289-b963-403a-9545-b3a6e3d4e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-59e2d875-8042-4325-baf4-5cfcf4ed1f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a05c4622-0170-4f47-88d0-0776fedbfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-5c8a4ac5-ec14-4fa4-887b-a91674fb695e,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-26eb7173-9f8c-4803-a74e-309813b81fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937748847-172.17.0.2-1598461782558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-71095aea-5742-47c7-aeaf-7c3b8b1c5e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-fd57acda-6d68-40e8-bb5c-6c2ffdcfa0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-f67697b2-0155-4537-98eb-e7c454ee830c,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-04f4b289-b963-403a-9545-b3a6e3d4e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-59e2d875-8042-4325-baf4-5cfcf4ed1f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a05c4622-0170-4f47-88d0-0776fedbfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-5c8a4ac5-ec14-4fa4-887b-a91674fb695e,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-26eb7173-9f8c-4803-a74e-309813b81fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511222006-172.17.0.2-1598461846076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-aaf21a95-9838-4ef5-92f8-4e94c9d1e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-8f8a2bf0-2e9a-45cd-b230-a27fd7295e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-8c7ce6e0-118c-4ab4-a9b7-81908bc760ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-6d88a9d8-e57c-4086-964f-28ef5681fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-ae23ea0d-d712-4630-ab34-821f826ed018,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-653f7d6f-58f2-4028-a63a-12dda24e1304,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-b5a490a0-a345-41ca-9913-12216a88414e,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-d3a57254-3ed3-448f-b156-8e422614fbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511222006-172.17.0.2-1598461846076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-aaf21a95-9838-4ef5-92f8-4e94c9d1e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-8f8a2bf0-2e9a-45cd-b230-a27fd7295e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-8c7ce6e0-118c-4ab4-a9b7-81908bc760ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-6d88a9d8-e57c-4086-964f-28ef5681fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-ae23ea0d-d712-4630-ab34-821f826ed018,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-653f7d6f-58f2-4028-a63a-12dda24e1304,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-b5a490a0-a345-41ca-9913-12216a88414e,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-d3a57254-3ed3-448f-b156-8e422614fbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007914062-172.17.0.2-1598462050067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-19be6221-6992-4f79-8351-f346ea7c2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-fe69b235-4590-4c6b-b013-9d4b9b47ea67,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-092ae91a-aa58-4090-9172-be35aac19ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-d1477b2e-83e2-4105-ae6d-da200a370af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-3c3954ef-1765-4127-9d63-7b5e536a0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-3a3cdd79-3bf3-4c64-8455-8193c301e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-1934be53-1e30-44b7-858c-ea9b6c400b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-756801bd-39b5-4544-8b34-5b7c501fd5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007914062-172.17.0.2-1598462050067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-19be6221-6992-4f79-8351-f346ea7c2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-fe69b235-4590-4c6b-b013-9d4b9b47ea67,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-092ae91a-aa58-4090-9172-be35aac19ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-d1477b2e-83e2-4105-ae6d-da200a370af3,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-3c3954ef-1765-4127-9d63-7b5e536a0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-3a3cdd79-3bf3-4c64-8455-8193c301e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-1934be53-1e30-44b7-858c-ea9b6c400b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-756801bd-39b5-4544-8b34-5b7c501fd5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878446831-172.17.0.2-1598462147697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-b2622c43-8009-40fd-8386-089c6603c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f0737606-1d20-4c40-8493-e215c6161985,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-631d5217-f752-48f0-8618-e0a204c9bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-94729d95-d1b4-4dfa-af4f-1ff93fae0693,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-1f3fc903-2801-4270-99b2-20fc02aedf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3ec7faf8-8c39-4e52-85c4-551b1307f098,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-080780b3-3c23-4855-8fdc-82a7a5dcd77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f435641f-6c96-4519-a162-9a2f3e569411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878446831-172.17.0.2-1598462147697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-b2622c43-8009-40fd-8386-089c6603c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f0737606-1d20-4c40-8493-e215c6161985,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-631d5217-f752-48f0-8618-e0a204c9bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-94729d95-d1b4-4dfa-af4f-1ff93fae0693,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-1f3fc903-2801-4270-99b2-20fc02aedf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3ec7faf8-8c39-4e52-85c4-551b1307f098,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-080780b3-3c23-4855-8fdc-82a7a5dcd77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-f435641f-6c96-4519-a162-9a2f3e569411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54975287-172.17.0.2-1598462328046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-0ed222bb-9e1b-40f5-87ed-ec4baf3d1004,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-0dd51beb-34de-4a94-b6ec-3ec96d26ee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-89fa49f3-5b4a-4d32-8ebb-bce0b097e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-f93f09c5-b5c6-4276-9a1d-4e5818885d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7458801f-629e-4214-97fc-869378507f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-e2197d02-384c-4014-8ad0-84151e1ef722,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-641b26d0-07f6-477f-a3ff-0020f1d19633,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-02e767ee-b0c3-4984-b8f0-c034db1671fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54975287-172.17.0.2-1598462328046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-0ed222bb-9e1b-40f5-87ed-ec4baf3d1004,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-0dd51beb-34de-4a94-b6ec-3ec96d26ee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-89fa49f3-5b4a-4d32-8ebb-bce0b097e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-f93f09c5-b5c6-4276-9a1d-4e5818885d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7458801f-629e-4214-97fc-869378507f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-e2197d02-384c-4014-8ad0-84151e1ef722,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-641b26d0-07f6-477f-a3ff-0020f1d19633,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-02e767ee-b0c3-4984-b8f0-c034db1671fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 4970
