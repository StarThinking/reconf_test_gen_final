reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279563182-172.17.0.10-1598334417712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-132ff6cc-e19b-4185-b973-44319350be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b104aae0-85c7-4d13-8dd1-fedf82d83917,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-bdb6cd05-d25d-429f-8be3-1b8e5be16463,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-4b6f2e00-a807-4b39-89a7-c22b05cfbdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-9856bb20-b01d-4f9e-91d2-5fd56d591a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-a10747c9-62c0-42e6-9e96-9adb510188eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-8f072bfb-f233-4a48-ac96-70f27293f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-40423206-7670-460a-a439-8693386a49cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279563182-172.17.0.10-1598334417712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-132ff6cc-e19b-4185-b973-44319350be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-b104aae0-85c7-4d13-8dd1-fedf82d83917,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-bdb6cd05-d25d-429f-8be3-1b8e5be16463,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-4b6f2e00-a807-4b39-89a7-c22b05cfbdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-9856bb20-b01d-4f9e-91d2-5fd56d591a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-a10747c9-62c0-42e6-9e96-9adb510188eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-8f072bfb-f233-4a48-ac96-70f27293f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-40423206-7670-460a-a439-8693386a49cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89442447-172.17.0.10-1598334451655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3b8e1740-ae22-44ed-a98c-0acbb93c4796,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b2bf1ad8-a985-4282-8843-9a3e851bc6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-2ddd7ec6-5176-40b6-ac85-11165ebca1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-b6d4d54e-7488-45c5-bea2-890e35b4c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-d4977271-3548-4db9-948b-4af76fb1b952,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-54711d22-e93a-4e6c-8dcb-b45acae382aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-512f1e10-1e47-4991-8326-cace2234dfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-74f7ae59-0b18-4413-b2d5-4bf5418f84fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89442447-172.17.0.10-1598334451655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3b8e1740-ae22-44ed-a98c-0acbb93c4796,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-b2bf1ad8-a985-4282-8843-9a3e851bc6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-2ddd7ec6-5176-40b6-ac85-11165ebca1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-b6d4d54e-7488-45c5-bea2-890e35b4c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-d4977271-3548-4db9-948b-4af76fb1b952,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-54711d22-e93a-4e6c-8dcb-b45acae382aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-512f1e10-1e47-4991-8326-cace2234dfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-74f7ae59-0b18-4413-b2d5-4bf5418f84fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830372772-172.17.0.10-1598334832979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-fb5933db-94b5-44a6-9e89-847718ecb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-8a7fb911-6fa3-4b2e-a984-2422a3d73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-7e5f12a4-d2d5-44ec-a3ab-7569bacad9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-4c7f63f3-4348-42d0-ab16-6fe4590fc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-2dca101b-6c14-4322-bda2-9319b4a95581,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-9397a017-a27e-4261-ab3d-168cebb0dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-768176b5-ddef-4238-b5f6-83da30768d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-67726581-8d8c-47cb-b62a-acf920fa4e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830372772-172.17.0.10-1598334832979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-fb5933db-94b5-44a6-9e89-847718ecb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-8a7fb911-6fa3-4b2e-a984-2422a3d73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-7e5f12a4-d2d5-44ec-a3ab-7569bacad9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-4c7f63f3-4348-42d0-ab16-6fe4590fc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-2dca101b-6c14-4322-bda2-9319b4a95581,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-9397a017-a27e-4261-ab3d-168cebb0dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-768176b5-ddef-4238-b5f6-83da30768d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-67726581-8d8c-47cb-b62a-acf920fa4e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288896699-172.17.0.10-1598335132943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-2f1019b3-c94d-41f1-bb13-0327fa6d04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-32c00580-2d1a-454d-91cf-2d3103dc6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-20fa9942-e083-4365-a7a7-d81756eda77e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-91a6e276-7785-4f43-81b0-4bef52f3755e,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-89c1acba-1124-437c-a1f0-db03bdeeb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-fb6332d0-3280-41cd-99fb-b5ca227bfc40,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5a302199-beec-41aa-be1d-46f62c965fee,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-a0ba7f34-af49-466e-b666-81ffd616459b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288896699-172.17.0.10-1598335132943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-2f1019b3-c94d-41f1-bb13-0327fa6d04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-32c00580-2d1a-454d-91cf-2d3103dc6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-20fa9942-e083-4365-a7a7-d81756eda77e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-91a6e276-7785-4f43-81b0-4bef52f3755e,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-89c1acba-1124-437c-a1f0-db03bdeeb42f,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-fb6332d0-3280-41cd-99fb-b5ca227bfc40,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5a302199-beec-41aa-be1d-46f62c965fee,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-a0ba7f34-af49-466e-b666-81ffd616459b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271854646-172.17.0.10-1598335171612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38205,DS-4de6de1e-5446-42da-bdfe-24149cc10425,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-f03b4f29-7b9b-4418-8155-ec644651fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-8d6f0b24-d03f-4a7b-938d-ba168648c887,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-fcdd36db-4a95-4f41-9692-ae823cc9003c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-acab01e3-8e2a-46ee-a974-71360c98b062,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-5c843f6c-00fc-43fc-9b5d-5a1dd28c7e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-690aa831-1083-4c7e-addc-75d42900b996,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-9a8edff4-5b63-48aa-bbe4-e38f59931a6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271854646-172.17.0.10-1598335171612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38205,DS-4de6de1e-5446-42da-bdfe-24149cc10425,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-f03b4f29-7b9b-4418-8155-ec644651fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-8d6f0b24-d03f-4a7b-938d-ba168648c887,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-fcdd36db-4a95-4f41-9692-ae823cc9003c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-acab01e3-8e2a-46ee-a974-71360c98b062,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-5c843f6c-00fc-43fc-9b5d-5a1dd28c7e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-690aa831-1083-4c7e-addc-75d42900b996,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-9a8edff4-5b63-48aa-bbe4-e38f59931a6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482279545-172.17.0.10-1598335368608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35483,DS-0151980e-18fd-430d-a326-144e5b4285eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-60b6858c-e637-43bd-aacf-125e0b2dce62,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-f1bef9f0-b77a-4b90-8a60-48365afc9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-864f238e-880c-43de-b838-a920420362e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-4bf60ce1-7662-46b6-b88c-d8520a93f1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-083a799a-297b-4a56-ad63-538f7e4f8604,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-786fcf4b-1bec-4499-8ed5-82a4a6989f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-d413263e-3f43-4a2b-921d-a6aea0e1b5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482279545-172.17.0.10-1598335368608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35483,DS-0151980e-18fd-430d-a326-144e5b4285eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-60b6858c-e637-43bd-aacf-125e0b2dce62,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-f1bef9f0-b77a-4b90-8a60-48365afc9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-864f238e-880c-43de-b838-a920420362e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-4bf60ce1-7662-46b6-b88c-d8520a93f1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-083a799a-297b-4a56-ad63-538f7e4f8604,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-786fcf4b-1bec-4499-8ed5-82a4a6989f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-d413263e-3f43-4a2b-921d-a6aea0e1b5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413004369-172.17.0.10-1598335550112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-279372f8-7e5b-470b-adcb-4018d164911a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-cb696665-32d1-430f-b9ee-ac4800324b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-68da697d-7593-43c4-bf17-5dc2ec096ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-437acf7d-42db-4982-a111-934a91e98773,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-0e49d8a4-12bd-464a-99fc-35db3d9c8e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-06bb3c55-37b9-46b5-b72d-c1be07c2c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-abd9b72f-68a0-44d5-917f-4d15c499bfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-71d641e6-6073-4dcd-9f73-3c550c8e8466,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413004369-172.17.0.10-1598335550112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-279372f8-7e5b-470b-adcb-4018d164911a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-cb696665-32d1-430f-b9ee-ac4800324b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-68da697d-7593-43c4-bf17-5dc2ec096ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-437acf7d-42db-4982-a111-934a91e98773,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-0e49d8a4-12bd-464a-99fc-35db3d9c8e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-06bb3c55-37b9-46b5-b72d-c1be07c2c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-abd9b72f-68a0-44d5-917f-4d15c499bfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-71d641e6-6073-4dcd-9f73-3c550c8e8466,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914519142-172.17.0.10-1598335780187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-dc6328ab-8515-469c-820c-3bc1f19b3f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-7657762b-ca5a-473f-b03e-b2fdf7d023e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-65c1fef0-c3eb-4ee7-94c4-a1d72e99034d,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-c4f2eed3-b0ec-4e5b-ad4b-7bcf8b84a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-8afeca6f-d8d9-4501-b645-4289eb25bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-464b792e-1df6-426e-b4d7-93391c74e383,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-6f122eab-5095-4896-b69a-542f2e1a159a,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ec55f147-eddd-439f-8997-ace51e759d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914519142-172.17.0.10-1598335780187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-dc6328ab-8515-469c-820c-3bc1f19b3f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-7657762b-ca5a-473f-b03e-b2fdf7d023e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-65c1fef0-c3eb-4ee7-94c4-a1d72e99034d,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-c4f2eed3-b0ec-4e5b-ad4b-7bcf8b84a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-8afeca6f-d8d9-4501-b645-4289eb25bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-464b792e-1df6-426e-b4d7-93391c74e383,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-6f122eab-5095-4896-b69a-542f2e1a159a,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ec55f147-eddd-439f-8997-ace51e759d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095109895-172.17.0.10-1598335817149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42287,DS-6af58573-e478-4d80-bc1a-88b56b4cc62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-a76e6e68-b714-4424-b334-ac5c9d2ad332,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-ba51e0f2-26b9-4dde-a43b-d821179b51e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-a41b8409-d2c4-4f47-82d8-3570b57685bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-6e2df298-9bcb-4500-988a-a8d39a4cf8df,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-9e0a6cdd-8acf-4f32-a263-145dba679290,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-f00fc9b4-fc20-4943-967a-6686c2fce068,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-0bcaf6ee-1db5-46b5-b82d-bb14e4687f3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095109895-172.17.0.10-1598335817149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42287,DS-6af58573-e478-4d80-bc1a-88b56b4cc62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-a76e6e68-b714-4424-b334-ac5c9d2ad332,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-ba51e0f2-26b9-4dde-a43b-d821179b51e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-a41b8409-d2c4-4f47-82d8-3570b57685bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-6e2df298-9bcb-4500-988a-a8d39a4cf8df,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-9e0a6cdd-8acf-4f32-a263-145dba679290,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-f00fc9b4-fc20-4943-967a-6686c2fce068,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-0bcaf6ee-1db5-46b5-b82d-bb14e4687f3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423840282-172.17.0.10-1598335966860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-077640bb-2be5-42a2-bb38-0b4916f49569,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-a7f40abe-119f-45dc-b5b0-81b1b61eb866,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3968049b-adbd-4abb-9333-0e355f98e044,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-9a6ef8f5-438f-4328-9a05-5289a77fd9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-e20569b7-4670-43b0-9a51-0cef825886ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-41bc396c-7703-4836-b1f9-fdc729b805d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-42cf179f-b5ea-4792-ada3-8b4f60f2db95,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-bdafecde-92a4-435e-99fe-bb7a4d4fb134,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423840282-172.17.0.10-1598335966860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-077640bb-2be5-42a2-bb38-0b4916f49569,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-a7f40abe-119f-45dc-b5b0-81b1b61eb866,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3968049b-adbd-4abb-9333-0e355f98e044,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-9a6ef8f5-438f-4328-9a05-5289a77fd9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-e20569b7-4670-43b0-9a51-0cef825886ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-41bc396c-7703-4836-b1f9-fdc729b805d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-42cf179f-b5ea-4792-ada3-8b4f60f2db95,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-bdafecde-92a4-435e-99fe-bb7a4d4fb134,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453156438-172.17.0.10-1598336108170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-315dc152-7897-4ba5-bcb5-a3d03238f186,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-e258e545-f896-482e-8d69-d38fb6370c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-15868052-c563-4faf-b64a-4f79e30666fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-e0a4eb21-10da-4bef-aa65-4a6d1ee3070b,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-18a3e5de-a0f5-4ea6-a00f-7e7ca7561f34,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-8ecd1ae2-fd3b-495e-81ee-e4219eb72096,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-0b6de233-8f7e-444c-8288-bb1475a8fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0034f0e8-96e4-4302-a91b-0ae4f710625a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453156438-172.17.0.10-1598336108170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-315dc152-7897-4ba5-bcb5-a3d03238f186,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-e258e545-f896-482e-8d69-d38fb6370c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-15868052-c563-4faf-b64a-4f79e30666fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-e0a4eb21-10da-4bef-aa65-4a6d1ee3070b,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-18a3e5de-a0f5-4ea6-a00f-7e7ca7561f34,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-8ecd1ae2-fd3b-495e-81ee-e4219eb72096,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-0b6de233-8f7e-444c-8288-bb1475a8fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-0034f0e8-96e4-4302-a91b-0ae4f710625a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738063403-172.17.0.10-1598336137936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-0b7c3edd-ca16-4734-a6fb-7f992dcb8200,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ff3a9624-7f16-493f-a8e7-36121695d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-99e56685-4eb4-4a63-836a-5ef140dc1dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-77b71b4c-0d71-4d09-8bee-7e7f32644b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-7ed6d9e8-add0-42fc-8664-ea38a40a2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b0e6169e-6b9f-46ff-8d38-2999b849b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-94b23c12-ba78-46a9-8b2e-73f587de3727,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-32e5fb3c-ff2f-4819-b629-b7f78f3ef7ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738063403-172.17.0.10-1598336137936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-0b7c3edd-ca16-4734-a6fb-7f992dcb8200,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ff3a9624-7f16-493f-a8e7-36121695d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-99e56685-4eb4-4a63-836a-5ef140dc1dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-77b71b4c-0d71-4d09-8bee-7e7f32644b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-7ed6d9e8-add0-42fc-8664-ea38a40a2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b0e6169e-6b9f-46ff-8d38-2999b849b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-94b23c12-ba78-46a9-8b2e-73f587de3727,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-32e5fb3c-ff2f-4819-b629-b7f78f3ef7ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934851631-172.17.0.10-1598336173545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-fae6e9d1-67b5-4636-a224-9320f09aa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-607b817d-5601-47fc-a1da-fa04f94faf63,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c5065cf6-6a9e-4afd-a9de-a0f835dfcd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-592a2331-79c1-4af0-8e99-c57c4893e13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-f7518daa-bfc9-4eab-a24d-ed88ced53925,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-4912640c-3960-4563-8640-056d26be73be,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-a168b173-8f05-4991-a04a-055dcbcdccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-04c07174-a8ef-4bf2-8951-25198b953833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934851631-172.17.0.10-1598336173545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-fae6e9d1-67b5-4636-a224-9320f09aa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-607b817d-5601-47fc-a1da-fa04f94faf63,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c5065cf6-6a9e-4afd-a9de-a0f835dfcd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-592a2331-79c1-4af0-8e99-c57c4893e13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-f7518daa-bfc9-4eab-a24d-ed88ced53925,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-4912640c-3960-4563-8640-056d26be73be,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-a168b173-8f05-4991-a04a-055dcbcdccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-04c07174-a8ef-4bf2-8951-25198b953833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653989844-172.17.0.10-1598336337132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-c2f0400d-f008-4e84-a73e-f3820361f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2ac7514d-be4b-4c0c-9284-d4542282d910,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-52fa7838-9d5e-4299-8b94-962ecdedb66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0a5cc276-edfe-4b8c-a129-4e7eaf37102f,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-29c898e2-77da-4b45-aa89-61f0517d3011,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-cac0b4db-a69a-40ac-b9af-27356b445717,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-4bffd679-0ce7-4388-8492-495dbe633da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-ff95b2d6-a9c3-4085-8f35-cd802161d62c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653989844-172.17.0.10-1598336337132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-c2f0400d-f008-4e84-a73e-f3820361f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-2ac7514d-be4b-4c0c-9284-d4542282d910,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-52fa7838-9d5e-4299-8b94-962ecdedb66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0a5cc276-edfe-4b8c-a129-4e7eaf37102f,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-29c898e2-77da-4b45-aa89-61f0517d3011,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-cac0b4db-a69a-40ac-b9af-27356b445717,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-4bffd679-0ce7-4388-8492-495dbe633da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-ff95b2d6-a9c3-4085-8f35-cd802161d62c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85082316-172.17.0.10-1598336374939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-5d85d486-b386-4c75-8cad-9d17f7fd1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-4fd6c738-ed0a-441a-b0bd-35f53b299f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-bc8cbd9e-6ee3-4498-832b-4680bf0616e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-97dc741e-7f18-4fb6-8aa4-9d28b4a267f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-a0fc2ed6-1941-4537-ae1e-34ddc3e74018,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a7695508-809e-432b-a071-86ba349bf020,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e76a46e0-4e08-40b3-bf92-a26e0f892bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-db9fd4b5-2bc8-4675-8921-612b275fc964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85082316-172.17.0.10-1598336374939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-5d85d486-b386-4c75-8cad-9d17f7fd1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-4fd6c738-ed0a-441a-b0bd-35f53b299f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-bc8cbd9e-6ee3-4498-832b-4680bf0616e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-97dc741e-7f18-4fb6-8aa4-9d28b4a267f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-a0fc2ed6-1941-4537-ae1e-34ddc3e74018,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a7695508-809e-432b-a071-86ba349bf020,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e76a46e0-4e08-40b3-bf92-a26e0f892bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-db9fd4b5-2bc8-4675-8921-612b275fc964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482676625-172.17.0.10-1598336658901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-ff9894ef-50f1-4149-a65b-c2b029056a34,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-b73d656c-eecd-402a-b601-86382ef92b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-88225868-0542-4a56-9e9a-6f687bb99d07,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-4eb783fc-49eb-46b4-bfb1-64551862c477,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-89df9b2f-d43a-436f-b19d-755829dec8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-c51bb569-5dac-43f8-b64c-4d20fc48419a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-63210ad1-a2f1-4290-9dab-ec491ff7accb,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-8196b189-9221-4851-bdd5-eea3d5cd18b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482676625-172.17.0.10-1598336658901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-ff9894ef-50f1-4149-a65b-c2b029056a34,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-b73d656c-eecd-402a-b601-86382ef92b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-88225868-0542-4a56-9e9a-6f687bb99d07,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-4eb783fc-49eb-46b4-bfb1-64551862c477,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-89df9b2f-d43a-436f-b19d-755829dec8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-c51bb569-5dac-43f8-b64c-4d20fc48419a,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-63210ad1-a2f1-4290-9dab-ec491ff7accb,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-8196b189-9221-4851-bdd5-eea3d5cd18b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181590993-172.17.0.10-1598337108091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-f0a4632c-1ba1-4db5-b075-25c1e896e5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-57d6a5af-9583-44a9-8104-385eded94cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-42595996-a3cf-4168-b994-971f36e824cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-d7ce1858-8d86-445e-95bd-f13b8b53176c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-70ee71cf-4973-4498-9b4b-0f8f9894dc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-76262da6-4615-41be-b3f1-423ff3231cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-1c13383f-a343-4908-a5b6-5f5b5c2335b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-e2fc50b3-c375-4731-9f47-38439d465d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181590993-172.17.0.10-1598337108091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-f0a4632c-1ba1-4db5-b075-25c1e896e5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-57d6a5af-9583-44a9-8104-385eded94cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-42595996-a3cf-4168-b994-971f36e824cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-d7ce1858-8d86-445e-95bd-f13b8b53176c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-70ee71cf-4973-4498-9b4b-0f8f9894dc72,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-76262da6-4615-41be-b3f1-423ff3231cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-1c13383f-a343-4908-a5b6-5f5b5c2335b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-e2fc50b3-c375-4731-9f47-38439d465d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948590011-172.17.0.10-1598337291054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-dea84a15-d105-406e-be1c-ecde926fabdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-e1de6c4c-be18-4a1a-b468-3e032dc54864,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-092feb65-695e-48e0-86f1-beb90d416678,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-68d64748-f74f-4d0f-b775-997630fdfcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-95d45737-bb86-4d60-ad6d-c3f3e9e86b27,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-ceb2f6d6-e925-4dc4-bee8-675438ac5bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-f1789342-011a-4e66-855a-4192457a61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-d11ecbb5-57d0-43d0-b2ed-8109d9b6bbe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948590011-172.17.0.10-1598337291054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-dea84a15-d105-406e-be1c-ecde926fabdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-e1de6c4c-be18-4a1a-b468-3e032dc54864,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-092feb65-695e-48e0-86f1-beb90d416678,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-68d64748-f74f-4d0f-b775-997630fdfcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-95d45737-bb86-4d60-ad6d-c3f3e9e86b27,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-ceb2f6d6-e925-4dc4-bee8-675438ac5bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-f1789342-011a-4e66-855a-4192457a61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-d11ecbb5-57d0-43d0-b2ed-8109d9b6bbe7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686236488-172.17.0.10-1598337538317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-1276757a-25f9-43c9-b648-8449d3f64a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fca5cd5c-d338-4904-b753-8c574b124d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-01b1dc2b-2f28-4a56-a6f7-0398f6dcf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-93d2b9c1-06f2-4952-9f7f-ed2c07904ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-3b9200a4-a969-449e-a75e-b19bfcd2545b,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-368d5711-dad5-460c-8ae5-27d63198b228,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f0a1c3ce-39c9-46db-bd08-f208edd417a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-3130db59-ac16-4f80-9e22-c952068a25b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686236488-172.17.0.10-1598337538317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-1276757a-25f9-43c9-b648-8449d3f64a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fca5cd5c-d338-4904-b753-8c574b124d88,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-01b1dc2b-2f28-4a56-a6f7-0398f6dcf4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-93d2b9c1-06f2-4952-9f7f-ed2c07904ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-3b9200a4-a969-449e-a75e-b19bfcd2545b,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-368d5711-dad5-460c-8ae5-27d63198b228,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f0a1c3ce-39c9-46db-bd08-f208edd417a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-3130db59-ac16-4f80-9e22-c952068a25b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975163384-172.17.0.10-1598337615012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-44864989-12cb-49c0-b4b2-374293991e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-62d25c6c-063a-4fe6-ad18-24c7b3918f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-0b6e272e-4bf8-4170-afdb-e332d3a35b24,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-dc89c4d9-401d-46d5-a89c-e673be80594f,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-4859fa9a-b12e-4335-901f-7f7199ec8248,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-bb115175-2b09-4986-ac8c-6d129588c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-4c7f8f10-40ae-4da5-9a4f-bfe328a92f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3dea8405-2ecb-4f2d-8483-b8f073572278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975163384-172.17.0.10-1598337615012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-44864989-12cb-49c0-b4b2-374293991e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-62d25c6c-063a-4fe6-ad18-24c7b3918f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-0b6e272e-4bf8-4170-afdb-e332d3a35b24,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-dc89c4d9-401d-46d5-a89c-e673be80594f,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-4859fa9a-b12e-4335-901f-7f7199ec8248,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-bb115175-2b09-4986-ac8c-6d129588c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-4c7f8f10-40ae-4da5-9a4f-bfe328a92f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3dea8405-2ecb-4f2d-8483-b8f073572278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508817453-172.17.0.10-1598337694138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-83f9dfdd-3ae6-42c1-98a1-bd8e4e1326c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-fa2c697b-1129-435d-a067-e1b96faa4006,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-89c8a70b-ea92-43ac-b1bf-1ec7dde8e976,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-ca2d1437-dd0a-473a-9125-b578204f2319,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-9458c583-0c20-49d5-952e-bd00d6c8164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-ab2c168f-21b8-4008-8db6-82ebf79c89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-802b8b21-dff4-43be-988e-30af479fc2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5552679b-d40f-4f3f-9ace-48fb0b2d33cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508817453-172.17.0.10-1598337694138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-83f9dfdd-3ae6-42c1-98a1-bd8e4e1326c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-fa2c697b-1129-435d-a067-e1b96faa4006,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-89c8a70b-ea92-43ac-b1bf-1ec7dde8e976,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-ca2d1437-dd0a-473a-9125-b578204f2319,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-9458c583-0c20-49d5-952e-bd00d6c8164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-ab2c168f-21b8-4008-8db6-82ebf79c89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-802b8b21-dff4-43be-988e-30af479fc2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5552679b-d40f-4f3f-9ace-48fb0b2d33cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119467852-172.17.0.10-1598337948752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-10f5bf48-f4d2-4b60-be41-57469f6142c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-e8e81aa0-52c8-4b12-a3ba-de7fb77e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-b6cd31e4-a47e-4cc4-a56c-58b6325e0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-608aaa22-90ed-4f78-aaab-d4b3e2a3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-dd062630-3a55-43dc-95f9-31dd1459ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-56c79b4a-bfd3-480c-b65a-fd4b3c498bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-18c58e86-81aa-4a03-a55a-bfcf0d6f9f39,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-ca7b4a42-8fb4-478e-827a-9d5fd42202ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119467852-172.17.0.10-1598337948752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-10f5bf48-f4d2-4b60-be41-57469f6142c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-e8e81aa0-52c8-4b12-a3ba-de7fb77e8267,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-b6cd31e4-a47e-4cc4-a56c-58b6325e0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-608aaa22-90ed-4f78-aaab-d4b3e2a3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-dd062630-3a55-43dc-95f9-31dd1459ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-56c79b4a-bfd3-480c-b65a-fd4b3c498bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-18c58e86-81aa-4a03-a55a-bfcf0d6f9f39,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-ca7b4a42-8fb4-478e-827a-9d5fd42202ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268502116-172.17.0.10-1598338134023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-5ea73333-de13-4648-bfa0-22eda8e3af60,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-3dc06b95-0d1e-405c-b7d8-25a6c1f48bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-bcc209a0-ec36-4e28-8371-37966c7de69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-55d10f6c-4b42-4001-aaae-334f73411dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-6db3a298-92dd-4530-a9bf-bf3907e40f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d11bc98e-3b22-451a-8277-906ccec0bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-e940e294-0776-4eaa-b60a-8cdb5c6c226c,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-62a9a038-6869-40de-a3d4-6fdd7335fab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268502116-172.17.0.10-1598338134023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-5ea73333-de13-4648-bfa0-22eda8e3af60,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-3dc06b95-0d1e-405c-b7d8-25a6c1f48bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-bcc209a0-ec36-4e28-8371-37966c7de69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-55d10f6c-4b42-4001-aaae-334f73411dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-6db3a298-92dd-4530-a9bf-bf3907e40f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d11bc98e-3b22-451a-8277-906ccec0bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-e940e294-0776-4eaa-b60a-8cdb5c6c226c,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-62a9a038-6869-40de-a3d4-6fdd7335fab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104391248-172.17.0.10-1598338354975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-8c4a4945-5aa2-4aa8-a11e-aa2e2a1955f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-637faa41-baa8-4ae7-9f0a-daf0dc08bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-6d4a992a-4e20-42c6-80bd-20aa9c0d8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-75069683-7927-4efa-897c-2d3e07d28909,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-ab0f0726-68ff-42f0-bfe3-9592366c2501,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-69dabfce-58b1-4519-baad-b30ad8af16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b18b5c35-36bf-4ab9-900e-9b5c1e5080c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-c3c8151b-a56c-4ecc-8ca8-8853da796d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104391248-172.17.0.10-1598338354975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-8c4a4945-5aa2-4aa8-a11e-aa2e2a1955f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-637faa41-baa8-4ae7-9f0a-daf0dc08bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-6d4a992a-4e20-42c6-80bd-20aa9c0d8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-75069683-7927-4efa-897c-2d3e07d28909,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-ab0f0726-68ff-42f0-bfe3-9592366c2501,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-69dabfce-58b1-4519-baad-b30ad8af16f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-b18b5c35-36bf-4ab9-900e-9b5c1e5080c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-c3c8151b-a56c-4ecc-8ca8-8853da796d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707615665-172.17.0.10-1598338393223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38107,DS-a86970ac-f22e-4b71-8c33-9a9f9f74e784,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7a61ca87-5e28-4d2e-8447-453b3143b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-41f9d81d-b191-4244-95a3-39112ae197b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-dfd3c984-38bc-4eeb-9a7e-57ec9afcb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-71d98a59-adcb-4ede-aeee-bd06c0a5d370,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-aeeb58ef-6f8f-4b86-956e-90dcc8edd276,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-6c262dc5-c32f-4e4f-9be9-9195e058da3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-efd00a86-766e-4c66-a65d-c9003dce3eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707615665-172.17.0.10-1598338393223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38107,DS-a86970ac-f22e-4b71-8c33-9a9f9f74e784,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7a61ca87-5e28-4d2e-8447-453b3143b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-41f9d81d-b191-4244-95a3-39112ae197b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-dfd3c984-38bc-4eeb-9a7e-57ec9afcb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-71d98a59-adcb-4ede-aeee-bd06c0a5d370,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-aeeb58ef-6f8f-4b86-956e-90dcc8edd276,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-6c262dc5-c32f-4e4f-9be9-9195e058da3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-efd00a86-766e-4c66-a65d-c9003dce3eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497253999-172.17.0.10-1598338432741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-5381ebbd-3f61-42df-85ad-4885313d8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-b5d6b3ef-ee28-4c99-b692-7c93b0f7da4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-a994fe4d-af7e-43e3-b3ed-931ade067409,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-650f93fc-1591-42f1-890f-39752122e686,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-3983c081-d1b3-4a84-b612-8cf3cdfb12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-25d274ef-2c14-4209-8045-741413a874e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-ea88f500-ed8f-42c5-9bfe-1dfa6f9917c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-01dca611-2460-4fe6-9822-922b0da3fa68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497253999-172.17.0.10-1598338432741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-5381ebbd-3f61-42df-85ad-4885313d8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-b5d6b3ef-ee28-4c99-b692-7c93b0f7da4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-a994fe4d-af7e-43e3-b3ed-931ade067409,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-650f93fc-1591-42f1-890f-39752122e686,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-3983c081-d1b3-4a84-b612-8cf3cdfb12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-25d274ef-2c14-4209-8045-741413a874e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-ea88f500-ed8f-42c5-9bfe-1dfa6f9917c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-01dca611-2460-4fe6-9822-922b0da3fa68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157618093-172.17.0.10-1598338651296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-3fe0b7bc-f0db-440f-93ce-035883640432,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-1bc6b8e1-9a04-43da-82e0-2f19d8d12486,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-c8a9b4e9-ce36-4db3-9f15-7bbeb8781e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-329c519c-00fc-44df-9f72-a81f9ba0f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-cce7061a-ffa4-43e8-bda0-da923c8420e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-2b8ac7fb-c1e1-4da8-9f49-7ecd055a7781,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-624cc5d7-7544-46a9-b02d-6ab87a502d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-9d3c92d1-6cb9-4bf2-84d1-798c8fb0cadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157618093-172.17.0.10-1598338651296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-3fe0b7bc-f0db-440f-93ce-035883640432,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-1bc6b8e1-9a04-43da-82e0-2f19d8d12486,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-c8a9b4e9-ce36-4db3-9f15-7bbeb8781e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-329c519c-00fc-44df-9f72-a81f9ba0f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-cce7061a-ffa4-43e8-bda0-da923c8420e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-2b8ac7fb-c1e1-4da8-9f49-7ecd055a7781,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-624cc5d7-7544-46a9-b02d-6ab87a502d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-9d3c92d1-6cb9-4bf2-84d1-798c8fb0cadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530530438-172.17.0.10-1598338920514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38010,DS-de3a031d-ef11-44ed-97fb-91c68f07867b,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-053093db-37a0-4cc1-b241-e7b0be75c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-d6892d34-a5ce-44e4-a6ad-6b515bf5ce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-eef0eb35-d8cd-4a00-bafd-a64c3a40720c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-113fcfa5-d9ce-4ed2-8259-af6790d6d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-7024b17e-4690-4dab-964f-5dfc2f31768b,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-497c7c1b-a5d5-47b4-9207-b4162695e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-bb3f40a8-f550-4372-9b64-7184f43a6d68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530530438-172.17.0.10-1598338920514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38010,DS-de3a031d-ef11-44ed-97fb-91c68f07867b,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-053093db-37a0-4cc1-b241-e7b0be75c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-d6892d34-a5ce-44e4-a6ad-6b515bf5ce3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-eef0eb35-d8cd-4a00-bafd-a64c3a40720c,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-113fcfa5-d9ce-4ed2-8259-af6790d6d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-7024b17e-4690-4dab-964f-5dfc2f31768b,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-497c7c1b-a5d5-47b4-9207-b4162695e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-bb3f40a8-f550-4372-9b64-7184f43a6d68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738683800-172.17.0.10-1598339062718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-88d26cbb-4614-46a9-a0ea-95e33b4ec870,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-56cf10e6-dc70-4ed0-bfb8-141d66499bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-15b81526-9b32-4055-9763-dd4b20f9457d,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-b49b4233-e94f-45f0-9042-5bf05eb58465,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-26e4f14e-d780-4107-b07b-c643dd906211,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-a0b4233b-56bb-44e8-b843-24815406f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-c7b413b5-2fae-4cd6-a107-1a5752b8922a,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-2cbc8397-6342-486f-b392-e9228cf2cb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738683800-172.17.0.10-1598339062718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-88d26cbb-4614-46a9-a0ea-95e33b4ec870,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-56cf10e6-dc70-4ed0-bfb8-141d66499bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-15b81526-9b32-4055-9763-dd4b20f9457d,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-b49b4233-e94f-45f0-9042-5bf05eb58465,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-26e4f14e-d780-4107-b07b-c643dd906211,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-a0b4233b-56bb-44e8-b843-24815406f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-c7b413b5-2fae-4cd6-a107-1a5752b8922a,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-2cbc8397-6342-486f-b392-e9228cf2cb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905077854-172.17.0.10-1598339164361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33536,DS-67df07ad-9256-4aca-b5a7-ecb92358dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-1803cb55-1f79-43b8-b15c-466fd7a9b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c8e4cf67-9e02-40fa-986d-c927046a75b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-b07d00f9-2144-493e-91dd-ccf4304b5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-fe5b12f0-27ff-40e7-b135-28cab6622e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-8af0ffbb-6c8a-46c7-a4db-40e4fdb3d506,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-bcd6cb9d-b77f-4039-8c18-fe2ae3a231a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-950bfb67-7811-4121-9b8f-31739595f33d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905077854-172.17.0.10-1598339164361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33536,DS-67df07ad-9256-4aca-b5a7-ecb92358dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-1803cb55-1f79-43b8-b15c-466fd7a9b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c8e4cf67-9e02-40fa-986d-c927046a75b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-b07d00f9-2144-493e-91dd-ccf4304b5f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-fe5b12f0-27ff-40e7-b135-28cab6622e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-8af0ffbb-6c8a-46c7-a4db-40e4fdb3d506,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-bcd6cb9d-b77f-4039-8c18-fe2ae3a231a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-950bfb67-7811-4121-9b8f-31739595f33d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252617850-172.17.0.10-1598339268998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-ff81cf1e-f8c7-47e0-9ff1-7fccd270cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-a682dd0f-8a21-4aef-99ec-c889780ba5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-8cdef307-c877-42b5-a1d2-f31f8d38d416,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-91437c40-d76b-487a-92fd-48e6508ceebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c3282331-1f60-4998-ba08-329d08b0ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-73ee3608-39ec-4a3a-9c74-23d0f8aa45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-9d3b8461-e082-46d1-b754-9b0e1cb7542b,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-26ddcd11-fdf9-43a9-9158-de436f6a5fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252617850-172.17.0.10-1598339268998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-ff81cf1e-f8c7-47e0-9ff1-7fccd270cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-a682dd0f-8a21-4aef-99ec-c889780ba5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-8cdef307-c877-42b5-a1d2-f31f8d38d416,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-91437c40-d76b-487a-92fd-48e6508ceebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c3282331-1f60-4998-ba08-329d08b0ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-73ee3608-39ec-4a3a-9c74-23d0f8aa45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-9d3b8461-e082-46d1-b754-9b0e1cb7542b,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-26ddcd11-fdf9-43a9-9158-de436f6a5fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611209007-172.17.0.10-1598339309114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35451,DS-8760be14-ec81-4113-85c3-7f05ebd0dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-720a3696-6877-4bde-b707-045cf3113a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-02917cb2-8f88-45c0-be71-47d30063da04,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-b0faeb29-df18-46a1-9042-7143729c38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d2de0777-86fc-40e1-9f18-c6da660b86f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-6b5d9f86-763f-422c-96e4-3773250a8a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-951b5577-04c5-42e0-ac31-ade7d1f4b297,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-1c553b84-1ebf-424d-acdf-306e36a3d1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611209007-172.17.0.10-1598339309114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35451,DS-8760be14-ec81-4113-85c3-7f05ebd0dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-720a3696-6877-4bde-b707-045cf3113a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-02917cb2-8f88-45c0-be71-47d30063da04,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-b0faeb29-df18-46a1-9042-7143729c38ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d2de0777-86fc-40e1-9f18-c6da660b86f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-6b5d9f86-763f-422c-96e4-3773250a8a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-951b5577-04c5-42e0-ac31-ade7d1f4b297,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-1c553b84-1ebf-424d-acdf-306e36a3d1a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327094947-172.17.0.10-1598339453499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-b5aaa948-f421-460e-8eb4-7cc6cd3c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-2360cd00-de9c-498a-a7b7-af0fe6484fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-6ee0e1bf-ec9d-4f76-beed-99fe6e411ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-fd75424a-f007-446f-aef6-79b0c6698b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-c4d6d717-5893-4a4b-a405-d078cf7da971,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-c23de1c3-2ff5-40b1-8566-1519cb9017b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-a0ef6395-5a33-40d7-b82a-662dd989461f,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-40a3df14-0477-46b8-bbce-aa1f1254dd66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327094947-172.17.0.10-1598339453499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-b5aaa948-f421-460e-8eb4-7cc6cd3c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-2360cd00-de9c-498a-a7b7-af0fe6484fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-6ee0e1bf-ec9d-4f76-beed-99fe6e411ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-fd75424a-f007-446f-aef6-79b0c6698b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-c4d6d717-5893-4a4b-a405-d078cf7da971,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-c23de1c3-2ff5-40b1-8566-1519cb9017b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-a0ef6395-5a33-40d7-b82a-662dd989461f,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-40a3df14-0477-46b8-bbce-aa1f1254dd66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437583770-172.17.0.10-1598339523711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-8bfe8471-24f1-44d1-99ec-a60c2641e118,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-e760a7a1-627e-4bab-92f3-2c3008103b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c2254ba4-794c-4235-b28d-0a2cf0e039f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0fa730e2-3c20-47a2-9ce6-7079b4e966a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-aca9ff41-79f9-434a-87ee-86d01acb7668,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-07540208-8b4e-4f78-b3ae-a50e67ba3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-8eb34100-97ef-4de3-9b90-5280fcaa0831,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-d3490641-6d27-4941-9568-eba5a0937b14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437583770-172.17.0.10-1598339523711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-8bfe8471-24f1-44d1-99ec-a60c2641e118,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-e760a7a1-627e-4bab-92f3-2c3008103b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c2254ba4-794c-4235-b28d-0a2cf0e039f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0fa730e2-3c20-47a2-9ce6-7079b4e966a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-aca9ff41-79f9-434a-87ee-86d01acb7668,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-07540208-8b4e-4f78-b3ae-a50e67ba3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-8eb34100-97ef-4de3-9b90-5280fcaa0831,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-d3490641-6d27-4941-9568-eba5a0937b14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037851891-172.17.0.10-1598339625088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-e42bed6d-e97b-4969-99ff-0049cd80f6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-db97b4fc-81a6-4754-9818-4aa68c100356,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-959b62ee-b197-44af-a716-44bfdf19b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-970e1f38-b380-4ce3-8392-29da8c86315b,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-0c94ac4e-77cb-4b4c-a225-7de05c000bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-7d55abf2-6373-4bc6-bc1f-3d7a97623ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-b204e2b7-c879-4f14-9db2-3681ae06ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-94fe50ad-934b-4438-8c17-95f2806c0ceb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037851891-172.17.0.10-1598339625088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-e42bed6d-e97b-4969-99ff-0049cd80f6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-db97b4fc-81a6-4754-9818-4aa68c100356,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-959b62ee-b197-44af-a716-44bfdf19b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-970e1f38-b380-4ce3-8392-29da8c86315b,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-0c94ac4e-77cb-4b4c-a225-7de05c000bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-7d55abf2-6373-4bc6-bc1f-3d7a97623ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-b204e2b7-c879-4f14-9db2-3681ae06ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-94fe50ad-934b-4438-8c17-95f2806c0ceb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5306
