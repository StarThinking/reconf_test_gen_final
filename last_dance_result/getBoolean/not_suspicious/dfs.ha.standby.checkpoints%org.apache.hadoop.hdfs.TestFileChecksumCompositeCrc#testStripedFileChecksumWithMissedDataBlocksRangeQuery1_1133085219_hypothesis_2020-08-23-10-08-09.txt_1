reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361799741-172.17.0.9-1598178278579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-4ad4fe1e-7990-4f5a-8623-011df4a6dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-86324ad6-0bac-4caf-b805-85a9f2a26d00,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-15745450-cfb1-416d-b360-cb59ff9f7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-2b08dc36-00f7-4259-90b6-4a071bc50398,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-40869fe0-0c42-4d4f-8a14-18e529903497,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-41ed1878-2792-4388-9d7e-df23d034fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-2b1b987f-097d-41bc-9613-6b8155c67264,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-7881e8dd-111a-4edb-a0dd-b1cf30427331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361799741-172.17.0.9-1598178278579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-4ad4fe1e-7990-4f5a-8623-011df4a6dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-86324ad6-0bac-4caf-b805-85a9f2a26d00,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-15745450-cfb1-416d-b360-cb59ff9f7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-2b08dc36-00f7-4259-90b6-4a071bc50398,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-40869fe0-0c42-4d4f-8a14-18e529903497,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-41ed1878-2792-4388-9d7e-df23d034fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-2b1b987f-097d-41bc-9613-6b8155c67264,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-7881e8dd-111a-4edb-a0dd-b1cf30427331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874674432-172.17.0.9-1598178318976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-2ea58bb3-b57a-4673-a7e1-20b94e7c2ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-5927c62f-b733-4535-832d-dd850b455d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-b5210fa6-c081-4902-ab71-bfecef476f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-23e757bd-9e40-4214-b225-0e45a706addc,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-8beddf8d-9336-4768-8f91-920825114a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-9e57c0ad-69fb-4174-9422-1e5c24d02aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-450534bc-ba3e-49ec-a529-6b91ef61c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-4e002ce7-fa73-45e2-a938-9b0548381ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874674432-172.17.0.9-1598178318976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-2ea58bb3-b57a-4673-a7e1-20b94e7c2ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-5927c62f-b733-4535-832d-dd850b455d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-b5210fa6-c081-4902-ab71-bfecef476f95,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-23e757bd-9e40-4214-b225-0e45a706addc,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-8beddf8d-9336-4768-8f91-920825114a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-9e57c0ad-69fb-4174-9422-1e5c24d02aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-450534bc-ba3e-49ec-a529-6b91ef61c6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-4e002ce7-fa73-45e2-a938-9b0548381ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319180576-172.17.0.9-1598178395553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-1e02151f-4983-4bdf-a4a1-4b4c878a771c,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-71684dee-db23-4ba6-a577-b7f46babce31,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-43d40e18-b5cc-4058-a25b-bcd406cce192,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ef28e0cb-e47d-4a7f-b14e-0ac46f79beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-87ba93f0-501c-48f4-9358-1df6036e383a,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-2cab8358-b494-4cd4-a55a-a45bf37fe1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-eb3d8b9e-e144-4232-900b-20a4dab6e575,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-bf52690f-ed93-45f6-a0d8-cf81c9d5ef54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319180576-172.17.0.9-1598178395553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-1e02151f-4983-4bdf-a4a1-4b4c878a771c,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-71684dee-db23-4ba6-a577-b7f46babce31,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-43d40e18-b5cc-4058-a25b-bcd406cce192,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ef28e0cb-e47d-4a7f-b14e-0ac46f79beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-87ba93f0-501c-48f4-9358-1df6036e383a,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-2cab8358-b494-4cd4-a55a-a45bf37fe1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-eb3d8b9e-e144-4232-900b-20a4dab6e575,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-bf52690f-ed93-45f6-a0d8-cf81c9d5ef54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330753875-172.17.0.9-1598178661336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-64b06a7b-b5e6-4249-99a5-7eb3d47aff02,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-bb82c2f9-4ddc-4035-9457-cfb7ffda3108,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-e978ebad-aaa4-4031-984b-448b5fc23041,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-3dff9a4b-edc7-4ac4-86cc-b12f03c37379,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-1c2a1c60-1a28-442b-ba92-8fbf280774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-22e97c7e-9639-498b-af76-41d83777fd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-b36ebe02-41b8-4e8a-b341-93680a6f2877,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-05a2280c-bbce-4172-94b0-4009ee2f6b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330753875-172.17.0.9-1598178661336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-64b06a7b-b5e6-4249-99a5-7eb3d47aff02,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-bb82c2f9-4ddc-4035-9457-cfb7ffda3108,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-e978ebad-aaa4-4031-984b-448b5fc23041,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-3dff9a4b-edc7-4ac4-86cc-b12f03c37379,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-1c2a1c60-1a28-442b-ba92-8fbf280774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-22e97c7e-9639-498b-af76-41d83777fd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-b36ebe02-41b8-4e8a-b341-93680a6f2877,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-05a2280c-bbce-4172-94b0-4009ee2f6b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271614946-172.17.0.9-1598178764728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-ea9a97b4-4ffd-41b7-a090-8d342d980fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-ac2f0320-709b-45a7-b87f-b53c5829a642,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-dcb3dcb5-0697-4a3a-9206-b0b706e8c657,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-8c0fc513-4984-4576-86fb-a51bdc2bbd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-de25db54-71dc-47d6-ba28-8dd731cd471a,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-0b99df81-ba71-421a-847a-be9f79613c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-63ac210e-9e7d-4eeb-af7b-627524bcf3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-66c6fdbc-d58c-4558-850a-7331f85741db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271614946-172.17.0.9-1598178764728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-ea9a97b4-4ffd-41b7-a090-8d342d980fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-ac2f0320-709b-45a7-b87f-b53c5829a642,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-dcb3dcb5-0697-4a3a-9206-b0b706e8c657,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-8c0fc513-4984-4576-86fb-a51bdc2bbd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-de25db54-71dc-47d6-ba28-8dd731cd471a,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-0b99df81-ba71-421a-847a-be9f79613c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-63ac210e-9e7d-4eeb-af7b-627524bcf3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-66c6fdbc-d58c-4558-850a-7331f85741db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481227032-172.17.0.9-1598178803647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43593,DS-d2ff9480-eb18-4017-a2e3-6dd3e206c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-292fde22-d51f-430d-85ac-08e70de8d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-38e289b5-fdf2-4660-8057-618cea26ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-826aae8f-7cf7-49cf-837b-8f9196027aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-71ec54ed-634d-4fab-8648-a5d2564bde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-3233fb21-4e75-44d2-a9cb-b5a671dd454e,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-f400a032-9dbb-4e8c-be76-99526105bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-9a2d20cf-01ae-4aec-afad-6dc512a2e0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481227032-172.17.0.9-1598178803647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43593,DS-d2ff9480-eb18-4017-a2e3-6dd3e206c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-292fde22-d51f-430d-85ac-08e70de8d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-38e289b5-fdf2-4660-8057-618cea26ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-826aae8f-7cf7-49cf-837b-8f9196027aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-71ec54ed-634d-4fab-8648-a5d2564bde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-3233fb21-4e75-44d2-a9cb-b5a671dd454e,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-f400a032-9dbb-4e8c-be76-99526105bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-9a2d20cf-01ae-4aec-afad-6dc512a2e0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667575443-172.17.0.9-1598179155105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-c907d199-239c-46f6-a908-c9c75a4b3006,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-646d6394-c710-42ee-a0c0-04fdbfb20047,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-6986a80e-1474-432e-b721-2b522d20d6da,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-10bf1ec6-8352-4922-97b1-747efd97caec,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09f8cd31-2996-4c4e-a397-ab1b172ab284,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-7688e078-21c5-450e-80d5-c1da9636ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-9adbdff9-f5e1-4e9c-a5f1-ae657c3674a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-9a216a53-a95d-478e-b811-6b1169a4a233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667575443-172.17.0.9-1598179155105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-c907d199-239c-46f6-a908-c9c75a4b3006,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-646d6394-c710-42ee-a0c0-04fdbfb20047,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-6986a80e-1474-432e-b721-2b522d20d6da,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-10bf1ec6-8352-4922-97b1-747efd97caec,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09f8cd31-2996-4c4e-a397-ab1b172ab284,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-7688e078-21c5-450e-80d5-c1da9636ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-9adbdff9-f5e1-4e9c-a5f1-ae657c3674a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-9a216a53-a95d-478e-b811-6b1169a4a233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217789935-172.17.0.9-1598179627264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-5ad146de-9e78-4330-8306-56caceb9b797,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-4b4c27d5-0045-475f-a8ed-48e3749e172e,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-2f047f17-0387-4dc9-9221-49f09c2a7372,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-6df9144b-9405-4ce9-ba1f-5eb29d037f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-2695f7b3-b75a-4362-a44c-6504b06cfd31,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-8271bbb6-f5cf-477c-9893-a02dad0732d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-352323d6-f40c-4928-94bc-e028d0c80c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-a32c89ce-ba8d-4e1e-a078-2bf8ef43a257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217789935-172.17.0.9-1598179627264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-5ad146de-9e78-4330-8306-56caceb9b797,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-4b4c27d5-0045-475f-a8ed-48e3749e172e,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-2f047f17-0387-4dc9-9221-49f09c2a7372,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-6df9144b-9405-4ce9-ba1f-5eb29d037f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-2695f7b3-b75a-4362-a44c-6504b06cfd31,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-8271bbb6-f5cf-477c-9893-a02dad0732d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-352323d6-f40c-4928-94bc-e028d0c80c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-a32c89ce-ba8d-4e1e-a078-2bf8ef43a257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872507551-172.17.0.9-1598179738276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-a350b408-e627-405b-998c-c6dde4854819,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-f85fdb00-d7b7-44a3-8bf1-4a0f48e28bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-fcdfdc1c-ef96-4497-847d-cf1f96312b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-9a6f8aa9-2a7c-42a3-8305-ce719830d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-5779cd19-c741-4e2b-b3c8-acf17a6fcb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-ab02f20b-7737-4964-81a8-b6c3ad819d42,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c93d6e5c-a702-4cb1-9c98-3559a5b88a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-322d344f-105c-458e-9e87-f0b82c269904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872507551-172.17.0.9-1598179738276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-a350b408-e627-405b-998c-c6dde4854819,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-f85fdb00-d7b7-44a3-8bf1-4a0f48e28bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-fcdfdc1c-ef96-4497-847d-cf1f96312b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-9a6f8aa9-2a7c-42a3-8305-ce719830d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-5779cd19-c741-4e2b-b3c8-acf17a6fcb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-ab02f20b-7737-4964-81a8-b6c3ad819d42,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c93d6e5c-a702-4cb1-9c98-3559a5b88a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-322d344f-105c-458e-9e87-f0b82c269904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913986057-172.17.0.9-1598179814719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-17cc02a1-fbb7-4670-855b-b0edd804e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-ccdf78eb-e8e0-4800-8c07-fee88fad4f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-96824c16-81d8-455a-af10-e77d241d4b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-43848621-f4be-45c1-bbba-95de919dbaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-da37703b-4064-4f2d-b58a-661bcf1d918d,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-df9a2721-38c8-4536-807a-81af1194fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-9463a864-aee6-4c65-b88d-3ff063e8d616,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c49d8922-b77b-4ab3-af0d-55c038b95911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913986057-172.17.0.9-1598179814719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-17cc02a1-fbb7-4670-855b-b0edd804e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-ccdf78eb-e8e0-4800-8c07-fee88fad4f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-96824c16-81d8-455a-af10-e77d241d4b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-43848621-f4be-45c1-bbba-95de919dbaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-da37703b-4064-4f2d-b58a-661bcf1d918d,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-df9a2721-38c8-4536-807a-81af1194fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-9463a864-aee6-4c65-b88d-3ff063e8d616,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c49d8922-b77b-4ab3-af0d-55c038b95911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571443509-172.17.0.9-1598180111425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3b7f1194-07cd-4a4a-8c50-06981a8437f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-6ff5f351-15da-4125-a829-404ce82368fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-cf562bcf-098c-4426-91fd-3381f33bf73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-db897635-330a-4350-84e7-a441e809a132,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-e88413aa-2239-418f-91c3-0695b5469e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-9e1d66ff-2a3a-4014-ac76-fadcff142037,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-b2b76f95-bd46-49c6-8bfa-70b725f967a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-1163731b-f628-4578-a179-526554c54c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571443509-172.17.0.9-1598180111425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3b7f1194-07cd-4a4a-8c50-06981a8437f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-6ff5f351-15da-4125-a829-404ce82368fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-cf562bcf-098c-4426-91fd-3381f33bf73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-db897635-330a-4350-84e7-a441e809a132,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-e88413aa-2239-418f-91c3-0695b5469e44,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-9e1d66ff-2a3a-4014-ac76-fadcff142037,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-b2b76f95-bd46-49c6-8bfa-70b725f967a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-1163731b-f628-4578-a179-526554c54c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692032935-172.17.0.9-1598180228543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42675,DS-ad03e95b-c312-44ec-be0e-be53ac7dc394,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1b16cd83-e493-4820-a068-7f508229f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f2f7692e-b47a-42b1-bf06-4e24f8c68f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-e1a7662e-800a-47fc-9b80-30f2f66330d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-33f285ee-1311-4309-9471-c48102827978,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-73c23dfc-8536-466e-b84a-bbfe761ba821,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-41f8e200-e2cd-4b6d-a61e-b4f619e3ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-300c4c36-97a6-4dc9-8463-06b31f3327eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692032935-172.17.0.9-1598180228543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42675,DS-ad03e95b-c312-44ec-be0e-be53ac7dc394,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1b16cd83-e493-4820-a068-7f508229f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-f2f7692e-b47a-42b1-bf06-4e24f8c68f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-e1a7662e-800a-47fc-9b80-30f2f66330d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-33f285ee-1311-4309-9471-c48102827978,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-73c23dfc-8536-466e-b84a-bbfe761ba821,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-41f8e200-e2cd-4b6d-a61e-b4f619e3ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-300c4c36-97a6-4dc9-8463-06b31f3327eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074580113-172.17.0.9-1598180272501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-11a54cfa-66e5-406e-8c3d-f8a4fe7e2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-57109bde-adcc-4986-b716-d14b6880d6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-ac17282c-5b4c-41c8-8964-c436c159f756,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-8f21f904-93c3-49a1-8d14-b9ce2afc676f,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-220d9657-438c-408e-ac3d-6ba95ef8c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c53be964-d9e8-4721-bd91-75a13518fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-fe51acda-28c5-4e02-82cb-73bbe91c5f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-ac497dc6-df61-4f17-89cd-c732e6ddc81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074580113-172.17.0.9-1598180272501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-11a54cfa-66e5-406e-8c3d-f8a4fe7e2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-57109bde-adcc-4986-b716-d14b6880d6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-ac17282c-5b4c-41c8-8964-c436c159f756,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-8f21f904-93c3-49a1-8d14-b9ce2afc676f,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-220d9657-438c-408e-ac3d-6ba95ef8c9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c53be964-d9e8-4721-bd91-75a13518fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-fe51acda-28c5-4e02-82cb-73bbe91c5f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-ac497dc6-df61-4f17-89cd-c732e6ddc81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594220688-172.17.0.9-1598180601325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-f3f51a72-741e-4ceb-b6f6-8e396b11fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-bbeeaaf6-3cfc-46c7-a214-08de5a84bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-de3c2440-a9b6-4dfd-8f26-c0be29aaf83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-b59eb60f-eb41-46a6-a38c-0f156b08b570,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-4ef3b8e3-3388-4ff6-aae9-7740fddbd853,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-cf854aab-d3d4-4b12-9c75-7e7d4e2a6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-4e94e809-0647-436f-9f11-4c4614c770fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c32d150b-462e-4f56-84d9-57bc0dc4bd63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594220688-172.17.0.9-1598180601325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-f3f51a72-741e-4ceb-b6f6-8e396b11fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-bbeeaaf6-3cfc-46c7-a214-08de5a84bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-de3c2440-a9b6-4dfd-8f26-c0be29aaf83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-b59eb60f-eb41-46a6-a38c-0f156b08b570,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-4ef3b8e3-3388-4ff6-aae9-7740fddbd853,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-cf854aab-d3d4-4b12-9c75-7e7d4e2a6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-4e94e809-0647-436f-9f11-4c4614c770fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c32d150b-462e-4f56-84d9-57bc0dc4bd63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076118980-172.17.0.9-1598180779115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-45df1a63-dfec-4982-9acc-e988a0aedf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-8a7e28de-e178-4ded-82b1-fe866ebabec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f7e8e72e-08c3-4d8e-bbda-a1d634f84d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-a726dc80-97f3-4bc0-88c6-9a58cc1223ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-387c6c51-ea2a-4c2b-8bea-d1d851a8ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-0f8fd366-c49a-405d-a9f7-dd72a669b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-aaf704e8-4097-4df0-8a96-bd85b8f60cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-fc7505bb-4d5a-4d39-bcd5-deddb69b7277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076118980-172.17.0.9-1598180779115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-45df1a63-dfec-4982-9acc-e988a0aedf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-8a7e28de-e178-4ded-82b1-fe866ebabec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f7e8e72e-08c3-4d8e-bbda-a1d634f84d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-a726dc80-97f3-4bc0-88c6-9a58cc1223ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-387c6c51-ea2a-4c2b-8bea-d1d851a8ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-0f8fd366-c49a-405d-a9f7-dd72a669b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-aaf704e8-4097-4df0-8a96-bd85b8f60cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-fc7505bb-4d5a-4d39-bcd5-deddb69b7277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373162406-172.17.0.9-1598180912843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-fd2810f0-6d62-46f5-8be3-fbfee82a6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-6c6c2876-2d02-4ff0-888a-55cba967b127,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-1997a03a-c259-4513-aa3b-abb50b79a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-90ff5585-e371-49e4-a399-e47a57c81a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-44e7e6a9-91df-4010-9640-14fe7818acef,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-55a731c9-24df-4802-92b7-7288e907b352,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-27186e93-12dd-4b85-8380-f50261a64c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-99f50c63-5006-4b68-9fc8-3f0d1bdf404a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373162406-172.17.0.9-1598180912843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-fd2810f0-6d62-46f5-8be3-fbfee82a6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-6c6c2876-2d02-4ff0-888a-55cba967b127,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-1997a03a-c259-4513-aa3b-abb50b79a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-90ff5585-e371-49e4-a399-e47a57c81a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-44e7e6a9-91df-4010-9640-14fe7818acef,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-55a731c9-24df-4802-92b7-7288e907b352,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-27186e93-12dd-4b85-8380-f50261a64c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-99f50c63-5006-4b68-9fc8-3f0d1bdf404a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800319084-172.17.0.9-1598181259243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-65b7e7dc-9ea6-4492-b291-4dc48ea4d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-865e3f90-6fd2-4694-8855-94ec0c233d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-81461363-8c54-4dd4-b535-7b11a3e8c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b055a0f-69cd-4bff-8338-b3d561b3362d,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-05d91330-ba0a-4826-8266-c0c4c629b501,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-d768efeb-43b9-40a0-8158-9d102346fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-5e18f182-aba4-480d-ac02-64bad90be0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-210b99fb-8ffd-48f4-a4b9-4938b8e9476b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800319084-172.17.0.9-1598181259243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-65b7e7dc-9ea6-4492-b291-4dc48ea4d93b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-865e3f90-6fd2-4694-8855-94ec0c233d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-81461363-8c54-4dd4-b535-7b11a3e8c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-1b055a0f-69cd-4bff-8338-b3d561b3362d,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-05d91330-ba0a-4826-8266-c0c4c629b501,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-d768efeb-43b9-40a0-8158-9d102346fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-5e18f182-aba4-480d-ac02-64bad90be0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-210b99fb-8ffd-48f4-a4b9-4938b8e9476b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598740557-172.17.0.9-1598181660793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-2814e9b1-5c12-46fb-b824-68f8e269c0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-c30b6ceb-45c6-40d9-98a2-4ff7cedff9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-46cf1c39-2c93-446f-9433-148d091cf870,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-2c3d06c0-98eb-4389-a6de-25dcc778620c,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-0921593a-aeda-41af-a924-a4e694bae4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-c96ea7f8-7c7c-4d27-aa12-6d8b159ca128,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-54e4ccf5-57e5-42d8-a482-c4b9f9addf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-d682f90a-1c8c-4dcf-9525-179aba680ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598740557-172.17.0.9-1598181660793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-2814e9b1-5c12-46fb-b824-68f8e269c0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-c30b6ceb-45c6-40d9-98a2-4ff7cedff9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-46cf1c39-2c93-446f-9433-148d091cf870,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-2c3d06c0-98eb-4389-a6de-25dcc778620c,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-0921593a-aeda-41af-a924-a4e694bae4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-c96ea7f8-7c7c-4d27-aa12-6d8b159ca128,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-54e4ccf5-57e5-42d8-a482-c4b9f9addf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-d682f90a-1c8c-4dcf-9525-179aba680ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754986413-172.17.0.9-1598181991603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32820,DS-874fa30e-890a-40e0-9936-95be9ed05ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7e087427-161d-4744-b14e-6ee99b185f44,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-17e9b74b-3e72-41ce-abc6-f398f0ccfe80,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-35d7b529-1974-4602-9eb7-075c9dea0973,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3de2b6ff-88f8-49d0-80c5-facb9cdb1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-8c276317-0c52-443e-b642-4d8968b59266,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-ce2d3db5-017f-46a4-bf1e-47e854e1c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-6557a6eb-4baa-4217-90e5-d5b9c56b8f69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754986413-172.17.0.9-1598181991603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32820,DS-874fa30e-890a-40e0-9936-95be9ed05ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7e087427-161d-4744-b14e-6ee99b185f44,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-17e9b74b-3e72-41ce-abc6-f398f0ccfe80,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-35d7b529-1974-4602-9eb7-075c9dea0973,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-3de2b6ff-88f8-49d0-80c5-facb9cdb1b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-8c276317-0c52-443e-b642-4d8968b59266,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-ce2d3db5-017f-46a4-bf1e-47e854e1c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-6557a6eb-4baa-4217-90e5-d5b9c56b8f69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549787570-172.17.0.9-1598182287861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44194,DS-9a81af37-af4c-4b5c-a57d-cc209a9af17c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-7eab3098-499c-40ad-9e81-839209d79a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-56111b83-d0d0-4cb5-ac53-af5972127038,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-4b9e5d65-53fc-4f59-a86c-87287a48a3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-412d9a40-9dee-4557-8eeb-c8dfb7da5ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-66deffda-e7f9-4a4e-8d21-0f764edbe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-8e744d09-09c0-4fc3-ab14-6b8422cedb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-1c2064ae-ca2a-45d5-8106-de6bb32b22c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549787570-172.17.0.9-1598182287861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44194,DS-9a81af37-af4c-4b5c-a57d-cc209a9af17c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-7eab3098-499c-40ad-9e81-839209d79a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-56111b83-d0d0-4cb5-ac53-af5972127038,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-4b9e5d65-53fc-4f59-a86c-87287a48a3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-412d9a40-9dee-4557-8eeb-c8dfb7da5ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-66deffda-e7f9-4a4e-8d21-0f764edbe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-8e744d09-09c0-4fc3-ab14-6b8422cedb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-1c2064ae-ca2a-45d5-8106-de6bb32b22c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418545805-172.17.0.9-1598182362398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-50423e27-3873-4253-9d42-80ce3bc7a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-37d76a3d-60d6-497e-bc8a-85f65b74a257,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-03600680-cc19-4b8a-b6bb-8fc8c6fa7361,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-4204b481-ce52-4c2a-8239-02cf0a6a7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-aa2fa8ce-4e15-4b52-89f9-0f48c95a4978,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-008e79cb-2297-4c42-9193-b12d600bbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-efa83ec7-1286-43b6-9db1-06b8e34000dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-eeea2d23-6f5f-4ac2-9590-2bdb29e89140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418545805-172.17.0.9-1598182362398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-50423e27-3873-4253-9d42-80ce3bc7a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-37d76a3d-60d6-497e-bc8a-85f65b74a257,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-03600680-cc19-4b8a-b6bb-8fc8c6fa7361,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-4204b481-ce52-4c2a-8239-02cf0a6a7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-aa2fa8ce-4e15-4b52-89f9-0f48c95a4978,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-008e79cb-2297-4c42-9193-b12d600bbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-efa83ec7-1286-43b6-9db1-06b8e34000dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-eeea2d23-6f5f-4ac2-9590-2bdb29e89140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243831571-172.17.0.9-1598182536320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-85ca4b2e-e07e-451c-be03-6215e6178421,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-6f3381da-42cb-4e32-b57e-5babd887ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-5bfca1a3-14a2-464d-b30c-febf2a2f5d87,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-e4aeb96e-0fcf-48ef-ba03-8443e402807b,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-cc0b67fe-c51e-477d-a531-b6d655416671,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-7b46f087-86c7-4b85-b7a6-1b038b35511f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-976f73c2-1715-4d03-8d0a-c7176f04381e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-6a4861db-d936-4d0c-827e-1cfab7e397f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243831571-172.17.0.9-1598182536320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-85ca4b2e-e07e-451c-be03-6215e6178421,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-6f3381da-42cb-4e32-b57e-5babd887ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-5bfca1a3-14a2-464d-b30c-febf2a2f5d87,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-e4aeb96e-0fcf-48ef-ba03-8443e402807b,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-cc0b67fe-c51e-477d-a531-b6d655416671,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-7b46f087-86c7-4b85-b7a6-1b038b35511f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-976f73c2-1715-4d03-8d0a-c7176f04381e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-6a4861db-d936-4d0c-827e-1cfab7e397f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5561
