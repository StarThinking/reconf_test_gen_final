reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210671136-172.17.0.7-1598151717818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45203,DS-51790ecc-a2d5-4572-bf1c-4441662ff6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-b959e5ed-f869-4ad6-9015-5b5209c70bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-d8798060-edcd-4d62-9765-57d3cd3990c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-56d7f7ef-85f8-4a7c-9c4d-9ea8b15b1aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-62e6e74e-9384-49e3-89c8-9fec16619161,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-50461550-7df5-4cf4-b9b6-e5b33e922cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-fa84a1fe-a103-4f63-975c-6559a1cde54b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-c4b65c4d-e195-4ba2-841d-ce162ec5bd23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210671136-172.17.0.7-1598151717818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45203,DS-51790ecc-a2d5-4572-bf1c-4441662ff6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-b959e5ed-f869-4ad6-9015-5b5209c70bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-d8798060-edcd-4d62-9765-57d3cd3990c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-56d7f7ef-85f8-4a7c-9c4d-9ea8b15b1aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-62e6e74e-9384-49e3-89c8-9fec16619161,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-50461550-7df5-4cf4-b9b6-e5b33e922cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-fa84a1fe-a103-4f63-975c-6559a1cde54b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-c4b65c4d-e195-4ba2-841d-ce162ec5bd23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617003265-172.17.0.7-1598151750427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-e5abc83d-5036-4c84-8653-df14099ee74f,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-99fc1239-4f24-496b-9df3-fc15257c4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-647f64c6-75d6-442a-a918-0d770e6d1cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-13f20593-3ef4-4896-8be3-636c8380e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-25b8ec18-5f85-46c7-8840-d2df7b87d732,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-5439ab18-076f-4fd0-a299-4b8d8ad058f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-b3d59524-0873-443b-baa5-d6ca860d977c,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-2c7151c7-c837-4660-81d4-1c8eac6ab59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617003265-172.17.0.7-1598151750427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-e5abc83d-5036-4c84-8653-df14099ee74f,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-99fc1239-4f24-496b-9df3-fc15257c4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-647f64c6-75d6-442a-a918-0d770e6d1cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-13f20593-3ef4-4896-8be3-636c8380e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-25b8ec18-5f85-46c7-8840-d2df7b87d732,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-5439ab18-076f-4fd0-a299-4b8d8ad058f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-b3d59524-0873-443b-baa5-d6ca860d977c,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-2c7151c7-c837-4660-81d4-1c8eac6ab59b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072446112-172.17.0.7-1598151930093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-78d82971-fed1-4076-9fce-abe0de53246b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-44184071-ef92-4a64-8306-8939eb036681,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-53280810-e179-4e43-b200-15fa1469b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-06ca5273-d7e2-4cdc-896d-de22544c1330,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-167f673c-0e5c-4843-8bc3-2930e869034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-58576daf-e17e-4a8e-9e4e-4ed155dc21e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-02216a4e-abc8-459d-a0d0-d417d0df3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-588737c7-87b3-46bb-aa21-db3825abbcfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072446112-172.17.0.7-1598151930093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-78d82971-fed1-4076-9fce-abe0de53246b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-44184071-ef92-4a64-8306-8939eb036681,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-53280810-e179-4e43-b200-15fa1469b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-06ca5273-d7e2-4cdc-896d-de22544c1330,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-167f673c-0e5c-4843-8bc3-2930e869034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-58576daf-e17e-4a8e-9e4e-4ed155dc21e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-02216a4e-abc8-459d-a0d0-d417d0df3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-588737c7-87b3-46bb-aa21-db3825abbcfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564916242-172.17.0.7-1598152101499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-a82b6fe3-7cbc-460f-baef-153d69bcdcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-88e0a0c1-98dc-4947-b0e4-6983eeaf2474,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-5068835f-bf0d-4768-a12a-30fa4db75d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-0ac8f95b-60c3-4fc3-9e96-ee59e970647a,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-4aefc600-2f30-4f33-9ce1-2996b4b2647d,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-ffec1490-443d-4d56-a72e-bd519ea92d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-beccf356-a0a8-4709-8ca5-6cc223c10987,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-e6ba1991-8723-464a-99af-b877ca4fecb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564916242-172.17.0.7-1598152101499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-a82b6fe3-7cbc-460f-baef-153d69bcdcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-88e0a0c1-98dc-4947-b0e4-6983eeaf2474,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-5068835f-bf0d-4768-a12a-30fa4db75d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-0ac8f95b-60c3-4fc3-9e96-ee59e970647a,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-4aefc600-2f30-4f33-9ce1-2996b4b2647d,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-ffec1490-443d-4d56-a72e-bd519ea92d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-beccf356-a0a8-4709-8ca5-6cc223c10987,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-e6ba1991-8723-464a-99af-b877ca4fecb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445868133-172.17.0.7-1598152289584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-b33208fc-7280-4f95-93a3-401a1ea01d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-4330a69c-26c1-4b48-9fbd-105c71ebd54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-44cd9009-96ff-44d2-b8db-43219c3f4a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9c06f773-e68f-477f-9438-ba1cf5437360,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-031cfc00-9504-4dac-a942-695a416de138,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-ae1ff1b6-4d91-47a2-8952-b21aa4fcbc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-0ec6ba47-2aae-487a-821e-bb1c75a7580d,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0f28ce5f-44d2-402d-bedf-53c80c19d65a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445868133-172.17.0.7-1598152289584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-b33208fc-7280-4f95-93a3-401a1ea01d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-4330a69c-26c1-4b48-9fbd-105c71ebd54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-44cd9009-96ff-44d2-b8db-43219c3f4a54,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9c06f773-e68f-477f-9438-ba1cf5437360,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-031cfc00-9504-4dac-a942-695a416de138,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-ae1ff1b6-4d91-47a2-8952-b21aa4fcbc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-0ec6ba47-2aae-487a-821e-bb1c75a7580d,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0f28ce5f-44d2-402d-bedf-53c80c19d65a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231118901-172.17.0.7-1598152513190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-99ad9f1d-5a58-486c-9890-59de74de610a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-7637e1b1-c4ee-4b42-a13f-abbd32dfaa71,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-705567d7-de28-4326-8b80-f112764b5753,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-fbf75cc6-6b3f-493b-8fab-f6e810788219,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-5906c8e6-bff4-4aaa-afc2-c359112f103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-68d1a4e0-27ac-4671-81a0-8130790cb47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-4d17e8c7-c3fb-4024-8c86-7cc54356f624,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-b0f3a55d-655e-4f9f-8a9a-54e658987d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231118901-172.17.0.7-1598152513190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-99ad9f1d-5a58-486c-9890-59de74de610a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-7637e1b1-c4ee-4b42-a13f-abbd32dfaa71,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-705567d7-de28-4326-8b80-f112764b5753,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-fbf75cc6-6b3f-493b-8fab-f6e810788219,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-5906c8e6-bff4-4aaa-afc2-c359112f103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-68d1a4e0-27ac-4671-81a0-8130790cb47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-4d17e8c7-c3fb-4024-8c86-7cc54356f624,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-b0f3a55d-655e-4f9f-8a9a-54e658987d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206762065-172.17.0.7-1598152550220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-af458a5f-dcf9-45f2-b6a3-0f9e6bb74277,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-63dad10c-f6b7-4d13-acfb-9aa4e5ac2b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-5dad6814-0bc2-4df1-adec-ac5ef276a007,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-e6fa7704-d198-447d-ad4b-ebfe238c67fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-5a06cb7b-945a-435b-9859-6c3bbb0f6b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-7a3a901e-82a2-441b-a35b-56e05d5e7c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d14c0aea-6e0c-4436-963f-ceb53eb30f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-8db7d65c-9f32-4bd9-8275-7738be31fd83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206762065-172.17.0.7-1598152550220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-af458a5f-dcf9-45f2-b6a3-0f9e6bb74277,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-63dad10c-f6b7-4d13-acfb-9aa4e5ac2b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-5dad6814-0bc2-4df1-adec-ac5ef276a007,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-e6fa7704-d198-447d-ad4b-ebfe238c67fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-5a06cb7b-945a-435b-9859-6c3bbb0f6b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-7a3a901e-82a2-441b-a35b-56e05d5e7c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d14c0aea-6e0c-4436-963f-ceb53eb30f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-8db7d65c-9f32-4bd9-8275-7738be31fd83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550489281-172.17.0.7-1598152759072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-de519879-9539-4556-ad0e-4d5e95bad3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a65a9d57-1e48-476f-b0b2-0e2946bf58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-d8c1da21-37c5-4bd8-ba43-9b65dd3ea819,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-48b1af87-e664-417a-97fc-5391fa2effee,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3a33cd63-b42c-4951-87c0-dc94cc637f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-3abac973-9152-45cd-926a-ca0d8b5376e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-54cce46a-54b2-47dc-9a1a-a0ee58861a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-4a808558-810e-4c6d-9616-c00836ae4282,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550489281-172.17.0.7-1598152759072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-de519879-9539-4556-ad0e-4d5e95bad3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a65a9d57-1e48-476f-b0b2-0e2946bf58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-d8c1da21-37c5-4bd8-ba43-9b65dd3ea819,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-48b1af87-e664-417a-97fc-5391fa2effee,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3a33cd63-b42c-4951-87c0-dc94cc637f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-3abac973-9152-45cd-926a-ca0d8b5376e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-54cce46a-54b2-47dc-9a1a-a0ee58861a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-4a808558-810e-4c6d-9616-c00836ae4282,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333330407-172.17.0.7-1598152830563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-d8e92202-ac2c-4be8-b22a-872feb4e60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-5330750a-3c32-4faa-8bfb-0f4421dc2b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-f49a30d9-9a25-4d93-ba1e-d57b498769b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-54de0eb8-c17f-4805-b5fb-1c41dd73d881,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-390e0080-b284-4764-9831-93d9cc3fe033,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4aad5814-f649-4b5d-9d5c-f92a4c2f6cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-046e3bbe-521d-44b4-8371-c91e1ee9373f,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-20727816-8199-40d2-a9a5-da6d6aeb05b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333330407-172.17.0.7-1598152830563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-d8e92202-ac2c-4be8-b22a-872feb4e60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-5330750a-3c32-4faa-8bfb-0f4421dc2b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-f49a30d9-9a25-4d93-ba1e-d57b498769b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-54de0eb8-c17f-4805-b5fb-1c41dd73d881,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-390e0080-b284-4764-9831-93d9cc3fe033,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4aad5814-f649-4b5d-9d5c-f92a4c2f6cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-046e3bbe-521d-44b4-8371-c91e1ee9373f,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-20727816-8199-40d2-a9a5-da6d6aeb05b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580892619-172.17.0.7-1598152974011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-03812d54-946c-4583-858c-478e68549222,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3d91685e-5e39-4fe2-96d6-ef22a2ae3189,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-520845ef-4d7a-46be-bd3d-6a6f53b3fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b30d2215-a26b-4956-89a0-fe81ad2a8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-dd697f49-684d-4805-ad21-f8510b17ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-4cf62b7a-0859-4842-a82e-79ed8c002bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-b1efc967-1e79-42e5-9615-8227838a70d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-3e85bfda-d088-4817-91b6-e47559e67214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580892619-172.17.0.7-1598152974011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-03812d54-946c-4583-858c-478e68549222,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3d91685e-5e39-4fe2-96d6-ef22a2ae3189,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-520845ef-4d7a-46be-bd3d-6a6f53b3fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-b30d2215-a26b-4956-89a0-fe81ad2a8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-dd697f49-684d-4805-ad21-f8510b17ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-4cf62b7a-0859-4842-a82e-79ed8c002bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-b1efc967-1e79-42e5-9615-8227838a70d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-3e85bfda-d088-4817-91b6-e47559e67214,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270800507-172.17.0.7-1598153005707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-b719c952-8110-4bdb-a7a8-5ebd7e0ed908,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-a6a6be6f-ba95-4f55-a4fa-b0802dfd607f,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-4583c063-910e-4be0-99b4-79790ecc7991,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-e5e3cf07-dfac-44f8-8648-8c57e5e52cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-a2329b8a-81bd-4384-9432-adab01f1a589,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-1c336ae8-3ee2-4b6a-a27b-3331fcb75775,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-2395bc5d-0b3c-4b2f-9c26-b025341896d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f701d139-fac8-4b6e-8d08-c302b2570810,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270800507-172.17.0.7-1598153005707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-b719c952-8110-4bdb-a7a8-5ebd7e0ed908,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-a6a6be6f-ba95-4f55-a4fa-b0802dfd607f,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-4583c063-910e-4be0-99b4-79790ecc7991,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-e5e3cf07-dfac-44f8-8648-8c57e5e52cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-a2329b8a-81bd-4384-9432-adab01f1a589,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-1c336ae8-3ee2-4b6a-a27b-3331fcb75775,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-2395bc5d-0b3c-4b2f-9c26-b025341896d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f701d139-fac8-4b6e-8d08-c302b2570810,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866860184-172.17.0.7-1598153183224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-bdfa728a-3582-4512-94f6-233ba6637e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4af23cfb-705b-4def-9a42-c166102fcb24,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-67806a22-1ebb-4b87-95f2-f8350002d749,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6b3e0249-631b-480c-84ae-08f5e99d78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-4750097f-e7cf-4250-a6c2-4d6433bcce80,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-98742085-b8d5-4769-912c-63c11f99ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-493c9aee-707b-4fa5-953b-81f2db6f9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-045e0029-1a21-4fa8-bd8b-36227770301b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866860184-172.17.0.7-1598153183224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-bdfa728a-3582-4512-94f6-233ba6637e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4af23cfb-705b-4def-9a42-c166102fcb24,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-67806a22-1ebb-4b87-95f2-f8350002d749,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-6b3e0249-631b-480c-84ae-08f5e99d78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-4750097f-e7cf-4250-a6c2-4d6433bcce80,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-98742085-b8d5-4769-912c-63c11f99ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-493c9aee-707b-4fa5-953b-81f2db6f9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-045e0029-1a21-4fa8-bd8b-36227770301b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133726856-172.17.0.7-1598153583917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-4e8baee2-2b62-48e5-b4b3-9425e4acbd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-d99c3caa-0a81-4c52-864a-422c2c1b289d,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-8f49472e-4e05-40ab-91c7-c03024fcf8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-386b9de5-d3fc-4602-afb9-c28383dfa423,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-4a869192-0601-42b9-8b93-3860c92a4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-79d25756-020a-429f-a9cb-2a7aebec55c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-57cde928-c9ac-4f5e-9e34-8293e804e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-76362530-4754-4681-afb5-e4c8458c2cc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133726856-172.17.0.7-1598153583917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-4e8baee2-2b62-48e5-b4b3-9425e4acbd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-d99c3caa-0a81-4c52-864a-422c2c1b289d,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-8f49472e-4e05-40ab-91c7-c03024fcf8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-386b9de5-d3fc-4602-afb9-c28383dfa423,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-4a869192-0601-42b9-8b93-3860c92a4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-79d25756-020a-429f-a9cb-2a7aebec55c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-57cde928-c9ac-4f5e-9e34-8293e804e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-76362530-4754-4681-afb5-e4c8458c2cc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226885602-172.17.0.7-1598153682334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-d532a1ef-5804-4850-9b26-924fc3ef1f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-74d8a102-3494-448f-915e-a3cc24735a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-09e937ba-afa8-4939-aabe-18f53b3e7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-95ac8b73-0406-4db4-aa1f-d716966ea36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-b16f3309-192b-4f18-8b28-ff97da2de119,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-79dd599a-7ae8-4f3e-a3ae-70cadd27fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-a7e6d123-2569-4ca8-ad41-aac97e434b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-899fee2c-5502-4a9c-80a6-7f169f6606e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226885602-172.17.0.7-1598153682334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43524,DS-d532a1ef-5804-4850-9b26-924fc3ef1f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-74d8a102-3494-448f-915e-a3cc24735a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-09e937ba-afa8-4939-aabe-18f53b3e7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-95ac8b73-0406-4db4-aa1f-d716966ea36f,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-b16f3309-192b-4f18-8b28-ff97da2de119,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-79dd599a-7ae8-4f3e-a3ae-70cadd27fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-a7e6d123-2569-4ca8-ad41-aac97e434b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-899fee2c-5502-4a9c-80a6-7f169f6606e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355881353-172.17.0.7-1598153721085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37914,DS-f1bfa1c5-0f01-4131-aac6-d3b18b0b7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-f2942015-7e91-4c77-a597-3c3d45af9680,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-3ed4c4db-7a14-403c-b781-e0176fdec03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-d87ce051-cbd3-4760-a2dd-d7a31b40bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-e5eb8265-814a-4bf3-9c09-f35f1edf7998,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-699cf400-d578-471d-b649-49bdaac9965a,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-47c3c991-56e0-46d7-932c-f06e50aaf600,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-07ad8a46-25e1-4070-bad3-f0fa82712966,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355881353-172.17.0.7-1598153721085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37914,DS-f1bfa1c5-0f01-4131-aac6-d3b18b0b7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-f2942015-7e91-4c77-a597-3c3d45af9680,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-3ed4c4db-7a14-403c-b781-e0176fdec03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-d87ce051-cbd3-4760-a2dd-d7a31b40bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-e5eb8265-814a-4bf3-9c09-f35f1edf7998,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-699cf400-d578-471d-b649-49bdaac9965a,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-47c3c991-56e0-46d7-932c-f06e50aaf600,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-07ad8a46-25e1-4070-bad3-f0fa82712966,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174863022-172.17.0.7-1598153756070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-c081f41c-b271-4dcd-810a-0b19e0b80d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-28416340-61d1-4b22-bb40-b8e0d8dd39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-e95bd7c5-d619-4334-ad54-853405b08538,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f08c6e96-c11b-4256-b0d9-137777e9b354,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-7fcc8512-4a11-4980-ac12-25375b14b655,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-0ca0e9a7-8cf9-417e-9aad-f9ef228ba2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-1323be89-fa47-447a-9d29-9104ade118db,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-7c9d8552-0480-4317-8358-6480755bc30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174863022-172.17.0.7-1598153756070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-c081f41c-b271-4dcd-810a-0b19e0b80d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-28416340-61d1-4b22-bb40-b8e0d8dd39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-e95bd7c5-d619-4334-ad54-853405b08538,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f08c6e96-c11b-4256-b0d9-137777e9b354,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-7fcc8512-4a11-4980-ac12-25375b14b655,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-0ca0e9a7-8cf9-417e-9aad-f9ef228ba2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-1323be89-fa47-447a-9d29-9104ade118db,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-7c9d8552-0480-4317-8358-6480755bc30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498972366-172.17.0.7-1598153898414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-7add1585-d27e-44c6-8ff9-74030adf1550,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-d93706fe-8ad3-46a7-8d88-29a807fb9f43,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-312a866b-ab6a-40fc-acc5-ef1513b66e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-d8f45ffc-de18-4055-8678-152bcb8e9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-1fa62f15-4125-4367-a320-04c94572dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-4943baaa-54a8-4dfe-aa63-13db8b8248b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-edc16af0-ba13-4daf-a993-7ff2f6576707,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-725278f8-3ac0-4470-b1a5-fb2353263239,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498972366-172.17.0.7-1598153898414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-7add1585-d27e-44c6-8ff9-74030adf1550,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-d93706fe-8ad3-46a7-8d88-29a807fb9f43,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-312a866b-ab6a-40fc-acc5-ef1513b66e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-d8f45ffc-de18-4055-8678-152bcb8e9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-1fa62f15-4125-4367-a320-04c94572dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-4943baaa-54a8-4dfe-aa63-13db8b8248b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-edc16af0-ba13-4daf-a993-7ff2f6576707,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-725278f8-3ac0-4470-b1a5-fb2353263239,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481308376-172.17.0.7-1598153932630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-eb56c37f-9bee-4e45-9772-2f7c6dad5077,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-f3d3f3d2-4f8b-48d7-b44a-102a989e8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-7463b4c4-470d-421e-9fd1-3c646257c175,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-63d39268-396e-4f92-b270-7565647f8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-0c1b98b0-74d2-449e-852f-17203c391b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1b7bf933-d743-466d-9add-12f2fd7f6919,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-fc29a007-e6aa-48c8-a74f-d0025a282220,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-47ff68e5-ed94-4ac5-88d9-d5ac06e90f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481308376-172.17.0.7-1598153932630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-eb56c37f-9bee-4e45-9772-2f7c6dad5077,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-f3d3f3d2-4f8b-48d7-b44a-102a989e8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-7463b4c4-470d-421e-9fd1-3c646257c175,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-63d39268-396e-4f92-b270-7565647f8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-0c1b98b0-74d2-449e-852f-17203c391b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1b7bf933-d743-466d-9add-12f2fd7f6919,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-fc29a007-e6aa-48c8-a74f-d0025a282220,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-47ff68e5-ed94-4ac5-88d9-d5ac06e90f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327354529-172.17.0.7-1598154413609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-d0a58df4-00f3-424e-8879-a2ab87486dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-44f68f7f-1755-4566-98aa-f596c1532081,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-f67f7b01-77f9-43f5-9032-4041b484bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-aa5b218d-65f9-41b9-87ff-724cdd81daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-8ed7f304-1b40-474f-a5b5-6c140edee66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-fcbf9dc6-c0ae-4355-8ed9-ea2dc0c4f4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-81703f6c-1a31-40cc-abc9-d711f926ad73,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-c0b14bbd-0036-4c17-a49e-498cc7efb462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327354529-172.17.0.7-1598154413609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-d0a58df4-00f3-424e-8879-a2ab87486dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-44f68f7f-1755-4566-98aa-f596c1532081,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-f67f7b01-77f9-43f5-9032-4041b484bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-aa5b218d-65f9-41b9-87ff-724cdd81daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-8ed7f304-1b40-474f-a5b5-6c140edee66e,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-fcbf9dc6-c0ae-4355-8ed9-ea2dc0c4f4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-81703f6c-1a31-40cc-abc9-d711f926ad73,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-c0b14bbd-0036-4c17-a49e-498cc7efb462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945871636-172.17.0.7-1598154534290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-24acd5ff-ce8b-46b0-b253-dffedd79a874,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-86d86509-0083-492f-90e3-cbace7647854,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-be0027a8-cdac-4767-a30f-3df286a01363,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-fee3bebc-0ea6-4830-aaf8-e2ab6db0d713,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-a32dc7a0-3009-48ac-a4cf-225a806e1c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-8acca462-8cc2-4a3e-ad52-eed7c0486092,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-7e8dfa6f-462e-4f09-95c4-d135af653105,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-175e8955-17f3-497d-be3e-6e9ef4409edf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945871636-172.17.0.7-1598154534290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-24acd5ff-ce8b-46b0-b253-dffedd79a874,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-86d86509-0083-492f-90e3-cbace7647854,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-be0027a8-cdac-4767-a30f-3df286a01363,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-fee3bebc-0ea6-4830-aaf8-e2ab6db0d713,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-a32dc7a0-3009-48ac-a4cf-225a806e1c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-8acca462-8cc2-4a3e-ad52-eed7c0486092,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-7e8dfa6f-462e-4f09-95c4-d135af653105,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-175e8955-17f3-497d-be3e-6e9ef4409edf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945239987-172.17.0.7-1598154609982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-6f8aeeff-aa7e-432e-9f35-8e245ec2db98,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-d656b9e3-dc44-4b3f-b66f-be57507d4796,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a4333786-087e-4ecc-b60c-3d557954f173,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-fd950abd-e8da-4f16-9e76-63ab1ec904c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-d40ed5b9-8add-4712-91a9-95a281ca8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-01c02d02-77ff-417b-aed3-f41d82ad2125,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-678ed81a-dc7a-4d7b-9ca0-c6b65d591ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-32f1d4ab-e558-4f18-97fe-3f48172c5f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945239987-172.17.0.7-1598154609982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-6f8aeeff-aa7e-432e-9f35-8e245ec2db98,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-d656b9e3-dc44-4b3f-b66f-be57507d4796,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a4333786-087e-4ecc-b60c-3d557954f173,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-fd950abd-e8da-4f16-9e76-63ab1ec904c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-d40ed5b9-8add-4712-91a9-95a281ca8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-01c02d02-77ff-417b-aed3-f41d82ad2125,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-678ed81a-dc7a-4d7b-9ca0-c6b65d591ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-32f1d4ab-e558-4f18-97fe-3f48172c5f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523183144-172.17.0.7-1598154742051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36194,DS-33cc032f-d8ec-48ae-a223-a8d3198f9baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-a6ac2cab-c647-4c33-81d2-736729edbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-b6bbca6b-c2e4-4835-8aca-a7f64912ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-9c9c5d94-7c72-4641-82f6-fc1bed48a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-ad695936-853f-42f5-bf5c-8ae534ccac13,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-250440c3-122e-4f03-8525-cdaf848e632d,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-d5408258-1ba0-43cd-be88-cd851bcb2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-ac2ff520-03f8-41a0-b0d6-3a4bc95de32e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523183144-172.17.0.7-1598154742051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36194,DS-33cc032f-d8ec-48ae-a223-a8d3198f9baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-a6ac2cab-c647-4c33-81d2-736729edbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-b6bbca6b-c2e4-4835-8aca-a7f64912ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-9c9c5d94-7c72-4641-82f6-fc1bed48a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-ad695936-853f-42f5-bf5c-8ae534ccac13,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-250440c3-122e-4f03-8525-cdaf848e632d,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-d5408258-1ba0-43cd-be88-cd851bcb2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-ac2ff520-03f8-41a0-b0d6-3a4bc95de32e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619470990-172.17.0.7-1598154849750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38833,DS-4278368a-fcb3-480d-948d-d6985963adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-ad4ac437-409d-4457-a75c-a3290f4ff616,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b2a460d0-ddce-4204-a00c-8dd1fb5cb492,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-bcd19f7f-9f25-4719-9767-4a2c5b153004,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-34169e57-45bd-4797-bcc3-a29e40181f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-93ff0515-ffae-4340-8788-465b4cd5266f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-1c96dd20-feee-4299-8e2a-693a7ab820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-7f8cbb28-ae71-4426-8bcc-a95ad2410fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619470990-172.17.0.7-1598154849750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38833,DS-4278368a-fcb3-480d-948d-d6985963adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-ad4ac437-409d-4457-a75c-a3290f4ff616,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b2a460d0-ddce-4204-a00c-8dd1fb5cb492,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-bcd19f7f-9f25-4719-9767-4a2c5b153004,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-34169e57-45bd-4797-bcc3-a29e40181f12,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-93ff0515-ffae-4340-8788-465b4cd5266f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-1c96dd20-feee-4299-8e2a-693a7ab820b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-7f8cbb28-ae71-4426-8bcc-a95ad2410fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308879224-172.17.0.7-1598155002014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-b9b2ece8-1d7e-4212-a0a3-c22803699bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-1e2f3d40-e362-411e-9367-d734c5e96471,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-12c96b82-5e56-47e5-b792-67102fc8a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-355f3cc9-b96e-4438-a2c8-df39b7885360,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f5b5bc15-4f85-48fc-bead-5a3b444575a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-b6ca22f1-4a3e-4d0b-aab3-eac18b618ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-894ff0d3-098c-4c11-a6c8-69ebd24650d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-865bf409-3ea1-46f8-af8d-77846290afd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308879224-172.17.0.7-1598155002014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-b9b2ece8-1d7e-4212-a0a3-c22803699bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-1e2f3d40-e362-411e-9367-d734c5e96471,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-12c96b82-5e56-47e5-b792-67102fc8a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-355f3cc9-b96e-4438-a2c8-df39b7885360,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-f5b5bc15-4f85-48fc-bead-5a3b444575a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-b6ca22f1-4a3e-4d0b-aab3-eac18b618ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-894ff0d3-098c-4c11-a6c8-69ebd24650d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-865bf409-3ea1-46f8-af8d-77846290afd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503177493-172.17.0.7-1598155081006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-cdf4a722-e5e2-4552-98db-f1665a68405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-4fe2b1c9-c7a1-43e4-8783-3e364680b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-ef7c4624-9a76-4be9-a34d-5321b149a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-3847c006-b5ba-4e50-8bc7-f7af4c5bc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-62cac0e6-815f-4015-a369-c6c1bbfd8d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-b5a9e3d1-685f-4aab-b815-fd394bbd8947,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-9d41c7e5-d0f7-480e-a103-3e209660dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-9df056c7-2113-4af9-834e-2f03668c20d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503177493-172.17.0.7-1598155081006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-cdf4a722-e5e2-4552-98db-f1665a68405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-4fe2b1c9-c7a1-43e4-8783-3e364680b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-ef7c4624-9a76-4be9-a34d-5321b149a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-3847c006-b5ba-4e50-8bc7-f7af4c5bc9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-62cac0e6-815f-4015-a369-c6c1bbfd8d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-b5a9e3d1-685f-4aab-b815-fd394bbd8947,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-9d41c7e5-d0f7-480e-a103-3e209660dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-9df056c7-2113-4af9-834e-2f03668c20d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042590504-172.17.0.7-1598155949573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-c9ea8437-0ccb-4ab9-9a6a-79c80049a7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-1edafbe7-7985-49ce-8e22-02fca568714e,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-2a3b2720-cab1-41d9-9866-49b0263bd9df,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-a1b4b847-245e-4f7b-b99d-b07a61238fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-b3644647-df05-49bc-b334-f5f28a6c76de,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7d598aa2-bf92-462b-a3c5-6c50aa8ca9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-d9f6f026-9019-42a7-bcfd-c09f7929b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-cd85f6fe-2e95-4ef2-a2c5-0d12f076755a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042590504-172.17.0.7-1598155949573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-c9ea8437-0ccb-4ab9-9a6a-79c80049a7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-1edafbe7-7985-49ce-8e22-02fca568714e,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-2a3b2720-cab1-41d9-9866-49b0263bd9df,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-a1b4b847-245e-4f7b-b99d-b07a61238fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-b3644647-df05-49bc-b334-f5f28a6c76de,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7d598aa2-bf92-462b-a3c5-6c50aa8ca9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-d9f6f026-9019-42a7-bcfd-c09f7929b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-cd85f6fe-2e95-4ef2-a2c5-0d12f076755a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062745257-172.17.0.7-1598156052805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44500,DS-777156ee-4767-46b9-b3bf-01babbd2aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-13ddefcd-b4f8-4ee8-b7ec-7fc366ac5786,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-620832aa-c4f4-4884-9d01-1582308f12d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7c04e6d5-f07d-47f4-97fd-0e89e48d5e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-84e173c4-556f-4250-ad1b-0887195b4167,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-fe4d6606-0e06-4999-9005-4a82525f57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-7f00044c-0b5c-491f-b0fd-053f165e0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-b94a57d9-501b-4057-8e78-6dd0770014cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062745257-172.17.0.7-1598156052805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44500,DS-777156ee-4767-46b9-b3bf-01babbd2aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-13ddefcd-b4f8-4ee8-b7ec-7fc366ac5786,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-620832aa-c4f4-4884-9d01-1582308f12d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7c04e6d5-f07d-47f4-97fd-0e89e48d5e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-84e173c4-556f-4250-ad1b-0887195b4167,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-fe4d6606-0e06-4999-9005-4a82525f57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-7f00044c-0b5c-491f-b0fd-053f165e0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-b94a57d9-501b-4057-8e78-6dd0770014cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684856291-172.17.0.7-1598156244429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43980,DS-eade514e-7dfe-4bc3-80fb-408ac50af409,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-46cb31e4-d643-4fcd-80f8-a733029278d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-0c7dd101-502b-49fe-b23e-521d65b7595e,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-21246fc5-a8ad-4c35-be3c-1b1b1b2e4c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-c96f563f-db15-483f-8cca-01c43cdb9041,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-6395197a-b54d-4fbd-98f8-088e9240b004,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-effb0450-d63c-4f6a-a4f9-0d0a18563249,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-4f37f4d3-df0e-4b66-8497-a9023a2067a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684856291-172.17.0.7-1598156244429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43980,DS-eade514e-7dfe-4bc3-80fb-408ac50af409,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-46cb31e4-d643-4fcd-80f8-a733029278d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-0c7dd101-502b-49fe-b23e-521d65b7595e,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-21246fc5-a8ad-4c35-be3c-1b1b1b2e4c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-c96f563f-db15-483f-8cca-01c43cdb9041,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-6395197a-b54d-4fbd-98f8-088e9240b004,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-effb0450-d63c-4f6a-a4f9-0d0a18563249,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-4f37f4d3-df0e-4b66-8497-a9023a2067a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529664332-172.17.0.7-1598156522608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-ffe5366e-b5ac-49cc-bcb1-4d434d382501,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-19298002-709e-41ad-b68f-355450075e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-a372a604-0e00-4414-ad46-4565b2cf6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-03d96391-d321-4df3-9c45-29e91e726bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-752f1765-b881-4af7-88bc-71e92b477e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-a790c660-352f-4333-b10b-fa60f596ae2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-78a2dad8-8390-4948-869e-91d40b337208,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-18268f81-c6c4-4f2b-9b53-634893a9fc2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529664332-172.17.0.7-1598156522608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-ffe5366e-b5ac-49cc-bcb1-4d434d382501,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-19298002-709e-41ad-b68f-355450075e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-a372a604-0e00-4414-ad46-4565b2cf6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-03d96391-d321-4df3-9c45-29e91e726bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-752f1765-b881-4af7-88bc-71e92b477e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-a790c660-352f-4333-b10b-fa60f596ae2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-78a2dad8-8390-4948-869e-91d40b337208,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-18268f81-c6c4-4f2b-9b53-634893a9fc2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495767005-172.17.0.7-1598156643518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-95aeb935-102c-4b1b-abf3-5b02f0a2a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-e5b84633-0f82-4d6f-bcf5-a2390e53afea,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-bc36555a-16f5-474c-9bd2-52737d8442bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-9044e559-9463-4b9c-b5df-a8d02dbf7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-68526265-98b3-45b8-9d87-75d4c5e8efcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-35cb864c-c11f-476e-b503-24c400ffd61d,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-e04167d0-b521-4059-98d8-edaec015e961,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-82817b5f-6f1f-41a3-aa21-987e05ca914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495767005-172.17.0.7-1598156643518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-95aeb935-102c-4b1b-abf3-5b02f0a2a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-e5b84633-0f82-4d6f-bcf5-a2390e53afea,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-bc36555a-16f5-474c-9bd2-52737d8442bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-9044e559-9463-4b9c-b5df-a8d02dbf7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-68526265-98b3-45b8-9d87-75d4c5e8efcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-35cb864c-c11f-476e-b503-24c400ffd61d,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-e04167d0-b521-4059-98d8-edaec015e961,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-82817b5f-6f1f-41a3-aa21-987e05ca914f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669053845-172.17.0.7-1598156750159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-206ab531-3a6c-4805-bed1-2e442b50fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a53476b5-a531-4774-875f-4a562bd119ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-283dca7c-5044-4354-8bc7-a71268f5d3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-452567f1-8002-46c4-967c-fed6f6f6998c,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-093bbb66-235b-4fc2-a65c-90d0de1a3923,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-81254b14-a45c-4c7a-8722-dc15d3c493f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-e7821e58-27e9-4226-8175-4791fb3c302b,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-9c4a2136-416c-44bf-95fa-93a14be35af0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669053845-172.17.0.7-1598156750159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-206ab531-3a6c-4805-bed1-2e442b50fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a53476b5-a531-4774-875f-4a562bd119ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-283dca7c-5044-4354-8bc7-a71268f5d3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-452567f1-8002-46c4-967c-fed6f6f6998c,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-093bbb66-235b-4fc2-a65c-90d0de1a3923,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-81254b14-a45c-4c7a-8722-dc15d3c493f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-e7821e58-27e9-4226-8175-4791fb3c302b,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-9c4a2136-416c-44bf-95fa-93a14be35af0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5255
