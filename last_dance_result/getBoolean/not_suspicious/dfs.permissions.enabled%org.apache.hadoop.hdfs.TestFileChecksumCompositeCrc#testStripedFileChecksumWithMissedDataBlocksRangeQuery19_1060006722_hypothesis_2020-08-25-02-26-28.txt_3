reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002392264-172.17.0.5-1598322446812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-dea2212f-5955-43a5-86cb-383603f444c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-c1dfa9c9-cfc3-4f1a-880b-bde6b9ee96fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-ec236a50-fa52-48dc-8008-648c46e66532,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-e67b5920-bcd2-47cf-b043-fa5fba94d475,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-392bee15-de4e-497f-8d61-a1aea440508b,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-7ed34407-160b-4e6c-aa52-846f6e148727,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-59255450-b260-4a77-bf38-a3cfce1a9928,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-edf864de-09a8-4b95-9dcb-320dae23126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002392264-172.17.0.5-1598322446812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-dea2212f-5955-43a5-86cb-383603f444c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-c1dfa9c9-cfc3-4f1a-880b-bde6b9ee96fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-ec236a50-fa52-48dc-8008-648c46e66532,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-e67b5920-bcd2-47cf-b043-fa5fba94d475,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-392bee15-de4e-497f-8d61-a1aea440508b,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-7ed34407-160b-4e6c-aa52-846f6e148727,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-59255450-b260-4a77-bf38-a3cfce1a9928,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-edf864de-09a8-4b95-9dcb-320dae23126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532153030-172.17.0.5-1598322662631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-5ba011ab-bccc-431a-a82b-4dcd8143e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-d7376f18-c6ac-47bb-831d-6579c369476a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-0da91280-8c7e-4cbf-bd53-0796e035bd74,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-757d7eed-f480-41ef-b14d-66940df0c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-440114af-b243-43a8-a69d-1942c25cbdff,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-96b2e4cf-fcc3-4d63-9ae6-37943b6ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f772da74-6d0c-491b-ade5-f94135e59e30,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-2efa59b8-4425-4693-96de-1bd1dd39aea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532153030-172.17.0.5-1598322662631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-5ba011ab-bccc-431a-a82b-4dcd8143e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-d7376f18-c6ac-47bb-831d-6579c369476a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-0da91280-8c7e-4cbf-bd53-0796e035bd74,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-757d7eed-f480-41ef-b14d-66940df0c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-440114af-b243-43a8-a69d-1942c25cbdff,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-96b2e4cf-fcc3-4d63-9ae6-37943b6ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-f772da74-6d0c-491b-ade5-f94135e59e30,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-2efa59b8-4425-4693-96de-1bd1dd39aea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497498842-172.17.0.5-1598322839513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-36a92fd9-b363-43a1-bb1b-d516338ef751,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-88a718c6-9e6b-46b4-8119-445c047f3a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-3f96aaea-a1f1-4c78-851b-2080ca77e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-15ce25c1-d10c-4315-8791-9995615e0580,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a5b3b89c-59e7-4da0-8b9a-0d80481d7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-2c54deb1-ca9e-42db-bd9c-0797773088b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-9751c579-17f6-4ff4-ad90-ed8b283b1373,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-11efafa2-bdb7-4def-8b4a-65105d7c7c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497498842-172.17.0.5-1598322839513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-36a92fd9-b363-43a1-bb1b-d516338ef751,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-88a718c6-9e6b-46b4-8119-445c047f3a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-3f96aaea-a1f1-4c78-851b-2080ca77e3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-15ce25c1-d10c-4315-8791-9995615e0580,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a5b3b89c-59e7-4da0-8b9a-0d80481d7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-2c54deb1-ca9e-42db-bd9c-0797773088b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-9751c579-17f6-4ff4-ad90-ed8b283b1373,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-11efafa2-bdb7-4def-8b4a-65105d7c7c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441306933-172.17.0.5-1598323172031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-cba6ca80-f0a4-4d0f-8fcf-17f0116cde91,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-6065bf66-7063-4aab-9b7d-da4b5229b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-a04dd233-9187-4457-b108-82bd717fca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-f3ffdc23-cd05-4c3e-bd56-fc35f52a9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-320c37e4-61c5-4004-a4b5-290c2ce10441,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c8fb3bba-bff7-49f6-b69d-4ff7ea280c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-37edc89c-375c-4d41-bf7c-89dbf93a829f,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-5226c31f-2b2c-42ac-97fd-7aefcdd13061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441306933-172.17.0.5-1598323172031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-cba6ca80-f0a4-4d0f-8fcf-17f0116cde91,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-6065bf66-7063-4aab-9b7d-da4b5229b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-a04dd233-9187-4457-b108-82bd717fca6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-f3ffdc23-cd05-4c3e-bd56-fc35f52a9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-320c37e4-61c5-4004-a4b5-290c2ce10441,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-c8fb3bba-bff7-49f6-b69d-4ff7ea280c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-37edc89c-375c-4d41-bf7c-89dbf93a829f,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-5226c31f-2b2c-42ac-97fd-7aefcdd13061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361193101-172.17.0.5-1598323853956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-6420d4f9-578f-4cbb-a2a4-981986900624,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-f465e25c-97d7-4da4-bc5c-49695314382c,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-b0efa665-7ee5-4101-96c3-8da946a9540d,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-e29c6824-672e-4a02-a0d9-865e0e468df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-452884c3-7ba1-4ac6-a080-b4a85f4bb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-b22454d5-8873-4687-90df-f64b68da09d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5591575f-211b-4ad3-8bbd-91a971cb528f,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-06de54a7-7139-4c8a-b87d-09f313e4241e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361193101-172.17.0.5-1598323853956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-6420d4f9-578f-4cbb-a2a4-981986900624,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-f465e25c-97d7-4da4-bc5c-49695314382c,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-b0efa665-7ee5-4101-96c3-8da946a9540d,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-e29c6824-672e-4a02-a0d9-865e0e468df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-452884c3-7ba1-4ac6-a080-b4a85f4bb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-b22454d5-8873-4687-90df-f64b68da09d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5591575f-211b-4ad3-8bbd-91a971cb528f,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-06de54a7-7139-4c8a-b87d-09f313e4241e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975578826-172.17.0.5-1598324136468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-cf5130ff-ed59-43b7-880b-110326e2c466,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-5177ea7f-a561-4ffa-9595-7a30f22adee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-d05d171f-162d-43e5-b916-2ab0a18ae2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-82d8dc1c-7b3c-4db7-8ebe-77bae5402e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-0a742a8e-5709-4805-a62e-99936d57f625,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-21bc13b5-cba6-4a19-b617-b1c6fc410b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-ea385d60-25fb-4738-a563-d8ddc9b938bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-faa605e9-5b07-4c47-ae8a-5b85f53f1f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975578826-172.17.0.5-1598324136468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-cf5130ff-ed59-43b7-880b-110326e2c466,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-5177ea7f-a561-4ffa-9595-7a30f22adee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-d05d171f-162d-43e5-b916-2ab0a18ae2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-82d8dc1c-7b3c-4db7-8ebe-77bae5402e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-0a742a8e-5709-4805-a62e-99936d57f625,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-21bc13b5-cba6-4a19-b617-b1c6fc410b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-ea385d60-25fb-4738-a563-d8ddc9b938bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-faa605e9-5b07-4c47-ae8a-5b85f53f1f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705495937-172.17.0.5-1598325042611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-4f41776f-5c44-4352-b61a-5653b4f7c074,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-58e10c33-1d23-4fb3-a5cd-1dd75b442f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-138cf4fc-c3ce-41ec-99dc-6c1e74f61ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-ac302eb7-b25c-421a-bd77-873224717ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-2fb97f55-9d46-46b1-a433-4df904ca2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-0958a7c8-8b1f-486a-aa02-04b85af6192e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-30e586af-1f97-4967-a2aa-242d10cd5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-6a8d39e4-50b0-4599-890b-1fb9c49e04dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705495937-172.17.0.5-1598325042611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-4f41776f-5c44-4352-b61a-5653b4f7c074,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-58e10c33-1d23-4fb3-a5cd-1dd75b442f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-138cf4fc-c3ce-41ec-99dc-6c1e74f61ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-ac302eb7-b25c-421a-bd77-873224717ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-2fb97f55-9d46-46b1-a433-4df904ca2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-0958a7c8-8b1f-486a-aa02-04b85af6192e,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-30e586af-1f97-4967-a2aa-242d10cd5c70,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-6a8d39e4-50b0-4599-890b-1fb9c49e04dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894279428-172.17.0.5-1598325644316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33849,DS-c8e8a1eb-b1f4-4c81-9a1c-f5b45770c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-e8fc7ca5-ad04-4829-b66f-88465fdc18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-5c816b95-dd85-4b7f-ae08-8d8cd2ab6292,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-cf923006-c376-4319-b3b0-3eeb3f56088f,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-7d1ba954-ea90-445a-870c-3dbcc1286718,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-e8ff1ac4-59d0-434f-b38b-c0e82b9caf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-b50a25b3-b0dc-4a64-9c8d-52d468c70178,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4412c1df-6e03-4336-ad7f-0e23c8b21a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894279428-172.17.0.5-1598325644316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33849,DS-c8e8a1eb-b1f4-4c81-9a1c-f5b45770c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-e8fc7ca5-ad04-4829-b66f-88465fdc18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-5c816b95-dd85-4b7f-ae08-8d8cd2ab6292,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-cf923006-c376-4319-b3b0-3eeb3f56088f,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-7d1ba954-ea90-445a-870c-3dbcc1286718,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-e8ff1ac4-59d0-434f-b38b-c0e82b9caf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-b50a25b3-b0dc-4a64-9c8d-52d468c70178,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-4412c1df-6e03-4336-ad7f-0e23c8b21a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016786844-172.17.0.5-1598325847805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-036e0d8b-f7a5-4588-aace-d9fe9f3b9bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-8e2efc5b-f523-492c-8c86-ce592ef7916a,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-ca1f3c72-d13a-45ee-855f-ae12926be888,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8f3cd50d-db03-49d0-a196-393dd2b2325b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-2daa00a8-2b51-46e5-b3be-5661facba4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-6d8d848c-7e44-4825-9b9f-0c6c54415a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-e06b4707-51c8-4eae-a541-a95184df48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-4d6831ab-0b5b-48b7-a3c1-c0b0b333db3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016786844-172.17.0.5-1598325847805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-036e0d8b-f7a5-4588-aace-d9fe9f3b9bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-8e2efc5b-f523-492c-8c86-ce592ef7916a,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-ca1f3c72-d13a-45ee-855f-ae12926be888,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8f3cd50d-db03-49d0-a196-393dd2b2325b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-2daa00a8-2b51-46e5-b3be-5661facba4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-6d8d848c-7e44-4825-9b9f-0c6c54415a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-e06b4707-51c8-4eae-a541-a95184df48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-4d6831ab-0b5b-48b7-a3c1-c0b0b333db3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341686595-172.17.0.5-1598326025323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-fe9827bd-3faf-425d-a95d-bc95dbb0f236,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-97721503-bba5-48fc-b98d-bccac372f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-560d823d-85b0-4cca-9e04-3643c60d7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-953f552b-eded-465a-a285-61fd377dde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-3f3375e3-a894-460d-a638-1dcfc0498c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-43e9ce10-d313-40d2-a201-36870cc6d129,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-30d46d48-8be4-45bc-8e14-d81933170ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-3fe68119-69f2-4aeb-b780-b1be91381094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341686595-172.17.0.5-1598326025323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-fe9827bd-3faf-425d-a95d-bc95dbb0f236,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-97721503-bba5-48fc-b98d-bccac372f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-560d823d-85b0-4cca-9e04-3643c60d7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-953f552b-eded-465a-a285-61fd377dde1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-3f3375e3-a894-460d-a638-1dcfc0498c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-43e9ce10-d313-40d2-a201-36870cc6d129,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-30d46d48-8be4-45bc-8e14-d81933170ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-3fe68119-69f2-4aeb-b780-b1be91381094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672843883-172.17.0.5-1598326623770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-a06b80f2-fa84-4b18-a58d-60cee389177e,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-cd0cac87-71d0-44d9-b471-ccb9373b111a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-fe85c632-c5d8-473f-9a0f-f05bf2e4e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-8df0a1f1-8d6c-41be-841b-f420bcf055e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1b51c208-4084-43ac-b9c8-7a20bf43e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-4f8d57ed-634b-4740-8d13-dee8d734af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-7dc82f78-16cf-451e-be3a-3164f8dde417,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-9a30ad44-ba76-4e4a-9985-3e2c1ce23ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672843883-172.17.0.5-1598326623770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36364,DS-a06b80f2-fa84-4b18-a58d-60cee389177e,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-cd0cac87-71d0-44d9-b471-ccb9373b111a,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-fe85c632-c5d8-473f-9a0f-f05bf2e4e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-8df0a1f1-8d6c-41be-841b-f420bcf055e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1b51c208-4084-43ac-b9c8-7a20bf43e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-4f8d57ed-634b-4740-8d13-dee8d734af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-7dc82f78-16cf-451e-be3a-3164f8dde417,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-9a30ad44-ba76-4e4a-9985-3e2c1ce23ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954117021-172.17.0.5-1598326728589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-7d398c6f-4df5-4900-8573-16ea8e97710e,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3659aa87-4e12-4900-82ea-56807506373e,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-b0660afc-d7cd-46be-89ae-ced9e512b970,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-e498b19b-f57e-4c9f-80b7-f308b8443005,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-0a4b6044-5c9e-409b-93db-e8b1c30cea93,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-a4401c65-e8c2-4b64-b37c-27d2ae3c71e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-0e827da2-775a-4469-9b00-0e8ec9a834a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-21503692-048d-46ed-b99a-13d5852a0f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954117021-172.17.0.5-1598326728589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-7d398c6f-4df5-4900-8573-16ea8e97710e,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3659aa87-4e12-4900-82ea-56807506373e,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-b0660afc-d7cd-46be-89ae-ced9e512b970,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-e498b19b-f57e-4c9f-80b7-f308b8443005,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-0a4b6044-5c9e-409b-93db-e8b1c30cea93,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-a4401c65-e8c2-4b64-b37c-27d2ae3c71e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-0e827da2-775a-4469-9b00-0e8ec9a834a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-21503692-048d-46ed-b99a-13d5852a0f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117815369-172.17.0.5-1598326930791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-352a2940-7bd0-46e0-8015-ac0ae45fb6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-b7980cc1-5f61-444c-8230-71f6dcb06634,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-45f70732-845a-40aa-9267-76646780c083,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-e1145093-7817-490f-8792-774b317f2516,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-b91e2209-5b9a-4a5a-90a2-99a342bed48f,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d05010ef-e8a8-4236-96e3-fc484f353287,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-234c5a1c-344c-428c-8b02-e35f41aec5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-c66f5080-72ac-462d-a1fe-37bb15abc09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117815369-172.17.0.5-1598326930791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-352a2940-7bd0-46e0-8015-ac0ae45fb6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-b7980cc1-5f61-444c-8230-71f6dcb06634,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-45f70732-845a-40aa-9267-76646780c083,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-e1145093-7817-490f-8792-774b317f2516,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-b91e2209-5b9a-4a5a-90a2-99a342bed48f,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d05010ef-e8a8-4236-96e3-fc484f353287,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-234c5a1c-344c-428c-8b02-e35f41aec5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-c66f5080-72ac-462d-a1fe-37bb15abc09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550580343-172.17.0.5-1598326966080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-b2fb6989-2d8a-4d84-8f13-1facf25d1877,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b46bf5e9-ef9f-401b-93da-cea2448a5186,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-7566b268-19a5-4097-a139-83e1704f283e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-91e30332-2b4f-4940-850d-d72ec273a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-89c04645-6746-4e01-804b-7459d4c9b684,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7e907bbb-4e5e-4579-a843-204ee68bf382,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f8cd76ef-26bf-42fe-8e6e-104117f35d02,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c9f12f7-c3aa-4ee6-b65c-35afa23d070d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550580343-172.17.0.5-1598326966080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-b2fb6989-2d8a-4d84-8f13-1facf25d1877,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b46bf5e9-ef9f-401b-93da-cea2448a5186,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-7566b268-19a5-4097-a139-83e1704f283e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-91e30332-2b4f-4940-850d-d72ec273a90a,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-89c04645-6746-4e01-804b-7459d4c9b684,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-7e907bbb-4e5e-4579-a843-204ee68bf382,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f8cd76ef-26bf-42fe-8e6e-104117f35d02,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c9f12f7-c3aa-4ee6-b65c-35afa23d070d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089285869-172.17.0.5-1598327032151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-f6465e4f-a0f9-41a2-895c-e9c36ed6169b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-219175d9-2221-4722-a824-119375e218ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-ff27fdec-db0d-450c-b4c9-423082cd1388,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-382d47eb-7138-440d-be82-16c75202e251,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-c649a83c-7090-4298-a10f-5392f22073eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-ec2fdc8e-d4ef-46ed-8242-1a679acd0e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-927c7723-f597-4459-bf38-b5f69d9d6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-1ddea6e6-c5a9-44cb-b067-b3462c6aae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089285869-172.17.0.5-1598327032151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-f6465e4f-a0f9-41a2-895c-e9c36ed6169b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-219175d9-2221-4722-a824-119375e218ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-ff27fdec-db0d-450c-b4c9-423082cd1388,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-382d47eb-7138-440d-be82-16c75202e251,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-c649a83c-7090-4298-a10f-5392f22073eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-ec2fdc8e-d4ef-46ed-8242-1a679acd0e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-927c7723-f597-4459-bf38-b5f69d9d6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-1ddea6e6-c5a9-44cb-b067-b3462c6aae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495258237-172.17.0.5-1598327142207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43370,DS-89334535-9e60-451c-8ef8-265cfe3cd513,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-38af79b6-a57e-4904-b327-7d6b59f50da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-dbef131c-7839-412b-8b53-3e4561229337,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-71bb1a0d-58ca-4414-af1b-fa7a4515942f,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-5e8848b3-303e-4a76-929e-6774c3901080,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a658a344-c033-4594-ba39-3ffbeeab712b,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-755d50b1-f766-4adc-8ef6-993fc607d274,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9c260657-395d-4a17-9af1-a26535c357fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495258237-172.17.0.5-1598327142207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43370,DS-89334535-9e60-451c-8ef8-265cfe3cd513,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-38af79b6-a57e-4904-b327-7d6b59f50da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-dbef131c-7839-412b-8b53-3e4561229337,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-71bb1a0d-58ca-4414-af1b-fa7a4515942f,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-5e8848b3-303e-4a76-929e-6774c3901080,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a658a344-c033-4594-ba39-3ffbeeab712b,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-755d50b1-f766-4adc-8ef6-993fc607d274,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9c260657-395d-4a17-9af1-a26535c357fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888184688-172.17.0.5-1598327359298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-5004ca4d-0f21-41ff-843b-f5cc6dc4a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-b5e5cc10-226c-4219-9e7a-94eff167814e,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-7afc0caa-be11-4223-bba7-24d94a330a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-939b568b-472b-4c05-b755-f27d6aae69e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-e122315c-ce35-4961-bda4-21d73e147189,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-8d62207f-8db9-4a11-b61b-15ef23a6acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-4c00bfd1-541b-4096-a8c2-68a9832f3133,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-82d37e9c-57ab-4b01-9a1a-2da7ee5876d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888184688-172.17.0.5-1598327359298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-5004ca4d-0f21-41ff-843b-f5cc6dc4a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-b5e5cc10-226c-4219-9e7a-94eff167814e,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-7afc0caa-be11-4223-bba7-24d94a330a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-939b568b-472b-4c05-b755-f27d6aae69e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-e122315c-ce35-4961-bda4-21d73e147189,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-8d62207f-8db9-4a11-b61b-15ef23a6acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-4c00bfd1-541b-4096-a8c2-68a9832f3133,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-82d37e9c-57ab-4b01-9a1a-2da7ee5876d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730174479-172.17.0.5-1598327462655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-6f34a6b4-502b-47bb-bfd5-55639da69d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-e0a08b9b-38d9-491f-95d9-acdc0cfb99c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-272813d9-887a-44f6-8174-e486b7bfbdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-869318fb-885b-40c8-9df3-b40f2c8a0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-03d04ac4-9cfc-4853-9f51-d3c9821572f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-2cc87f09-8640-4745-aa7d-0b663e7b1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-466aa051-d559-403a-9fba-473c139f42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-2e3804c4-341e-4640-b1b9-302d7be2db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730174479-172.17.0.5-1598327462655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-6f34a6b4-502b-47bb-bfd5-55639da69d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-e0a08b9b-38d9-491f-95d9-acdc0cfb99c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-272813d9-887a-44f6-8174-e486b7bfbdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-869318fb-885b-40c8-9df3-b40f2c8a0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-03d04ac4-9cfc-4853-9f51-d3c9821572f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-2cc87f09-8640-4745-aa7d-0b663e7b1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-466aa051-d559-403a-9fba-473c139f42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-2e3804c4-341e-4640-b1b9-302d7be2db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123195096-172.17.0.5-1598327569674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37468,DS-79397a00-f3da-44d6-8fd7-37a98ba21568,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-dc086f4a-1c6a-46a2-83b2-c18b16a4fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-07533b48-b72b-41cf-9cf3-9ab45dd8d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-169088e2-7efd-47df-a957-7e79183d29b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6400f428-491c-4892-bec8-1d0f691ffd43,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-82391f64-bf60-44a1-ad3b-e5ff767f504b,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-da6a74a9-9c0f-4c1f-9a10-5e2d2a58a727,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-723c287d-b77a-4e97-8f54-6d3cb3bb47ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123195096-172.17.0.5-1598327569674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37468,DS-79397a00-f3da-44d6-8fd7-37a98ba21568,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-dc086f4a-1c6a-46a2-83b2-c18b16a4fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-07533b48-b72b-41cf-9cf3-9ab45dd8d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-169088e2-7efd-47df-a957-7e79183d29b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6400f428-491c-4892-bec8-1d0f691ffd43,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-82391f64-bf60-44a1-ad3b-e5ff767f504b,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-da6a74a9-9c0f-4c1f-9a10-5e2d2a58a727,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-723c287d-b77a-4e97-8f54-6d3cb3bb47ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5309
