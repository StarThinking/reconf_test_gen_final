reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625514937-172.17.0.19-1598173738093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-6eeaa9d4-ac9b-4e99-ac6d-71b917b50507,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-ecb7dca5-f83d-4ab8-ba18-59337349fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-fc5463be-2239-46b2-9366-db17d9b72b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a366f492-260d-4978-862e-6f04f796ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-f2f473bc-cf75-44e6-b2e2-316cf0041480,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-1c6aa4f2-e42f-44cb-84d4-460699ee56f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-b2b23d67-83d2-45e3-a65f-5c67b0761dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-a5e37b87-2570-4b93-b318-80f7cdc01c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625514937-172.17.0.19-1598173738093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-6eeaa9d4-ac9b-4e99-ac6d-71b917b50507,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-ecb7dca5-f83d-4ab8-ba18-59337349fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-fc5463be-2239-46b2-9366-db17d9b72b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-a366f492-260d-4978-862e-6f04f796ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-f2f473bc-cf75-44e6-b2e2-316cf0041480,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-1c6aa4f2-e42f-44cb-84d4-460699ee56f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-b2b23d67-83d2-45e3-a65f-5c67b0761dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-a5e37b87-2570-4b93-b318-80f7cdc01c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984434589-172.17.0.19-1598173913824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-d5388236-8b05-43f7-a76f-f0951185268a,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-10a28060-2a8e-4c3f-bbdc-48361cb517aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-2b8570b4-8364-40e3-8822-a0097935426e,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-cbd82766-616b-4663-b4bf-4e3126cb465a,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-ced5add2-a9f9-42e0-b573-4e076e5c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-83f617f1-9a93-42f8-a193-0f899634e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b4651303-520a-4a02-94b3-836de225a4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-0e778a63-7477-409e-b261-713a707c94b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984434589-172.17.0.19-1598173913824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-d5388236-8b05-43f7-a76f-f0951185268a,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-10a28060-2a8e-4c3f-bbdc-48361cb517aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-2b8570b4-8364-40e3-8822-a0097935426e,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-cbd82766-616b-4663-b4bf-4e3126cb465a,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-ced5add2-a9f9-42e0-b573-4e076e5c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-83f617f1-9a93-42f8-a193-0f899634e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b4651303-520a-4a02-94b3-836de225a4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-0e778a63-7477-409e-b261-713a707c94b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527024308-172.17.0.19-1598174851344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-8bdf69e2-0e0d-4657-a4e3-d8aced3fbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-7147acba-4e88-45fe-ae46-255b700512cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-1f234737-4e3f-46a8-98fb-4c2ccca058e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-a8d97a9d-d5f2-4961-92dc-9c6846892567,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-d2e882f3-f6ef-437d-a574-8ce63f5f799d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-3d823e18-88ff-41b0-8bb2-ea5f9053b851,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-4de6dc63-9b73-42a0-b1c4-3c4bc7860486,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8a163990-22ac-4cb4-8781-efafd484753a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527024308-172.17.0.19-1598174851344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-8bdf69e2-0e0d-4657-a4e3-d8aced3fbaad,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-7147acba-4e88-45fe-ae46-255b700512cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-1f234737-4e3f-46a8-98fb-4c2ccca058e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-a8d97a9d-d5f2-4961-92dc-9c6846892567,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-d2e882f3-f6ef-437d-a574-8ce63f5f799d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-3d823e18-88ff-41b0-8bb2-ea5f9053b851,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-4de6dc63-9b73-42a0-b1c4-3c4bc7860486,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8a163990-22ac-4cb4-8781-efafd484753a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703865402-172.17.0.19-1598175169762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-27c35ab5-ad5b-4268-bf7d-9b28cfdb732e,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-b8891ed9-e5ed-45c4-ae23-24f663709631,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-0b66eeb8-9870-41cf-a18e-e6cb1e4cee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-839f2211-ee5a-4774-8b5f-b5b74e49b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-50f8803a-f90a-4761-9615-72019982b084,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-ee81d9c6-f799-47c4-82e9-5cb0b214b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-78067b96-74d9-4881-85de-d70ddef8d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-a3dc0a7c-f66a-41a1-928d-4f9794ef9840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703865402-172.17.0.19-1598175169762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-27c35ab5-ad5b-4268-bf7d-9b28cfdb732e,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-b8891ed9-e5ed-45c4-ae23-24f663709631,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-0b66eeb8-9870-41cf-a18e-e6cb1e4cee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-839f2211-ee5a-4774-8b5f-b5b74e49b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-50f8803a-f90a-4761-9615-72019982b084,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-ee81d9c6-f799-47c4-82e9-5cb0b214b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-78067b96-74d9-4881-85de-d70ddef8d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-a3dc0a7c-f66a-41a1-928d-4f9794ef9840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407205806-172.17.0.19-1598175235817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-5bc882f5-4017-4fc8-b411-b52246bedab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-e06bf41e-619a-4ac2-a488-b0890ff486b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-e79d3079-383b-4826-ae79-3a2e420d3754,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-8b64abb1-f302-4c87-a9ce-7236aa8da459,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-5350ba5a-65e4-491e-b234-cc1bd4e5b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-6377f2c2-1f73-4f9e-b37c-bb8f9311282b,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-51b1f58b-857f-4879-9c31-b51692d94e10,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-eb7c654b-12b3-4372-8834-0290976bc689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407205806-172.17.0.19-1598175235817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-5bc882f5-4017-4fc8-b411-b52246bedab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-e06bf41e-619a-4ac2-a488-b0890ff486b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-e79d3079-383b-4826-ae79-3a2e420d3754,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-8b64abb1-f302-4c87-a9ce-7236aa8da459,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-5350ba5a-65e4-491e-b234-cc1bd4e5b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-6377f2c2-1f73-4f9e-b37c-bb8f9311282b,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-51b1f58b-857f-4879-9c31-b51692d94e10,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-eb7c654b-12b3-4372-8834-0290976bc689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845033689-172.17.0.19-1598175307576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-0e285bee-1c90-42bb-a362-512206e057f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-69db3a5e-3502-4a1a-bf7e-01aab662aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-40d8c105-e9b3-4ac0-ab7a-916564998ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-d02a41d2-71f5-43e4-b13c-a7ad4fefdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-5959d6b2-af55-4e34-bbff-03bb0e54440f,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-ce9fc418-23b8-4e07-b2bd-7556c931d1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-aecd98aa-68a5-410d-9f9f-3e1563abdb15,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-f4fbca0a-a605-46a2-acad-416b75b1b283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845033689-172.17.0.19-1598175307576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36651,DS-0e285bee-1c90-42bb-a362-512206e057f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-69db3a5e-3502-4a1a-bf7e-01aab662aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-40d8c105-e9b3-4ac0-ab7a-916564998ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-d02a41d2-71f5-43e4-b13c-a7ad4fefdd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-5959d6b2-af55-4e34-bbff-03bb0e54440f,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-ce9fc418-23b8-4e07-b2bd-7556c931d1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-aecd98aa-68a5-410d-9f9f-3e1563abdb15,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-f4fbca0a-a605-46a2-acad-416b75b1b283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668788129-172.17.0.19-1598175616182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-540618f3-c7b2-444b-a0f0-42a8fa6013d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-1d8a6f94-2475-4c99-b90e-f0f7549880fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-eb3f84f4-8289-490c-8500-681e40024549,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-51c3f353-139e-4342-bcec-25c128773894,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-a0437b12-6a4f-4e4f-b179-166687132701,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-fc549661-7546-40e4-ade1-585582f930e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-1bbac2d2-e52a-4eaa-8d1b-c65bd6ee4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-48b03dea-fee9-4187-bfaf-9172d70c1193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668788129-172.17.0.19-1598175616182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-540618f3-c7b2-444b-a0f0-42a8fa6013d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-1d8a6f94-2475-4c99-b90e-f0f7549880fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-eb3f84f4-8289-490c-8500-681e40024549,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-51c3f353-139e-4342-bcec-25c128773894,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-a0437b12-6a4f-4e4f-b179-166687132701,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-fc549661-7546-40e4-ade1-585582f930e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-1bbac2d2-e52a-4eaa-8d1b-c65bd6ee4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-48b03dea-fee9-4187-bfaf-9172d70c1193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617821281-172.17.0.19-1598175685807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-18dcb8bc-180a-4eea-9e8a-c6d1c8711ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-50974e09-37bf-4cdd-afdf-88599fd07c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-6e738dea-7dbf-4b92-8e57-547459089e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-4595b49a-077e-42ab-a0d1-9962b9c94d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-47a1829c-78f2-444f-9218-dd95d2fbd8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-e0916b68-17df-43fa-8a13-5bc9f6deb16c,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-8bac828c-0af4-400d-ab29-4e6d12792b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-e89d269c-d233-4654-8ac1-41090ded6a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617821281-172.17.0.19-1598175685807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-18dcb8bc-180a-4eea-9e8a-c6d1c8711ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-50974e09-37bf-4cdd-afdf-88599fd07c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-6e738dea-7dbf-4b92-8e57-547459089e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-4595b49a-077e-42ab-a0d1-9962b9c94d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-47a1829c-78f2-444f-9218-dd95d2fbd8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-e0916b68-17df-43fa-8a13-5bc9f6deb16c,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-8bac828c-0af4-400d-ab29-4e6d12792b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-e89d269c-d233-4654-8ac1-41090ded6a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733655797-172.17.0.19-1598176495329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36728,DS-53ddbb0d-4cb3-4fdc-bc50-0bbd23def1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-be4f293d-476d-4c90-8947-47733e2f40cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-3663df44-ae6a-4251-908f-be00243a0310,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d5fc9652-ee98-413f-8306-79a7cc075d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-a4091787-8949-474d-88fc-3b570f78c801,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-de28e09c-effa-4d9f-b41d-0ca4147269cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cbfa1770-3a21-4335-a2bc-9eb6151f3552,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-3ff34e70-6dcd-417f-8bbb-07f1ffa39fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733655797-172.17.0.19-1598176495329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36728,DS-53ddbb0d-4cb3-4fdc-bc50-0bbd23def1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-be4f293d-476d-4c90-8947-47733e2f40cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-3663df44-ae6a-4251-908f-be00243a0310,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d5fc9652-ee98-413f-8306-79a7cc075d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-a4091787-8949-474d-88fc-3b570f78c801,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-de28e09c-effa-4d9f-b41d-0ca4147269cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cbfa1770-3a21-4335-a2bc-9eb6151f3552,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-3ff34e70-6dcd-417f-8bbb-07f1ffa39fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461191795-172.17.0.19-1598176603981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39711,DS-7213c28d-ff7b-4933-95e4-22e0411b851b,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-9663eb30-a5f7-48a5-819f-b854e3bd97db,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d1af2d8b-8da8-4484-972e-e011be3fafda,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-5f20a8ce-410d-437c-baba-52dd57303713,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-3b153682-7612-4d66-b3e1-a06fb73f85aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-e94009d5-f22b-48bf-bdfd-7132b1a77fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-47931e8e-a0db-45d0-9e3a-24a9e56494da,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-be818546-7558-436d-bd6b-618fe3ee5310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461191795-172.17.0.19-1598176603981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39711,DS-7213c28d-ff7b-4933-95e4-22e0411b851b,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-9663eb30-a5f7-48a5-819f-b854e3bd97db,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-d1af2d8b-8da8-4484-972e-e011be3fafda,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-5f20a8ce-410d-437c-baba-52dd57303713,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-3b153682-7612-4d66-b3e1-a06fb73f85aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-e94009d5-f22b-48bf-bdfd-7132b1a77fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-47931e8e-a0db-45d0-9e3a-24a9e56494da,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-be818546-7558-436d-bd6b-618fe3ee5310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520194854-172.17.0.19-1598177445149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-4d6d9358-51f9-4a1c-874f-c5f566f56e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-ea08e87c-33da-4114-8e5f-4ff07b3dc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-620378d0-be03-4a16-8f88-3fe4d845d428,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-b1814981-48bc-4551-b474-8597908d053d,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-82c3a29c-8f38-4d6b-92fc-de4611c13154,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-5b321168-98a3-4522-91e7-ff6c90b71424,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-eee59895-883d-4fe9-a749-b986bc7b8564,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-6d6a4c9e-548e-4f5e-8478-d9ae22790e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520194854-172.17.0.19-1598177445149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42083,DS-4d6d9358-51f9-4a1c-874f-c5f566f56e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-ea08e87c-33da-4114-8e5f-4ff07b3dc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-620378d0-be03-4a16-8f88-3fe4d845d428,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-b1814981-48bc-4551-b474-8597908d053d,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-82c3a29c-8f38-4d6b-92fc-de4611c13154,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-5b321168-98a3-4522-91e7-ff6c90b71424,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-eee59895-883d-4fe9-a749-b986bc7b8564,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-6d6a4c9e-548e-4f5e-8478-d9ae22790e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388211256-172.17.0.19-1598177715124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-5488abf0-14c9-4e7b-833f-a6f6a94e0786,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5ecb9ed5-8c09-44e8-80d3-7cd7a0536a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-32288aaa-5dc2-4351-9ab9-660ff2fa8b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-82b103f1-a89a-46da-b6a7-399808b2475f,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-28361e55-5f2d-4d89-99f6-b1b635ca899c,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-df98a2cc-be6c-47e2-a2bd-9b17fc97d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cdfecf28-89f4-4bda-84cb-91b3b3839b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-fc0d85d9-ba35-4390-95ab-7553d17b98b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388211256-172.17.0.19-1598177715124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-5488abf0-14c9-4e7b-833f-a6f6a94e0786,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5ecb9ed5-8c09-44e8-80d3-7cd7a0536a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-32288aaa-5dc2-4351-9ab9-660ff2fa8b82,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-82b103f1-a89a-46da-b6a7-399808b2475f,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-28361e55-5f2d-4d89-99f6-b1b635ca899c,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-df98a2cc-be6c-47e2-a2bd-9b17fc97d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cdfecf28-89f4-4bda-84cb-91b3b3839b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-fc0d85d9-ba35-4390-95ab-7553d17b98b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853958128-172.17.0.19-1598178079849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-43de01a1-7a95-4a9c-bf5a-cc7db0caeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-eec636f2-2c26-4cff-ab77-6a85393ae45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-c5eb2b36-5460-4ddd-842f-1ab9e3c608c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-772b4637-49b6-4702-b0f3-4ad7f6f270cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-95e76d25-744d-48e9-a1af-5a3656a8dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-f02d1262-58cc-4ee8-8b44-ce5e923faafe,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-1e65d806-f331-44c8-b993-d4c5e9dac35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-a727e960-d05c-4dcb-add6-5b6dbd1e830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853958128-172.17.0.19-1598178079849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-43de01a1-7a95-4a9c-bf5a-cc7db0caeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-eec636f2-2c26-4cff-ab77-6a85393ae45b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-c5eb2b36-5460-4ddd-842f-1ab9e3c608c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-772b4637-49b6-4702-b0f3-4ad7f6f270cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-95e76d25-744d-48e9-a1af-5a3656a8dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-f02d1262-58cc-4ee8-8b44-ce5e923faafe,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-1e65d806-f331-44c8-b993-d4c5e9dac35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-a727e960-d05c-4dcb-add6-5b6dbd1e830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5067
