reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-45f9eb75-2e41-4c65-b47a-af3e99d87278,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-21d7c9e3-ec53-4531-af3c-7068962abfae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-45f9eb75-2e41-4c65-b47a-af3e99d87278,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-21d7c9e3-ec53-4531-af3c-7068962abfae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-45f9eb75-2e41-4c65-b47a-af3e99d87278,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-21d7c9e3-ec53-4531-af3c-7068962abfae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-45f9eb75-2e41-4c65-b47a-af3e99d87278,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-21d7c9e3-ec53-4531-af3c-7068962abfae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-4f977e3e-a508-4978-8cdc-506ce0b6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-4d71b941-baaf-4f00-b238-cc99e7b1e213,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-4f977e3e-a508-4978-8cdc-506ce0b6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-4d71b941-baaf-4f00-b238-cc99e7b1e213,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-4f977e3e-a508-4978-8cdc-506ce0b6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-4d71b941-baaf-4f00-b238-cc99e7b1e213,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-4f977e3e-a508-4978-8cdc-506ce0b6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-4d71b941-baaf-4f00-b238-cc99e7b1e213,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-a38a6966-1ff8-4fa6-ac03-ee3528b9519c,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7b0aed41-8431-44f0-a915-6f24baa38a2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-a38a6966-1ff8-4fa6-ac03-ee3528b9519c,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7b0aed41-8431-44f0-a915-6f24baa38a2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-a38a6966-1ff8-4fa6-ac03-ee3528b9519c,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7b0aed41-8431-44f0-a915-6f24baa38a2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-a38a6966-1ff8-4fa6-ac03-ee3528b9519c,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7b0aed41-8431-44f0-a915-6f24baa38a2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-92e2d35f-2844-4938-a135-4a59c3d7e513,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-43297c75-12f0-49da-bc2e-0c10d2c19397,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-92e2d35f-2844-4938-a135-4a59c3d7e513,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-43297c75-12f0-49da-bc2e-0c10d2c19397,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-92e2d35f-2844-4938-a135-4a59c3d7e513,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-43297c75-12f0-49da-bc2e-0c10d2c19397,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38763,DS-92e2d35f-2844-4938-a135-4a59c3d7e513,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-43297c75-12f0-49da-bc2e-0c10d2c19397,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-f22b834e-c2e4-4a97-b643-f13f09fe170c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-29f9bf7b-bdbb-4557-a359-c456a1e8282b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-f22b834e-c2e4-4a97-b643-f13f09fe170c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-29f9bf7b-bdbb-4557-a359-c456a1e8282b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-f22b834e-c2e4-4a97-b643-f13f09fe170c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-29f9bf7b-bdbb-4557-a359-c456a1e8282b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-f22b834e-c2e4-4a97-b643-f13f09fe170c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-29f9bf7b-bdbb-4557-a359-c456a1e8282b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-8385cc65-3ce9-47cd-a883-5cb1e6a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-316d3e7e-5654-4e21-b122-b32699a9219a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-8385cc65-3ce9-47cd-a883-5cb1e6a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-316d3e7e-5654-4e21-b122-b32699a9219a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-8385cc65-3ce9-47cd-a883-5cb1e6a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-316d3e7e-5654-4e21-b122-b32699a9219a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-8385cc65-3ce9-47cd-a883-5cb1e6a41156,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-316d3e7e-5654-4e21-b122-b32699a9219a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-786c7359-c086-47b7-9b49-ae5766436e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-1c2a3938-5448-4838-8ebf-938e6ca1e0cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-786c7359-c086-47b7-9b49-ae5766436e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-1c2a3938-5448-4838-8ebf-938e6ca1e0cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-786c7359-c086-47b7-9b49-ae5766436e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-1c2a3938-5448-4838-8ebf-938e6ca1e0cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-786c7359-c086-47b7-9b49-ae5766436e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-1c2a3938-5448-4838-8ebf-938e6ca1e0cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-c6f5e90a-4920-4d8a-858a-5b2760fa96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-444e84bd-4a36-4d47-ad90-8f254fec280d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-c6f5e90a-4920-4d8a-858a-5b2760fa96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-444e84bd-4a36-4d47-ad90-8f254fec280d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-c6f5e90a-4920-4d8a-858a-5b2760fa96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-444e84bd-4a36-4d47-ad90-8f254fec280d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38162,DS-c6f5e90a-4920-4d8a-858a-5b2760fa96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-444e84bd-4a36-4d47-ad90-8f254fec280d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34362,DS-e04b065d-d29a-4025-9b32-220644c10b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-891c3371-222c-4983-9266-c384edd31a3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-891c3371-222c-4983-9266-c384edd31a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-e04b065d-d29a-4025-9b32-220644c10b6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34362,DS-e04b065d-d29a-4025-9b32-220644c10b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-891c3371-222c-4983-9266-c384edd31a3d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-891c3371-222c-4983-9266-c384edd31a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-e04b065d-d29a-4025-9b32-220644c10b6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-a76b290e-634b-41de-a971-d52661dc1429,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e01dab95-5825-4096-948b-698954fdeef0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-a76b290e-634b-41de-a971-d52661dc1429,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e01dab95-5825-4096-948b-698954fdeef0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-a76b290e-634b-41de-a971-d52661dc1429,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e01dab95-5825-4096-948b-698954fdeef0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-a76b290e-634b-41de-a971-d52661dc1429,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e01dab95-5825-4096-948b-698954fdeef0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 669
