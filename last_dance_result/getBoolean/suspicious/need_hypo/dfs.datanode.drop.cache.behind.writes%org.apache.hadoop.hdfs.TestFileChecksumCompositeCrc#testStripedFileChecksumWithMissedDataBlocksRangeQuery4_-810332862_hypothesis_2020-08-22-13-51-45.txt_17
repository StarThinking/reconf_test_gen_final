reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123549924-172.17.0.2-1598104317642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38913,DS-ec4de8f2-59b2-493d-9731-acbd912603f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-78823168-d900-49d7-af1c-d47592f97466,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ea02ed85-6b8a-4aa8-920e-0855addc12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-c208e318-de89-402f-96bd-7506dc73d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-de3e1ac8-2f04-477b-bf05-abe6a8e09548,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-57d08386-2496-49e2-9036-53eae62cdbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-810de687-bed3-4c86-9c8c-842a3798cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-945ddc4f-5d30-4294-b2e8-08f7fc550836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123549924-172.17.0.2-1598104317642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38913,DS-ec4de8f2-59b2-493d-9731-acbd912603f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-78823168-d900-49d7-af1c-d47592f97466,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ea02ed85-6b8a-4aa8-920e-0855addc12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-c208e318-de89-402f-96bd-7506dc73d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-de3e1ac8-2f04-477b-bf05-abe6a8e09548,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-57d08386-2496-49e2-9036-53eae62cdbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-810de687-bed3-4c86-9c8c-842a3798cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-945ddc4f-5d30-4294-b2e8-08f7fc550836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453225302-172.17.0.2-1598104477558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-9b792e03-8380-4d4f-bc05-5b881ebf3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-bfb11b31-81b6-4c55-88b7-1a62ed878b31,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-1801eb3d-3cb6-4e47-a9fd-3b8da9fb4783,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-845c0eb3-fc92-4265-b5ac-1e3673f901ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2ebca279-bc27-47e7-a891-f3b27e01e314,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-e47e637f-00a3-416d-bed3-a8408cfbcc19,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-2634592c-5686-4097-bd2c-1f81707c5588,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-dc1f984e-59a6-4bf9-92f9-bc154ac037a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453225302-172.17.0.2-1598104477558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-9b792e03-8380-4d4f-bc05-5b881ebf3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-bfb11b31-81b6-4c55-88b7-1a62ed878b31,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-1801eb3d-3cb6-4e47-a9fd-3b8da9fb4783,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-845c0eb3-fc92-4265-b5ac-1e3673f901ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2ebca279-bc27-47e7-a891-f3b27e01e314,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-e47e637f-00a3-416d-bed3-a8408cfbcc19,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-2634592c-5686-4097-bd2c-1f81707c5588,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-dc1f984e-59a6-4bf9-92f9-bc154ac037a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435885068-172.17.0.2-1598104662308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-41a352e6-4ab7-4edd-887a-d6c5200b6f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-0b5078bf-f493-49a1-915b-30ac39e6d067,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-023303cf-07e2-4fc1-bff5-abf57bf7cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-0a63ffae-3e9e-4a57-863e-eff3020be2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-f33f69e7-3a6f-48a3-89d8-b11f81bdbb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-01cec497-83da-404b-9a54-8d5aed5ef158,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-3cde566f-b399-4bad-abf7-6efe62eb1e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e1628e8e-f30a-4bbd-8566-511a9045ea7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435885068-172.17.0.2-1598104662308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-41a352e6-4ab7-4edd-887a-d6c5200b6f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-0b5078bf-f493-49a1-915b-30ac39e6d067,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-023303cf-07e2-4fc1-bff5-abf57bf7cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-0a63ffae-3e9e-4a57-863e-eff3020be2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-f33f69e7-3a6f-48a3-89d8-b11f81bdbb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-01cec497-83da-404b-9a54-8d5aed5ef158,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-3cde566f-b399-4bad-abf7-6efe62eb1e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e1628e8e-f30a-4bbd-8566-511a9045ea7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642630080-172.17.0.2-1598104708360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-12a9d5ce-e26c-4ec0-9511-bad65a669987,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-6b3d22c9-a312-4d25-99f4-f0d615f42da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-b2d5ad03-7327-456f-84a6-d5de2f3089e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-a0e45e48-821d-40ed-b88a-8db5e8a36a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-1ab94d76-579d-4308-97b0-03eb720b8800,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-f0e022da-08ae-4148-ab04-58b1cc024b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-abca54d5-3251-467d-a572-1b71389451f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-45677087-a1da-4a34-89a6-e9e8fe3216d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642630080-172.17.0.2-1598104708360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-12a9d5ce-e26c-4ec0-9511-bad65a669987,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-6b3d22c9-a312-4d25-99f4-f0d615f42da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-b2d5ad03-7327-456f-84a6-d5de2f3089e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-a0e45e48-821d-40ed-b88a-8db5e8a36a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-1ab94d76-579d-4308-97b0-03eb720b8800,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-f0e022da-08ae-4148-ab04-58b1cc024b43,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-abca54d5-3251-467d-a572-1b71389451f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-45677087-a1da-4a34-89a6-e9e8fe3216d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842324340-172.17.0.2-1598104774448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-0ee88447-42fa-4e83-9e13-c68ba3a7a954,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-aaf9765c-9d38-4103-944e-e09f537670ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-78679f07-683e-42cb-a342-d6e07d1703b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-26cf26bc-d9bd-4d29-95c8-ebbcc6bb968f,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-72a13027-0e7e-48eb-8b88-ee1653898529,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-07037ebb-6bd0-468d-8754-0262e3dabbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-8d82a50d-8ce9-4694-bb0c-7888a794b36f,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-d62058b6-3649-44f8-bee1-41e5afe54072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842324340-172.17.0.2-1598104774448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-0ee88447-42fa-4e83-9e13-c68ba3a7a954,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-aaf9765c-9d38-4103-944e-e09f537670ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-78679f07-683e-42cb-a342-d6e07d1703b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-26cf26bc-d9bd-4d29-95c8-ebbcc6bb968f,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-72a13027-0e7e-48eb-8b88-ee1653898529,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-07037ebb-6bd0-468d-8754-0262e3dabbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-8d82a50d-8ce9-4694-bb0c-7888a794b36f,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-d62058b6-3649-44f8-bee1-41e5afe54072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086035851-172.17.0.2-1598106021069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-0814b4a0-f0d5-4a77-aba7-d913e681448b,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-c5aa957e-8b34-4bd9-a1f2-50df10c4ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2f15f31c-02b5-402d-ae1c-d4b3aa5c46c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-3f8e6d83-9ecf-4c16-846e-8e5cbb8961c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5843cf31-82f1-4ca1-9487-b4bd79f401c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-7e0ba9e8-088e-4c22-8f7e-2cb8d43d8125,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-f03f6dd8-6244-4c8a-99b4-3ceb2bc9522a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-41017c66-2ee0-42e7-9e27-24547b4f80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086035851-172.17.0.2-1598106021069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-0814b4a0-f0d5-4a77-aba7-d913e681448b,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-c5aa957e-8b34-4bd9-a1f2-50df10c4ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-2f15f31c-02b5-402d-ae1c-d4b3aa5c46c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-3f8e6d83-9ecf-4c16-846e-8e5cbb8961c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5843cf31-82f1-4ca1-9487-b4bd79f401c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-7e0ba9e8-088e-4c22-8f7e-2cb8d43d8125,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-f03f6dd8-6244-4c8a-99b4-3ceb2bc9522a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-41017c66-2ee0-42e7-9e27-24547b4f80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147170376-172.17.0.2-1598106302850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-31b10ad8-9477-4889-9adf-c441bd21e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-dc0e884b-0636-4520-9fb9-077935103375,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fcf5e9f8-0ee8-4fc9-a584-a3c55f8f37da,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-63d216e1-4ff4-44c7-9804-9ad25b3a5c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-4967b146-3b68-4d0a-bc59-7ea4963507f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-52139b55-619d-4647-9d31-fde66767a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-e9fdb674-b965-47bc-81a1-e297314df6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-dd7d33cc-a157-491a-83ec-691f4974eb19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147170376-172.17.0.2-1598106302850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-31b10ad8-9477-4889-9adf-c441bd21e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-dc0e884b-0636-4520-9fb9-077935103375,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-fcf5e9f8-0ee8-4fc9-a584-a3c55f8f37da,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-63d216e1-4ff4-44c7-9804-9ad25b3a5c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-4967b146-3b68-4d0a-bc59-7ea4963507f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-52139b55-619d-4647-9d31-fde66767a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-e9fdb674-b965-47bc-81a1-e297314df6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-dd7d33cc-a157-491a-83ec-691f4974eb19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503951271-172.17.0.2-1598106416914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-ea95bc3b-8e44-4eb9-8b9e-22f216acc12c,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-aff0ddda-dd9c-4c8b-9ab0-cd6638b1a073,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-188c7989-d677-4f8e-9fa9-2af7c2457028,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-77a79d58-5a3d-4b32-a7cc-7cea51f383f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-ee1da303-8bc4-44dc-be5d-a16c44045edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-cda1a839-9941-4b2c-bcd0-0416d4b64854,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-021aea7b-864d-4f4a-9d49-2cfc86cfd903,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-61d3e464-2a82-48b0-9067-8eaf7c7b767f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503951271-172.17.0.2-1598106416914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-ea95bc3b-8e44-4eb9-8b9e-22f216acc12c,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-aff0ddda-dd9c-4c8b-9ab0-cd6638b1a073,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-188c7989-d677-4f8e-9fa9-2af7c2457028,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-77a79d58-5a3d-4b32-a7cc-7cea51f383f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-ee1da303-8bc4-44dc-be5d-a16c44045edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-cda1a839-9941-4b2c-bcd0-0416d4b64854,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-021aea7b-864d-4f4a-9d49-2cfc86cfd903,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-61d3e464-2a82-48b0-9067-8eaf7c7b767f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369592951-172.17.0.2-1598106678450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-a9603c82-19c4-470f-8d1e-e6bf0a5b1cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a6841f70-babe-4820-b7ef-5c686da128ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c50f0d88-bee0-49ab-abb3-17abbeac0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-53665fc4-266e-4a4b-bdd5-74153993c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-cbfe01d4-00b4-4e58-9234-fe32797ccd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-2af2453f-a908-419e-878e-6d749866df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-4971e056-a4b5-40c5-a85a-4b17b638d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-c7d66c47-7061-49aa-bd89-7d9c75ec4520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369592951-172.17.0.2-1598106678450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-a9603c82-19c4-470f-8d1e-e6bf0a5b1cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a6841f70-babe-4820-b7ef-5c686da128ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c50f0d88-bee0-49ab-abb3-17abbeac0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-53665fc4-266e-4a4b-bdd5-74153993c7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-cbfe01d4-00b4-4e58-9234-fe32797ccd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-2af2453f-a908-419e-878e-6d749866df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-4971e056-a4b5-40c5-a85a-4b17b638d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-c7d66c47-7061-49aa-bd89-7d9c75ec4520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989696172-172.17.0.2-1598106702691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-aa30f5a7-d61d-47d5-b5e3-4ed2a173bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-837a9bce-5356-4572-b619-33fea2f4621c,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-bf8ec1f8-f08f-4f35-8c0b-eac81a0ef5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-47403b65-5573-4cb8-a768-efac361afd23,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-7c4faa89-b4dd-490b-9e93-fbe868725e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-52e9afad-47ae-4ffe-98b3-e5c5f96dca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-43e8a565-f124-4198-8fd0-5eced79c4abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-91f9e774-dd1f-4aee-9025-ab41fe80e610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989696172-172.17.0.2-1598106702691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-aa30f5a7-d61d-47d5-b5e3-4ed2a173bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-837a9bce-5356-4572-b619-33fea2f4621c,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-bf8ec1f8-f08f-4f35-8c0b-eac81a0ef5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-47403b65-5573-4cb8-a768-efac361afd23,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-7c4faa89-b4dd-490b-9e93-fbe868725e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-52e9afad-47ae-4ffe-98b3-e5c5f96dca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-43e8a565-f124-4198-8fd0-5eced79c4abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-91f9e774-dd1f-4aee-9025-ab41fe80e610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291781780-172.17.0.2-1598106774726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-36de29d7-ad8f-46da-8b5f-8c0708399a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-61a26b37-3155-424a-8de3-c36fc0e67a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-025744c7-0a10-4d1e-964c-83d405d77149,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-1d6afa33-4b22-49ea-af96-229393b3c174,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-6a19b12b-a23d-4d18-bdfb-95b92ca3e819,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-bd1c713b-0a74-4c7b-b5a1-56ffb6f14f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a746d02f-e39e-4c4e-b7af-ea049ba9bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-f4b36871-53b5-4c08-a2ad-93ff5c159bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291781780-172.17.0.2-1598106774726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-36de29d7-ad8f-46da-8b5f-8c0708399a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-61a26b37-3155-424a-8de3-c36fc0e67a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-025744c7-0a10-4d1e-964c-83d405d77149,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-1d6afa33-4b22-49ea-af96-229393b3c174,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-6a19b12b-a23d-4d18-bdfb-95b92ca3e819,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-bd1c713b-0a74-4c7b-b5a1-56ffb6f14f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a746d02f-e39e-4c4e-b7af-ea049ba9bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-f4b36871-53b5-4c08-a2ad-93ff5c159bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847859759-172.17.0.2-1598106883196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-1be1e4db-40fd-424c-afff-b26dcf0206ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-b8524ec3-0a5f-496f-b08b-a14ee0ae32af,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-071fe74f-eb0e-4c04-98ed-bb7788205ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-d3130a22-e31f-4f99-807d-d222b23b7e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-2bd250f7-8049-4fad-8a90-2b74f905dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-000b5f0e-4f4b-4c80-9aed-133fe5a08a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-664066fe-7b13-4d48-a546-2802e822b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-9d3fa24a-6703-4481-a597-9b93cec24f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847859759-172.17.0.2-1598106883196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-1be1e4db-40fd-424c-afff-b26dcf0206ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-b8524ec3-0a5f-496f-b08b-a14ee0ae32af,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-071fe74f-eb0e-4c04-98ed-bb7788205ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-d3130a22-e31f-4f99-807d-d222b23b7e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-2bd250f7-8049-4fad-8a90-2b74f905dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-000b5f0e-4f4b-4c80-9aed-133fe5a08a58,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-664066fe-7b13-4d48-a546-2802e822b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-9d3fa24a-6703-4481-a597-9b93cec24f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816621922-172.17.0.2-1598106909757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-90a85037-ea69-41f0-beab-414c8f7e8690,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-9d1fddbb-6ed4-4e42-833f-7051383b3561,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-29a5240b-f132-4798-a4be-b34767cd4650,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-ee3392b2-898d-46c8-97bd-bf9289564476,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-db403b33-d42e-4760-bec8-bc85d33e3d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2a99030a-5bde-4fa3-a130-2920d0be6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-c2df8e9e-92de-4ee5-92a7-25680045c336,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-bd52d1fe-d0f0-4d9c-9a10-f995e6d1058e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816621922-172.17.0.2-1598106909757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-90a85037-ea69-41f0-beab-414c8f7e8690,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-9d1fddbb-6ed4-4e42-833f-7051383b3561,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-29a5240b-f132-4798-a4be-b34767cd4650,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-ee3392b2-898d-46c8-97bd-bf9289564476,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-db403b33-d42e-4760-bec8-bc85d33e3d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2a99030a-5bde-4fa3-a130-2920d0be6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-c2df8e9e-92de-4ee5-92a7-25680045c336,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-bd52d1fe-d0f0-4d9c-9a10-f995e6d1058e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795277170-172.17.0.2-1598107500170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-85c98c4d-8bf6-4f03-bfcd-78d401137365,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-1aa6a5d5-b3b6-42c2-ad1c-4b3fa9d77237,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-84c6f124-c9aa-41f8-8bc1-1644bb92b950,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e997d66c-3e51-4339-a617-7890b3aece88,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-f2436c70-7650-4480-8971-43b6346c4686,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-cb7ca536-3ba7-46ad-8a66-865dcecef13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-05e1fdb7-cc08-4453-98dc-d5b1b9c311a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-555a774b-5bf6-41bb-bb45-ad6cfb060962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795277170-172.17.0.2-1598107500170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-85c98c4d-8bf6-4f03-bfcd-78d401137365,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-1aa6a5d5-b3b6-42c2-ad1c-4b3fa9d77237,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-84c6f124-c9aa-41f8-8bc1-1644bb92b950,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e997d66c-3e51-4339-a617-7890b3aece88,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-f2436c70-7650-4480-8971-43b6346c4686,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-cb7ca536-3ba7-46ad-8a66-865dcecef13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-05e1fdb7-cc08-4453-98dc-d5b1b9c311a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-555a774b-5bf6-41bb-bb45-ad6cfb060962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631999669-172.17.0.2-1598107688416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-7f67eb40-9db9-4125-96ad-60d019c16778,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-3b84cd57-85d0-4fb5-b4ba-efd900ada1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-3c6766e4-c76f-43f4-8b6c-cdcc316fa853,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-2060ec0a-99f2-485a-a4f0-dc4e06f70c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2d1cceec-4305-409f-94dc-185abe7ca5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-7aa3f4b5-1e12-49de-bf8e-be02c6b97996,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-17c4d0f8-8270-47d8-b2e3-cf8d7d3fdde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-929c8940-322e-4922-b352-dd40caf7c4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631999669-172.17.0.2-1598107688416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43368,DS-7f67eb40-9db9-4125-96ad-60d019c16778,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-3b84cd57-85d0-4fb5-b4ba-efd900ada1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-3c6766e4-c76f-43f4-8b6c-cdcc316fa853,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-2060ec0a-99f2-485a-a4f0-dc4e06f70c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2d1cceec-4305-409f-94dc-185abe7ca5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-7aa3f4b5-1e12-49de-bf8e-be02c6b97996,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-17c4d0f8-8270-47d8-b2e3-cf8d7d3fdde7,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-929c8940-322e-4922-b352-dd40caf7c4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865832083-172.17.0.2-1598107852546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-b77d547f-e4bc-4dea-8469-c16a6f6a9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-31086ac0-178f-47e5-93f7-0e6a0c7c657c,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-1bdcdc34-f575-457a-9063-6e6a8bfb3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-4cf3cbe0-4447-44ee-9fd8-1270c06781bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-4badaf1f-9403-4452-9aa1-941bb31bf010,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-99ceda3d-c155-4fbe-a2da-91f5ab57b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-ca263784-315d-4d3a-bff7-ec2496a0f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-4e10a009-68ce-4482-89c4-544d5c9bb2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865832083-172.17.0.2-1598107852546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-b77d547f-e4bc-4dea-8469-c16a6f6a9be6,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-31086ac0-178f-47e5-93f7-0e6a0c7c657c,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-1bdcdc34-f575-457a-9063-6e6a8bfb3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-4cf3cbe0-4447-44ee-9fd8-1270c06781bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-4badaf1f-9403-4452-9aa1-941bb31bf010,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-99ceda3d-c155-4fbe-a2da-91f5ab57b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-ca263784-315d-4d3a-bff7-ec2496a0f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-4e10a009-68ce-4482-89c4-544d5c9bb2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645734494-172.17.0.2-1598108197515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-38b8618b-3780-4828-8a95-fe5b7f756e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-30924124-502f-4d8c-8705-c21a1cc8d244,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-fc06dfff-ec59-4c6b-8567-c454b2f44759,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-0aeb2b2b-a99c-47dc-a5be-bb6359a9c9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-fef6c3c1-714e-44ea-a310-2300d821d333,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-dcce9110-9277-46e7-8ae3-37fab531cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0f638686-846a-4d7e-a92e-2714e58f3d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-b6903ddd-b327-4eff-8940-555b9a8c266d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645734494-172.17.0.2-1598108197515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-38b8618b-3780-4828-8a95-fe5b7f756e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-30924124-502f-4d8c-8705-c21a1cc8d244,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-fc06dfff-ec59-4c6b-8567-c454b2f44759,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-0aeb2b2b-a99c-47dc-a5be-bb6359a9c9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-fef6c3c1-714e-44ea-a310-2300d821d333,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-dcce9110-9277-46e7-8ae3-37fab531cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-0f638686-846a-4d7e-a92e-2714e58f3d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-b6903ddd-b327-4eff-8940-555b9a8c266d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621248781-172.17.0.2-1598108634450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-d7548ee7-ca29-4a84-b3a4-9cd8329dde93,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-923545cd-a31f-43d2-b07b-b505d4573ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-51bb05b2-2046-482b-bbf1-31019105f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-4f1c8470-1ecd-42cc-b54b-c8f5c46737ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-adccee52-cba3-4dfe-95ff-ec681003ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-42c9278f-9cd0-4bd3-9fe1-8f4544122b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ac6365c1-1531-49f3-9668-623186c10091,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-763f786b-3164-4519-a02d-c2ae19a150e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621248781-172.17.0.2-1598108634450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-d7548ee7-ca29-4a84-b3a4-9cd8329dde93,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-923545cd-a31f-43d2-b07b-b505d4573ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-51bb05b2-2046-482b-bbf1-31019105f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-4f1c8470-1ecd-42cc-b54b-c8f5c46737ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-adccee52-cba3-4dfe-95ff-ec681003ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-42c9278f-9cd0-4bd3-9fe1-8f4544122b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ac6365c1-1531-49f3-9668-623186c10091,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-763f786b-3164-4519-a02d-c2ae19a150e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706114077-172.17.0.2-1598108810943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39386,DS-417310cd-6cf4-43be-b7b3-424f754f8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f97637cd-8ae1-44e8-b7d6-624405698253,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-346de77c-ab07-48f4-a328-e3d5c6a37ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-cac71f25-5ec1-468e-b712-6339d732587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-b23c5986-bb39-4ed8-9869-2a04cbc8f200,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-6439ef42-1ef6-4f8d-9c32-006705177e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-17c9eeb9-253e-4232-9528-389c473f6203,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0979f0f-8b1d-479b-b630-f9b121de930c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706114077-172.17.0.2-1598108810943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39386,DS-417310cd-6cf4-43be-b7b3-424f754f8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-f97637cd-8ae1-44e8-b7d6-624405698253,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-346de77c-ab07-48f4-a328-e3d5c6a37ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-cac71f25-5ec1-468e-b712-6339d732587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-b23c5986-bb39-4ed8-9869-2a04cbc8f200,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-6439ef42-1ef6-4f8d-9c32-006705177e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-17c9eeb9-253e-4232-9528-389c473f6203,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-e0979f0f-8b1d-479b-b630-f9b121de930c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619316586-172.17.0.2-1598109070107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-04f5e889-0c97-4620-bb65-f461c00a65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f1e0704c-7f1b-4142-b46b-28e34ea5f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-9d1583f3-2faf-4860-ab68-26d845e649ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-e9891df9-ad53-42b4-a86c-bef1df2b2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-80298a22-5981-401f-b608-a78c4efebd51,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-72af7ab4-5ba5-427f-8f1c-f4af738de3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ab9cb5fc-0050-4338-9830-4ac5e3fb4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-a640f1a9-ccb3-4d93-85ad-51e4dd0ab904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619316586-172.17.0.2-1598109070107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-04f5e889-0c97-4620-bb65-f461c00a65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-f1e0704c-7f1b-4142-b46b-28e34ea5f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-9d1583f3-2faf-4860-ab68-26d845e649ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-e9891df9-ad53-42b4-a86c-bef1df2b2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-80298a22-5981-401f-b608-a78c4efebd51,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-72af7ab4-5ba5-427f-8f1c-f4af738de3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-ab9cb5fc-0050-4338-9830-4ac5e3fb4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-a640f1a9-ccb3-4d93-85ad-51e4dd0ab904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689726625-172.17.0.2-1598109720812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-156325bb-c1c6-4856-8819-afb437cc9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-35692d5a-23eb-475a-9cc5-fa98dc0ea1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-943c04e6-039a-438f-a4d5-dca819bb88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-31d007d2-981a-4f59-89f9-b4f042ecd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-d0d6d9db-cb64-4c51-9318-e92a7229e342,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-89dab592-279c-431f-850a-425471cdc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-6a944aca-6685-41d9-b90d-5ce9e7c4da5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-ca9d5431-fb5a-457a-88e6-5c32b19bdc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689726625-172.17.0.2-1598109720812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-156325bb-c1c6-4856-8819-afb437cc9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-35692d5a-23eb-475a-9cc5-fa98dc0ea1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-943c04e6-039a-438f-a4d5-dca819bb88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-31d007d2-981a-4f59-89f9-b4f042ecd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-d0d6d9db-cb64-4c51-9318-e92a7229e342,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-89dab592-279c-431f-850a-425471cdc288,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-6a944aca-6685-41d9-b90d-5ce9e7c4da5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-ca9d5431-fb5a-457a-88e6-5c32b19bdc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386292722-172.17.0.2-1598109834766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40482,DS-2b23123e-5919-4be8-9449-478082f08a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-65fe91df-97d7-4303-bfa9-3ee32c740729,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e6f0a5c9-1451-46e1-aac0-f8bdeed5132a,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-6c4fd1c8-65bc-4b89-a9fc-478ffabf8ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-28b00fe1-a2ff-4cd6-9834-169f8362434f,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-f9dc50e5-2d0a-4809-931f-94c89252dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-d8e765d9-9df1-4941-a056-7c5d54e5965a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-9d34e127-0f49-4dea-b0a7-1538dd7bd86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386292722-172.17.0.2-1598109834766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40482,DS-2b23123e-5919-4be8-9449-478082f08a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-65fe91df-97d7-4303-bfa9-3ee32c740729,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e6f0a5c9-1451-46e1-aac0-f8bdeed5132a,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-6c4fd1c8-65bc-4b89-a9fc-478ffabf8ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-28b00fe1-a2ff-4cd6-9834-169f8362434f,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-f9dc50e5-2d0a-4809-931f-94c89252dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-d8e765d9-9df1-4941-a056-7c5d54e5965a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-9d34e127-0f49-4dea-b0a7-1538dd7bd86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5622
