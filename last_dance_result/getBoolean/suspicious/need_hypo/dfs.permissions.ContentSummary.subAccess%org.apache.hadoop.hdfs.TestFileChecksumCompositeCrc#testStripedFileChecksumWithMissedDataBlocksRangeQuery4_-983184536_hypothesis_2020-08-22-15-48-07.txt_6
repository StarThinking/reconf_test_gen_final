reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374893098-172.17.0.20-1598111661384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-ad4b0fb4-8fef-45f1-bf0b-69f6923b8938,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-47c8c254-cf0c-4014-9d37-5751c6de6918,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-6f31157f-d568-472c-bfcd-5880bd54c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-a85e0b7e-81ca-4bcc-b3ab-3e79e147f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-486692b4-e913-4abd-b7a4-f3e7377dfb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-1ed4d032-a751-4506-98c1-ca0c0199e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-bd3389b8-019c-4413-987d-7cad72727d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-955d6fa5-dae9-4581-af60-7fdde0af1cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374893098-172.17.0.20-1598111661384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-ad4b0fb4-8fef-45f1-bf0b-69f6923b8938,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-47c8c254-cf0c-4014-9d37-5751c6de6918,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-6f31157f-d568-472c-bfcd-5880bd54c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-a85e0b7e-81ca-4bcc-b3ab-3e79e147f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-486692b4-e913-4abd-b7a4-f3e7377dfb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-1ed4d032-a751-4506-98c1-ca0c0199e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-bd3389b8-019c-4413-987d-7cad72727d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-955d6fa5-dae9-4581-af60-7fdde0af1cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482240212-172.17.0.20-1598111810298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-d6d8fe04-97dc-429c-b22c-dee5dfc7cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-b12774ff-5069-4e2a-87ff-2d7cbd447278,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-34709fc0-61a1-4e99-8925-dc487b82323a,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-433e3665-47cd-4c71-8f69-070f293a27bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-374f843d-e753-434e-91b6-a30cbbec7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-3aa66d87-250a-414c-b1a6-57c4644e9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-bd0a5256-ea87-4939-b3ba-4683c0a55139,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-7bb02fab-caa7-4ed8-afcb-ea4499b37c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482240212-172.17.0.20-1598111810298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-d6d8fe04-97dc-429c-b22c-dee5dfc7cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-b12774ff-5069-4e2a-87ff-2d7cbd447278,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-34709fc0-61a1-4e99-8925-dc487b82323a,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-433e3665-47cd-4c71-8f69-070f293a27bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-374f843d-e753-434e-91b6-a30cbbec7fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-3aa66d87-250a-414c-b1a6-57c4644e9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-bd0a5256-ea87-4939-b3ba-4683c0a55139,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-7bb02fab-caa7-4ed8-afcb-ea4499b37c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630850644-172.17.0.20-1598111967282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-ba7476e7-be13-4b0c-a3e5-667a57579803,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-7addd2ab-2871-4a8c-83d9-0bd954ac13da,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-42972dec-54d2-4a77-9dad-ca516dba0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-42baf115-ec12-4087-a2e5-89996366f4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-011ff249-cf5d-41a9-b5af-ad011f1fe0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-03f5f11b-1452-499c-9b77-39845f8f9989,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-cab7a079-2362-4889-9350-b70987c96ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-4b3a3693-987f-40b7-990c-53ad42948d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630850644-172.17.0.20-1598111967282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-ba7476e7-be13-4b0c-a3e5-667a57579803,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-7addd2ab-2871-4a8c-83d9-0bd954ac13da,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-42972dec-54d2-4a77-9dad-ca516dba0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-42baf115-ec12-4087-a2e5-89996366f4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-011ff249-cf5d-41a9-b5af-ad011f1fe0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-03f5f11b-1452-499c-9b77-39845f8f9989,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-cab7a079-2362-4889-9350-b70987c96ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-4b3a3693-987f-40b7-990c-53ad42948d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942332889-172.17.0.20-1598112077478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-1d744e93-e84d-4247-94fb-c1ec99ac6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-e5f2074c-889c-440b-afbe-d136454409f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-6edfcf2a-6f70-41fe-8909-d58717b17144,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-f9d1509d-6216-4bd2-8382-e4d92345ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-fc4eff89-7620-4679-bfa4-6c60e3d4e757,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-435d9992-4007-4ab4-8d91-ccd9debf4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-dd73dbde-2bf3-47fa-b829-3885d74e4f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-3342a88c-64a5-49a9-9c2f-15fa3234dc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942332889-172.17.0.20-1598112077478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-1d744e93-e84d-4247-94fb-c1ec99ac6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-e5f2074c-889c-440b-afbe-d136454409f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-6edfcf2a-6f70-41fe-8909-d58717b17144,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-f9d1509d-6216-4bd2-8382-e4d92345ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-fc4eff89-7620-4679-bfa4-6c60e3d4e757,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-435d9992-4007-4ab4-8d91-ccd9debf4c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-dd73dbde-2bf3-47fa-b829-3885d74e4f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-3342a88c-64a5-49a9-9c2f-15fa3234dc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585276717-172.17.0.20-1598112174548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-4e5698b0-5432-45d8-ad0d-0c7ab38e9033,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-954916c3-f012-4dbb-aa57-5df80ead4c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-eaf047de-6e53-4f53-b668-17e26fc274c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d3e8a2a7-8bd2-46fe-b8c3-49185257a1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-09c33d16-065f-4bc3-b1a5-ae08a87d180c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-bd479e13-4e32-4e52-9f9e-d9dea09f99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-3a677c08-3f95-45d6-9aa2-16109f516289,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-9177ac45-b18f-4562-8b09-ff4b7aaefb9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585276717-172.17.0.20-1598112174548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-4e5698b0-5432-45d8-ad0d-0c7ab38e9033,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-954916c3-f012-4dbb-aa57-5df80ead4c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-eaf047de-6e53-4f53-b668-17e26fc274c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d3e8a2a7-8bd2-46fe-b8c3-49185257a1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-09c33d16-065f-4bc3-b1a5-ae08a87d180c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-bd479e13-4e32-4e52-9f9e-d9dea09f99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-3a677c08-3f95-45d6-9aa2-16109f516289,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-9177ac45-b18f-4562-8b09-ff4b7aaefb9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300420408-172.17.0.20-1598113275802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-ea961d8a-04eb-495f-a8ce-f1fa1d99713c,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1a16561b-4c3e-44a1-98d1-a4cd92aaaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-c4c7fcc2-63eb-4afd-a411-de48de91416f,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-4db80993-d82c-4306-ba8d-33c3cd71c865,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-403445e2-aa5b-4340-9597-cb54addd9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-55454ef1-1c38-4e7b-ae3d-892feee76f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-b8a00f79-1ea9-4ccb-b857-ed399e503b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-af3dfdc0-cc21-4f19-b167-105b61c9bd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300420408-172.17.0.20-1598113275802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-ea961d8a-04eb-495f-a8ce-f1fa1d99713c,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1a16561b-4c3e-44a1-98d1-a4cd92aaaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-c4c7fcc2-63eb-4afd-a411-de48de91416f,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-4db80993-d82c-4306-ba8d-33c3cd71c865,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-403445e2-aa5b-4340-9597-cb54addd9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-55454ef1-1c38-4e7b-ae3d-892feee76f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-b8a00f79-1ea9-4ccb-b857-ed399e503b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-af3dfdc0-cc21-4f19-b167-105b61c9bd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364766985-172.17.0.20-1598113525330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35526,DS-4f08e479-56f4-4b77-8077-15c42dfcd33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-f16fd9b6-b961-45dc-addd-0d55176c4b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-28e48729-0301-48c9-8d2c-f25fabb09ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-8e3aa747-0ee1-4422-aae4-0a152c5429cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-3e92b053-a7ee-4f49-9b9e-87e297dc1451,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-bef86112-57b6-4ae8-bb1f-b89a4df0909c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-67a1623a-409d-40c2-9c9c-15d49d48474c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-0ebd915a-d18e-4db3-9403-35f4f78e239e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364766985-172.17.0.20-1598113525330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35526,DS-4f08e479-56f4-4b77-8077-15c42dfcd33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-f16fd9b6-b961-45dc-addd-0d55176c4b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-28e48729-0301-48c9-8d2c-f25fabb09ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-8e3aa747-0ee1-4422-aae4-0a152c5429cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-3e92b053-a7ee-4f49-9b9e-87e297dc1451,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-bef86112-57b6-4ae8-bb1f-b89a4df0909c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-67a1623a-409d-40c2-9c9c-15d49d48474c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-0ebd915a-d18e-4db3-9403-35f4f78e239e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105279013-172.17.0.20-1598113581742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-6df47bc6-5012-4d90-a616-f02aaa4b0aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-7605092d-f026-488d-a567-2e5837c2b870,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-3b7ea124-4f5c-45ec-b4eb-957be8e89f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1b165dd4-b3b6-42d5-8e1b-5e6bbed3cade,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-437a13a3-d91c-415e-b128-59760c37eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-6fa8ba04-463f-46da-bf53-b975c42cc3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-47554835-e789-4086-8e61-91ac0af21cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-59c39610-ca34-418b-b207-4c83a9f7d594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105279013-172.17.0.20-1598113581742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-6df47bc6-5012-4d90-a616-f02aaa4b0aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-7605092d-f026-488d-a567-2e5837c2b870,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-3b7ea124-4f5c-45ec-b4eb-957be8e89f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1b165dd4-b3b6-42d5-8e1b-5e6bbed3cade,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-437a13a3-d91c-415e-b128-59760c37eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-6fa8ba04-463f-46da-bf53-b975c42cc3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-47554835-e789-4086-8e61-91ac0af21cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-59c39610-ca34-418b-b207-4c83a9f7d594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140244976-172.17.0.20-1598113882485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-030a77fd-94ad-431a-a649-44001acc0fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-90ae7f1e-00bc-49df-861f-1d839d8a79ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-6e0ccff1-0ec0-4666-985a-93d9691e2408,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f7e43ae-50bf-4073-b951-ad958f7673e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-fc346120-71f0-484a-b1b4-50bdaf9d273d,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-408a0f47-a4aa-4150-9384-0171fbabc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-88a229a7-c3e1-4906-b195-26888d444934,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-de573289-ce0a-46b1-8768-905e93801405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140244976-172.17.0.20-1598113882485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-030a77fd-94ad-431a-a649-44001acc0fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-90ae7f1e-00bc-49df-861f-1d839d8a79ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-6e0ccff1-0ec0-4666-985a-93d9691e2408,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f7e43ae-50bf-4073-b951-ad958f7673e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-fc346120-71f0-484a-b1b4-50bdaf9d273d,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-408a0f47-a4aa-4150-9384-0171fbabc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-88a229a7-c3e1-4906-b195-26888d444934,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-de573289-ce0a-46b1-8768-905e93801405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254265175-172.17.0.20-1598113988181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-cece7b1e-7b45-4ef5-ac2c-8596d61f9518,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-c4e027fa-5637-46a5-b88f-07a0346eaff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-2a559a90-6dd8-48f0-881d-f35921a225c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-05199882-ea22-42db-b971-a3cbdae5ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-bcbc51d4-2aa9-45ba-879f-302182a56dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-00667815-e18b-4fa4-ba86-46d036ea03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dc076bc1-1bf8-483a-a846-97f448107517,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-371b11d2-7930-471d-8e79-5c0150387144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254265175-172.17.0.20-1598113988181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33670,DS-cece7b1e-7b45-4ef5-ac2c-8596d61f9518,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-c4e027fa-5637-46a5-b88f-07a0346eaff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-2a559a90-6dd8-48f0-881d-f35921a225c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-05199882-ea22-42db-b971-a3cbdae5ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-bcbc51d4-2aa9-45ba-879f-302182a56dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-00667815-e18b-4fa4-ba86-46d036ea03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dc076bc1-1bf8-483a-a846-97f448107517,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-371b11d2-7930-471d-8e79-5c0150387144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088948093-172.17.0.20-1598114261268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-e8ce7a9e-674b-4cb6-9014-aee69fe9388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-23ce8fa8-93ab-4a95-9653-0927e01ff0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-ea30e7ed-2e93-45fc-b45a-b63be0713dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c8630324-d146-451c-a621-508413173d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d2a5fbf4-f3ce-412e-ae6b-063e0989107a,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-60b74bbd-427f-43ba-b412-567ccf3f6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-979c71af-0799-4106-a316-a2d698ec17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-6cd96241-5ae5-439b-9470-3c3dfee81bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088948093-172.17.0.20-1598114261268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-e8ce7a9e-674b-4cb6-9014-aee69fe9388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-23ce8fa8-93ab-4a95-9653-0927e01ff0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-ea30e7ed-2e93-45fc-b45a-b63be0713dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c8630324-d146-451c-a621-508413173d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-d2a5fbf4-f3ce-412e-ae6b-063e0989107a,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-60b74bbd-427f-43ba-b412-567ccf3f6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-979c71af-0799-4106-a316-a2d698ec17b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-6cd96241-5ae5-439b-9470-3c3dfee81bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934814055-172.17.0.20-1598115261738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32834,DS-86c01501-3715-44c4-a984-3acbbe6e33dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-50307328-48b2-4dae-bb7d-2e55d28f44e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-36838bbf-1cbf-435b-9aa0-8eed3dce19fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-faf39ca6-bb85-4b7a-8e2b-3ed7396fb313,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-f9e18546-258e-441e-b985-1fc7eecf345b,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-bfa5792f-1c63-4f7b-8e4c-8657e8d78e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9125385f-6106-4c3e-9717-e802e73527c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-be117e0e-5cc2-4770-bb46-822e42365599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934814055-172.17.0.20-1598115261738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32834,DS-86c01501-3715-44c4-a984-3acbbe6e33dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-50307328-48b2-4dae-bb7d-2e55d28f44e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-36838bbf-1cbf-435b-9aa0-8eed3dce19fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-faf39ca6-bb85-4b7a-8e2b-3ed7396fb313,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-f9e18546-258e-441e-b985-1fc7eecf345b,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-bfa5792f-1c63-4f7b-8e4c-8657e8d78e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9125385f-6106-4c3e-9717-e802e73527c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-be117e0e-5cc2-4770-bb46-822e42365599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044797751-172.17.0.20-1598115683265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-0f484a8b-4e09-492e-968f-20ef0ca9618f,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-16ec7cb5-f292-45b1-b8fe-cb0aca58ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-5e2bc780-9ed9-40a1-8abc-1914f7b34e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-5b95ead2-cab8-4fa4-a9ae-867bd50b3164,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-ee1c07f9-ffa4-4800-b3e1-a64f39a0f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-2893afc6-36d7-47dc-b768-2cc23c9c906d,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3251167b-bae0-435c-a626-48f0103c54b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-1f058f37-5239-4daf-805d-4bfcc5e4f9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044797751-172.17.0.20-1598115683265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-0f484a8b-4e09-492e-968f-20ef0ca9618f,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-16ec7cb5-f292-45b1-b8fe-cb0aca58ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-5e2bc780-9ed9-40a1-8abc-1914f7b34e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-5b95ead2-cab8-4fa4-a9ae-867bd50b3164,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-ee1c07f9-ffa4-4800-b3e1-a64f39a0f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-2893afc6-36d7-47dc-b768-2cc23c9c906d,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-3251167b-bae0-435c-a626-48f0103c54b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-1f058f37-5239-4daf-805d-4bfcc5e4f9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601842123-172.17.0.20-1598116049894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-336cfaa2-e890-47ea-8946-b0d73f93c640,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-ea2c045c-6a1b-4df7-88f3-c29f15f2e6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-320ddaa6-1731-43b3-94a5-b6a2c980e820,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b811922-7f60-4273-9743-5422f5460ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-4119a765-a173-4aa4-9f86-6e9bfa24ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-26d891c4-12e9-48fe-b463-6f0e90f180f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-0f985812-2fc9-416d-98be-02072920ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-a0e9174f-901b-4f6b-a99b-030ef36f0382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601842123-172.17.0.20-1598116049894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-336cfaa2-e890-47ea-8946-b0d73f93c640,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-ea2c045c-6a1b-4df7-88f3-c29f15f2e6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-320ddaa6-1731-43b3-94a5-b6a2c980e820,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b811922-7f60-4273-9743-5422f5460ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-4119a765-a173-4aa4-9f86-6e9bfa24ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-26d891c4-12e9-48fe-b463-6f0e90f180f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-0f985812-2fc9-416d-98be-02072920ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-a0e9174f-901b-4f6b-a99b-030ef36f0382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727762230-172.17.0.20-1598116481080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-c91689e2-9c61-4a57-9ac1-01c134f95b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-18b7dbf4-4c7e-4f82-b2dd-b5d4fcf2ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-da453654-61fd-4a9f-bfd1-5a67e7cc5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-a57c52c2-19b1-4880-a662-77af71fccb36,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-d0fecb82-69c8-4ca7-a427-9926be14181d,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-9f016c1c-6470-4911-a0b7-6de51082a040,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-658e864a-bbab-4df6-852f-54e80c98e190,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-210b690b-cd8b-45a0-9885-a7f3aee8ecd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727762230-172.17.0.20-1598116481080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-c91689e2-9c61-4a57-9ac1-01c134f95b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-18b7dbf4-4c7e-4f82-b2dd-b5d4fcf2ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-da453654-61fd-4a9f-bfd1-5a67e7cc5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-a57c52c2-19b1-4880-a662-77af71fccb36,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-d0fecb82-69c8-4ca7-a427-9926be14181d,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-9f016c1c-6470-4911-a0b7-6de51082a040,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-658e864a-bbab-4df6-852f-54e80c98e190,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-210b690b-cd8b-45a0-9885-a7f3aee8ecd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5286
