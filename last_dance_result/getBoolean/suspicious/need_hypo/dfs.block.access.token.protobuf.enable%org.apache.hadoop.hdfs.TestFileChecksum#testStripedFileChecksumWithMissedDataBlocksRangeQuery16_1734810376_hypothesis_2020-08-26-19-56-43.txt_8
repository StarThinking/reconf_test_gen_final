reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322759458-172.17.0.5-1598472238967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-62a80445-5b11-45e6-b753-6d32ca3836bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-5d9710c7-c71f-484b-b24d-6e82359f9850,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-39fcc4b1-4d46-4079-aed4-a5e5e62c931e,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-e115b313-2224-4c23-a6ed-8d2e01c30a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-bbfc34d4-23d5-4bed-b14b-2cb75b8c1070,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-e1a911d2-1f4c-4a87-9a1d-b813b736ba94,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-e8691a4d-1c10-4c8d-bd1c-90a5cfb2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-bc6a090c-87a9-4dda-bac7-365fa3a270a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322759458-172.17.0.5-1598472238967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-62a80445-5b11-45e6-b753-6d32ca3836bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-5d9710c7-c71f-484b-b24d-6e82359f9850,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-39fcc4b1-4d46-4079-aed4-a5e5e62c931e,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-e115b313-2224-4c23-a6ed-8d2e01c30a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-bbfc34d4-23d5-4bed-b14b-2cb75b8c1070,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-e1a911d2-1f4c-4a87-9a1d-b813b736ba94,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-e8691a4d-1c10-4c8d-bd1c-90a5cfb2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-bc6a090c-87a9-4dda-bac7-365fa3a270a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878729901-172.17.0.5-1598472451517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33181,DS-ea2be77a-0867-4f45-81f0-5f67feecfb53,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-56d9f2f2-2c8b-4b8b-87fa-7ca18b8d30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6a19ed26-5388-4ffc-a374-65f30addce33,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-0a119dfb-be9d-4565-a704-b84a388de111,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-dc791f60-db0f-43c4-9e4c-3293f66fb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-a339eb4e-b6d1-4e7b-817e-d1342189fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-6e750581-1dbf-4282-9a5d-c065c6c61d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-9353f21d-085f-4fad-a67d-cf67b56c1197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878729901-172.17.0.5-1598472451517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33181,DS-ea2be77a-0867-4f45-81f0-5f67feecfb53,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-56d9f2f2-2c8b-4b8b-87fa-7ca18b8d30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6a19ed26-5388-4ffc-a374-65f30addce33,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-0a119dfb-be9d-4565-a704-b84a388de111,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-dc791f60-db0f-43c4-9e4c-3293f66fb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-a339eb4e-b6d1-4e7b-817e-d1342189fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-6e750581-1dbf-4282-9a5d-c065c6c61d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-9353f21d-085f-4fad-a67d-cf67b56c1197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552450160-172.17.0.5-1598472535079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-85d9b075-99d8-43e3-b487-4d0bcebd7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-f21eaae7-0273-4279-95e2-e1e9b71a7a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-a48b7723-622c-4e8b-a01f-3d30185c5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3c2a8196-d865-40f2-87d7-b02bf146403c,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-4e24c24a-87d2-4e55-b077-be7cf59a9780,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b5ab057b-c2e6-4e13-b6ab-9fdb79cddbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-6f5fd3cf-e4f1-4da2-a51c-0f8cb9513db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-eca19ed8-3e09-43cf-a365-2e977a85be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552450160-172.17.0.5-1598472535079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-85d9b075-99d8-43e3-b487-4d0bcebd7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-f21eaae7-0273-4279-95e2-e1e9b71a7a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-a48b7723-622c-4e8b-a01f-3d30185c5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3c2a8196-d865-40f2-87d7-b02bf146403c,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-4e24c24a-87d2-4e55-b077-be7cf59a9780,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-b5ab057b-c2e6-4e13-b6ab-9fdb79cddbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-6f5fd3cf-e4f1-4da2-a51c-0f8cb9513db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-eca19ed8-3e09-43cf-a365-2e977a85be2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098209375-172.17.0.5-1598472647793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-90c02036-1bed-4f3b-8a8e-0e450aa0df82,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-257586e9-8d86-4dbb-b021-62fbda0c8a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-399d85bf-d5e1-4a52-8912-c9a6c0ba450b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3c4d5005-f6ef-46aa-9bef-e3380a8af166,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-947d3fa9-a046-4730-a166-3d7725f3c14a,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ea1121f8-b7e4-4576-b761-e4957a86230f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a1da260d-4873-4d39-a841-41cd1555af54,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-810f1136-b894-4b8d-ba4a-b94bfc56929d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098209375-172.17.0.5-1598472647793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-90c02036-1bed-4f3b-8a8e-0e450aa0df82,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-257586e9-8d86-4dbb-b021-62fbda0c8a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-399d85bf-d5e1-4a52-8912-c9a6c0ba450b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3c4d5005-f6ef-46aa-9bef-e3380a8af166,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-947d3fa9-a046-4730-a166-3d7725f3c14a,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ea1121f8-b7e4-4576-b761-e4957a86230f,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a1da260d-4873-4d39-a841-41cd1555af54,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-810f1136-b894-4b8d-ba4a-b94bfc56929d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32764266-172.17.0.5-1598472795157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-89990824-4206-489b-8b49-54cbc19dab8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-36d2f61e-7a62-4aaa-bad0-787d94af675f,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-f2b2a249-1e01-41b3-9a0c-419f573ecb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3764f000-b6ac-40c6-b4d7-e6f519973c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-3a4392bd-2301-42ef-8a64-7a8fb7c0a8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-c77a8205-62e8-414b-b282-8d19179d427d,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-0962f12b-1fc2-4eae-84f6-d10ed4f1f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-8e7fc438-9576-4c61-bf61-a736d8ecf63d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32764266-172.17.0.5-1598472795157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-89990824-4206-489b-8b49-54cbc19dab8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-36d2f61e-7a62-4aaa-bad0-787d94af675f,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-f2b2a249-1e01-41b3-9a0c-419f573ecb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3764f000-b6ac-40c6-b4d7-e6f519973c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-3a4392bd-2301-42ef-8a64-7a8fb7c0a8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-c77a8205-62e8-414b-b282-8d19179d427d,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-0962f12b-1fc2-4eae-84f6-d10ed4f1f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-8e7fc438-9576-4c61-bf61-a736d8ecf63d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522857997-172.17.0.5-1598472893436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-f409e7c3-a03b-475c-8e6a-7d686d3b6be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-6c5c4640-6c86-4008-8d9d-7955898d82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-f961f83d-8291-4dba-83b8-492d2ff2dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5f5e7aa1-4995-4fb9-8697-122ffc70b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-8c1ac5ef-8557-44dc-91c1-d118167c1236,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-e7665cf0-6ae5-404b-90c2-ad31e7f96035,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-65394402-aa2e-4523-aa5b-a1ae9d7a1576,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-761fc9cd-cf40-42cd-94bd-9336685a417e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522857997-172.17.0.5-1598472893436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-f409e7c3-a03b-475c-8e6a-7d686d3b6be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-6c5c4640-6c86-4008-8d9d-7955898d82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-f961f83d-8291-4dba-83b8-492d2ff2dc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5f5e7aa1-4995-4fb9-8697-122ffc70b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-8c1ac5ef-8557-44dc-91c1-d118167c1236,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-e7665cf0-6ae5-404b-90c2-ad31e7f96035,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-65394402-aa2e-4523-aa5b-a1ae9d7a1576,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-761fc9cd-cf40-42cd-94bd-9336685a417e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945131123-172.17.0.5-1598473156451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-49cd6e20-328a-4c78-a31b-7f07593cc617,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-436968f9-98fd-4e3b-96d5-d3157e186a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-85206e40-0055-44c0-bf5d-d7a35599d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-a2be7c45-5b0d-4e63-85ab-8d21ec76aff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-1c633f49-cc0e-425f-bf6e-6212d626e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-7b2f95ba-8481-47cf-a9a2-3fd1990ff19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-1929d088-74e8-4a2d-9f41-160e8d528ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-78f0073a-1f87-4120-a717-7311d511e396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945131123-172.17.0.5-1598473156451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-49cd6e20-328a-4c78-a31b-7f07593cc617,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-436968f9-98fd-4e3b-96d5-d3157e186a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-85206e40-0055-44c0-bf5d-d7a35599d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-a2be7c45-5b0d-4e63-85ab-8d21ec76aff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-1c633f49-cc0e-425f-bf6e-6212d626e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-7b2f95ba-8481-47cf-a9a2-3fd1990ff19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-1929d088-74e8-4a2d-9f41-160e8d528ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-78f0073a-1f87-4120-a717-7311d511e396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368035943-172.17.0.5-1598473597056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-fc46b6d0-b6db-4d86-ad60-6be2618faa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-b64865a1-c6af-4e18-bccd-1ab46729d873,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-4194289a-2fac-4ace-9ec9-9c2dc435eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-dc1a72d1-4bae-4bb5-84b5-e027a8f012ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-762e4d5a-895d-4964-939d-26b5da54c903,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1efbf259-4177-4d66-aac9-1616e998cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-26f13996-bbf0-4a7f-b5dd-37824b90d607,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-61c3d83c-b108-420f-b8f0-78416186b424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368035943-172.17.0.5-1598473597056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-fc46b6d0-b6db-4d86-ad60-6be2618faa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-b64865a1-c6af-4e18-bccd-1ab46729d873,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-4194289a-2fac-4ace-9ec9-9c2dc435eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-dc1a72d1-4bae-4bb5-84b5-e027a8f012ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-762e4d5a-895d-4964-939d-26b5da54c903,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-1efbf259-4177-4d66-aac9-1616e998cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-26f13996-bbf0-4a7f-b5dd-37824b90d607,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-61c3d83c-b108-420f-b8f0-78416186b424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280279318-172.17.0.5-1598473726618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39562,DS-97509142-11f5-4ee3-97fd-2cdedc2af979,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-68108066-f2ad-4dcc-8674-8e647162de50,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-c38fdfcd-a4b1-4621-ac4a-1026794a35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-b63d09e6-c5f1-4ad2-b3e5-dda2f8b6fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-24bb0198-e4fd-4ad6-b4ae-c633f7494b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ace724b4-70aa-4901-99fd-819ec15be424,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-563a1b5d-a339-490a-9b87-ab52d637c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-f8047c07-a880-4caa-8de8-7d04f3ae17c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280279318-172.17.0.5-1598473726618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39562,DS-97509142-11f5-4ee3-97fd-2cdedc2af979,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-68108066-f2ad-4dcc-8674-8e647162de50,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-c38fdfcd-a4b1-4621-ac4a-1026794a35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-b63d09e6-c5f1-4ad2-b3e5-dda2f8b6fe56,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-24bb0198-e4fd-4ad6-b4ae-c633f7494b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ace724b4-70aa-4901-99fd-819ec15be424,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-563a1b5d-a339-490a-9b87-ab52d637c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-f8047c07-a880-4caa-8de8-7d04f3ae17c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006832586-172.17.0.5-1598473825232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-fc98236c-0728-4a9d-9eaa-567ffd9ac2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-48a306c0-1c1a-47ee-b893-74c811785b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-825e1462-74b6-4c5c-8337-78ca06078211,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-a5ae26df-8cc1-466a-9d7b-d2ee106031a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-20eaaea5-6765-4094-a5cf-b29d65f5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-d8b008d7-9fd2-4d23-99d4-eb06d7a87a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-e4802d38-3557-4e68-8f10-219c92673502,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-1656b729-8011-4fff-a9e5-98604be1f244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006832586-172.17.0.5-1598473825232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-fc98236c-0728-4a9d-9eaa-567ffd9ac2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-48a306c0-1c1a-47ee-b893-74c811785b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-825e1462-74b6-4c5c-8337-78ca06078211,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-a5ae26df-8cc1-466a-9d7b-d2ee106031a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-20eaaea5-6765-4094-a5cf-b29d65f5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-d8b008d7-9fd2-4d23-99d4-eb06d7a87a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-e4802d38-3557-4e68-8f10-219c92673502,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-1656b729-8011-4fff-a9e5-98604be1f244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843286834-172.17.0.5-1598473922668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-a9ea9843-ed04-423a-8166-2d27327fbb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-514049a3-360f-4c7b-959a-26f120422536,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0bc9b75a-ca49-44ad-be70-e6e89abe21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-54bc7890-4580-4cac-b7d7-b0d3e83ad862,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-ed804f37-ef08-43ef-a8b2-5d786b836e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-d21ad994-7cc6-405b-8c5c-513b492441b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-4e8ddc16-1646-4623-8fae-46b85c66988a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-89dc26ab-ebcb-4574-b159-73477ceced31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843286834-172.17.0.5-1598473922668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-a9ea9843-ed04-423a-8166-2d27327fbb18,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-514049a3-360f-4c7b-959a-26f120422536,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-0bc9b75a-ca49-44ad-be70-e6e89abe21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-54bc7890-4580-4cac-b7d7-b0d3e83ad862,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-ed804f37-ef08-43ef-a8b2-5d786b836e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-d21ad994-7cc6-405b-8c5c-513b492441b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-4e8ddc16-1646-4623-8fae-46b85c66988a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-89dc26ab-ebcb-4574-b159-73477ceced31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276937639-172.17.0.5-1598473939173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-2e97a583-7558-498f-ac0c-67d23ca967b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-1722eae7-d0ec-4c00-a176-e4b26bf25bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-9ea79e31-e693-4e2e-a038-71108978bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-0ed5eefc-d363-4901-80df-847f3e5a6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-b70d1d2c-fb09-4206-99ff-9e56c8d09f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-f7023837-7ec8-4b0c-94eb-451fa177cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-d0cee209-cd9e-4e4a-8ae5-7b5e8fcc2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-150c3718-4504-4432-a208-e37c2753ddfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276937639-172.17.0.5-1598473939173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-2e97a583-7558-498f-ac0c-67d23ca967b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-1722eae7-d0ec-4c00-a176-e4b26bf25bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-9ea79e31-e693-4e2e-a038-71108978bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-0ed5eefc-d363-4901-80df-847f3e5a6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-b70d1d2c-fb09-4206-99ff-9e56c8d09f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-f7023837-7ec8-4b0c-94eb-451fa177cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-d0cee209-cd9e-4e4a-8ae5-7b5e8fcc2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-150c3718-4504-4432-a208-e37c2753ddfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666868045-172.17.0.5-1598474168290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-d442bc85-aee8-40d8-a06e-f1ccbfb8db92,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-8abda58c-957a-45db-a8fd-f7833274e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-85907e53-8fa3-49f3-93cc-129d52c0e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-7bd8521a-c1c9-49c6-afcb-2ed12e043558,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-0b545bba-edd6-4c02-a267-e295add84ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-1ecd2032-a6ab-4870-a0a1-b9ffd402f719,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-9a50ab74-f919-4252-b0fa-f6580f875036,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-ed236ac0-2201-4eb8-898b-0b91a90fd14c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666868045-172.17.0.5-1598474168290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-d442bc85-aee8-40d8-a06e-f1ccbfb8db92,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-8abda58c-957a-45db-a8fd-f7833274e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-85907e53-8fa3-49f3-93cc-129d52c0e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-7bd8521a-c1c9-49c6-afcb-2ed12e043558,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-0b545bba-edd6-4c02-a267-e295add84ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-1ecd2032-a6ab-4870-a0a1-b9ffd402f719,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-9a50ab74-f919-4252-b0fa-f6580f875036,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-ed236ac0-2201-4eb8-898b-0b91a90fd14c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703202427-172.17.0.5-1598474267739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-37d38d22-a73f-4ae4-bb0d-c3cddb69e188,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-b29315df-6483-4310-b870-999f66798239,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-838129e4-6247-4e50-8d25-4cb7317b0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-cd30e931-aef3-4594-b199-04fc2e4fdf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c9a8f55-f5fc-42cc-8ed0-f90e087fca64,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-0b85b4ee-d37a-47be-b69a-3c8292011307,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-2671f760-db27-4a72-9837-7cacc6d58e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a85c76b1-7405-42f5-8e96-2e0823c5e887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703202427-172.17.0.5-1598474267739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-37d38d22-a73f-4ae4-bb0d-c3cddb69e188,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-b29315df-6483-4310-b870-999f66798239,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-838129e4-6247-4e50-8d25-4cb7317b0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-cd30e931-aef3-4594-b199-04fc2e4fdf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c9a8f55-f5fc-42cc-8ed0-f90e087fca64,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-0b85b4ee-d37a-47be-b69a-3c8292011307,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-2671f760-db27-4a72-9837-7cacc6d58e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-a85c76b1-7405-42f5-8e96-2e0823c5e887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 2604
