reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906794673-172.17.0.5-1598539918954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-3e68386c-8e37-4e79-91f1-35b9f4ad337f,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-34608083-1d9b-4b2a-a67b-62d9f096d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-7bbc113a-9bb5-4752-8b06-569fdb5bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-94f9c688-bb76-4c51-a6c0-3fb9a2aed9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-bd1b736f-2c73-45ff-aa99-b8250f51c950,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-7931c37d-1249-4af0-a2c5-88b34b47aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-549de523-0784-4d3e-a56e-12e7e2a8e52d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-a2e5cd61-ae27-4cb0-9ad7-dab4d12c09ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906794673-172.17.0.5-1598539918954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-3e68386c-8e37-4e79-91f1-35b9f4ad337f,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-34608083-1d9b-4b2a-a67b-62d9f096d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-7bbc113a-9bb5-4752-8b06-569fdb5bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-94f9c688-bb76-4c51-a6c0-3fb9a2aed9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-bd1b736f-2c73-45ff-aa99-b8250f51c950,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-7931c37d-1249-4af0-a2c5-88b34b47aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-549de523-0784-4d3e-a56e-12e7e2a8e52d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-a2e5cd61-ae27-4cb0-9ad7-dab4d12c09ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194522863-172.17.0.5-1598540029140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33524,DS-bc0964a2-175a-4dd5-8f4e-a4c42fdf0740,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-79165d9d-20c4-4e37-a7e0-f9f50f475673,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-1dcd4557-b5a4-4e2a-95f5-0cff959c44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-a2a9f787-4689-4a83-888c-cea601a2cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-eee06a0c-bb75-44b4-85ac-96ba854dd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-e7d0ab2b-21a4-44b6-93c0-160fec3af041,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-d321c86d-57f1-4c0d-86b8-d269d71dda06,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-c3986641-fbcb-4acb-b094-4b20050dcc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194522863-172.17.0.5-1598540029140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33524,DS-bc0964a2-175a-4dd5-8f4e-a4c42fdf0740,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-79165d9d-20c4-4e37-a7e0-f9f50f475673,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-1dcd4557-b5a4-4e2a-95f5-0cff959c44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-a2a9f787-4689-4a83-888c-cea601a2cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-eee06a0c-bb75-44b4-85ac-96ba854dd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-e7d0ab2b-21a4-44b6-93c0-160fec3af041,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-d321c86d-57f1-4c0d-86b8-d269d71dda06,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-c3986641-fbcb-4acb-b094-4b20050dcc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001130259-172.17.0.5-1598540293370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-dc46ca01-7318-4e71-8752-f924a265e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-04ef9860-0329-4c1d-af98-15ea8f94531e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-c9ae6967-9134-47b1-94f5-8b16bec73d33,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-3185c070-d68b-4519-9307-456511674cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-65b4daf1-a106-431f-a40e-94f0a5857ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-392794d8-b4bd-42ac-845a-0fa04f853e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-5d973d40-793e-4f38-a504-afdcb658fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-10ecc2e0-f48e-4035-ba62-bbd2081d6edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001130259-172.17.0.5-1598540293370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-dc46ca01-7318-4e71-8752-f924a265e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-04ef9860-0329-4c1d-af98-15ea8f94531e,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-c9ae6967-9134-47b1-94f5-8b16bec73d33,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-3185c070-d68b-4519-9307-456511674cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-65b4daf1-a106-431f-a40e-94f0a5857ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-392794d8-b4bd-42ac-845a-0fa04f853e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-5d973d40-793e-4f38-a504-afdcb658fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-10ecc2e0-f48e-4035-ba62-bbd2081d6edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816685620-172.17.0.5-1598540781430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-f3480df2-23d6-4d7a-9dfc-ffde9b3db28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-463b8e68-9194-4c54-804c-cb56576f439d,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-bbd70f2a-1b31-4814-ad8d-3ef68cf16fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a98b8496-b4fb-442b-a6c2-fd5f47fff689,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-470bf568-d1f7-4bd9-b8f2-617e6e10955e,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-335b2c90-620f-42bc-8a87-cab1aff68ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-8ce88be7-9cb8-4099-9114-1a72abebfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-cb9d1fa9-7999-4fe9-ac0f-85c94b74d332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816685620-172.17.0.5-1598540781430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-f3480df2-23d6-4d7a-9dfc-ffde9b3db28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-463b8e68-9194-4c54-804c-cb56576f439d,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-bbd70f2a-1b31-4814-ad8d-3ef68cf16fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-a98b8496-b4fb-442b-a6c2-fd5f47fff689,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-470bf568-d1f7-4bd9-b8f2-617e6e10955e,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-335b2c90-620f-42bc-8a87-cab1aff68ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-8ce88be7-9cb8-4099-9114-1a72abebfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-cb9d1fa9-7999-4fe9-ac0f-85c94b74d332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044624433-172.17.0.5-1598541964717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-f99c1919-f3f5-4267-b52b-956c4e5db29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-8427621b-3c19-4d9e-8e70-08a6630ea8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ada31130-86c9-42d0-ba37-8798c4f2ee70,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-6937336b-a3e7-4968-a0b2-9f3ae6cccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-980dfc3d-059d-4318-9f81-a1307cc4195a,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-5367b31a-24e0-42ab-b67c-8fb5dc492d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-9e8fb4b5-f94f-45fa-a5d3-f063e174aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-3d2d757b-23ef-4e1a-b30c-0644b4cd31e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044624433-172.17.0.5-1598541964717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-f99c1919-f3f5-4267-b52b-956c4e5db29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-8427621b-3c19-4d9e-8e70-08a6630ea8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-ada31130-86c9-42d0-ba37-8798c4f2ee70,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-6937336b-a3e7-4968-a0b2-9f3ae6cccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-980dfc3d-059d-4318-9f81-a1307cc4195a,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-5367b31a-24e0-42ab-b67c-8fb5dc492d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-9e8fb4b5-f94f-45fa-a5d3-f063e174aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-3d2d757b-23ef-4e1a-b30c-0644b4cd31e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680909331-172.17.0.5-1598542079975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-ba9aa0c2-0093-47bf-92e1-a3bedaba5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-7435defd-0da2-4ce7-b36a-418c2ae3bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1bcb5181-5bc4-413f-ab43-7b7bc001bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-23c0a36d-f97b-4379-83d9-9119a1c84bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-6be5102e-c0f1-4ae0-8466-e15cee81c025,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-0a719dca-867a-4dbc-bfe8-4d5ae81d6e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-408e43ff-516a-4106-a746-2b7f70a9070e,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-a8cbaaa6-82f5-4bda-9eac-284917296156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680909331-172.17.0.5-1598542079975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-ba9aa0c2-0093-47bf-92e1-a3bedaba5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-7435defd-0da2-4ce7-b36a-418c2ae3bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1bcb5181-5bc4-413f-ab43-7b7bc001bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-23c0a36d-f97b-4379-83d9-9119a1c84bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-6be5102e-c0f1-4ae0-8466-e15cee81c025,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-0a719dca-867a-4dbc-bfe8-4d5ae81d6e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-408e43ff-516a-4106-a746-2b7f70a9070e,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-a8cbaaa6-82f5-4bda-9eac-284917296156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574929144-172.17.0.5-1598542439058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-499a9da3-264e-43c9-9b66-9a3591d415f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-45b413dc-5ee2-4c60-882a-55038283e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-8b141ef4-0aa7-424d-82c1-48084e650878,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f05e9c93-8d28-461a-9e93-7cca0895be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-b5bce2a9-5d80-4864-8b1e-33f23550b331,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-85304633-09c2-4821-a94b-642e71335ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-50fe382c-c040-449a-956e-0a186f73636d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-72f0f478-e6c4-419a-9c41-23f2eadffe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574929144-172.17.0.5-1598542439058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38061,DS-499a9da3-264e-43c9-9b66-9a3591d415f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-45b413dc-5ee2-4c60-882a-55038283e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-8b141ef4-0aa7-424d-82c1-48084e650878,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f05e9c93-8d28-461a-9e93-7cca0895be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-b5bce2a9-5d80-4864-8b1e-33f23550b331,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-85304633-09c2-4821-a94b-642e71335ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-50fe382c-c040-449a-956e-0a186f73636d,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-72f0f478-e6c4-419a-9c41-23f2eadffe29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748656888-172.17.0.5-1598542728869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-db299336-c0ec-4bab-bb7a-8ffbe600cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-203cc45a-3379-4bf6-bf7d-f92ec7c6cced,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-b60c5b1d-507a-466a-acd3-d93e5b13c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-96cc3ad1-09c8-42d3-843b-de1dfa8d8305,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-3029f56e-1d0b-4599-98d6-6049b1b8e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-985e908b-446e-4184-acb2-e4371c3d0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-72606e0e-e434-494c-8d5e-6265ab5eb040,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-b308072f-9f78-4967-9e1f-630f3d5e5da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748656888-172.17.0.5-1598542728869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33187,DS-db299336-c0ec-4bab-bb7a-8ffbe600cfca,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-203cc45a-3379-4bf6-bf7d-f92ec7c6cced,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-b60c5b1d-507a-466a-acd3-d93e5b13c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-96cc3ad1-09c8-42d3-843b-de1dfa8d8305,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-3029f56e-1d0b-4599-98d6-6049b1b8e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-985e908b-446e-4184-acb2-e4371c3d0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-72606e0e-e434-494c-8d5e-6265ab5eb040,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-b308072f-9f78-4967-9e1f-630f3d5e5da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898059530-172.17.0.5-1598542875687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-82079b62-b1d2-41cf-a302-793d639d93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-1dd866ed-834c-4e71-a1c1-3572b7138800,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ea3b854f-017a-40dc-bacd-fc9df910e469,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-b4d04cd3-1834-4651-9757-52d08a06c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-33f8e07e-0615-43ba-be0a-33f1be2318d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-cc4b3ec2-cde2-4381-a8a4-3d985d08b378,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-190ff5fa-c49f-455e-8a53-52d62e48e738,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-69f6d367-55ad-4124-aeeb-37f80c79d775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898059530-172.17.0.5-1598542875687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-82079b62-b1d2-41cf-a302-793d639d93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-1dd866ed-834c-4e71-a1c1-3572b7138800,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-ea3b854f-017a-40dc-bacd-fc9df910e469,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-b4d04cd3-1834-4651-9757-52d08a06c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-33f8e07e-0615-43ba-be0a-33f1be2318d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-cc4b3ec2-cde2-4381-a8a4-3d985d08b378,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-190ff5fa-c49f-455e-8a53-52d62e48e738,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-69f6d367-55ad-4124-aeeb-37f80c79d775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086662703-172.17.0.5-1598543229711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-b6f77400-47b0-4566-a1d0-1ff0abe5531a,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-67f60f9f-03e9-4502-8d9b-3c1bf864b168,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-e940fb54-87b0-4e03-8240-8d1a446d7d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-ebff010a-c9a5-4406-8c99-2912ab5a9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-751239c5-eea2-40cc-bcec-b9cb48eadc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-987eb75e-7682-4337-9144-da707c70c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-8017cfed-311d-4477-99e2-b661b03cfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-96f17e16-aa4d-45d7-aa3f-df3850b9f993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086662703-172.17.0.5-1598543229711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-b6f77400-47b0-4566-a1d0-1ff0abe5531a,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-67f60f9f-03e9-4502-8d9b-3c1bf864b168,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-e940fb54-87b0-4e03-8240-8d1a446d7d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-ebff010a-c9a5-4406-8c99-2912ab5a9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-751239c5-eea2-40cc-bcec-b9cb48eadc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-987eb75e-7682-4337-9144-da707c70c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-8017cfed-311d-4477-99e2-b661b03cfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-96f17e16-aa4d-45d7-aa3f-df3850b9f993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043533572-172.17.0.5-1598543689463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-ad9f879d-5188-4fed-a58f-a9fe3e1b65a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-db1b3722-065c-4aee-a8d1-863a92af6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-5d19c1af-4c41-423a-98e1-dfb59f4a0880,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-6f2f4468-6632-415e-8931-e9f827cd274e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-810c2a35-bd42-436d-b6ae-ceb60ce381ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-48653735-1fb3-485a-98f8-d34371fc1449,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-44fb3780-6b8f-45b7-9853-161652b7d7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-f145fcd1-ba66-4138-a881-481251310c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043533572-172.17.0.5-1598543689463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-ad9f879d-5188-4fed-a58f-a9fe3e1b65a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-db1b3722-065c-4aee-a8d1-863a92af6cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-5d19c1af-4c41-423a-98e1-dfb59f4a0880,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-6f2f4468-6632-415e-8931-e9f827cd274e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-810c2a35-bd42-436d-b6ae-ceb60ce381ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-48653735-1fb3-485a-98f8-d34371fc1449,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-44fb3780-6b8f-45b7-9853-161652b7d7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-f145fcd1-ba66-4138-a881-481251310c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165820561-172.17.0.5-1598543818783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-cc672574-0ede-4449-b68a-0e86be4cecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-a6123898-03f6-4643-bf81-289191b71879,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-abb870e1-84ee-4b47-9b47-adef4b7695f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-ef488800-0e20-4933-9285-7340f0171284,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-afe806e4-4080-422b-828b-ede67f27217d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-1779efb2-c5ea-48b5-8530-18e7426fc561,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a1884bd6-f012-430b-adc9-48a13b5466e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-bf7614a6-c244-4f7a-b16f-7e61ee213b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165820561-172.17.0.5-1598543818783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-cc672574-0ede-4449-b68a-0e86be4cecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-a6123898-03f6-4643-bf81-289191b71879,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-abb870e1-84ee-4b47-9b47-adef4b7695f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-ef488800-0e20-4933-9285-7340f0171284,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-afe806e4-4080-422b-828b-ede67f27217d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-1779efb2-c5ea-48b5-8530-18e7426fc561,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a1884bd6-f012-430b-adc9-48a13b5466e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-bf7614a6-c244-4f7a-b16f-7e61ee213b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756565860-172.17.0.5-1598543925344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-844a0439-465d-46fd-ac3e-703c42991c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-073f9a93-c844-41f4-baf1-5ab2bbe806fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-21d4f2f4-fc89-4d27-84f7-171a52b4a03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-7497ba06-baa8-4209-9162-1886d4a49c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-20ea51a9-fbda-48df-86cb-d9b4e3daab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-aa4c7949-3467-45ca-8616-c0f6fd82e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-39a2a881-61c1-4289-8a0f-2eb4e6cac37c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-487189cd-4bc1-4f87-9498-874c1b74b9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756565860-172.17.0.5-1598543925344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-844a0439-465d-46fd-ac3e-703c42991c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-073f9a93-c844-41f4-baf1-5ab2bbe806fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-21d4f2f4-fc89-4d27-84f7-171a52b4a03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-7497ba06-baa8-4209-9162-1886d4a49c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-20ea51a9-fbda-48df-86cb-d9b4e3daab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-aa4c7949-3467-45ca-8616-c0f6fd82e71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-39a2a881-61c1-4289-8a0f-2eb4e6cac37c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-487189cd-4bc1-4f87-9498-874c1b74b9bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794088884-172.17.0.5-1598544575808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-449f1bd0-7b6b-4768-b337-c2d31eb4a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6f23e1df-4e8a-4542-ab66-1a166b74b629,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-ec0fa077-e4ac-4d6b-b20e-ee496ffa1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-e11ae8a9-9a8c-436c-845a-14b1ca1d03f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-5efd8361-1b46-4ee7-b2ae-9fd8e1a76e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-312e4681-9a46-4aea-9373-78612a71eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-e2095a7d-9804-4f6e-8a92-6cfef37d4833,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-bf743607-d20b-46f4-90f9-c46736ed414a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794088884-172.17.0.5-1598544575808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-449f1bd0-7b6b-4768-b337-c2d31eb4a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6f23e1df-4e8a-4542-ab66-1a166b74b629,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-ec0fa077-e4ac-4d6b-b20e-ee496ffa1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-e11ae8a9-9a8c-436c-845a-14b1ca1d03f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-5efd8361-1b46-4ee7-b2ae-9fd8e1a76e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-312e4681-9a46-4aea-9373-78612a71eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-e2095a7d-9804-4f6e-8a92-6cfef37d4833,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-bf743607-d20b-46f4-90f9-c46736ed414a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5335
