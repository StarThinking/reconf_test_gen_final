reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569550720-172.17.0.14-1598492099754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33754,DS-ee4fe433-0176-4d36-ac62-6d58aefc9224,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-5576f897-7b07-4d8d-9fc1-ba6565b8d656,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-39434999-6f49-4d2c-b4f9-d0b727f1cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-a314d733-bce4-4763-becc-0d0a1d0aa8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-65da3034-652c-419b-aa09-72df722a88eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-fc03f773-b580-4607-a856-149fa2820c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-9e0ebad2-c1e3-4089-af41-84e0cdc54fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-cf6a63e9-5525-4b07-aebe-608d193fc898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569550720-172.17.0.14-1598492099754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33754,DS-ee4fe433-0176-4d36-ac62-6d58aefc9224,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-5576f897-7b07-4d8d-9fc1-ba6565b8d656,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-39434999-6f49-4d2c-b4f9-d0b727f1cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-a314d733-bce4-4763-becc-0d0a1d0aa8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-65da3034-652c-419b-aa09-72df722a88eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-fc03f773-b580-4607-a856-149fa2820c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-9e0ebad2-c1e3-4089-af41-84e0cdc54fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-cf6a63e9-5525-4b07-aebe-608d193fc898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237510549-172.17.0.14-1598492132192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-33a67f24-0e48-49bd-be77-33a6f10b62c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-fc5f0d6e-44a9-4166-b9e7-8a6cba293bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-e48a9cd8-f79b-49ba-a365-f9fd875f317d,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-b472b9c5-65eb-4b45-a526-f0ebf8526de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-30cbd74e-c8ce-4a92-8df0-5fbbe7b465ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-24d42a0e-6d1b-4135-ad9f-85f501878ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-7ca23a01-409b-4e3a-83af-2ca9c727f480,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0ee8679a-a613-4245-9377-fd2dfb71a960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237510549-172.17.0.14-1598492132192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-33a67f24-0e48-49bd-be77-33a6f10b62c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-fc5f0d6e-44a9-4166-b9e7-8a6cba293bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-e48a9cd8-f79b-49ba-a365-f9fd875f317d,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-b472b9c5-65eb-4b45-a526-f0ebf8526de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-30cbd74e-c8ce-4a92-8df0-5fbbe7b465ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-24d42a0e-6d1b-4135-ad9f-85f501878ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-7ca23a01-409b-4e3a-83af-2ca9c727f480,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0ee8679a-a613-4245-9377-fd2dfb71a960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146177767-172.17.0.14-1598492528619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-10da59fa-6a06-4886-a5a7-2989ba15a218,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-7a7ddd15-9f31-4d45-be2a-f6e3d5dbb592,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-35ca44a5-8c57-406c-a698-e4129d28fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-9ae9f987-71c9-4a0f-8442-4e5e53686268,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-4e044ca7-d23d-4090-b1a7-ca3f7d55ef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-40ba3614-a2d7-4775-8f86-6488c8a7894c,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-02f3cd44-af74-430c-9f60-b8b998801fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-3f7fc903-ea85-4574-aa88-3a2d77c5e1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146177767-172.17.0.14-1598492528619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-10da59fa-6a06-4886-a5a7-2989ba15a218,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-7a7ddd15-9f31-4d45-be2a-f6e3d5dbb592,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-35ca44a5-8c57-406c-a698-e4129d28fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-9ae9f987-71c9-4a0f-8442-4e5e53686268,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-4e044ca7-d23d-4090-b1a7-ca3f7d55ef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-40ba3614-a2d7-4775-8f86-6488c8a7894c,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-02f3cd44-af74-430c-9f60-b8b998801fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-3f7fc903-ea85-4574-aa88-3a2d77c5e1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39450209-172.17.0.14-1598493160015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-26d2face-db80-484e-a180-14c42615c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-ece67470-d831-4778-8cb0-4e1569c81b85,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-2c853e41-7f7d-463a-96bb-2af88415f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-09168c6e-8e8f-429e-829f-7cb455714910,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-3e790617-6dd4-4f7c-8bec-1ea4db32f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-83867672-519f-4b80-a512-92d7763d90e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-33505194-2a39-484d-9640-b301ea5a1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-d7700d84-5d14-4abe-8cc6-4b821c4e048a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39450209-172.17.0.14-1598493160015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35311,DS-26d2face-db80-484e-a180-14c42615c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-ece67470-d831-4778-8cb0-4e1569c81b85,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-2c853e41-7f7d-463a-96bb-2af88415f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-09168c6e-8e8f-429e-829f-7cb455714910,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-3e790617-6dd4-4f7c-8bec-1ea4db32f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-83867672-519f-4b80-a512-92d7763d90e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-33505194-2a39-484d-9640-b301ea5a1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-d7700d84-5d14-4abe-8cc6-4b821c4e048a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42015172-172.17.0.14-1598493366546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-b631107d-09d5-41a2-82b9-60b2be61a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-551ce953-505e-4d84-887c-caa7cf09a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-1a54b820-ebd5-4fb9-8e7b-e4fb7e5fa7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-69f3712f-6541-4912-8381-4990a67ed971,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-392dd0d3-8981-422d-ae88-73a7d789d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-8be44bb8-980c-4918-b188-3301f6565d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-d2fde71f-23bb-4059-83a6-3f3a0bd320ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-0748faac-9a07-4f05-9b05-602b3a5c6f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42015172-172.17.0.14-1598493366546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-b631107d-09d5-41a2-82b9-60b2be61a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-551ce953-505e-4d84-887c-caa7cf09a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-1a54b820-ebd5-4fb9-8e7b-e4fb7e5fa7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-69f3712f-6541-4912-8381-4990a67ed971,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-392dd0d3-8981-422d-ae88-73a7d789d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-8be44bb8-980c-4918-b188-3301f6565d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-d2fde71f-23bb-4059-83a6-3f3a0bd320ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-0748faac-9a07-4f05-9b05-602b3a5c6f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013830842-172.17.0.14-1598493398607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-8dff7ce0-bc25-480a-bbb5-0505502a231c,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-e7029cbe-afa8-4aef-9a2c-336320eddff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-73783b52-2014-4b86-a245-64d7fd69fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-17b6f12b-1451-4bb9-af32-ba26af3d087c,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e8e77843-3ff5-402f-a34c-d1be52480c03,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-4fd6d4f6-7085-414a-a9ac-0651d2699aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-9813b6f8-f1f0-4123-a2c4-5368204fcbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-2a893ec6-e322-4293-af90-e9f971231a09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013830842-172.17.0.14-1598493398607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-8dff7ce0-bc25-480a-bbb5-0505502a231c,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-e7029cbe-afa8-4aef-9a2c-336320eddff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-73783b52-2014-4b86-a245-64d7fd69fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-17b6f12b-1451-4bb9-af32-ba26af3d087c,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e8e77843-3ff5-402f-a34c-d1be52480c03,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-4fd6d4f6-7085-414a-a9ac-0651d2699aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-9813b6f8-f1f0-4123-a2c4-5368204fcbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-2a893ec6-e322-4293-af90-e9f971231a09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999843336-172.17.0.14-1598493606393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-2fc9404a-c14f-4019-8e06-fc7aef5e8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d682584e-5fb0-46a4-9f34-43ac72cb3b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-aa42091e-2e4d-4756-a0be-0b360a2243a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-43c8a05f-5b1e-42ed-a5f4-d6bca831fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-a3a91c34-48aa-4489-93c6-fcb537aad0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-f8e9c9ee-d28e-47c5-8599-db38c8844a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-e3ba5cac-2b7a-4891-b485-3963953650b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-a3e3bd56-d0fd-490f-844a-9a3a8193ea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999843336-172.17.0.14-1598493606393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-2fc9404a-c14f-4019-8e06-fc7aef5e8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d682584e-5fb0-46a4-9f34-43ac72cb3b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-aa42091e-2e4d-4756-a0be-0b360a2243a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-43c8a05f-5b1e-42ed-a5f4-d6bca831fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-a3a91c34-48aa-4489-93c6-fcb537aad0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-f8e9c9ee-d28e-47c5-8599-db38c8844a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-e3ba5cac-2b7a-4891-b485-3963953650b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-a3e3bd56-d0fd-490f-844a-9a3a8193ea83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354583209-172.17.0.14-1598493712215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-7c845d58-e4cd-4849-b99e-5e89d9261ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-6bc6a58b-5161-4ad3-8cb0-64bc87e2dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-82f04f32-82cd-4b72-9fd4-db808aafce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f8935d13-0896-477a-8f13-b994332c0f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-3172fdac-67c0-4397-948b-8144689fe6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-202a23e4-956f-42d9-92f9-82bb4a34b095,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-56ec4eff-bce5-4044-be60-a6a0d54890e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-5c8d59c2-0e95-4510-bc3f-97223ac34eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354583209-172.17.0.14-1598493712215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-7c845d58-e4cd-4849-b99e-5e89d9261ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-6bc6a58b-5161-4ad3-8cb0-64bc87e2dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-82f04f32-82cd-4b72-9fd4-db808aafce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f8935d13-0896-477a-8f13-b994332c0f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-3172fdac-67c0-4397-948b-8144689fe6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-202a23e4-956f-42d9-92f9-82bb4a34b095,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-56ec4eff-bce5-4044-be60-a6a0d54890e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-5c8d59c2-0e95-4510-bc3f-97223ac34eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197793318-172.17.0.14-1598494913291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-2037a772-87c6-4ede-a72e-87c9fa62c71a,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-18c9771a-9e60-4649-8c03-73ad031830f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-38463642-3ec1-409d-b2b3-85aa821eed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c7161677-9d89-4433-a274-0f31333895cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-97a9e819-d35d-43c9-a630-144bd9e9892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-f50e96e0-e336-4fdc-a61e-77f150e84b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-db973bc8-5048-4c9b-a99b-aaed581f92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-2a4a22f4-acee-4a09-aee1-9604217dc67b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197793318-172.17.0.14-1598494913291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-2037a772-87c6-4ede-a72e-87c9fa62c71a,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-18c9771a-9e60-4649-8c03-73ad031830f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-38463642-3ec1-409d-b2b3-85aa821eed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c7161677-9d89-4433-a274-0f31333895cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-97a9e819-d35d-43c9-a630-144bd9e9892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-f50e96e0-e336-4fdc-a61e-77f150e84b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-db973bc8-5048-4c9b-a99b-aaed581f92ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-2a4a22f4-acee-4a09-aee1-9604217dc67b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616173178-172.17.0.14-1598495020443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-44b8b092-0988-4469-a616-9022d6a7f049,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-1402b659-53c8-49d6-925e-8db9e9a7ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-793eac65-d50c-4956-9dfe-d67a5ef18220,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-60ffcc9f-772a-4c83-8dd9-d71cd97410ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1f30af4e-e0e7-435c-81e7-af56f0447c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-f21f863d-8aae-4d3b-9fcb-04b01643315a,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-64a71e75-6fee-49e5-b372-b58c3e4695e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-e688e44b-9dd4-4624-9a6b-a32da74efd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616173178-172.17.0.14-1598495020443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46031,DS-44b8b092-0988-4469-a616-9022d6a7f049,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-1402b659-53c8-49d6-925e-8db9e9a7ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-793eac65-d50c-4956-9dfe-d67a5ef18220,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-60ffcc9f-772a-4c83-8dd9-d71cd97410ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1f30af4e-e0e7-435c-81e7-af56f0447c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-f21f863d-8aae-4d3b-9fcb-04b01643315a,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-64a71e75-6fee-49e5-b372-b58c3e4695e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-e688e44b-9dd4-4624-9a6b-a32da74efd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267744955-172.17.0.14-1598495052757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-aa7b2a07-f072-4cdf-883c-d3f3682a7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a37ecaee-9be1-4e43-90cb-b92bd94e48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-8c7a1b39-e5f9-4caf-8378-b14e31f22d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-1d6f0329-d2ef-4597-8ce2-67fe1fc47563,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-5b86846d-3e90-4033-86f0-2e0633a1cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7b99c314-9f5c-4436-a2eb-7124ca1be47d,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-e9e2c98a-8661-490f-ad4b-9e96e209ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-b4b01fd4-7b1d-4698-847c-fab39f80b743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267744955-172.17.0.14-1598495052757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-aa7b2a07-f072-4cdf-883c-d3f3682a7ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a37ecaee-9be1-4e43-90cb-b92bd94e48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-8c7a1b39-e5f9-4caf-8378-b14e31f22d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-1d6f0329-d2ef-4597-8ce2-67fe1fc47563,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-5b86846d-3e90-4033-86f0-2e0633a1cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7b99c314-9f5c-4436-a2eb-7124ca1be47d,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-e9e2c98a-8661-490f-ad4b-9e96e209ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-b4b01fd4-7b1d-4698-847c-fab39f80b743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659575440-172.17.0.14-1598495787744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-8863c763-bba0-4203-8fdf-9f414c39d7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-c6228d91-6670-4d44-9adf-9c755c1b2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-b42beea2-5be5-49dd-ab9c-b569c7bcc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-934de3fa-db1b-484e-96cb-08ec38bbf1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-e643b14f-e863-42f8-a79d-400079ac5e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-61c9181b-3578-49fe-8fee-0f140c67a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-85af13ee-b838-4916-8a96-727f01e65262,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-e60b9082-a945-4e6c-9844-d03851ad457b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659575440-172.17.0.14-1598495787744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-8863c763-bba0-4203-8fdf-9f414c39d7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-c6228d91-6670-4d44-9adf-9c755c1b2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-b42beea2-5be5-49dd-ab9c-b569c7bcc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-934de3fa-db1b-484e-96cb-08ec38bbf1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-e643b14f-e863-42f8-a79d-400079ac5e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-61c9181b-3578-49fe-8fee-0f140c67a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-85af13ee-b838-4916-8a96-727f01e65262,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-e60b9082-a945-4e6c-9844-d03851ad457b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376549704-172.17.0.14-1598495820404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43702,DS-c973f891-d439-482d-993a-1b937f940d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-bb2003e4-a6dd-4a85-aeab-a10000492728,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-5eed5432-f59d-47a0-a89f-3ceecb9a584f,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ad5fdf60-0b27-4d82-8ac5-c42d74344b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-0641cc5e-dc9b-48df-a568-54afe2766051,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-dd9f4e5f-85b0-40b9-aa38-976dc1dfba26,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-2af23eee-f889-45f7-bf9e-45186a846f51,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-8bfb53ba-20c9-4155-a220-eaa50d8d0f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376549704-172.17.0.14-1598495820404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43702,DS-c973f891-d439-482d-993a-1b937f940d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-bb2003e4-a6dd-4a85-aeab-a10000492728,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-5eed5432-f59d-47a0-a89f-3ceecb9a584f,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ad5fdf60-0b27-4d82-8ac5-c42d74344b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-0641cc5e-dc9b-48df-a568-54afe2766051,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-dd9f4e5f-85b0-40b9-aa38-976dc1dfba26,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-2af23eee-f889-45f7-bf9e-45186a846f51,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-8bfb53ba-20c9-4155-a220-eaa50d8d0f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036944962-172.17.0.14-1598495894325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-0f4a72e2-af7a-4398-813a-8b134de5c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-0aaba2bb-e06b-4c86-a192-3af1db7eb44e,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-61f29778-83bb-402d-a159-7ee59587177b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-7e4e4eb6-1ffd-4fd6-8d9b-b91f4505fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-3752bc30-ff6b-405f-aaef-1b6c216c8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f5b96cd7-0f18-49f2-8370-9aae2a04fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9546a7a5-0e47-4518-bf4d-bf456d630d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-da3fc128-10ff-4326-9231-f66e99bff535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036944962-172.17.0.14-1598495894325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-0f4a72e2-af7a-4398-813a-8b134de5c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-0aaba2bb-e06b-4c86-a192-3af1db7eb44e,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-61f29778-83bb-402d-a159-7ee59587177b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-7e4e4eb6-1ffd-4fd6-8d9b-b91f4505fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-3752bc30-ff6b-405f-aaef-1b6c216c8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f5b96cd7-0f18-49f2-8370-9aae2a04fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9546a7a5-0e47-4518-bf4d-bf456d630d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-da3fc128-10ff-4326-9231-f66e99bff535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5028
