reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072660677-172.17.0.19-1598581235902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43070,DS-aeb99b53-774d-4433-a497-139a98015d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-4597409e-0916-4ae8-ae28-2982d33946d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-008cf70e-7157-446d-8e65-575c7d9f341e,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-7803f46f-b9b2-415b-8f5d-915d7784c256,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-285cf6ea-1aa2-4c7a-9b00-178b7475b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-3ebb13ee-6c19-4c43-88b5-b3e90ae2e151,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-c0ac05f7-8c1e-481d-b6c1-4d5992c6a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-e7ba8f4a-abd5-485e-b141-db63306e421d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072660677-172.17.0.19-1598581235902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43070,DS-aeb99b53-774d-4433-a497-139a98015d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-4597409e-0916-4ae8-ae28-2982d33946d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-008cf70e-7157-446d-8e65-575c7d9f341e,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-7803f46f-b9b2-415b-8f5d-915d7784c256,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-285cf6ea-1aa2-4c7a-9b00-178b7475b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-3ebb13ee-6c19-4c43-88b5-b3e90ae2e151,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-c0ac05f7-8c1e-481d-b6c1-4d5992c6a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-e7ba8f4a-abd5-485e-b141-db63306e421d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224992267-172.17.0.19-1598581743228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-115badb5-fadc-4046-bfe2-ae3822cd7932,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-3bc0db2c-3432-4bb1-9c72-8b858c854d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-dc3ccb27-052a-4066-9cd5-56d6fe2eb1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-bb46b011-d5e1-4d41-b0d9-5618d494da93,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-0195bf57-4b63-493d-8cd0-343f8bd8b901,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ae432b11-a1df-459b-9571-9bdb3801e118,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-86354bff-d75b-45c4-9ecf-8a0b1fd69125,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-7b44a48d-9077-4643-8cfb-c41887fe5e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224992267-172.17.0.19-1598581743228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-115badb5-fadc-4046-bfe2-ae3822cd7932,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-3bc0db2c-3432-4bb1-9c72-8b858c854d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-dc3ccb27-052a-4066-9cd5-56d6fe2eb1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-bb46b011-d5e1-4d41-b0d9-5618d494da93,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-0195bf57-4b63-493d-8cd0-343f8bd8b901,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ae432b11-a1df-459b-9571-9bdb3801e118,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-86354bff-d75b-45c4-9ecf-8a0b1fd69125,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-7b44a48d-9077-4643-8cfb-c41887fe5e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321276812-172.17.0.19-1598581960427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-13e9f244-7a75-4592-ba7c-00439de52144,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-09f96293-d17a-4c18-ac49-d70c6b7f9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-bfa183e3-eb9f-4bae-ad04-a9bdc20c831b,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-48e52dc1-ffbf-4615-a9cc-7bd6be4aa2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-d338495d-e4cf-4811-9170-2e4507f89909,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-9129c481-872f-4a9d-af52-628ff8d4944c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-c8b3ce5e-0444-4970-a379-e998786ff15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-11000de4-e045-4677-8061-e198c945a130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321276812-172.17.0.19-1598581960427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-13e9f244-7a75-4592-ba7c-00439de52144,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-09f96293-d17a-4c18-ac49-d70c6b7f9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-bfa183e3-eb9f-4bae-ad04-a9bdc20c831b,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-48e52dc1-ffbf-4615-a9cc-7bd6be4aa2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-d338495d-e4cf-4811-9170-2e4507f89909,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-9129c481-872f-4a9d-af52-628ff8d4944c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-c8b3ce5e-0444-4970-a379-e998786ff15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-11000de4-e045-4677-8061-e198c945a130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363994187-172.17.0.19-1598582185898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-ae03e0c3-61b0-4f0e-9496-34ffa9ee70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e66bac60-63db-456d-b723-b18066b6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-d937c4bc-57bd-4058-9c63-9a64db33446b,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-aef5dc67-87c9-43db-a9d2-f608b13397a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-f55016d6-2516-4458-8b19-d9eb1bee85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-440c501e-e6ff-4821-96c8-f50dd5704abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-a0235828-a56e-400d-9df9-610abad089ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-39bf8ae3-621e-47e0-8867-98c8f494f1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363994187-172.17.0.19-1598582185898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-ae03e0c3-61b0-4f0e-9496-34ffa9ee70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e66bac60-63db-456d-b723-b18066b6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-d937c4bc-57bd-4058-9c63-9a64db33446b,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-aef5dc67-87c9-43db-a9d2-f608b13397a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-f55016d6-2516-4458-8b19-d9eb1bee85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-440c501e-e6ff-4821-96c8-f50dd5704abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-a0235828-a56e-400d-9df9-610abad089ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-39bf8ae3-621e-47e0-8867-98c8f494f1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842437779-172.17.0.19-1598582505760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-73b3750b-1c9f-402f-8d02-fecb5f2295a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-2aba00fd-c28d-4daa-99bd-3bb8c130f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-885fb66e-49b6-4518-a187-b212da31a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-94674290-dd20-4db0-ae50-6698c53e3322,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-1b934aea-12ed-443d-875a-b06d3252eae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-5f056bdd-41d4-46ad-82e7-59881b09519c,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-9412bb1e-2f6d-4959-8b70-f2a9d0e656c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-9fdcd49b-fd20-47b7-8e5e-e018f9bde272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842437779-172.17.0.19-1598582505760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-73b3750b-1c9f-402f-8d02-fecb5f2295a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-2aba00fd-c28d-4daa-99bd-3bb8c130f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-885fb66e-49b6-4518-a187-b212da31a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-94674290-dd20-4db0-ae50-6698c53e3322,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-1b934aea-12ed-443d-875a-b06d3252eae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-5f056bdd-41d4-46ad-82e7-59881b09519c,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-9412bb1e-2f6d-4959-8b70-f2a9d0e656c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-9fdcd49b-fd20-47b7-8e5e-e018f9bde272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387147250-172.17.0.19-1598582962382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36362,DS-0c8ce68e-2115-4dc8-9cef-bd14c008cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-1ebf1265-935f-4591-9e21-07780ea2436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-7b02c45b-5ca2-4f7b-af9a-241a9c4a2408,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-83f31b7e-93ce-49d2-b685-743d6d961def,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-0034c4a1-f6cf-4d0f-9828-9b3bca1b6d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d4cdd74c-4eef-4220-bb4b-ae4c1c87035c,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b8d72959-ccd3-4182-95f8-7dd3326c20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-f7d2127d-cff8-4caf-a572-bb198c7225e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387147250-172.17.0.19-1598582962382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36362,DS-0c8ce68e-2115-4dc8-9cef-bd14c008cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-1ebf1265-935f-4591-9e21-07780ea2436d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-7b02c45b-5ca2-4f7b-af9a-241a9c4a2408,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-83f31b7e-93ce-49d2-b685-743d6d961def,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-0034c4a1-f6cf-4d0f-9828-9b3bca1b6d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d4cdd74c-4eef-4220-bb4b-ae4c1c87035c,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b8d72959-ccd3-4182-95f8-7dd3326c20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-f7d2127d-cff8-4caf-a572-bb198c7225e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562623609-172.17.0.19-1598583002726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-6a5bc6f0-c805-461e-9240-c8f95a12c4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-bb342fba-059d-4b04-bc62-87840fdc76ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-776a68e8-539c-43a7-bd3a-9ddcc8bf3854,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-38206145-5468-4def-aaff-1e3d5bfcc916,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-59efb8d9-3b51-48fb-97e1-fcc3d0b8a775,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-baa1a0fd-fa80-4897-9e74-5477dcf78eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9ff4f6e1-d9db-4911-b98b-8d334915a47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0f992aa4-e8b3-4e9b-9828-138387b7fe11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562623609-172.17.0.19-1598583002726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-6a5bc6f0-c805-461e-9240-c8f95a12c4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-bb342fba-059d-4b04-bc62-87840fdc76ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-776a68e8-539c-43a7-bd3a-9ddcc8bf3854,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-38206145-5468-4def-aaff-1e3d5bfcc916,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-59efb8d9-3b51-48fb-97e1-fcc3d0b8a775,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-baa1a0fd-fa80-4897-9e74-5477dcf78eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9ff4f6e1-d9db-4911-b98b-8d334915a47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0f992aa4-e8b3-4e9b-9828-138387b7fe11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932920013-172.17.0.19-1598583794073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-e8febca1-037a-41ad-a8c1-cd23f3db9e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-be48fe90-2b9e-4271-9eb0-18475b151ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-30edb45b-e245-4dfd-8739-829b379010ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-d40e620f-8c93-4862-89c2-b6450e889c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-f854eb15-5a31-439e-b28d-7973530f3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-7a712d67-e396-43c9-be8e-0fbc3e91272b,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-e2d7f54f-d5d3-4514-8273-a8414dac6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-cc592ea1-73cf-469e-b09b-71dc46594955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932920013-172.17.0.19-1598583794073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-e8febca1-037a-41ad-a8c1-cd23f3db9e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-be48fe90-2b9e-4271-9eb0-18475b151ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-30edb45b-e245-4dfd-8739-829b379010ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-d40e620f-8c93-4862-89c2-b6450e889c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-f854eb15-5a31-439e-b28d-7973530f3f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-7a712d67-e396-43c9-be8e-0fbc3e91272b,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-e2d7f54f-d5d3-4514-8273-a8414dac6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-cc592ea1-73cf-469e-b09b-71dc46594955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785772078-172.17.0.19-1598583867792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-5dab1b92-83d2-4ed6-bc73-9d9771a5f095,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-b6dc5540-019c-4412-81a3-2b62fb5b6797,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-8042d3e7-c99a-48cc-b164-2313a610c481,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-ef227cd6-bd9b-4afe-a592-62efdcb86054,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-0c2f63bb-bdd2-4478-ba9b-68f08ec7b107,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-87f0df8b-33fe-4ae1-82ae-0c6433bb90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-d4135c2a-fd5a-4271-96de-93e803487f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-ac09e8a7-e926-4773-9112-aaf892b42caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785772078-172.17.0.19-1598583867792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-5dab1b92-83d2-4ed6-bc73-9d9771a5f095,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-b6dc5540-019c-4412-81a3-2b62fb5b6797,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-8042d3e7-c99a-48cc-b164-2313a610c481,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-ef227cd6-bd9b-4afe-a592-62efdcb86054,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-0c2f63bb-bdd2-4478-ba9b-68f08ec7b107,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-87f0df8b-33fe-4ae1-82ae-0c6433bb90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-d4135c2a-fd5a-4271-96de-93e803487f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-ac09e8a7-e926-4773-9112-aaf892b42caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695500237-172.17.0.19-1598584273012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-9043e195-9cd7-40c8-ac33-a5893c5643b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-86f078b6-7873-4df3-abbf-7ae1e008e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-a71cb7ca-6fb8-4957-b6e3-8cbd5e04a800,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-03102f38-e1fb-4d54-b3d2-13d29fb4c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-aea53e3b-516f-4922-a9cd-30202468fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e25c465e-c1ba-4e4a-9832-a321e31fef31,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-514b4cf6-7013-4ece-9cb1-89bfdaba4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-ef315f27-ee34-4358-84e2-c393c93041f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695500237-172.17.0.19-1598584273012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-9043e195-9cd7-40c8-ac33-a5893c5643b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-86f078b6-7873-4df3-abbf-7ae1e008e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-a71cb7ca-6fb8-4957-b6e3-8cbd5e04a800,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-03102f38-e1fb-4d54-b3d2-13d29fb4c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-aea53e3b-516f-4922-a9cd-30202468fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e25c465e-c1ba-4e4a-9832-a321e31fef31,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-514b4cf6-7013-4ece-9cb1-89bfdaba4e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-ef315f27-ee34-4358-84e2-c393c93041f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677304929-172.17.0.19-1598584534086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43761,DS-992a0b42-1528-42a1-acbe-72f4ec981979,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-f3a3a0db-db84-4d82-92eb-531d10a915da,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-682e2bf3-106d-4580-8493-5b26c92e74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-7eb25d2a-7e69-478e-95d1-2a5c6e2b7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-4ed75d3d-dd30-45a6-8c35-49db75d6ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-3a003b0a-e6a2-4f8a-a2a0-d586d512c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-653fae38-b6b7-4412-bc05-8644480e179b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-3d0ace0b-f9ee-424d-971b-846ca584f007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677304929-172.17.0.19-1598584534086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43761,DS-992a0b42-1528-42a1-acbe-72f4ec981979,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-f3a3a0db-db84-4d82-92eb-531d10a915da,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-682e2bf3-106d-4580-8493-5b26c92e74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-7eb25d2a-7e69-478e-95d1-2a5c6e2b7e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-4ed75d3d-dd30-45a6-8c35-49db75d6ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-3a003b0a-e6a2-4f8a-a2a0-d586d512c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-653fae38-b6b7-4412-bc05-8644480e179b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-3d0ace0b-f9ee-424d-971b-846ca584f007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788718410-172.17.0.19-1598584603813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35702,DS-672f21db-950c-4f4e-bf28-7fe01e48bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-b1c8dd76-14f3-4a67-9955-1d8407922b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-31436c28-4e6f-47e1-bf63-82ab8b253790,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a57b18d5-d43b-42d1-af35-f9217bbf3924,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-838bd9e3-bb91-458f-b612-2a93cc9c9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-07a85856-c4cb-4503-b4d3-a90f48390e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-b3db75cb-479d-4bcd-943e-57bb11d68fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-7da84949-12b8-4c2c-a7fc-9b26cd4b985f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788718410-172.17.0.19-1598584603813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35702,DS-672f21db-950c-4f4e-bf28-7fe01e48bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-b1c8dd76-14f3-4a67-9955-1d8407922b43,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-31436c28-4e6f-47e1-bf63-82ab8b253790,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a57b18d5-d43b-42d1-af35-f9217bbf3924,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-838bd9e3-bb91-458f-b612-2a93cc9c9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-07a85856-c4cb-4503-b4d3-a90f48390e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-b3db75cb-479d-4bcd-943e-57bb11d68fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-7da84949-12b8-4c2c-a7fc-9b26cd4b985f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113658570-172.17.0.19-1598584748670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39765,DS-18351c85-26ca-40f0-870d-599cd289baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9afb313b-0bdf-4794-af9d-54e3fade6a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-2c323a45-b1a7-46f7-a030-76d8986f26c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-02a7dee1-5156-4cbc-9f38-f11695fe2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-b46dc4f1-0a5e-4764-8173-459a061a09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-c0d18755-1189-4573-8f12-bee62ca237b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-069e5c45-6b48-47be-8dab-b6f994200a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-ba1f3449-8f63-4d37-b30f-c6bdee3210cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113658570-172.17.0.19-1598584748670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39765,DS-18351c85-26ca-40f0-870d-599cd289baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9afb313b-0bdf-4794-af9d-54e3fade6a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-2c323a45-b1a7-46f7-a030-76d8986f26c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-02a7dee1-5156-4cbc-9f38-f11695fe2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-b46dc4f1-0a5e-4764-8173-459a061a09d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-c0d18755-1189-4573-8f12-bee62ca237b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-069e5c45-6b48-47be-8dab-b6f994200a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-ba1f3449-8f63-4d37-b30f-c6bdee3210cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638765901-172.17.0.19-1598584819901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-a2290d98-d01e-43f1-a690-108d0d38d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-9df2b8bd-45a3-4e48-8803-9c8f98bf1358,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-c2ea0fae-9afc-4bbe-bcf2-39a4986322d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b895898c-79b1-4949-83cb-3d251977e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-e27ea4aa-ae47-4689-96c7-3d73f25a37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-66ea543e-cd55-4bef-a1f3-d4f10a278db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7582cf17-5986-43cf-898c-8b3f68c9f141,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-256c3194-dd12-48b0-8509-117be2231d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638765901-172.17.0.19-1598584819901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-a2290d98-d01e-43f1-a690-108d0d38d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-9df2b8bd-45a3-4e48-8803-9c8f98bf1358,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-c2ea0fae-9afc-4bbe-bcf2-39a4986322d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b895898c-79b1-4949-83cb-3d251977e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-e27ea4aa-ae47-4689-96c7-3d73f25a37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-66ea543e-cd55-4bef-a1f3-d4f10a278db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7582cf17-5986-43cf-898c-8b3f68c9f141,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-256c3194-dd12-48b0-8509-117be2231d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999246332-172.17.0.19-1598585486946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-40a773a2-5015-4d39-9170-2a841e2995d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-fe255f24-87c2-4c46-b8bd-a0e2250da2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-0a027453-c841-464e-9bee-d15e66a6701c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-3191a7ef-75c1-4555-89ae-c37522911699,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-b158b6a7-a781-4ea9-ada5-d3371fc6fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-6b88ceee-f16a-4672-a0be-579e7936e766,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-522bc224-9d1d-4030-b19e-c520b777047b,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-6a273f3d-5085-48b1-afad-ca326bb470ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999246332-172.17.0.19-1598585486946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-40a773a2-5015-4d39-9170-2a841e2995d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-fe255f24-87c2-4c46-b8bd-a0e2250da2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-0a027453-c841-464e-9bee-d15e66a6701c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-3191a7ef-75c1-4555-89ae-c37522911699,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-b158b6a7-a781-4ea9-ada5-d3371fc6fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-6b88ceee-f16a-4672-a0be-579e7936e766,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-522bc224-9d1d-4030-b19e-c520b777047b,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-6a273f3d-5085-48b1-afad-ca326bb470ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381558642-172.17.0.19-1598585528141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41545,DS-ac526b9a-86ec-4935-9aea-9c70bd9f8461,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-8d990c14-19d5-4803-aecc-616de43fd8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-f63dd4c6-3dce-49e7-9da0-39c94a28a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-2746f8c5-8808-4885-b124-df68dd6a7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-0279856c-a814-471a-9ecd-1fe25e996945,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-fd7f8bf8-7c87-4164-a198-d522c68a1008,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-1da23889-d3c6-4ddb-b134-64d57d89ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-bafdedc1-47b0-4103-a3f7-b61ebfeaecbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381558642-172.17.0.19-1598585528141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41545,DS-ac526b9a-86ec-4935-9aea-9c70bd9f8461,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-8d990c14-19d5-4803-aecc-616de43fd8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-f63dd4c6-3dce-49e7-9da0-39c94a28a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-2746f8c5-8808-4885-b124-df68dd6a7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-0279856c-a814-471a-9ecd-1fe25e996945,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-fd7f8bf8-7c87-4164-a198-d522c68a1008,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-1da23889-d3c6-4ddb-b134-64d57d89ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-bafdedc1-47b0-4103-a3f7-b61ebfeaecbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876693318-172.17.0.19-1598585872423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-c5434b2b-5c25-4833-98a6-e38a89807999,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-85007115-7063-4775-914f-336c902d072d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-c2908910-4d85-414b-8bc4-3bfb0c7fae21,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-758f1e4c-9fe1-4fcd-92c1-c5d6050e5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1159769a-cc9f-48e4-b1f6-e6a155023ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b6f9673a-9034-4a98-8831-c0ac5f10e352,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-c5700ba4-f406-492b-aa81-254986466d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-47512361-b856-49c0-b843-97eb0de3f99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876693318-172.17.0.19-1598585872423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-c5434b2b-5c25-4833-98a6-e38a89807999,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-85007115-7063-4775-914f-336c902d072d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-c2908910-4d85-414b-8bc4-3bfb0c7fae21,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-758f1e4c-9fe1-4fcd-92c1-c5d6050e5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1159769a-cc9f-48e4-b1f6-e6a155023ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-b6f9673a-9034-4a98-8831-c0ac5f10e352,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-c5700ba4-f406-492b-aa81-254986466d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-47512361-b856-49c0-b843-97eb0de3f99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916394159-172.17.0.19-1598586476767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35337,DS-76b1267c-bef9-4aa2-9bd0-6dceade9265d,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-0c4f395d-6be3-449a-affb-04b5893d12d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b4e999ba-5304-41c5-ab7e-d5fbc7d2ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-9c8b2553-d35a-449f-a0d6-7833cfa61b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-898f2bf0-a7eb-4b27-bbd5-8919e0d961ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-8f4a828f-aea7-493a-8721-02b83ed5f138,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-816db7f1-80fe-4ace-aa8a-c1defa40fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-998fcf76-c012-4480-b7c8-9333dbabf61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916394159-172.17.0.19-1598586476767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35337,DS-76b1267c-bef9-4aa2-9bd0-6dceade9265d,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-0c4f395d-6be3-449a-affb-04b5893d12d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b4e999ba-5304-41c5-ab7e-d5fbc7d2ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-9c8b2553-d35a-449f-a0d6-7833cfa61b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-898f2bf0-a7eb-4b27-bbd5-8919e0d961ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-8f4a828f-aea7-493a-8721-02b83ed5f138,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-816db7f1-80fe-4ace-aa8a-c1defa40fb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-998fcf76-c012-4480-b7c8-9333dbabf61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 50
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118188804-172.17.0.19-1598586551651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-e657d481-793f-4260-a0a8-9230ff0c14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-40964ba1-40e5-4ff1-9598-be0863390598,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-826de244-9dcb-415d-96d2-f40e8d804a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-1344eac4-2b81-4f6e-9977-7aaa032d3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-d803c1f8-f55b-480d-98ec-e841c787ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-4c36fb43-e678-4344-aaa9-c9ee5bd0f847,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-75149b37-d909-4b8b-98ac-cbcf588db6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-654da55b-ca05-4f6f-93d6-4787de5bd81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118188804-172.17.0.19-1598586551651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-e657d481-793f-4260-a0a8-9230ff0c14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-40964ba1-40e5-4ff1-9598-be0863390598,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-826de244-9dcb-415d-96d2-f40e8d804a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-1344eac4-2b81-4f6e-9977-7aaa032d3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-d803c1f8-f55b-480d-98ec-e841c787ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-4c36fb43-e678-4344-aaa9-c9ee5bd0f847,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-75149b37-d909-4b8b-98ac-cbcf588db6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-654da55b-ca05-4f6f-93d6-4787de5bd81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5461
