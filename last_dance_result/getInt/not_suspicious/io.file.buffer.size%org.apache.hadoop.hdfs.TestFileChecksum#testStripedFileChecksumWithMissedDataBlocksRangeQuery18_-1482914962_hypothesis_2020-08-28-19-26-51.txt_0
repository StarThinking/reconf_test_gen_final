reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949938432-172.17.0.18-1598643022373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-589c25bc-b08a-4525-91ff-483fb57f4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-10beaaaf-5192-474b-8506-5fb7f2938103,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-f353129c-182d-4a5e-b467-bb40c0f8fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-7b9c60d0-ea32-40a5-8f24-a7f063b60a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-03901a96-d00c-4dfc-a17e-13c93201d669,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-989666c7-16e5-4a00-9126-cb984776b368,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-27ac4482-5cdb-40cd-8aea-4d7373c3caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-b136d52d-412c-4936-b82a-29d9032f016a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949938432-172.17.0.18-1598643022373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-589c25bc-b08a-4525-91ff-483fb57f4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-10beaaaf-5192-474b-8506-5fb7f2938103,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-f353129c-182d-4a5e-b467-bb40c0f8fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-7b9c60d0-ea32-40a5-8f24-a7f063b60a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-03901a96-d00c-4dfc-a17e-13c93201d669,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-989666c7-16e5-4a00-9126-cb984776b368,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-27ac4482-5cdb-40cd-8aea-4d7373c3caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-b136d52d-412c-4936-b82a-29d9032f016a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321034786-172.17.0.18-1598643278131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-d71530b4-223a-49cf-a1b7-36e45c9b3bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7b4cba8a-0336-4575-8240-a9b72da9e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-28504b62-b8ba-4479-a6bc-b88088bdc4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-5eba1166-b83f-435b-9cdc-6b8bd73324aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7cad004f-2344-47e4-bacf-705f293e2b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-34a1e2f2-64b0-479e-be25-ce19852e0f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-8e327f74-dc6c-4f2f-af07-f76d4d4d7347,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-1d9978c4-7477-4523-8323-4d82f15cd393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321034786-172.17.0.18-1598643278131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-d71530b4-223a-49cf-a1b7-36e45c9b3bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7b4cba8a-0336-4575-8240-a9b72da9e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-28504b62-b8ba-4479-a6bc-b88088bdc4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-5eba1166-b83f-435b-9cdc-6b8bd73324aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7cad004f-2344-47e4-bacf-705f293e2b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-34a1e2f2-64b0-479e-be25-ce19852e0f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-8e327f74-dc6c-4f2f-af07-f76d4d4d7347,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-1d9978c4-7477-4523-8323-4d82f15cd393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741001045-172.17.0.18-1598643718583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-37047e26-1899-49e6-967c-a69caf402021,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-10ce11fa-588e-4108-aa6f-de95fdf972f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-738fcf2e-340d-430a-b644-3b19ea0c6da5,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-b75a1631-35f7-42e9-88b3-e90e51361b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-abfafecd-2708-43e7-b44a-ed5fb18b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-6c345c49-fd51-4c9b-9e21-45a058485c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-5522ab24-3b80-4289-8711-36c9608a268b,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-94c76fd2-5d3e-424e-b890-328d90a9b312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741001045-172.17.0.18-1598643718583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-37047e26-1899-49e6-967c-a69caf402021,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-10ce11fa-588e-4108-aa6f-de95fdf972f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-738fcf2e-340d-430a-b644-3b19ea0c6da5,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-b75a1631-35f7-42e9-88b3-e90e51361b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-abfafecd-2708-43e7-b44a-ed5fb18b74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-6c345c49-fd51-4c9b-9e21-45a058485c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-5522ab24-3b80-4289-8711-36c9608a268b,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-94c76fd2-5d3e-424e-b890-328d90a9b312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633188708-172.17.0.18-1598643982982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-5212716c-0349-4f43-906f-9a52a044dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-88487509-b185-422f-8f0b-019127486e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-4f1b79f3-c031-43ba-a648-049e47960994,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3f76c978-abb4-4ed9-babc-b97d353448ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-5ca718eb-5610-4983-967a-b75f3d940273,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-3468c15d-a0a9-408b-ac18-edfe3e11c37a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-ddfda92b-ef7a-4a3c-aef9-163eb5601f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-3cf12ee9-24d9-4d04-bd79-d3b8d93405f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633188708-172.17.0.18-1598643982982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-5212716c-0349-4f43-906f-9a52a044dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-88487509-b185-422f-8f0b-019127486e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-4f1b79f3-c031-43ba-a648-049e47960994,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3f76c978-abb4-4ed9-babc-b97d353448ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-5ca718eb-5610-4983-967a-b75f3d940273,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-3468c15d-a0a9-408b-ac18-edfe3e11c37a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-ddfda92b-ef7a-4a3c-aef9-163eb5601f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-3cf12ee9-24d9-4d04-bd79-d3b8d93405f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482389733-172.17.0.18-1598645730681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-5ac6a6d9-2833-4620-8952-5675f951dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-7292fd7c-c4c4-4813-935a-524a95920292,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-ace44768-16b7-4513-9f22-1ffc4bb872f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c20e467f-2844-4204-9a86-cac7b3848f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-7b558609-b03b-471f-8509-39b6b4ceac53,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-260b07bb-e652-40b5-829e-670c43293cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-f320c230-c787-45de-9841-e9577c42814a,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-adb3713c-33c9-4e32-9158-703a10548a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482389733-172.17.0.18-1598645730681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-5ac6a6d9-2833-4620-8952-5675f951dcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-7292fd7c-c4c4-4813-935a-524a95920292,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-ace44768-16b7-4513-9f22-1ffc4bb872f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c20e467f-2844-4204-9a86-cac7b3848f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-7b558609-b03b-471f-8509-39b6b4ceac53,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-260b07bb-e652-40b5-829e-670c43293cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-f320c230-c787-45de-9841-e9577c42814a,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-adb3713c-33c9-4e32-9158-703a10548a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566103977-172.17.0.18-1598645765540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-2075d705-104d-46d1-9fc1-26e112e1b080,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-5cc4bfd5-29ca-470c-a8fc-672b54775197,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-6e79425f-c666-4fd6-bbd7-abdf33ce75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-686b8a7f-82c0-41d7-8578-31ccf2cf8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-5ec0a817-fbad-45ac-9a42-5372b104b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-9f88f892-0f2e-4ade-a6dd-c70cc9fd3997,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c1996210-9a4b-450e-9f4e-cb83654a414e,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-036494e7-a89c-45ea-be7e-cd1dd362ada9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566103977-172.17.0.18-1598645765540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-2075d705-104d-46d1-9fc1-26e112e1b080,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-5cc4bfd5-29ca-470c-a8fc-672b54775197,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-6e79425f-c666-4fd6-bbd7-abdf33ce75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-686b8a7f-82c0-41d7-8578-31ccf2cf8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-5ec0a817-fbad-45ac-9a42-5372b104b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-9f88f892-0f2e-4ade-a6dd-c70cc9fd3997,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c1996210-9a4b-450e-9f4e-cb83654a414e,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-036494e7-a89c-45ea-be7e-cd1dd362ada9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480272696-172.17.0.18-1598645879596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-d9eacc5b-e9ed-4a3d-b217-f7cbe28acb03,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-49f88361-1756-4efb-a83f-711c6679d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-52d6d84b-5e78-4f3d-b9da-10e0f7b6e7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-a28860f6-8248-4fd1-85f6-5ddccf298b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-83f225e1-0738-4c3c-a164-e4d2297b0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-d3ccad30-7201-44b0-b646-3ca10138f723,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-ad7b646c-b08a-4373-86fa-8f49d5daf202,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-f978c876-5191-4c3b-8a6d-eb13291b943a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480272696-172.17.0.18-1598645879596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-d9eacc5b-e9ed-4a3d-b217-f7cbe28acb03,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-49f88361-1756-4efb-a83f-711c6679d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-52d6d84b-5e78-4f3d-b9da-10e0f7b6e7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-a28860f6-8248-4fd1-85f6-5ddccf298b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-83f225e1-0738-4c3c-a164-e4d2297b0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-d3ccad30-7201-44b0-b646-3ca10138f723,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-ad7b646c-b08a-4373-86fa-8f49d5daf202,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-f978c876-5191-4c3b-8a6d-eb13291b943a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469559267-172.17.0.18-1598645943834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-05b93392-8304-40e4-8b49-41d8258b0972,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-ad9349e1-9fe8-4506-8ca2-9bd3dd971fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-a2e84e6e-3626-44c0-bb81-36c1a8b0e120,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-86ce8bea-0a74-4757-9e72-e40222448ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-6e8e220a-8dc4-4aae-9121-3afff914373c,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-61d7a147-a98f-4d05-9d3c-5a89bad7cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-d017f19b-b669-49e6-b761-410f7f7894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-91f7400b-cbb5-4008-94ea-dfc1fbfcf353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469559267-172.17.0.18-1598645943834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-05b93392-8304-40e4-8b49-41d8258b0972,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-ad9349e1-9fe8-4506-8ca2-9bd3dd971fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-a2e84e6e-3626-44c0-bb81-36c1a8b0e120,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-86ce8bea-0a74-4757-9e72-e40222448ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-6e8e220a-8dc4-4aae-9121-3afff914373c,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-61d7a147-a98f-4d05-9d3c-5a89bad7cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-d017f19b-b669-49e6-b761-410f7f7894e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-91f7400b-cbb5-4008-94ea-dfc1fbfcf353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142194409-172.17.0.18-1598646082441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-09b894d1-88d9-40d5-b194-7541aa47fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-ff56513a-a03e-47b1-b843-1c0e2f96ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-df11b185-2753-4973-9642-502024480b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6998e11d-a534-4cae-b4c9-59d9f532c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-12f479f5-4d26-4caf-b558-caeb9ca5b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-6c47d318-590b-46c3-be73-2177de55736b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-b5f6ebcb-a1e8-4f24-bc2c-ad4eb3b9710a,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-bfbc4e15-a56f-423a-ac6c-11fd9b8358f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142194409-172.17.0.18-1598646082441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-09b894d1-88d9-40d5-b194-7541aa47fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-ff56513a-a03e-47b1-b843-1c0e2f96ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-df11b185-2753-4973-9642-502024480b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6998e11d-a534-4cae-b4c9-59d9f532c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-12f479f5-4d26-4caf-b558-caeb9ca5b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-6c47d318-590b-46c3-be73-2177de55736b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-b5f6ebcb-a1e8-4f24-bc2c-ad4eb3b9710a,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-bfbc4e15-a56f-423a-ac6c-11fd9b8358f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525324145-172.17.0.18-1598646160084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-404584af-a87d-4c7b-83b8-b8aaf49b8220,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ddc4a960-ebb9-4764-9dee-4fb95b8efeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-ca7044c8-1a98-4386-8a50-8d6ce60a148d,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-dfa69690-4069-4ec5-ba8d-833d53e6019f,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-d1688ddb-0c03-49a8-a878-20f856849423,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-43e5f447-606d-4792-8363-51c8e1ca0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-2376c67e-bb23-43d0-aeb0-76dd30815144,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-5b39f057-0c2e-40f5-a9ee-2d9a749e2a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525324145-172.17.0.18-1598646160084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-404584af-a87d-4c7b-83b8-b8aaf49b8220,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-ddc4a960-ebb9-4764-9dee-4fb95b8efeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-ca7044c8-1a98-4386-8a50-8d6ce60a148d,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-dfa69690-4069-4ec5-ba8d-833d53e6019f,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-d1688ddb-0c03-49a8-a878-20f856849423,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-43e5f447-606d-4792-8363-51c8e1ca0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-2376c67e-bb23-43d0-aeb0-76dd30815144,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-5b39f057-0c2e-40f5-a9ee-2d9a749e2a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754805729-172.17.0.18-1598646895292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-c3481e29-20d8-43c9-9a56-b726c5fbd852,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-ba775131-fee5-4aa7-a719-0283d4605587,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-9062b57e-f734-41e0-9bb5-8d1e687dbe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a41d678-d39b-454d-9ea9-c94d0f1bab34,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-09ba3ebd-08ba-411b-b823-83d8760c5ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-32442d71-0d2d-48c7-8f23-41107dfa3133,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-81ca18ff-67f6-46ad-a839-5879d199c2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-d3bce509-61e7-4990-a21f-260e11da5718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754805729-172.17.0.18-1598646895292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-c3481e29-20d8-43c9-9a56-b726c5fbd852,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-ba775131-fee5-4aa7-a719-0283d4605587,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-9062b57e-f734-41e0-9bb5-8d1e687dbe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-8a41d678-d39b-454d-9ea9-c94d0f1bab34,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-09ba3ebd-08ba-411b-b823-83d8760c5ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-32442d71-0d2d-48c7-8f23-41107dfa3133,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-81ca18ff-67f6-46ad-a839-5879d199c2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-d3bce509-61e7-4990-a21f-260e11da5718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502774754-172.17.0.18-1598647055129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-fb0ec0b0-0347-4538-8a4c-9adf42272a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-7d03ee2e-4a97-4801-b3e5-cccd58fe848b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-33719c12-485c-4a14-bea4-90be1d900a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-fa39715e-b6e0-42f4-8433-102f9828a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-57a16091-5ad0-4eb0-9bf1-03205619a348,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bf5b0cb2-8a1b-4e66-979f-13069977ce52,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-6d7cab09-ad77-45d4-80bf-0150fc2bfc20,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-2dffe39d-1892-4355-93d5-ea98b5cfc0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502774754-172.17.0.18-1598647055129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-fb0ec0b0-0347-4538-8a4c-9adf42272a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-7d03ee2e-4a97-4801-b3e5-cccd58fe848b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-33719c12-485c-4a14-bea4-90be1d900a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-fa39715e-b6e0-42f4-8433-102f9828a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-57a16091-5ad0-4eb0-9bf1-03205619a348,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-bf5b0cb2-8a1b-4e66-979f-13069977ce52,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-6d7cab09-ad77-45d4-80bf-0150fc2bfc20,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-2dffe39d-1892-4355-93d5-ea98b5cfc0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923358478-172.17.0.18-1598647206337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-cb523e65-b8c3-427b-b3d6-012947bac675,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1cf3c073-296c-44fe-9121-a3e3774a2656,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-9ecb1d05-dd3e-4c9f-8053-ad0517781161,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-f4e4f7d6-53a6-44e5-82e9-a0293d91da93,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-ee0cc66c-d447-4aaf-ad59-4ed263eabcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-494d1c77-7423-428f-bf97-76dc2abaae03,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-ca0e46d7-b524-4565-a7c1-a399672d57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-3fa860a9-e173-4ed9-a9f5-c0ed6bbf6ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923358478-172.17.0.18-1598647206337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-cb523e65-b8c3-427b-b3d6-012947bac675,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1cf3c073-296c-44fe-9121-a3e3774a2656,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-9ecb1d05-dd3e-4c9f-8053-ad0517781161,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-f4e4f7d6-53a6-44e5-82e9-a0293d91da93,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-ee0cc66c-d447-4aaf-ad59-4ed263eabcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-494d1c77-7423-428f-bf97-76dc2abaae03,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-ca0e46d7-b524-4565-a7c1-a399672d57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-3fa860a9-e173-4ed9-a9f5-c0ed6bbf6ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001443865-172.17.0.18-1598647238205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-4b2e855c-fd67-437b-9b20-e2651371eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-6be508e0-a3df-46a0-8b6a-f6495061e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-49d9448c-4bb2-41bd-b951-7df0cda57b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-87f424ae-053f-4263-ba99-2e8dbc82d18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-0b8b8ffc-f300-4330-a5df-c68bd818d395,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-547986c1-63df-4440-bb3c-1be63d87a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-d3410a7f-84f2-47e6-b9c4-0e3f2a7247ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-591eb0cd-3830-449f-b3c1-50d7fe4aa4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001443865-172.17.0.18-1598647238205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-4b2e855c-fd67-437b-9b20-e2651371eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-6be508e0-a3df-46a0-8b6a-f6495061e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-49d9448c-4bb2-41bd-b951-7df0cda57b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-87f424ae-053f-4263-ba99-2e8dbc82d18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-0b8b8ffc-f300-4330-a5df-c68bd818d395,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-547986c1-63df-4440-bb3c-1be63d87a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-d3410a7f-84f2-47e6-b9c4-0e3f2a7247ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-591eb0cd-3830-449f-b3c1-50d7fe4aa4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563381091-172.17.0.18-1598647381285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46479,DS-be43e420-5886-4310-9f8c-80fdc319c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-8e143d61-48f0-49ba-a497-aa86562576db,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-5d8c0369-8486-42e8-aa65-840831ea3434,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-23127478-2d94-4fbc-abcb-246253e268ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-42bb3e2e-535c-4034-8ee4-f102bf27f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-d7d1d83c-08f0-41fb-9812-0db9ecade303,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-69c97d46-351a-439d-91dc-05c899c7c529,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-fde36468-0d5f-4fe1-b9ad-10f9314d3dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563381091-172.17.0.18-1598647381285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46479,DS-be43e420-5886-4310-9f8c-80fdc319c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-8e143d61-48f0-49ba-a497-aa86562576db,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-5d8c0369-8486-42e8-aa65-840831ea3434,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-23127478-2d94-4fbc-abcb-246253e268ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-42bb3e2e-535c-4034-8ee4-f102bf27f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-d7d1d83c-08f0-41fb-9812-0db9ecade303,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-69c97d46-351a-439d-91dc-05c899c7c529,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-fde36468-0d5f-4fe1-b9ad-10f9314d3dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5444
