reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438109472-172.17.0.11-1598609616134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-4429a384-36a7-45f2-966c-e6b02d193191,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-d9cdf5e1-663e-4828-88a5-a52491604219,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-ca6bace7-ae1f-4c4c-8f6a-65954a78c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-5f3c215e-8a25-4d3d-953a-9c28015cc391,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-e8ecbba3-cc17-4490-8320-9f375be9a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-ee7743aa-e815-4dbc-b859-9ef51b853789,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-962bee33-b3bf-454a-9564-d68fff735153,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-85199b85-309c-4846-9b79-1d3447d9a815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438109472-172.17.0.11-1598609616134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-4429a384-36a7-45f2-966c-e6b02d193191,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-d9cdf5e1-663e-4828-88a5-a52491604219,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-ca6bace7-ae1f-4c4c-8f6a-65954a78c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-5f3c215e-8a25-4d3d-953a-9c28015cc391,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-e8ecbba3-cc17-4490-8320-9f375be9a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-ee7743aa-e815-4dbc-b859-9ef51b853789,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-962bee33-b3bf-454a-9564-d68fff735153,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-85199b85-309c-4846-9b79-1d3447d9a815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126532477-172.17.0.11-1598609654626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-0ef2b191-fbb0-498a-ba80-4ab1586fe971,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-455d6468-7bab-495c-8d84-15c2d864822c,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-03811b2d-1652-45ca-9cb4-627a77c49646,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-17abf43a-15be-41a6-83ea-d4935c6316b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-aa72dca0-d6b1-4bf8-9894-b2f8a5cf9677,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0c5b4b6d-b64d-4989-98ad-4afe613258ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-a04ab557-ceec-487f-ac97-ea274551b682,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a62acaa8-5d0f-4752-a902-6710b400842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126532477-172.17.0.11-1598609654626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-0ef2b191-fbb0-498a-ba80-4ab1586fe971,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-455d6468-7bab-495c-8d84-15c2d864822c,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-03811b2d-1652-45ca-9cb4-627a77c49646,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-17abf43a-15be-41a6-83ea-d4935c6316b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-aa72dca0-d6b1-4bf8-9894-b2f8a5cf9677,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0c5b4b6d-b64d-4989-98ad-4afe613258ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-a04ab557-ceec-487f-ac97-ea274551b682,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a62acaa8-5d0f-4752-a902-6710b400842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852361152-172.17.0.11-1598609691556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-b264037f-5406-4504-b10c-aaab6975ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-72a69f02-d358-4f20-9dc8-18c0f23e84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-150c6420-f39d-41f7-8ba9-659971fd366e,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-d39ed94d-7e8c-4870-9efc-bc9c3ff6130b,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-dcf6a1b2-204d-4294-9f95-9a92a2e334e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-0522a130-51ec-4d63-9a8d-93173292a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-de81146a-c55f-41a4-8f1d-b6a779f220a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-74dfa2cb-b9ef-4580-aa81-ba8e65363509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852361152-172.17.0.11-1598609691556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-b264037f-5406-4504-b10c-aaab6975ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-72a69f02-d358-4f20-9dc8-18c0f23e84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-150c6420-f39d-41f7-8ba9-659971fd366e,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-d39ed94d-7e8c-4870-9efc-bc9c3ff6130b,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-dcf6a1b2-204d-4294-9f95-9a92a2e334e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-0522a130-51ec-4d63-9a8d-93173292a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-de81146a-c55f-41a4-8f1d-b6a779f220a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-74dfa2cb-b9ef-4580-aa81-ba8e65363509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565245161-172.17.0.11-1598610116848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9c0be5e4-5784-4b9f-997a-60369f0b314b,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-574c6556-ef2b-4f3c-b51d-2d6214489b12,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-69816cfc-564b-40fe-8f82-f43507968ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-fbcdc05b-0388-4ff8-b386-a434d0a51b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-e3cb99af-5b6c-4eee-a777-02b4ad6e2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-b63d8011-3276-4e60-b49c-af52b8ed75e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-c1d5c317-7c6a-4a46-96d2-b71fe34d3558,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-b6717c1f-0c48-45f4-b571-e2fe2e74ef61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565245161-172.17.0.11-1598610116848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43107,DS-9c0be5e4-5784-4b9f-997a-60369f0b314b,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-574c6556-ef2b-4f3c-b51d-2d6214489b12,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-69816cfc-564b-40fe-8f82-f43507968ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-fbcdc05b-0388-4ff8-b386-a434d0a51b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-e3cb99af-5b6c-4eee-a777-02b4ad6e2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-b63d8011-3276-4e60-b49c-af52b8ed75e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-c1d5c317-7c6a-4a46-96d2-b71fe34d3558,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-b6717c1f-0c48-45f4-b571-e2fe2e74ef61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589065449-172.17.0.11-1598610565190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-2b909439-ffbd-4115-87a4-116b9d20cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-89a398e3-75ad-4780-a076-ae598b969b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-c3b55f46-a2ea-42c5-a757-0100918ac8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-f1b22556-5d19-4488-9075-1ebef33ccf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-e69ab4be-2b45-44e9-9c69-7cc7b2801e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-98b38b4e-25ac-400a-8785-8d282b54ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-ae57839b-a9a3-4fd9-9092-09d56a4c7f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-e5176cee-22a9-426c-913a-2f94599d0e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589065449-172.17.0.11-1598610565190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-2b909439-ffbd-4115-87a4-116b9d20cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-89a398e3-75ad-4780-a076-ae598b969b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-c3b55f46-a2ea-42c5-a757-0100918ac8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-f1b22556-5d19-4488-9075-1ebef33ccf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-e69ab4be-2b45-44e9-9c69-7cc7b2801e42,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-98b38b4e-25ac-400a-8785-8d282b54ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-ae57839b-a9a3-4fd9-9092-09d56a4c7f50,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-e5176cee-22a9-426c-913a-2f94599d0e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396398540-172.17.0.11-1598610698403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-42dea336-1b9f-4f5f-af40-57af6d968c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-cfd327fb-08c0-4b44-b3ae-e024bb10483d,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-de7f4e6f-05d3-4bea-847b-d821b08a6b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-bcc8bb53-cb82-4ab1-bd57-4b7546a78241,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2a9c8844-18aa-466f-b3c0-84d6116e16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-3112cec0-4c90-467f-a08e-191bf29bc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-06ec7b75-ab84-4c07-a757-1e3da8a87154,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-1039dc54-c111-4a39-b9a7-1ea777255127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396398540-172.17.0.11-1598610698403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-42dea336-1b9f-4f5f-af40-57af6d968c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-cfd327fb-08c0-4b44-b3ae-e024bb10483d,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-de7f4e6f-05d3-4bea-847b-d821b08a6b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-bcc8bb53-cb82-4ab1-bd57-4b7546a78241,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2a9c8844-18aa-466f-b3c0-84d6116e16ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-3112cec0-4c90-467f-a08e-191bf29bc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-06ec7b75-ab84-4c07-a757-1e3da8a87154,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-1039dc54-c111-4a39-b9a7-1ea777255127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212989539-172.17.0.11-1598612051325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-f3169d73-b080-4938-8804-b15d0e05e423,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-262f8908-8a96-4b58-8a42-f05fa0fb4a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-d4e281a9-1361-46f5-a080-1e93e20379c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-b0ea5a3b-33cc-4d22-a871-bfb046d3899f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c7836453-06f2-4af4-ab6b-6f64dc3f0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-600dc1d5-68d2-49b0-b274-504ccf77b28a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-cae58b12-c229-4a04-8de8-62942a8b61bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-5bb5f161-968b-4fd7-ad30-f267c7b3a747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212989539-172.17.0.11-1598612051325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-f3169d73-b080-4938-8804-b15d0e05e423,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-262f8908-8a96-4b58-8a42-f05fa0fb4a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-d4e281a9-1361-46f5-a080-1e93e20379c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-b0ea5a3b-33cc-4d22-a871-bfb046d3899f,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c7836453-06f2-4af4-ab6b-6f64dc3f0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-600dc1d5-68d2-49b0-b274-504ccf77b28a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-cae58b12-c229-4a04-8de8-62942a8b61bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-5bb5f161-968b-4fd7-ad30-f267c7b3a747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239402622-172.17.0.11-1598613080897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-66207610-b485-458b-b9db-57a93cee5304,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-97ed0098-37f6-4610-9a62-c4a542f3b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-a334f226-dfe3-4ef4-89ce-2d9aaa39be59,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-cf122a32-1227-4388-843d-47733b008d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fcf03f09-c856-4db4-8224-9bb30433e072,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-6fdd6519-05a1-4102-8253-bdde5ce3b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-02607507-7540-421b-b43a-e681ee58946c,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-18909532-9e5c-4447-aa49-b6946ff0cd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239402622-172.17.0.11-1598613080897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-66207610-b485-458b-b9db-57a93cee5304,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-97ed0098-37f6-4610-9a62-c4a542f3b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-a334f226-dfe3-4ef4-89ce-2d9aaa39be59,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-cf122a32-1227-4388-843d-47733b008d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fcf03f09-c856-4db4-8224-9bb30433e072,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-6fdd6519-05a1-4102-8253-bdde5ce3b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-02607507-7540-421b-b43a-e681ee58946c,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-18909532-9e5c-4447-aa49-b6946ff0cd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406789602-172.17.0.11-1598613573133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-a89b6d5d-6f39-433e-ad49-d483097025c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b067db9f-f40e-49ea-93ae-4659c121ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-b1ac961b-7ee1-4def-8d7d-e00a7eab10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d541e7ea-455a-41c2-bbe2-f31472341cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-8ab9f65c-1365-46ee-80de-eb841f6d7da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-6d16005d-95ce-457b-b260-023ed9fec134,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-17491385-d88a-413f-9804-1835f9c8591d,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-b8149749-0c64-450f-8f92-a1904ea71a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406789602-172.17.0.11-1598613573133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-a89b6d5d-6f39-433e-ad49-d483097025c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b067db9f-f40e-49ea-93ae-4659c121ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-b1ac961b-7ee1-4def-8d7d-e00a7eab10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-d541e7ea-455a-41c2-bbe2-f31472341cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-8ab9f65c-1365-46ee-80de-eb841f6d7da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-6d16005d-95ce-457b-b260-023ed9fec134,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-17491385-d88a-413f-9804-1835f9c8591d,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-b8149749-0c64-450f-8f92-a1904ea71a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324352469-172.17.0.11-1598613948803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-8b122537-13ac-41dd-928e-4ad3059d9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-df874c56-290d-4aaa-82a2-b5e0253c3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-b6630dec-3b36-47f7-b2fa-3f04c87e80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-dca4ec8c-14f4-4824-92b5-35b4221ef3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-fce2736a-712b-4a0c-8c26-e365e1747be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-fd0420c1-a3e7-40c0-b8e7-bd0531f5f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-0610391c-5e10-448e-826b-96732c546b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-a8f65bdd-9a5f-43d2-9e16-56ee6be46152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324352469-172.17.0.11-1598613948803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-8b122537-13ac-41dd-928e-4ad3059d9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-df874c56-290d-4aaa-82a2-b5e0253c3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-b6630dec-3b36-47f7-b2fa-3f04c87e80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-dca4ec8c-14f4-4824-92b5-35b4221ef3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-fce2736a-712b-4a0c-8c26-e365e1747be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-fd0420c1-a3e7-40c0-b8e7-bd0531f5f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-0610391c-5e10-448e-826b-96732c546b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-a8f65bdd-9a5f-43d2-9e16-56ee6be46152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612781738-172.17.0.11-1598614358840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-b42bda36-72a8-4b86-957d-7da446049ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-64bbba6b-a052-4486-bc9f-81ef99d79a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-4eb18405-cd6b-4d45-bf80-b5b2abea0154,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-e994269b-96bb-4277-a6cc-458422b69728,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-fc327a3c-2e5b-487d-ab76-32e52e7595eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-45ec8630-dffb-4a11-9c42-5abe0c907a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-a68d4798-0bb4-4fed-be7d-54b5f082653c,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-b7b29b76-abc5-4c1b-8687-2b90c7485a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612781738-172.17.0.11-1598614358840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-b42bda36-72a8-4b86-957d-7da446049ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-64bbba6b-a052-4486-bc9f-81ef99d79a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-4eb18405-cd6b-4d45-bf80-b5b2abea0154,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-e994269b-96bb-4277-a6cc-458422b69728,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-fc327a3c-2e5b-487d-ab76-32e52e7595eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-45ec8630-dffb-4a11-9c42-5abe0c907a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-a68d4798-0bb4-4fed-be7d-54b5f082653c,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-b7b29b76-abc5-4c1b-8687-2b90c7485a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299016183-172.17.0.11-1598614394508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-8603c83f-b646-4096-9f03-4dc12841567c,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-9abcf810-262b-40a0-84cd-9f7a15ad1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-e7184131-f169-4148-8cc1-ea33dab9b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-6ce339c9-ba81-4404-b954-0fb46120f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-4eafdc08-5052-41d6-b12f-849849b4c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-53d4a276-882b-4f1f-81d5-09e40dbdf19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-351dc6da-a4d5-43d9-af29-886b525d1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-b93d8fee-f826-462c-bc04-659aa73c59c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299016183-172.17.0.11-1598614394508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-8603c83f-b646-4096-9f03-4dc12841567c,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-9abcf810-262b-40a0-84cd-9f7a15ad1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-e7184131-f169-4148-8cc1-ea33dab9b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-6ce339c9-ba81-4404-b954-0fb46120f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-4eafdc08-5052-41d6-b12f-849849b4c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-53d4a276-882b-4f1f-81d5-09e40dbdf19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-351dc6da-a4d5-43d9-af29-886b525d1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-b93d8fee-f826-462c-bc04-659aa73c59c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569070275-172.17.0.11-1598614581763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-efd3ee5b-ffe7-4127-af97-9a6b012356f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-bba0edc8-4cbf-4d77-bfa1-c0cc336c099e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-0b89aa6f-89e6-4750-9f2a-ae2bec28a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-8c796433-ce75-4a51-a68b-7cd051a376c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-858cf7e1-5b0a-483a-bfd1-c20311734efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-45c13655-6993-40ee-8118-3eae89d3df01,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-780f354f-80d1-4f2d-b7d9-43d91e55107e,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-03bc284c-168d-4abd-8f7d-c4d66d77f8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569070275-172.17.0.11-1598614581763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-efd3ee5b-ffe7-4127-af97-9a6b012356f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-bba0edc8-4cbf-4d77-bfa1-c0cc336c099e,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-0b89aa6f-89e6-4750-9f2a-ae2bec28a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-8c796433-ce75-4a51-a68b-7cd051a376c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-858cf7e1-5b0a-483a-bfd1-c20311734efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-45c13655-6993-40ee-8118-3eae89d3df01,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-780f354f-80d1-4f2d-b7d9-43d91e55107e,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-03bc284c-168d-4abd-8f7d-c4d66d77f8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5311
