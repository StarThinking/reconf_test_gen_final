reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915071157-172.17.0.2-1598554206092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-a64bee15-920a-4df0-a90d-723fcee111bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-b1b11535-7420-4ee6-a0dd-4f7755524ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-e0d957e9-f81d-413c-88a7-469370dbe68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-237e6496-204a-4eb6-89c7-47ae1016e49e,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-f946e7ad-c305-40d9-a26d-644f38f60865,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-0a66b62b-d6d7-4166-936f-450b023b1713,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-525edc70-c3f4-49b6-b1ad-20534433a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-a38045bb-37f2-47f9-9b3b-cb44083591d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915071157-172.17.0.2-1598554206092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-a64bee15-920a-4df0-a90d-723fcee111bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-b1b11535-7420-4ee6-a0dd-4f7755524ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-e0d957e9-f81d-413c-88a7-469370dbe68e,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-237e6496-204a-4eb6-89c7-47ae1016e49e,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-f946e7ad-c305-40d9-a26d-644f38f60865,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-0a66b62b-d6d7-4166-936f-450b023b1713,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-525edc70-c3f4-49b6-b1ad-20534433a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-a38045bb-37f2-47f9-9b3b-cb44083591d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095064309-172.17.0.2-1598554418741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-29268604-0f15-4098-9c39-b35423a801ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-7e2f3c6a-29e4-4e0f-bbdd-058cbf9408cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-16670603-c2b0-4bec-9e61-b342fc31fc32,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-0719784a-1f36-4d4f-b075-3332c9a5c402,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-09c949ae-f25b-4e7d-be92-a3019b613a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-8a935066-2b60-452f-9def-e35f9dfc4390,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b0981ad1-af33-4343-a06d-c51be2419f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-d2713ab0-4f76-4244-bebf-bffbfa494f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095064309-172.17.0.2-1598554418741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-29268604-0f15-4098-9c39-b35423a801ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-7e2f3c6a-29e4-4e0f-bbdd-058cbf9408cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-16670603-c2b0-4bec-9e61-b342fc31fc32,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-0719784a-1f36-4d4f-b075-3332c9a5c402,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-09c949ae-f25b-4e7d-be92-a3019b613a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-8a935066-2b60-452f-9def-e35f9dfc4390,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b0981ad1-af33-4343-a06d-c51be2419f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-d2713ab0-4f76-4244-bebf-bffbfa494f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063128572-172.17.0.2-1598554491815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-60d125e2-23b4-438e-b5bb-15379f2168a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-1623db6c-2cea-433c-aaa7-610114d804ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-4f624616-7a32-4aed-a39b-ed99d5bc7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-fc3b5d3a-7c4c-405c-9e0f-c80c9dc0497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-380bbd67-cf99-4087-955b-be7fe092dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-919e96ed-e434-4688-ba5c-b28f196da725,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-5c934dbe-08c1-4696-8c4a-7763a73fd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-bc94de23-93b8-49c3-8c6b-e3b6813da78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063128572-172.17.0.2-1598554491815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-60d125e2-23b4-438e-b5bb-15379f2168a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-1623db6c-2cea-433c-aaa7-610114d804ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-4f624616-7a32-4aed-a39b-ed99d5bc7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-fc3b5d3a-7c4c-405c-9e0f-c80c9dc0497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-380bbd67-cf99-4087-955b-be7fe092dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-919e96ed-e434-4688-ba5c-b28f196da725,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-5c934dbe-08c1-4696-8c4a-7763a73fd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-bc94de23-93b8-49c3-8c6b-e3b6813da78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835678916-172.17.0.2-1598554776236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-067132c6-61a7-4175-b7f9-3c2407f757a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-2f1f48cd-f8f7-484d-b262-143d04eec48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-00ec7c42-4c97-43bd-b2a3-bff8e4dd196f,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c17bb5b3-f058-489c-bd0f-4acbf3fc3b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-5b80d5a8-dda4-45d5-9917-f74421dd2501,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-a8969d18-1ee6-42ab-a648-6a90588fd759,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-e873daba-3503-4205-862d-aa8f3d1d402c,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-d72bedaa-bf9b-480c-95f6-cf8c7df92dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835678916-172.17.0.2-1598554776236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-067132c6-61a7-4175-b7f9-3c2407f757a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-2f1f48cd-f8f7-484d-b262-143d04eec48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-00ec7c42-4c97-43bd-b2a3-bff8e4dd196f,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c17bb5b3-f058-489c-bd0f-4acbf3fc3b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-5b80d5a8-dda4-45d5-9917-f74421dd2501,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-a8969d18-1ee6-42ab-a648-6a90588fd759,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-e873daba-3503-4205-862d-aa8f3d1d402c,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-d72bedaa-bf9b-480c-95f6-cf8c7df92dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33150944-172.17.0.2-1598555678546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35350,DS-d779d404-59bd-424f-a425-529b6d49e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-64c92746-c177-4f5b-9002-9e8b5a7fe726,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d542c508-0dec-4a85-852e-9666402a3073,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-f71a260b-2518-40c6-9b36-bce1fcca27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-6033457d-03b3-407a-ba4a-b8bcdd6b0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-10537dae-4a80-4950-85ba-21d33ea5690b,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-d92e99c7-b061-4f72-8bfa-eddd3d01d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e034aae8-d40c-437c-ab95-2810e391ed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33150944-172.17.0.2-1598555678546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35350,DS-d779d404-59bd-424f-a425-529b6d49e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-64c92746-c177-4f5b-9002-9e8b5a7fe726,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d542c508-0dec-4a85-852e-9666402a3073,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-f71a260b-2518-40c6-9b36-bce1fcca27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-6033457d-03b3-407a-ba4a-b8bcdd6b0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-10537dae-4a80-4950-85ba-21d33ea5690b,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-d92e99c7-b061-4f72-8bfa-eddd3d01d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e034aae8-d40c-437c-ab95-2810e391ed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723063746-172.17.0.2-1598556185341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-7c1eb969-b893-4606-9551-c558a7643233,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-58f1a36c-14ad-43e6-9a4f-beccabb851e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-2d605ef2-85ad-4fbb-9833-3b6a1eda4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-126c4c59-b11b-4bdd-9c38-6596547194ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-819ca36b-9aae-4976-ad75-8b901e7a7d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-12f0105e-ecfe-4c13-ad45-df38d1974816,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-d414aef7-93c8-449f-97a3-45bbb3178833,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-e8c7f2c6-ac26-461b-8405-ad1005d04cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723063746-172.17.0.2-1598556185341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-7c1eb969-b893-4606-9551-c558a7643233,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-58f1a36c-14ad-43e6-9a4f-beccabb851e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-2d605ef2-85ad-4fbb-9833-3b6a1eda4ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-126c4c59-b11b-4bdd-9c38-6596547194ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-819ca36b-9aae-4976-ad75-8b901e7a7d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-12f0105e-ecfe-4c13-ad45-df38d1974816,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-d414aef7-93c8-449f-97a3-45bbb3178833,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-e8c7f2c6-ac26-461b-8405-ad1005d04cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955000706-172.17.0.2-1598556260563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-7b957e56-06e9-46ec-ae09-63a5d50d2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-a970152b-35f7-4957-95b0-a84ffe977387,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-fce65d37-dd9e-4a63-b408-858a9eceec59,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-99b26c16-fa44-43e0-8416-3dd2d3181e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-cd5dbc53-4ce5-4404-aaa5-29f9e1710515,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-86858a66-16a0-43e2-bce3-21489c3b30be,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-6fab7ad3-504c-4d57-806a-5986c033af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-daddcede-d0bd-4648-bd8d-0a799ba05609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955000706-172.17.0.2-1598556260563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-7b957e56-06e9-46ec-ae09-63a5d50d2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-a970152b-35f7-4957-95b0-a84ffe977387,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-fce65d37-dd9e-4a63-b408-858a9eceec59,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-99b26c16-fa44-43e0-8416-3dd2d3181e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-cd5dbc53-4ce5-4404-aaa5-29f9e1710515,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-86858a66-16a0-43e2-bce3-21489c3b30be,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-6fab7ad3-504c-4d57-806a-5986c033af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-daddcede-d0bd-4648-bd8d-0a799ba05609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752026122-172.17.0.2-1598556404402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-7bf26a4e-ec7b-48e3-878e-c18b6442ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-d37ca9f9-6445-473e-a2c1-6f8ead12249a,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-c507911b-7f76-458e-8089-f53ff8646abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-ec525e6a-ebab-493b-b24d-dd9b09f4817b,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-4d4d6d67-c2d8-4b5a-a61f-2e80b36355f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-169d6132-0ce4-4302-8f39-30a97d410788,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-958a3946-404d-450b-9796-c313404b8619,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-cbb0d4d1-4316-4f6c-849f-a3407a362e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752026122-172.17.0.2-1598556404402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-7bf26a4e-ec7b-48e3-878e-c18b6442ed92,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-d37ca9f9-6445-473e-a2c1-6f8ead12249a,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-c507911b-7f76-458e-8089-f53ff8646abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-ec525e6a-ebab-493b-b24d-dd9b09f4817b,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-4d4d6d67-c2d8-4b5a-a61f-2e80b36355f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-169d6132-0ce4-4302-8f39-30a97d410788,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-958a3946-404d-450b-9796-c313404b8619,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-cbb0d4d1-4316-4f6c-849f-a3407a362e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318319445-172.17.0.2-1598556564702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-b6b7ae66-c2a9-429d-b484-c8f13a4f8283,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-376b0f2f-d138-4fc9-9ae1-09261c43e509,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f1252aa5-22f1-4dc2-8934-39211fef948e,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-50b4fa6c-7b45-4ece-b4f1-4f6aec69e157,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b4b61f5d-69c4-497a-9167-50d6e88a1fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-6ab748f4-21e1-4b25-b2e1-68b08fe450ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-d439d8b5-de03-4842-9986-f9882ce00a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-371d1c94-9225-4526-99b9-aed7ccde35f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318319445-172.17.0.2-1598556564702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-b6b7ae66-c2a9-429d-b484-c8f13a4f8283,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-376b0f2f-d138-4fc9-9ae1-09261c43e509,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f1252aa5-22f1-4dc2-8934-39211fef948e,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-50b4fa6c-7b45-4ece-b4f1-4f6aec69e157,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-b4b61f5d-69c4-497a-9167-50d6e88a1fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-6ab748f4-21e1-4b25-b2e1-68b08fe450ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-d439d8b5-de03-4842-9986-f9882ce00a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-371d1c94-9225-4526-99b9-aed7ccde35f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470117759-172.17.0.2-1598556627122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-65bd6a9c-5a6c-46a2-a0ae-c2db40c7481c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-d6edc15c-e0d2-4022-bb3a-a860a46182b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-55909ab6-61da-43cf-9524-6a54940404b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-70a3fa03-9083-4aec-898b-e578c0223381,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d594f9c0-0ad4-4067-8ce4-678fb538878a,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-6f13692a-1920-4304-a447-564ffd809977,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-9285d8ec-521c-4584-aaa6-8053526bd289,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-d028461a-c001-4a27-888d-269a4905e150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470117759-172.17.0.2-1598556627122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-65bd6a9c-5a6c-46a2-a0ae-c2db40c7481c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-d6edc15c-e0d2-4022-bb3a-a860a46182b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-55909ab6-61da-43cf-9524-6a54940404b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-70a3fa03-9083-4aec-898b-e578c0223381,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d594f9c0-0ad4-4067-8ce4-678fb538878a,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-6f13692a-1920-4304-a447-564ffd809977,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-9285d8ec-521c-4584-aaa6-8053526bd289,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-d028461a-c001-4a27-888d-269a4905e150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610147688-172.17.0.2-1598557301380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-a05fe6d4-f277-41db-a510-5f944d78ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-62a0db18-7b81-4a9b-a727-e15fc9167f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-40a94920-71eb-448e-b8e7-c2b4771da138,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-285c11ec-ca15-4703-a68f-870d8313b292,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-b33bd27b-3157-416a-8ea3-82ec0eb8964c,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-6b6246bf-abc2-4d23-a691-c7f5135faea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-70e45a66-e591-471d-b946-be242771a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-66ff6de2-6c2f-4387-be52-c0d5aea7eba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-610147688-172.17.0.2-1598557301380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-a05fe6d4-f277-41db-a510-5f944d78ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-62a0db18-7b81-4a9b-a727-e15fc9167f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-40a94920-71eb-448e-b8e7-c2b4771da138,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-285c11ec-ca15-4703-a68f-870d8313b292,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-b33bd27b-3157-416a-8ea3-82ec0eb8964c,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-6b6246bf-abc2-4d23-a691-c7f5135faea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-70e45a66-e591-471d-b946-be242771a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-66ff6de2-6c2f-4387-be52-c0d5aea7eba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631705072-172.17.0.2-1598557364377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-fffe866d-bdb3-4bdb-b37a-26c75dc9cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-33a50c29-7a3e-4f3b-8566-2b2e5e7508da,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-ec2eca99-fcec-4cdf-b638-1b6721852986,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-7a516bc3-67dd-4aa7-afb5-2f1e218b3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-4e708ff2-2f65-4b5c-9e12-f625ad03af44,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-4ccf565a-bb7b-45f2-afc1-b9de5b65d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6202e814-092d-48d9-8cfa-938becc1a5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-cade6f26-ebe6-499c-b113-5260ed7b1c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631705072-172.17.0.2-1598557364377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-fffe866d-bdb3-4bdb-b37a-26c75dc9cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-33a50c29-7a3e-4f3b-8566-2b2e5e7508da,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-ec2eca99-fcec-4cdf-b638-1b6721852986,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-7a516bc3-67dd-4aa7-afb5-2f1e218b3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-4e708ff2-2f65-4b5c-9e12-f625ad03af44,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-4ccf565a-bb7b-45f2-afc1-b9de5b65d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6202e814-092d-48d9-8cfa-938becc1a5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-cade6f26-ebe6-499c-b113-5260ed7b1c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111944292-172.17.0.2-1598557985720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-18865945-8f58-44e0-9442-e7ecc0501a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-92142596-651e-4857-a394-34f6ee41ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-41ed7354-abe9-451c-873a-c7deee289600,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-3520ee9e-8bd7-47b6-9c2a-7ff0e604be12,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-74d2d385-e236-4363-a447-efc578942a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f78f52c3-261b-410c-be59-c17c326fb431,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-6041e57e-87fe-44f9-9435-7138c779bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-a4f143a5-9326-439d-89c5-42d8ebcef679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111944292-172.17.0.2-1598557985720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-18865945-8f58-44e0-9442-e7ecc0501a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-92142596-651e-4857-a394-34f6ee41ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-41ed7354-abe9-451c-873a-c7deee289600,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-3520ee9e-8bd7-47b6-9c2a-7ff0e604be12,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-74d2d385-e236-4363-a447-efc578942a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f78f52c3-261b-410c-be59-c17c326fb431,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-6041e57e-87fe-44f9-9435-7138c779bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-a4f143a5-9326-439d-89c5-42d8ebcef679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021759522-172.17.0.2-1598558022668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-23461775-91f5-423a-a4b1-b5ed227bee51,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-db30b59e-24ba-45d7-9da4-e01708daae31,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-80111209-7e35-4296-9eca-d9b7e98c713e,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-780a7f1f-8831-4e5d-9ad9-5d3b8b73ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-28e5cfea-e545-4016-889c-32da5ed7f1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-fc5c03a3-cab6-49d3-926d-9d1fc3221d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-a5659e11-d204-4d30-afab-9ae0a0dfb487,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-233ca2ca-55ee-448e-882a-699b1fe9cd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021759522-172.17.0.2-1598558022668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-23461775-91f5-423a-a4b1-b5ed227bee51,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-db30b59e-24ba-45d7-9da4-e01708daae31,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-80111209-7e35-4296-9eca-d9b7e98c713e,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-780a7f1f-8831-4e5d-9ad9-5d3b8b73ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-28e5cfea-e545-4016-889c-32da5ed7f1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-fc5c03a3-cab6-49d3-926d-9d1fc3221d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-a5659e11-d204-4d30-afab-9ae0a0dfb487,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-233ca2ca-55ee-448e-882a-699b1fe9cd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811180256-172.17.0.2-1598558089227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-3f6104bb-ebae-4e0a-a561-0b2c989d83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-91a0a581-1a6a-4647-b2d5-681625227128,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-c852a78f-63f6-4882-a83c-20c667cec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d417b9d4-3178-4523-8efe-32b48cf949f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-cede637e-df02-45fb-a3a2-4fc42d0f6ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-8341a3c2-427f-433a-a2e3-395de1ac2532,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-2ed4e499-382c-4fc6-8784-04a101338aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-4fc151a4-788d-48c4-bc71-083fa61762b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811180256-172.17.0.2-1598558089227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-3f6104bb-ebae-4e0a-a561-0b2c989d83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-91a0a581-1a6a-4647-b2d5-681625227128,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-c852a78f-63f6-4882-a83c-20c667cec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d417b9d4-3178-4523-8efe-32b48cf949f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-cede637e-df02-45fb-a3a2-4fc42d0f6ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-8341a3c2-427f-433a-a2e3-395de1ac2532,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-2ed4e499-382c-4fc6-8784-04a101338aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-4fc151a4-788d-48c4-bc71-083fa61762b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492304869-172.17.0.2-1598558330662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-12078252-269a-4316-9a79-05ae8a516cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-8dd9eeff-b71d-4c16-9fad-efa03a7993f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-9727d35b-305e-4540-bf18-5a111745bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-54bd2a49-0282-4812-a49b-baeb7f3eff04,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-6dae0f8e-7ff2-4992-8052-1d73a869157a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-43fa0d33-2091-4d75-94cb-9e93cbf935f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-22832f38-7dfc-4b43-8346-d64c6f797b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-822575fc-2798-4523-8462-9a2beee5dcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492304869-172.17.0.2-1598558330662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-12078252-269a-4316-9a79-05ae8a516cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-8dd9eeff-b71d-4c16-9fad-efa03a7993f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-9727d35b-305e-4540-bf18-5a111745bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-54bd2a49-0282-4812-a49b-baeb7f3eff04,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-6dae0f8e-7ff2-4992-8052-1d73a869157a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-43fa0d33-2091-4d75-94cb-9e93cbf935f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-22832f38-7dfc-4b43-8346-d64c6f797b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-822575fc-2798-4523-8462-9a2beee5dcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480085525-172.17.0.2-1598558363334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-c447de8c-21ad-4606-9386-563ea2fb9ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-629f4fbc-a081-46dc-82e9-d0fb2580f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c80e27fe-7517-4f5c-8775-4d136a79daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-781baefb-48c8-4e0f-b02a-bf20a786ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-86c3e824-f28d-4c03-95a3-1f8bd48a07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-a590352a-d04e-4f52-867c-25e6775374d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-0f0e1c88-30d6-4fa6-a7a4-e55cce901110,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-23af0e06-f396-4007-9d2f-73dbc9ecf238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480085525-172.17.0.2-1598558363334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-c447de8c-21ad-4606-9386-563ea2fb9ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-629f4fbc-a081-46dc-82e9-d0fb2580f2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c80e27fe-7517-4f5c-8775-4d136a79daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-781baefb-48c8-4e0f-b02a-bf20a786ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-86c3e824-f28d-4c03-95a3-1f8bd48a07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-a590352a-d04e-4f52-867c-25e6775374d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-0f0e1c88-30d6-4fa6-a7a4-e55cce901110,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-23af0e06-f396-4007-9d2f-73dbc9ecf238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630180538-172.17.0.2-1598558399149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-57c9fa62-a5eb-4a62-b13c-345d26a9b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-b6f292a5-6bec-4e8d-99de-61a98331da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-efa0a74f-6b31-493b-9f40-3172fb65fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-d84699e4-8d72-4a1f-8af3-453b1c3b3c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-c9ce9638-e317-4635-84a8-142dac470c20,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c533533f-6782-4831-a074-4e0ad30f6d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-734da4a6-969d-4f44-85f2-a617bcd917c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-97795579-cee2-4d6f-96f4-13aa8da6f6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630180538-172.17.0.2-1598558399149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-57c9fa62-a5eb-4a62-b13c-345d26a9b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-b6f292a5-6bec-4e8d-99de-61a98331da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-efa0a74f-6b31-493b-9f40-3172fb65fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-d84699e4-8d72-4a1f-8af3-453b1c3b3c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-c9ce9638-e317-4635-84a8-142dac470c20,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c533533f-6782-4831-a074-4e0ad30f6d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-734da4a6-969d-4f44-85f2-a617bcd917c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-97795579-cee2-4d6f-96f4-13aa8da6f6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454262891-172.17.0.2-1598558800865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-39e6dc99-8371-47f3-8759-3ea9ac216e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-a264f75b-8fd5-42e1-b6c7-dc63dd384ede,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-709b1232-a503-4bcf-ba16-8ae33ce42c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e4955d56-c5c2-452d-8109-c87dba380545,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-b1ce465e-0ee4-4464-8b3e-3e008f6dc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-36984e9a-d527-4cf9-9adb-696de31b9855,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-ef30aad2-7efc-4e32-a22b-7c73b3beac92,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-7782785f-52c2-4db4-8d7a-747921e9b6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454262891-172.17.0.2-1598558800865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-39e6dc99-8371-47f3-8759-3ea9ac216e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-a264f75b-8fd5-42e1-b6c7-dc63dd384ede,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-709b1232-a503-4bcf-ba16-8ae33ce42c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-e4955d56-c5c2-452d-8109-c87dba380545,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-b1ce465e-0ee4-4464-8b3e-3e008f6dc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-36984e9a-d527-4cf9-9adb-696de31b9855,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-ef30aad2-7efc-4e32-a22b-7c73b3beac92,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-7782785f-52c2-4db4-8d7a-747921e9b6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5075
