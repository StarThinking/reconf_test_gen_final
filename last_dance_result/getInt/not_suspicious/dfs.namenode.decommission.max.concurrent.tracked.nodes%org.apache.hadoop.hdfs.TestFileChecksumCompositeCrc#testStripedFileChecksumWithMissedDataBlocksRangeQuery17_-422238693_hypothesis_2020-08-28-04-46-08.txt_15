reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496509782-172.17.0.13-1598590193943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-5e38b4ff-4d13-4367-810f-d56edb5dca57,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-9e8c7961-be08-4d4f-b44b-5c6dd7f1d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-a63386ec-80b1-41ed-bb52-1cba65d6bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e063ab16-c06f-494a-a4b8-aec0b17ebcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-4abe8be6-d3bd-4c45-856f-3935f9ba16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-c8bde5f5-7387-4b47-9d1f-1890cf225a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-efade291-4306-4c46-a069-86659ff48fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-f566fe64-c989-42a2-9d8f-40419f60b556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496509782-172.17.0.13-1598590193943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-5e38b4ff-4d13-4367-810f-d56edb5dca57,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-9e8c7961-be08-4d4f-b44b-5c6dd7f1d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-a63386ec-80b1-41ed-bb52-1cba65d6bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e063ab16-c06f-494a-a4b8-aec0b17ebcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-4abe8be6-d3bd-4c45-856f-3935f9ba16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-c8bde5f5-7387-4b47-9d1f-1890cf225a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-efade291-4306-4c46-a069-86659ff48fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-f566fe64-c989-42a2-9d8f-40419f60b556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114154623-172.17.0.13-1598590868221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41872,DS-d6a1ba0c-aa30-4f04-8a84-d1a4a8aff1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-69d60a6d-486d-4f0d-9dce-cd484b414c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-f131d41d-ddf3-476a-a446-a85f34f7dea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-aebf8d1c-20d4-4bf1-b164-e04a86248604,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-f4a0365c-9916-4ad0-a121-968c90ca076d,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-d1ce8f1a-99ed-47fc-a0ee-7738af86a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-961e4106-c2b8-4aca-ba44-ec4c9158edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-2af3056a-9ff5-4259-b444-7d14c3d76aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114154623-172.17.0.13-1598590868221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41872,DS-d6a1ba0c-aa30-4f04-8a84-d1a4a8aff1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-69d60a6d-486d-4f0d-9dce-cd484b414c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-f131d41d-ddf3-476a-a446-a85f34f7dea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-aebf8d1c-20d4-4bf1-b164-e04a86248604,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-f4a0365c-9916-4ad0-a121-968c90ca076d,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-d1ce8f1a-99ed-47fc-a0ee-7738af86a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-961e4106-c2b8-4aca-ba44-ec4c9158edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-2af3056a-9ff5-4259-b444-7d14c3d76aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861099918-172.17.0.13-1598591161971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40755,DS-24a5c1b3-6cfe-477a-ab35-108456ee6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-4bfedbbf-01a9-47eb-9300-bbfada2be1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-b07b6168-e12c-471f-ba05-4692ec3bf4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-76070615-c6e2-4933-8109-819f9d2fae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-92b818f6-cc20-4d6e-909d-d74f04c70d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d291cc84-c606-4e57-826f-802c25fecaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e48e4df2-d324-41c7-8bba-11c16a04d280,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-1bd63bd8-eefb-454f-9fbe-1bf4141c831d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861099918-172.17.0.13-1598591161971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40755,DS-24a5c1b3-6cfe-477a-ab35-108456ee6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-4bfedbbf-01a9-47eb-9300-bbfada2be1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-b07b6168-e12c-471f-ba05-4692ec3bf4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-76070615-c6e2-4933-8109-819f9d2fae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-92b818f6-cc20-4d6e-909d-d74f04c70d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d291cc84-c606-4e57-826f-802c25fecaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e48e4df2-d324-41c7-8bba-11c16a04d280,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-1bd63bd8-eefb-454f-9fbe-1bf4141c831d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092138459-172.17.0.13-1598591225414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-2aeba2d1-bf02-40e2-bd14-dae45c92a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-72540ef3-a261-4b2a-a279-59555d4f6098,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-0b3cbfc3-cad8-4fb6-b324-4e8e67365bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-5b0f5704-5188-48b5-94bf-b302020f3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2d3f5202-0ae6-4980-af10-82f6a3be0477,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-0059756e-333a-4e77-a5ad-ba02c03c4ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-60daf6a7-a9ea-48b2-9170-8612e6d4a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-60b9154d-929b-4a2f-ab1a-22ba7e9cdd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092138459-172.17.0.13-1598591225414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-2aeba2d1-bf02-40e2-bd14-dae45c92a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-72540ef3-a261-4b2a-a279-59555d4f6098,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-0b3cbfc3-cad8-4fb6-b324-4e8e67365bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-5b0f5704-5188-48b5-94bf-b302020f3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2d3f5202-0ae6-4980-af10-82f6a3be0477,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-0059756e-333a-4e77-a5ad-ba02c03c4ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-60daf6a7-a9ea-48b2-9170-8612e6d4a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-60b9154d-929b-4a2f-ab1a-22ba7e9cdd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944409318-172.17.0.13-1598591254885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-9465c704-6ad8-476c-91e4-292a82d20435,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-893794d6-5164-4ce9-8e2c-ed15f3b004f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-01797124-6610-4e24-9abe-84b71d2e746d,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-71c8a495-3dd5-4da3-ae2b-4cefe2f75f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-f9c6ceed-7a1c-4953-a881-abdb51de5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-75d85edf-aa2d-4908-9d62-d9261ddd6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-42b4f53f-877c-469c-8228-7d761385d05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-4b9fa629-dc99-45f9-b243-5446954ed63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944409318-172.17.0.13-1598591254885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-9465c704-6ad8-476c-91e4-292a82d20435,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-893794d6-5164-4ce9-8e2c-ed15f3b004f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-01797124-6610-4e24-9abe-84b71d2e746d,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-71c8a495-3dd5-4da3-ae2b-4cefe2f75f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-f9c6ceed-7a1c-4953-a881-abdb51de5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-75d85edf-aa2d-4908-9d62-d9261ddd6c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-42b4f53f-877c-469c-8228-7d761385d05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-4b9fa629-dc99-45f9-b243-5446954ed63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480291357-172.17.0.13-1598591656294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-227dfbc9-fd47-43cc-a1db-8d1b01f76b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-aa288b84-ca50-4b6a-ad8f-aa7edfe85f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-374dde4b-a4a1-4fa2-9b83-e3dabcc71463,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-b5926585-661b-457a-97f1-99adac456df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-280313fd-c51e-4b57-970a-49471ba7aab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-4f5a84c9-eb14-4fc8-929a-ba7f1621aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-15ab3412-6edb-4dde-b3f2-db80a73bdc35,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-981e6c47-b1d3-4e38-9a74-8b29ddce097b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480291357-172.17.0.13-1598591656294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-227dfbc9-fd47-43cc-a1db-8d1b01f76b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-aa288b84-ca50-4b6a-ad8f-aa7edfe85f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-374dde4b-a4a1-4fa2-9b83-e3dabcc71463,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-b5926585-661b-457a-97f1-99adac456df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-280313fd-c51e-4b57-970a-49471ba7aab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-4f5a84c9-eb14-4fc8-929a-ba7f1621aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-15ab3412-6edb-4dde-b3f2-db80a73bdc35,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-981e6c47-b1d3-4e38-9a74-8b29ddce097b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27112728-172.17.0.13-1598591735509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-67308e11-06f8-44b7-b8df-750a10b6d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-82d23db8-1a07-4a56-8870-c3fe80952f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-d9b6b441-b956-4505-b4be-62c06d510d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-9627f711-6cec-4b3d-94f1-089e05871ead,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-acfa065d-2774-4b9f-acd2-c21b08c71e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-14e635bf-7358-4c65-8d10-54b37a24ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2ad04501-838d-4de1-9342-3047d04f4c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f8d28aa4-9de4-4e1e-a6f9-5cce78ff6880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27112728-172.17.0.13-1598591735509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-67308e11-06f8-44b7-b8df-750a10b6d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-82d23db8-1a07-4a56-8870-c3fe80952f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-d9b6b441-b956-4505-b4be-62c06d510d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-9627f711-6cec-4b3d-94f1-089e05871ead,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-acfa065d-2774-4b9f-acd2-c21b08c71e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-14e635bf-7358-4c65-8d10-54b37a24ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2ad04501-838d-4de1-9342-3047d04f4c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f8d28aa4-9de4-4e1e-a6f9-5cce78ff6880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521174914-172.17.0.13-1598591769327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-341abf4f-8e3e-46cf-bcd1-e4ee77ed172f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b4b890b0-881e-49d0-9fb5-353fd0a69c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-28e1d955-f349-4e7d-b820-826cca161e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-54ceba99-375f-46c1-b9b2-ef7d2c2bfb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-38626b9f-57ac-48cd-8b71-cda43d539384,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-2d4813bf-7fe7-4f6f-9405-2386aa660204,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-55291765-0fd2-4ab4-95b0-7139ab371931,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-299f534a-2fce-4883-a253-ad5914428dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521174914-172.17.0.13-1598591769327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-341abf4f-8e3e-46cf-bcd1-e4ee77ed172f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b4b890b0-881e-49d0-9fb5-353fd0a69c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-28e1d955-f349-4e7d-b820-826cca161e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-54ceba99-375f-46c1-b9b2-ef7d2c2bfb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-38626b9f-57ac-48cd-8b71-cda43d539384,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-2d4813bf-7fe7-4f6f-9405-2386aa660204,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-55291765-0fd2-4ab4-95b0-7139ab371931,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-299f534a-2fce-4883-a253-ad5914428dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515569736-172.17.0.13-1598592196384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-25d50119-f3bb-475b-a199-a4505cb1ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-799fad49-738e-4581-ac2b-356ff987012f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-0a46ea29-a1d6-46fd-bea8-fd0fefb04146,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-6f3105ae-9db7-4f41-9802-45f3f4109963,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-da241479-fd7a-4e2c-9835-30789cf62b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-442f7165-7e02-4abf-914b-fc311c88a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-88ecb7ca-e185-4927-8a41-37dd13f7f5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-050b8116-1a57-4ca8-8c62-c150528f0ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515569736-172.17.0.13-1598592196384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-25d50119-f3bb-475b-a199-a4505cb1ac73,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-799fad49-738e-4581-ac2b-356ff987012f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-0a46ea29-a1d6-46fd-bea8-fd0fefb04146,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-6f3105ae-9db7-4f41-9802-45f3f4109963,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-da241479-fd7a-4e2c-9835-30789cf62b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-442f7165-7e02-4abf-914b-fc311c88a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-88ecb7ca-e185-4927-8a41-37dd13f7f5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-050b8116-1a57-4ca8-8c62-c150528f0ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105354620-172.17.0.13-1598592268917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-047151f8-55d2-44a9-a2a1-aa870837e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-626e586f-f9fa-4a8b-a90b-5b0eb1f4baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-35568ab7-b712-4116-804d-dfc4e6306cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-184cb68c-7350-4ed6-b303-01eb525bc84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8bee4640-7ae8-42fd-9a74-c90dce4c64ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-09ee5187-e612-4090-b94d-2eb5d1a508d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-02988c8a-9870-472b-9e54-ae40929ad913,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-d00d4ac4-f87f-43d7-9e17-87fc94e147db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105354620-172.17.0.13-1598592268917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-047151f8-55d2-44a9-a2a1-aa870837e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-626e586f-f9fa-4a8b-a90b-5b0eb1f4baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-35568ab7-b712-4116-804d-dfc4e6306cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-184cb68c-7350-4ed6-b303-01eb525bc84e,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8bee4640-7ae8-42fd-9a74-c90dce4c64ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-09ee5187-e612-4090-b94d-2eb5d1a508d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-02988c8a-9870-472b-9e54-ae40929ad913,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-d00d4ac4-f87f-43d7-9e17-87fc94e147db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567914038-172.17.0.13-1598592692936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-398881f0-ffe5-49cb-8927-22f452b2d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-ae5b18ee-0820-4d43-b9fe-a28fb5baba89,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-590285c9-6595-4b87-bd5f-e241ee82c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-4d6fffa9-7261-4c70-a119-ca145867c331,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-45d76562-fb88-4e66-b362-83598cbded48,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-247565a7-114e-46fd-b1bd-49d8b71c3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-572566de-1a8b-435e-b860-ce5315dda7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-2234de57-a2d4-40f0-a527-c1f0fdcb5ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567914038-172.17.0.13-1598592692936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-398881f0-ffe5-49cb-8927-22f452b2d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-ae5b18ee-0820-4d43-b9fe-a28fb5baba89,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-590285c9-6595-4b87-bd5f-e241ee82c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-4d6fffa9-7261-4c70-a119-ca145867c331,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-45d76562-fb88-4e66-b362-83598cbded48,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-247565a7-114e-46fd-b1bd-49d8b71c3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-572566de-1a8b-435e-b860-ce5315dda7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-2234de57-a2d4-40f0-a527-c1f0fdcb5ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577756793-172.17.0.13-1598592725029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-6308b9d2-a132-4909-80b9-80bd6f3f3228,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-d392daf8-d84b-46eb-a269-73a49fca8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9f68d83e-052a-4710-9b5c-4c261d5ff166,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-6dae1fba-5ca0-42e1-ab1b-d4c06105bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-15f3cf1d-7774-43c5-a07b-0ab8bd87cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-8272bc18-e26a-4070-bcf8-f3b9342ef436,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-30ca4ebb-750e-4855-a458-ee8f2887577a,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-86d6513e-7b95-4fff-9176-9c1acd946fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577756793-172.17.0.13-1598592725029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-6308b9d2-a132-4909-80b9-80bd6f3f3228,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-d392daf8-d84b-46eb-a269-73a49fca8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9f68d83e-052a-4710-9b5c-4c261d5ff166,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-6dae1fba-5ca0-42e1-ab1b-d4c06105bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-15f3cf1d-7774-43c5-a07b-0ab8bd87cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-8272bc18-e26a-4070-bcf8-f3b9342ef436,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-30ca4ebb-750e-4855-a458-ee8f2887577a,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-86d6513e-7b95-4fff-9176-9c1acd946fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609317175-172.17.0.13-1598592758816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-6504124b-9237-4fdc-b75d-b74ec4fa2709,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-e97612e7-e4bd-4f82-a1ea-7f3dbc1b498b,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-02be2829-a163-4a1e-80df-bb97ec25b582,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-172355b7-1299-4dea-b47f-2629bd7d2920,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8353d3f6-d591-454d-8051-69efe96cc934,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-3134733f-2730-4237-9093-6aafec0509ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-9fc22afb-90d4-4382-bbe3-f76a14abf060,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-1e596580-e460-4b8e-8312-f06f15683072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609317175-172.17.0.13-1598592758816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-6504124b-9237-4fdc-b75d-b74ec4fa2709,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-e97612e7-e4bd-4f82-a1ea-7f3dbc1b498b,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-02be2829-a163-4a1e-80df-bb97ec25b582,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-172355b7-1299-4dea-b47f-2629bd7d2920,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-8353d3f6-d591-454d-8051-69efe96cc934,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-3134733f-2730-4237-9093-6aafec0509ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-9fc22afb-90d4-4382-bbe3-f76a14abf060,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-1e596580-e460-4b8e-8312-f06f15683072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568114110-172.17.0.13-1598592791446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-e9e6bb9b-76ed-4d99-b230-4e57aa311c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-6a345d6c-ba6e-44b4-8ec6-22b3bdd5ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-f54cbea4-76b7-4091-9086-0630a42b78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-8f598167-ee1f-4865-9338-11596ffb7352,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-0872c700-d941-4e60-a5da-909d704d2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-47e494eb-d3c9-444b-86ad-8c220981aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-052a9c67-189d-48b3-9e22-d4afaf9d8ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-ecde0e72-0ca5-44ce-9e3f-c9ce4668231d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568114110-172.17.0.13-1598592791446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-e9e6bb9b-76ed-4d99-b230-4e57aa311c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-6a345d6c-ba6e-44b4-8ec6-22b3bdd5ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-f54cbea4-76b7-4091-9086-0630a42b78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-8f598167-ee1f-4865-9338-11596ffb7352,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-0872c700-d941-4e60-a5da-909d704d2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-47e494eb-d3c9-444b-86ad-8c220981aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-052a9c67-189d-48b3-9e22-d4afaf9d8ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-ecde0e72-0ca5-44ce-9e3f-c9ce4668231d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118110676-172.17.0.13-1598593384612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-e188f223-7589-43b6-a7dc-c38aaeae3bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-7e75b345-aa43-47d0-a216-257d8338ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-0046fd6d-73bd-4ec5-b6b7-f5dcf02f2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2e8cf391-9d2b-4482-9d86-1500c75f63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-64439034-cb9c-4c82-89f2-17ec15266ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-22a1fc69-8ff1-4bc7-928a-5a4a3ec00a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-5e4cf519-338b-46df-a4c8-cf2a013195b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5534a05e-2287-48b3-9d85-893f32e8dfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118110676-172.17.0.13-1598593384612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-e188f223-7589-43b6-a7dc-c38aaeae3bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-7e75b345-aa43-47d0-a216-257d8338ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-0046fd6d-73bd-4ec5-b6b7-f5dcf02f2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2e8cf391-9d2b-4482-9d86-1500c75f63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-64439034-cb9c-4c82-89f2-17ec15266ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-22a1fc69-8ff1-4bc7-928a-5a4a3ec00a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-5e4cf519-338b-46df-a4c8-cf2a013195b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5534a05e-2287-48b3-9d85-893f32e8dfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727409343-172.17.0.13-1598593561280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-d37ec2ca-d7ad-4960-8f57-fff0e60cf7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-dd6958cf-bb21-4566-adbf-6fff5c986046,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-13fede2f-05c7-4891-b943-55ab49e5a953,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-1c147b29-639c-4e14-98a8-3d7976ddc526,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-945fccc8-36d3-430d-a7a2-fa6b9219a495,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-14704602-6267-47bd-b13c-5f8edfc7298c,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-90d28df2-1862-4b18-a672-fadbb19c9261,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-ca2149c2-4f81-4c02-bcb3-23c32d109aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727409343-172.17.0.13-1598593561280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-d37ec2ca-d7ad-4960-8f57-fff0e60cf7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-dd6958cf-bb21-4566-adbf-6fff5c986046,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-13fede2f-05c7-4891-b943-55ab49e5a953,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-1c147b29-639c-4e14-98a8-3d7976ddc526,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-945fccc8-36d3-430d-a7a2-fa6b9219a495,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-14704602-6267-47bd-b13c-5f8edfc7298c,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-90d28df2-1862-4b18-a672-fadbb19c9261,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-ca2149c2-4f81-4c02-bcb3-23c32d109aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765560549-172.17.0.13-1598593589269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-20b2e88c-95e8-4d13-93ce-019f2805f011,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-5a161b40-8939-4818-9312-5b4c7781baea,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-56b6e961-6643-431e-bb43-32bca4d1bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-052f1723-6266-4f94-81c0-957d083b7f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-bb48ae2b-b2f9-4d4e-a65b-b551effc2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-20a53900-a48a-4dfd-9d3a-00f7ac0bb288,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-4c82860b-271e-4eb8-b6fa-14e563156c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c6a36095-d5e3-4021-9deb-0ab064cd5e9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765560549-172.17.0.13-1598593589269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38361,DS-20b2e88c-95e8-4d13-93ce-019f2805f011,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-5a161b40-8939-4818-9312-5b4c7781baea,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-56b6e961-6643-431e-bb43-32bca4d1bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-052f1723-6266-4f94-81c0-957d083b7f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-bb48ae2b-b2f9-4d4e-a65b-b551effc2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-20a53900-a48a-4dfd-9d3a-00f7ac0bb288,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-4c82860b-271e-4eb8-b6fa-14e563156c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-c6a36095-d5e3-4021-9deb-0ab064cd5e9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232278177-172.17.0.13-1598594160953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-4d9e54b4-c1d6-4a04-8e23-ed3549a7124e,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-58283605-1775-4be0-b4f2-7c47451e2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-062767d7-3085-497c-83ae-0843220cbb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-024324eb-37fc-4cea-9b29-fda6db672251,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-97f3f580-defa-439a-b298-644ec2b4eb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-7eb7bec7-8647-422a-93df-48c3031bad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-c44722b1-7be2-4f61-b3db-5a906d80c138,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-3f14fa6c-d40c-4e9a-8133-cdf1bc9fe820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232278177-172.17.0.13-1598594160953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-4d9e54b4-c1d6-4a04-8e23-ed3549a7124e,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-58283605-1775-4be0-b4f2-7c47451e2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-062767d7-3085-497c-83ae-0843220cbb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-024324eb-37fc-4cea-9b29-fda6db672251,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-97f3f580-defa-439a-b298-644ec2b4eb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-7eb7bec7-8647-422a-93df-48c3031bad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-c44722b1-7be2-4f61-b3db-5a906d80c138,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-3f14fa6c-d40c-4e9a-8133-cdf1bc9fe820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5414612-172.17.0.13-1598594381994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-11dc81d6-1bb9-4277-a674-51df96eb8124,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3cc7d3de-b8c3-433c-80b7-dca516a8f990,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-fd35cff8-5f26-4aad-857a-249412a0d678,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-2aa76aad-fc42-4f89-ad83-a74cf67ca26e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-d015cf51-cc45-4f55-a244-1aaf045f404e,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-c68b5f63-512f-4edf-9ba6-a4b91d3906ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-96cd7472-a41c-4213-a855-57a6ec45dd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-00029a46-b9ad-44c6-9393-8634c2caf58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5414612-172.17.0.13-1598594381994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-11dc81d6-1bb9-4277-a674-51df96eb8124,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3cc7d3de-b8c3-433c-80b7-dca516a8f990,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-fd35cff8-5f26-4aad-857a-249412a0d678,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-2aa76aad-fc42-4f89-ad83-a74cf67ca26e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-d015cf51-cc45-4f55-a244-1aaf045f404e,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-c68b5f63-512f-4edf-9ba6-a4b91d3906ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-96cd7472-a41c-4213-a855-57a6ec45dd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-00029a46-b9ad-44c6-9393-8634c2caf58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5007
