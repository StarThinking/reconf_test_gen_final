reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161664939-172.17.0.14-1598636258845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-ce6978d8-39df-47fc-967b-3ad0762835d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-e5c028c6-e4ce-473a-9302-e18c1d16ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-484dede9-6b7a-467b-a77b-0ed969884377,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-2cd01b92-47a4-4ec3-a62c-41159da74079,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-0547f2e3-485e-429c-ba4c-33a1fd6bd34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-32604f09-3cf9-433f-afec-a6f20a16b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-ea8ab284-3a12-43b8-8337-d597332af3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ea521dca-234d-4a2b-ae16-f8014de72059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161664939-172.17.0.14-1598636258845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-ce6978d8-39df-47fc-967b-3ad0762835d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-e5c028c6-e4ce-473a-9302-e18c1d16ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-484dede9-6b7a-467b-a77b-0ed969884377,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-2cd01b92-47a4-4ec3-a62c-41159da74079,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-0547f2e3-485e-429c-ba4c-33a1fd6bd34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-32604f09-3cf9-433f-afec-a6f20a16b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-ea8ab284-3a12-43b8-8337-d597332af3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ea521dca-234d-4a2b-ae16-f8014de72059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883619833-172.17.0.14-1598636365574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-cfb09e97-b267-41fd-a154-a3187e1941ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-ed9dcfcc-5244-4ce7-ba44-e207f7cc9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-98559790-153a-4af6-8a56-971f86fb7128,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-40985111-61f7-4b6b-9554-3550304d525e,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-242d2c5a-b1d6-4d8e-ab6f-585f24cadf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-54d62000-bc1f-4854-bf10-c45e35f4000b,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b6c03891-d50b-46af-b355-1add1ae2442e,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-c3942981-4e71-454e-b493-2922d5bfc99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883619833-172.17.0.14-1598636365574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-cfb09e97-b267-41fd-a154-a3187e1941ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-ed9dcfcc-5244-4ce7-ba44-e207f7cc9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-98559790-153a-4af6-8a56-971f86fb7128,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-40985111-61f7-4b6b-9554-3550304d525e,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-242d2c5a-b1d6-4d8e-ab6f-585f24cadf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-54d62000-bc1f-4854-bf10-c45e35f4000b,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b6c03891-d50b-46af-b355-1add1ae2442e,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-c3942981-4e71-454e-b493-2922d5bfc99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193469890-172.17.0.14-1598636498481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-48fa9a70-5c45-4059-a634-98af3a6d336b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-19c18d1c-e205-4d5f-84e0-0a612c9af259,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-10500bfd-c923-47e3-9517-de7ea99c466e,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c5c6e59e-9d65-4458-b991-98a3b789517b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-6be83d19-e4b4-48a5-b1cd-8005721a1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a38e5a96-2bb8-459a-b8b4-0456c0119078,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-301aad90-ba50-4cf7-98d6-e165fd7ae565,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-06ac6d70-2cf7-49ef-b1b2-fe4617fda714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193469890-172.17.0.14-1598636498481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-48fa9a70-5c45-4059-a634-98af3a6d336b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-19c18d1c-e205-4d5f-84e0-0a612c9af259,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-10500bfd-c923-47e3-9517-de7ea99c466e,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c5c6e59e-9d65-4458-b991-98a3b789517b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-6be83d19-e4b4-48a5-b1cd-8005721a1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a38e5a96-2bb8-459a-b8b4-0456c0119078,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-301aad90-ba50-4cf7-98d6-e165fd7ae565,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-06ac6d70-2cf7-49ef-b1b2-fe4617fda714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173194456-172.17.0.14-1598636676792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-4b6b4c5e-01fa-4264-881b-fd842007169d,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-e478b60a-c898-4fda-9dbf-daf5312c630e,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-bcf431e2-25d2-419d-bf0a-fa543e2b042c,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-15798636-d6e1-4c73-91ba-b4a7c2ef926b,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-de99b93e-c3a8-4c35-8b69-84a123281f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-59ba798e-afec-4387-825d-0d380e532116,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-92487390-ee13-453d-921e-6898aab3cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-8f79cd97-3d2b-4a7a-881b-0d9a1f789b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173194456-172.17.0.14-1598636676792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-4b6b4c5e-01fa-4264-881b-fd842007169d,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-e478b60a-c898-4fda-9dbf-daf5312c630e,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-bcf431e2-25d2-419d-bf0a-fa543e2b042c,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-15798636-d6e1-4c73-91ba-b4a7c2ef926b,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-de99b93e-c3a8-4c35-8b69-84a123281f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-59ba798e-afec-4387-825d-0d380e532116,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-92487390-ee13-453d-921e-6898aab3cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-8f79cd97-3d2b-4a7a-881b-0d9a1f789b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942115781-172.17.0.14-1598636916712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-dd383971-107c-4276-9958-adbf913ab32c,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-d6519207-e9c9-42e9-b4e5-9b1e29fe61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-1fada12e-37d9-4d16-9ccc-830dabfcd035,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-d82f97ae-f8c7-4347-94a7-0767a6b308e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-23916ecf-8508-479b-a3a4-8c19e4015c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f156c81c-b009-4e21-ac3f-5238a8e44cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-4631261c-04c9-43e1-9d1f-63196a90ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-f1622673-ea14-4b93-9c56-b942e5eb7766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942115781-172.17.0.14-1598636916712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-dd383971-107c-4276-9958-adbf913ab32c,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-d6519207-e9c9-42e9-b4e5-9b1e29fe61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-1fada12e-37d9-4d16-9ccc-830dabfcd035,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-d82f97ae-f8c7-4347-94a7-0767a6b308e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-23916ecf-8508-479b-a3a4-8c19e4015c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-f156c81c-b009-4e21-ac3f-5238a8e44cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-4631261c-04c9-43e1-9d1f-63196a90ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-f1622673-ea14-4b93-9c56-b942e5eb7766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869262700-172.17.0.14-1598637549221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-6033cd45-d3aa-4819-9602-dd51306801f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-b5e56484-f570-4048-b4ae-009b76631941,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-5dc9930c-53ab-48ee-ab3f-24e008852638,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-01e49442-0e5c-4ea7-8e76-1a89f63ad988,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-688edefd-0591-4d20-b87e-54630a2b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-9033d898-3ef5-42bd-860d-8b2eb0b4a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-8cb25c48-872c-42d4-b3f8-799f7d65ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-9a94eac1-6905-44ec-a91b-6210be343659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869262700-172.17.0.14-1598637549221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-6033cd45-d3aa-4819-9602-dd51306801f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-b5e56484-f570-4048-b4ae-009b76631941,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-5dc9930c-53ab-48ee-ab3f-24e008852638,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-01e49442-0e5c-4ea7-8e76-1a89f63ad988,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-688edefd-0591-4d20-b87e-54630a2b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-9033d898-3ef5-42bd-860d-8b2eb0b4a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-8cb25c48-872c-42d4-b3f8-799f7d65ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-9a94eac1-6905-44ec-a91b-6210be343659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845776581-172.17.0.14-1598638007197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-ad03c795-ddb6-436a-9b3f-419b53a6d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-ed335b73-2b06-404d-b4f9-3fed8760d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-42d98468-dc9c-4310-8a1e-9fb8aab4e878,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-24e373fe-71d9-4968-a76f-697c6be00af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-c0351237-080f-4ff3-8d45-e00895bc3c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-9c71df04-e2c0-4bf3-ac1a-32f0f90e17de,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-11ee04cf-7056-4a04-96ab-c230ecbe0627,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0523c1e0-b931-4de2-928f-3e5be0642b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845776581-172.17.0.14-1598638007197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-ad03c795-ddb6-436a-9b3f-419b53a6d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-ed335b73-2b06-404d-b4f9-3fed8760d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-42d98468-dc9c-4310-8a1e-9fb8aab4e878,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-24e373fe-71d9-4968-a76f-697c6be00af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-c0351237-080f-4ff3-8d45-e00895bc3c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-9c71df04-e2c0-4bf3-ac1a-32f0f90e17de,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-11ee04cf-7056-4a04-96ab-c230ecbe0627,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0523c1e0-b931-4de2-928f-3e5be0642b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799748171-172.17.0.14-1598638043798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-8ba52f9b-74bd-40fb-a864-900dd83a833c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-dff2af45-93cb-444f-8cd6-92e1aa45b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-6fe9b27c-c593-422e-997e-6693d661357c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-e33a661b-2bdc-4df6-99be-58adf5c97229,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-bfd772e5-15f9-4fd0-b3ac-55409945a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0f4945fe-6f8a-466c-90c3-cbed3d434032,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-3b3a717d-1fea-461f-86ec-6b515c41927c,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-a66e1225-a08f-48a6-99c0-b77bef2fa268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799748171-172.17.0.14-1598638043798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-8ba52f9b-74bd-40fb-a864-900dd83a833c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-dff2af45-93cb-444f-8cd6-92e1aa45b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-6fe9b27c-c593-422e-997e-6693d661357c,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-e33a661b-2bdc-4df6-99be-58adf5c97229,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-bfd772e5-15f9-4fd0-b3ac-55409945a05e,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0f4945fe-6f8a-466c-90c3-cbed3d434032,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-3b3a717d-1fea-461f-86ec-6b515c41927c,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-a66e1225-a08f-48a6-99c0-b77bef2fa268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31533528-172.17.0.14-1598638491897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-e83c3d50-ebae-4679-9627-8fceaf3b327f,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-ddf7b3b3-ceac-4f6c-a2c5-4a6bd29a99fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-1699559c-cac8-47f7-bae3-a48d6dd24af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-0deb5011-e2ea-49e7-81aa-9a6cb626a120,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-86c338eb-3393-4dc5-b41a-cbe69b70a608,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-62ce5bd3-9a63-4997-b73f-7385e6fc1e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-30cbcec1-f9ea-46a8-b849-4bce029067ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-abfd0549-36b4-428d-8bdc-f559d59c3232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31533528-172.17.0.14-1598638491897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35015,DS-e83c3d50-ebae-4679-9627-8fceaf3b327f,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-ddf7b3b3-ceac-4f6c-a2c5-4a6bd29a99fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-1699559c-cac8-47f7-bae3-a48d6dd24af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-0deb5011-e2ea-49e7-81aa-9a6cb626a120,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-86c338eb-3393-4dc5-b41a-cbe69b70a608,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-62ce5bd3-9a63-4997-b73f-7385e6fc1e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-30cbcec1-f9ea-46a8-b849-4bce029067ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-abfd0549-36b4-428d-8bdc-f559d59c3232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195813398-172.17.0.14-1598638708583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-eeb60ce4-fe88-4b45-9c4e-a3e3bc139bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-e4d659d3-aacd-42a0-b119-47e5114542bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-9be8b5a5-1307-4025-aeb0-9253aeddf3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-460a3522-e1b8-45d2-a89f-dbee8b1072dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-5b6348b6-1ade-4d15-b6a9-836dcd418201,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-9494a87c-32be-4244-b1f7-cf39f8ddbb55,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-0e7aa606-872b-4566-98af-522949713e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-08496d3a-ee3b-4f11-9dad-81fbe8772cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195813398-172.17.0.14-1598638708583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-eeb60ce4-fe88-4b45-9c4e-a3e3bc139bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-e4d659d3-aacd-42a0-b119-47e5114542bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-9be8b5a5-1307-4025-aeb0-9253aeddf3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-460a3522-e1b8-45d2-a89f-dbee8b1072dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-5b6348b6-1ade-4d15-b6a9-836dcd418201,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-9494a87c-32be-4244-b1f7-cf39f8ddbb55,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-0e7aa606-872b-4566-98af-522949713e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-08496d3a-ee3b-4f11-9dad-81fbe8772cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171057359-172.17.0.14-1598639935890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-62f95e25-3d4d-40dc-91a2-488b1b847c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-6a11d750-2003-41b7-b3d4-554013593a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-c892fa4e-f2f2-4639-b2c9-abf08e11f094,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-92881001-e78e-40f8-9c0c-981dbc6b143b,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-b0fdf260-3c45-4fb3-8519-e35d4e2e35b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d29b205a-a4c0-438b-bdd4-c3b84edefd90,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-5a7131af-bee0-406b-831c-a5ec51e08e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-6fbc403f-8e58-41fe-8170-05414ad637aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171057359-172.17.0.14-1598639935890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-62f95e25-3d4d-40dc-91a2-488b1b847c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-6a11d750-2003-41b7-b3d4-554013593a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-c892fa4e-f2f2-4639-b2c9-abf08e11f094,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-92881001-e78e-40f8-9c0c-981dbc6b143b,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-b0fdf260-3c45-4fb3-8519-e35d4e2e35b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d29b205a-a4c0-438b-bdd4-c3b84edefd90,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-5a7131af-bee0-406b-831c-a5ec51e08e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-6fbc403f-8e58-41fe-8170-05414ad637aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151657452-172.17.0.14-1598640205776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-e82e4a5c-64b2-4287-9de5-b5611bc43396,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-09973b52-bcaf-4561-a24d-1792add17103,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-375f46b1-4c08-4fd5-8c23-b019186aa3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-79fbff91-10b9-4d8c-a6de-3cf2d2bff283,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-2db92f1d-c3ac-4171-bf73-2d473f9724de,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-1254d24d-0e19-4b0c-b695-54748708a105,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-232490a0-e3f9-4333-851e-90875e8fc4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-a6651ab0-62f9-49de-bcc2-065637a4031a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151657452-172.17.0.14-1598640205776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-e82e4a5c-64b2-4287-9de5-b5611bc43396,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-09973b52-bcaf-4561-a24d-1792add17103,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-375f46b1-4c08-4fd5-8c23-b019186aa3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-79fbff91-10b9-4d8c-a6de-3cf2d2bff283,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-2db92f1d-c3ac-4171-bf73-2d473f9724de,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-1254d24d-0e19-4b0c-b695-54748708a105,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-232490a0-e3f9-4333-851e-90875e8fc4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-a6651ab0-62f9-49de-bcc2-065637a4031a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628442304-172.17.0.14-1598640819166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-8c822c38-9134-48e7-8730-390b1943cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-92847ef5-7a3f-47a3-9ab3-401841da06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-34bfdad2-ae79-4604-a94c-ffda5a5eab51,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-1feee49c-53a1-41e7-a3f5-d162e516cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-24d6e4b6-77da-4d38-9d93-161bc4038bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-7f4fca68-93a1-490b-86ed-aff734e71a51,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-8638eb6a-20ec-4312-810e-4ee1e4ff90a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-bcabe3d7-8d12-49ba-8d47-671c5ce601a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628442304-172.17.0.14-1598640819166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42018,DS-8c822c38-9134-48e7-8730-390b1943cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-92847ef5-7a3f-47a3-9ab3-401841da06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-34bfdad2-ae79-4604-a94c-ffda5a5eab51,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-1feee49c-53a1-41e7-a3f5-d162e516cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-24d6e4b6-77da-4d38-9d93-161bc4038bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-7f4fca68-93a1-490b-86ed-aff734e71a51,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-8638eb6a-20ec-4312-810e-4ee1e4ff90a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-bcabe3d7-8d12-49ba-8d47-671c5ce601a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005749018-172.17.0.14-1598641205026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-fbf7b587-4415-46b5-aeba-649fd039a269,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9e135d07-22f9-4e12-b15e-61bbd8f0415d,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-94046782-0b34-4108-80f5-4ab3bccb4209,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-55c20c31-8302-45de-832a-bfe5137deaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-98440084-cc30-4f65-8a4e-57d38997181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-2f50daa9-7c98-45a6-952c-32255abca152,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-094dfecb-de85-4ee4-8b01-336fe17a3375,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-4896458b-5bdc-4899-8f13-2fe15a73170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005749018-172.17.0.14-1598641205026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-fbf7b587-4415-46b5-aeba-649fd039a269,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9e135d07-22f9-4e12-b15e-61bbd8f0415d,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-94046782-0b34-4108-80f5-4ab3bccb4209,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-55c20c31-8302-45de-832a-bfe5137deaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-98440084-cc30-4f65-8a4e-57d38997181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-2f50daa9-7c98-45a6-952c-32255abca152,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-094dfecb-de85-4ee4-8b01-336fe17a3375,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-4896458b-5bdc-4899-8f13-2fe15a73170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5584
