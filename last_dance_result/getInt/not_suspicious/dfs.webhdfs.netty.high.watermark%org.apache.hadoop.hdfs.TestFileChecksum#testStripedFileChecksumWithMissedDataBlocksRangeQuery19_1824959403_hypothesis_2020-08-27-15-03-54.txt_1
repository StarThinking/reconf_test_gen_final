reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641314440-172.17.0.19-1598540911191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-f9a514f8-8cb2-4c02-b604-2f7ea5e72d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-3f2b090d-33e6-4f7f-8c81-5da922a3765e,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-a94e8b56-ca0d-4af5-bcd5-68060ea5ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-39eb6313-7a72-44a9-8f32-5f01a7389650,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-cfb55f7f-fe8c-4262-bc9c-3f2b78ef84c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-c00bbe10-b757-4711-8216-8e9d91b59b93,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-71135aba-5a7a-44f5-8f80-5fda7f31dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-16e55a7b-1a7e-49ae-8f7c-b0fb8f6fe6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641314440-172.17.0.19-1598540911191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-f9a514f8-8cb2-4c02-b604-2f7ea5e72d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-3f2b090d-33e6-4f7f-8c81-5da922a3765e,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-a94e8b56-ca0d-4af5-bcd5-68060ea5ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-39eb6313-7a72-44a9-8f32-5f01a7389650,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-cfb55f7f-fe8c-4262-bc9c-3f2b78ef84c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-c00bbe10-b757-4711-8216-8e9d91b59b93,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-71135aba-5a7a-44f5-8f80-5fda7f31dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-16e55a7b-1a7e-49ae-8f7c-b0fb8f6fe6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352404593-172.17.0.19-1598541119972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44951,DS-a2ea9cf0-f543-4aa8-a81b-5c4dfd12dcde,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-e93e679b-4e42-4d43-b560-874d883f30db,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-bf33ef2d-6f63-44d3-8f32-44cf6e309131,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-ac36a4b3-aefc-4e5c-807e-fecd910073ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-debed824-34c3-4cba-baf8-73294837a0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-1fd9e0e1-2b5e-408a-9b4d-a55dc4810284,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-85a01b2a-0860-4d63-8461-7a520f1c2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-30ba99ac-5aea-45a6-bd0d-f02a304c8009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352404593-172.17.0.19-1598541119972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44951,DS-a2ea9cf0-f543-4aa8-a81b-5c4dfd12dcde,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-e93e679b-4e42-4d43-b560-874d883f30db,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-bf33ef2d-6f63-44d3-8f32-44cf6e309131,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-ac36a4b3-aefc-4e5c-807e-fecd910073ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-debed824-34c3-4cba-baf8-73294837a0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-1fd9e0e1-2b5e-408a-9b4d-a55dc4810284,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-85a01b2a-0860-4d63-8461-7a520f1c2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-30ba99ac-5aea-45a6-bd0d-f02a304c8009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765341908-172.17.0.19-1598541231542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-d190f8c7-29f6-4fee-8a90-c360672912cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-7b1e9fa8-ea19-4cd5-a70d-95f1d2be2fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-a2576f4f-d9c6-45f7-a16e-87fb941a7717,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-bfc69afd-9aad-4f4c-bb32-21de86c133da,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-0404626d-e269-4ce4-a68c-d68e42256325,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-cbce0404-dab7-4f93-893c-b0abcfbfed98,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-76f62fa6-9f78-4027-9c06-2fee41e4a646,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-56be1c58-20d2-4cff-a8af-2dabab60a4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765341908-172.17.0.19-1598541231542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-d190f8c7-29f6-4fee-8a90-c360672912cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-7b1e9fa8-ea19-4cd5-a70d-95f1d2be2fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-a2576f4f-d9c6-45f7-a16e-87fb941a7717,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-bfc69afd-9aad-4f4c-bb32-21de86c133da,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-0404626d-e269-4ce4-a68c-d68e42256325,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-cbce0404-dab7-4f93-893c-b0abcfbfed98,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-76f62fa6-9f78-4027-9c06-2fee41e4a646,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-56be1c58-20d2-4cff-a8af-2dabab60a4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199106828-172.17.0.19-1598541520033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43153,DS-348fc4c5-0535-4844-8ad0-5cb8ef993650,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-ab855580-7920-4799-a0d7-27cfe7e13970,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-bef948c3-a92c-438f-8dcc-ad1224f80885,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-132f3dba-a757-4eaa-98d1-41b85e2839eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-ec009ffd-86cc-4f06-a9cb-f14f02da55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-1832e1d2-1ff6-479b-80e6-4cf3d323f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-b3ba7f89-75ab-4275-9b60-8d34175a66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-77186ce8-3c5c-415d-810e-045e81656fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199106828-172.17.0.19-1598541520033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43153,DS-348fc4c5-0535-4844-8ad0-5cb8ef993650,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-ab855580-7920-4799-a0d7-27cfe7e13970,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-bef948c3-a92c-438f-8dcc-ad1224f80885,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-132f3dba-a757-4eaa-98d1-41b85e2839eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-ec009ffd-86cc-4f06-a9cb-f14f02da55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-1832e1d2-1ff6-479b-80e6-4cf3d323f948,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-b3ba7f89-75ab-4275-9b60-8d34175a66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-77186ce8-3c5c-415d-810e-045e81656fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729587032-172.17.0.19-1598541962864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-8e69b1ef-db1c-41f5-8dda-64ddcb753c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-39f22bda-a519-4905-b66c-2ded640bfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-29f99317-0b4e-48b4-95ce-b9b7526c4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4eaf2f94-19dc-47d5-bcbb-f2bacf2219b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-403329e9-bf7d-4f6a-a799-29010e0b9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-6c633aab-109a-4c2f-b738-1eb394b47157,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8ebf2368-27fc-43bd-b6b9-8b7af1b2b327,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-11497deb-4f30-4a52-91ae-418ccd221cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729587032-172.17.0.19-1598541962864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-8e69b1ef-db1c-41f5-8dda-64ddcb753c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-39f22bda-a519-4905-b66c-2ded640bfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-29f99317-0b4e-48b4-95ce-b9b7526c4af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4eaf2f94-19dc-47d5-bcbb-f2bacf2219b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-403329e9-bf7d-4f6a-a799-29010e0b9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-6c633aab-109a-4c2f-b738-1eb394b47157,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-8ebf2368-27fc-43bd-b6b9-8b7af1b2b327,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-11497deb-4f30-4a52-91ae-418ccd221cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765299797-172.17.0.19-1598542115038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-37048582-e278-401b-ae92-2078bf8cfa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-89f0d878-e2ff-4d15-bcd0-30b77f92ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-aab600d7-53a3-4c40-bba8-5f1cd5d22c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-a00f02bd-0c27-4c01-8494-6ef8cade0476,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-4a3a33f1-fe8a-485f-995d-18e9540756cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-16e50c35-64fa-422f-9f9c-6e6c6c10d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-82fce14d-f3f9-4fb4-89a7-ae1700699ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-e10ea74e-8dd2-4516-ae34-e423e52c6f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765299797-172.17.0.19-1598542115038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-37048582-e278-401b-ae92-2078bf8cfa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-89f0d878-e2ff-4d15-bcd0-30b77f92ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-aab600d7-53a3-4c40-bba8-5f1cd5d22c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-a00f02bd-0c27-4c01-8494-6ef8cade0476,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-4a3a33f1-fe8a-485f-995d-18e9540756cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-16e50c35-64fa-422f-9f9c-6e6c6c10d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-82fce14d-f3f9-4fb4-89a7-ae1700699ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-e10ea74e-8dd2-4516-ae34-e423e52c6f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167177664-172.17.0.19-1598542152786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-573a2d93-ea69-4660-ad36-63fddaa14c10,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2ed9272e-e0a3-4fa7-a96c-269ac1a0806e,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-05520c96-37e2-4453-bc07-07052f538c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-3e95abd3-3179-467a-9534-17dc792355b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-258dc7a1-752a-4625-9778-9dfc0cc27d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-e487069b-50f7-41e0-8101-d05fec769684,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-a7752dd7-0cf7-4405-96e4-4a79c751cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-9030ced6-ef08-43e9-8162-4bfd3a2913e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167177664-172.17.0.19-1598542152786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-573a2d93-ea69-4660-ad36-63fddaa14c10,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2ed9272e-e0a3-4fa7-a96c-269ac1a0806e,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-05520c96-37e2-4453-bc07-07052f538c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-3e95abd3-3179-467a-9534-17dc792355b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-258dc7a1-752a-4625-9778-9dfc0cc27d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-e487069b-50f7-41e0-8101-d05fec769684,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-a7752dd7-0cf7-4405-96e4-4a79c751cd94,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-9030ced6-ef08-43e9-8162-4bfd3a2913e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778487351-172.17.0.19-1598542718942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39605,DS-a135e9f7-5bd6-41c2-aa3e-3cf3a6baaecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-3f463e43-9ab5-4e3b-bae7-265eaba5fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-6ea447d7-ee40-4e7a-bbea-21ecae190e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-6c119920-78d0-4c28-bc66-ebd1517349ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-53008706-14bb-4bb7-b58a-51994b34b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-4ad48798-518a-4634-820b-29b00065b464,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a974a7da-6f00-4ec6-bb13-eecfc7039278,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fd01ece4-a7a9-4038-8f54-14e459557264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778487351-172.17.0.19-1598542718942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39605,DS-a135e9f7-5bd6-41c2-aa3e-3cf3a6baaecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-3f463e43-9ab5-4e3b-bae7-265eaba5fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-6ea447d7-ee40-4e7a-bbea-21ecae190e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-6c119920-78d0-4c28-bc66-ebd1517349ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-53008706-14bb-4bb7-b58a-51994b34b57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-4ad48798-518a-4634-820b-29b00065b464,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a974a7da-6f00-4ec6-bb13-eecfc7039278,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fd01ece4-a7a9-4038-8f54-14e459557264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731571818-172.17.0.19-1598543204552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-258c1f6c-0393-4cf4-a100-b48c664527c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-24146e4c-6bba-4d46-b8ca-987892844ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-ec5138cc-45a4-457b-836a-6f75f0c7e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-54e2bdf3-b006-4a90-b6e0-3b3070213a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2e535905-cf79-44e1-9baf-f2a14648c342,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-928528a9-d401-433e-892e-f3810907fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-ebc7dd57-0d2e-4689-b841-249ee8b8f199,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-71828510-25e4-48de-9cfe-f93ceb143f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731571818-172.17.0.19-1598543204552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-258c1f6c-0393-4cf4-a100-b48c664527c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-24146e4c-6bba-4d46-b8ca-987892844ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-ec5138cc-45a4-457b-836a-6f75f0c7e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-54e2bdf3-b006-4a90-b6e0-3b3070213a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2e535905-cf79-44e1-9baf-f2a14648c342,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-928528a9-d401-433e-892e-f3810907fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-ebc7dd57-0d2e-4689-b841-249ee8b8f199,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-71828510-25e4-48de-9cfe-f93ceb143f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782827761-172.17.0.19-1598543787560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-5f529888-4f4d-42dd-8e1a-af57249ecb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-0391efcc-a07a-4b4e-9508-f0473b3e0ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-71799de6-bab1-45cf-9ebe-7b50da49c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-641afc7c-91a4-440c-9aba-b46099e101fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6ae13af2-7da8-46fd-92d6-b5546c212b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-15a258dc-587c-41c9-b96d-d01ac8c6378c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-4c40c176-39fc-4d11-895e-5d8db9d4fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-f3813974-fe2e-48bd-8740-c8113121c716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782827761-172.17.0.19-1598543787560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-5f529888-4f4d-42dd-8e1a-af57249ecb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-0391efcc-a07a-4b4e-9508-f0473b3e0ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-71799de6-bab1-45cf-9ebe-7b50da49c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-641afc7c-91a4-440c-9aba-b46099e101fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-6ae13af2-7da8-46fd-92d6-b5546c212b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-15a258dc-587c-41c9-b96d-d01ac8c6378c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-4c40c176-39fc-4d11-895e-5d8db9d4fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-f3813974-fe2e-48bd-8740-c8113121c716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147222796-172.17.0.19-1598544393212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-a32f8a20-591f-464e-9ac8-6fa13b9fc3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-f297d6bf-988d-4c4a-b8f4-14f528411b96,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-43993960-5abf-47da-b3e3-c492e5282906,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c5acef66-0fd6-444d-8fde-e780443894c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-993dc7a4-004a-491f-842e-68a18997a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-ab18a593-9cfd-416b-be8a-3239bc3470fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-33899278-ea44-4bb5-a1d3-b2a8628984b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-5a3874f8-eb7f-43d4-88f9-21bb9213151d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147222796-172.17.0.19-1598544393212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-a32f8a20-591f-464e-9ac8-6fa13b9fc3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-f297d6bf-988d-4c4a-b8f4-14f528411b96,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-43993960-5abf-47da-b3e3-c492e5282906,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c5acef66-0fd6-444d-8fde-e780443894c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-993dc7a4-004a-491f-842e-68a18997a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-ab18a593-9cfd-416b-be8a-3239bc3470fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-33899278-ea44-4bb5-a1d3-b2a8628984b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-5a3874f8-eb7f-43d4-88f9-21bb9213151d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123745183-172.17.0.19-1598544876619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-46806111-749e-4b68-b7c2-07f8474ade4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3cfa7a8b-2892-4be2-b22d-66c4f4db076f,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-b1083c88-7676-4746-80c2-68c7169cbe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-48b2c09d-5c5e-4656-9df1-7f2da131edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-6350ce1c-3d02-48af-b0a3-5f5f820c937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-acb3821a-6f79-4e75-8509-9e886dd43b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-0a613e22-b35a-4136-9fcc-ec8ee01b1ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-2b152e06-a9e5-4cc2-b1a2-3b4c5ab0144b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123745183-172.17.0.19-1598544876619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-46806111-749e-4b68-b7c2-07f8474ade4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3cfa7a8b-2892-4be2-b22d-66c4f4db076f,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-b1083c88-7676-4746-80c2-68c7169cbe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-48b2c09d-5c5e-4656-9df1-7f2da131edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-6350ce1c-3d02-48af-b0a3-5f5f820c937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-acb3821a-6f79-4e75-8509-9e886dd43b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-0a613e22-b35a-4136-9fcc-ec8ee01b1ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-2b152e06-a9e5-4cc2-b1a2-3b4c5ab0144b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190491942-172.17.0.19-1598545251203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-0da3b24d-09c4-4936-b32f-fe8abd4c62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-35bb15b6-9e40-4525-8818-c3def41eb4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-07bac6c6-54b7-4ac5-99ff-1db8eea0c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-af8fc146-6eef-4945-9004-fafc511a8e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-5899ef71-5c13-48ac-b2c6-c9f82f851264,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-0708eae7-8b4f-45f1-b5d4-6d0c658c9486,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-acdc0ef2-283e-4058-aaeb-94276229c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d19944cd-cee6-4fec-8932-fd0a43ed00f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190491942-172.17.0.19-1598545251203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-0da3b24d-09c4-4936-b32f-fe8abd4c62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-35bb15b6-9e40-4525-8818-c3def41eb4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-07bac6c6-54b7-4ac5-99ff-1db8eea0c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-af8fc146-6eef-4945-9004-fafc511a8e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-5899ef71-5c13-48ac-b2c6-c9f82f851264,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-0708eae7-8b4f-45f1-b5d4-6d0c658c9486,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-acdc0ef2-283e-4058-aaeb-94276229c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d19944cd-cee6-4fec-8932-fd0a43ed00f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889549580-172.17.0.19-1598545331917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-5f9c9050-923c-48b6-b28d-1ac0d36132d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-f09d01c3-c775-47aa-b221-7dc4accc3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-1cb69527-6578-433d-b79a-ead144fb85dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-ea817d20-580f-4c0f-83ce-2a5d95252062,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-522e9741-62e6-49f6-aa05-01fbc950d437,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-2fc20309-51f6-4efa-830f-cfd33fc498b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-6574eaee-2544-4e96-9384-72d6cd7db382,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-725176cc-2d38-422f-bcbe-e9a69d3f127c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889549580-172.17.0.19-1598545331917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-5f9c9050-923c-48b6-b28d-1ac0d36132d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-f09d01c3-c775-47aa-b221-7dc4accc3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-1cb69527-6578-433d-b79a-ead144fb85dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-ea817d20-580f-4c0f-83ce-2a5d95252062,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-522e9741-62e6-49f6-aa05-01fbc950d437,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-2fc20309-51f6-4efa-830f-cfd33fc498b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-6574eaee-2544-4e96-9384-72d6cd7db382,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-725176cc-2d38-422f-bcbe-e9a69d3f127c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530667640-172.17.0.19-1598545849984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-9cd4c3db-408f-4fdf-b8c7-7f773cd8aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-f70a407c-84f7-4d80-b3dc-ec7dbb8dca26,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-c31478a9-1397-4b2d-a3a8-63abaaab92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-616c91db-4e0a-48a1-9a69-4bb7e13655de,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-fb77fc2f-9c2a-4840-8447-05d1e7e13934,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4bb25e12-928a-4cb9-b1b9-3b690e36ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-2fc97758-3db9-4051-9592-5e6a1fa7a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-3df2da07-0952-43fe-813c-5b5b847d935b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530667640-172.17.0.19-1598545849984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-9cd4c3db-408f-4fdf-b8c7-7f773cd8aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-f70a407c-84f7-4d80-b3dc-ec7dbb8dca26,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-c31478a9-1397-4b2d-a3a8-63abaaab92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-616c91db-4e0a-48a1-9a69-4bb7e13655de,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-fb77fc2f-9c2a-4840-8447-05d1e7e13934,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4bb25e12-928a-4cb9-b1b9-3b690e36ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-2fc97758-3db9-4051-9592-5e6a1fa7a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-3df2da07-0952-43fe-813c-5b5b847d935b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176248356-172.17.0.19-1598545922544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32939,DS-e1d66645-176c-465f-9ae0-ece017e547bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-4bfe45f0-5091-4195-94aa-238eda1c4c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-071d65e2-575e-46bb-ac39-c5cd4342e613,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-dc2fffef-6919-49e0-a7eb-8a6d7e01a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-897d3632-9472-4379-9b37-65120d6cfaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-e19a5364-a85a-4971-af42-e504a21c8b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-5a6e5beb-8a5c-44e6-b908-18fe1966be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e06fcaa0-7bbb-4ce3-a597-5d0be75a9eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176248356-172.17.0.19-1598545922544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32939,DS-e1d66645-176c-465f-9ae0-ece017e547bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-4bfe45f0-5091-4195-94aa-238eda1c4c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-071d65e2-575e-46bb-ac39-c5cd4342e613,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-dc2fffef-6919-49e0-a7eb-8a6d7e01a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-897d3632-9472-4379-9b37-65120d6cfaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-e19a5364-a85a-4971-af42-e504a21c8b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-5a6e5beb-8a5c-44e6-b908-18fe1966be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e06fcaa0-7bbb-4ce3-a597-5d0be75a9eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927575957-172.17.0.19-1598546034153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-f00f2081-073b-44e8-8723-9e25d2443e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-b438faae-f1c9-41d3-8ba0-369cb2820544,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-eedebb41-4b58-4333-a40b-aa799b400626,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-d933396c-5211-4bef-a580-c255a93ee1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-9f6fe865-b6f6-4073-b224-29efd1a6bc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-665d60c3-a167-4961-a11b-3b61c7b922d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-b72f2590-6986-4de0-94a6-ee7508bc274f,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-10e13d7c-a0d7-4728-a53d-de8e4194526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927575957-172.17.0.19-1598546034153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-f00f2081-073b-44e8-8723-9e25d2443e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-b438faae-f1c9-41d3-8ba0-369cb2820544,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-eedebb41-4b58-4333-a40b-aa799b400626,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-d933396c-5211-4bef-a580-c255a93ee1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-9f6fe865-b6f6-4073-b224-29efd1a6bc02,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-665d60c3-a167-4961-a11b-3b61c7b922d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-b72f2590-6986-4de0-94a6-ee7508bc274f,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-10e13d7c-a0d7-4728-a53d-de8e4194526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 16384
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762902161-172.17.0.19-1598546074585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-3f5ffec2-d67d-4e6a-b11f-b633f82b0479,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-0e477a49-19d5-4b2f-98d8-6297fd50fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-ef0c0922-267e-415d-b627-2f61749e6115,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e36a074c-73ec-460e-ab6a-fb659d850992,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-8e97ac87-11b3-4e86-9011-8b137ac48f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-70152238-b654-4cef-92e8-9187d33a9a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-4bc85253-7f63-42d9-bb76-fedd89e4514d,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-98223f87-4aea-499e-ba60-b3a471ad04cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762902161-172.17.0.19-1598546074585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-3f5ffec2-d67d-4e6a-b11f-b633f82b0479,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-0e477a49-19d5-4b2f-98d8-6297fd50fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-ef0c0922-267e-415d-b627-2f61749e6115,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e36a074c-73ec-460e-ab6a-fb659d850992,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-8e97ac87-11b3-4e86-9011-8b137ac48f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-70152238-b654-4cef-92e8-9187d33a9a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-4bc85253-7f63-42d9-bb76-fedd89e4514d,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-98223f87-4aea-499e-ba60-b3a471ad04cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5459
