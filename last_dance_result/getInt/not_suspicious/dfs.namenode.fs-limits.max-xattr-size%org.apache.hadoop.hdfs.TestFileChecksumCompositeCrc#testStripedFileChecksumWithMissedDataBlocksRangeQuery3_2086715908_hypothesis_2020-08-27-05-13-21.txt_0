reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765911153-172.17.0.10-1598505823265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-803118bc-3da9-4efe-afc7-28048f1a5470,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-de1dfa32-e68e-4e65-8bba-81a63f8c47ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6f623352-52e8-452b-9506-8341cfb3abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-5dfd4cfe-966b-4c3f-812f-8524bc2a4bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-622a7091-8766-494f-bc68-5be32eb7bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-40467c24-f6a8-48ec-a592-b84b28707409,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-e567ac1f-2871-47a8-954d-53e3b7267be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-6668c675-1291-42bf-8d3c-599fc00f34d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765911153-172.17.0.10-1598505823265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-803118bc-3da9-4efe-afc7-28048f1a5470,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-de1dfa32-e68e-4e65-8bba-81a63f8c47ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-6f623352-52e8-452b-9506-8341cfb3abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-5dfd4cfe-966b-4c3f-812f-8524bc2a4bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-622a7091-8766-494f-bc68-5be32eb7bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-40467c24-f6a8-48ec-a592-b84b28707409,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-e567ac1f-2871-47a8-954d-53e3b7267be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-6668c675-1291-42bf-8d3c-599fc00f34d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099023545-172.17.0.10-1598506302886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-51065345-4eac-4ac9-9ce6-c0b9ea495b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-ccc56496-49c0-473f-9cff-3c316a431f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-0373b072-52fd-4d42-8c18-e984459a8683,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-0226e296-f997-45c7-9e6c-f4687b679392,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-5b69dfef-ce53-4b1e-97c1-58862cd3cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-f05695fd-b400-46ee-8600-28e8a964e643,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-938b97ac-dc27-48ec-adca-a117ca8b3154,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-232f90eb-4baf-4063-af08-7d82bcdd9e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099023545-172.17.0.10-1598506302886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-51065345-4eac-4ac9-9ce6-c0b9ea495b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-ccc56496-49c0-473f-9cff-3c316a431f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-0373b072-52fd-4d42-8c18-e984459a8683,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-0226e296-f997-45c7-9e6c-f4687b679392,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-5b69dfef-ce53-4b1e-97c1-58862cd3cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-f05695fd-b400-46ee-8600-28e8a964e643,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-938b97ac-dc27-48ec-adca-a117ca8b3154,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-232f90eb-4baf-4063-af08-7d82bcdd9e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87975286-172.17.0.10-1598506761110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-3b67822b-eecf-4c0f-acef-bc0087da2194,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ef296e01-adde-4341-9422-f68ffe1bc567,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-746fde7e-6e92-433d-85b7-b4316e28d31e,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-8a8cebbf-cd0e-4604-b54c-360d4d91fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-70127dbf-bcb9-4f9d-bd5a-ab0c52e9b314,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-f4eabce7-5692-4446-a60a-437ee912a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-85f4fd45-3c5a-4498-bfe6-4413c67064ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-cb4a96b9-ec43-443d-9233-26a68e7ba419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87975286-172.17.0.10-1598506761110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-3b67822b-eecf-4c0f-acef-bc0087da2194,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-ef296e01-adde-4341-9422-f68ffe1bc567,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-746fde7e-6e92-433d-85b7-b4316e28d31e,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-8a8cebbf-cd0e-4604-b54c-360d4d91fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-70127dbf-bcb9-4f9d-bd5a-ab0c52e9b314,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-f4eabce7-5692-4446-a60a-437ee912a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-85f4fd45-3c5a-4498-bfe6-4413c67064ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-cb4a96b9-ec43-443d-9233-26a68e7ba419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214367364-172.17.0.10-1598507022565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-98641ffe-76d2-4469-a4d1-6392d8ba2711,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-5b135b9c-a4c8-4634-b433-a18f8e6999c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-bb0e4b47-34a9-40af-8729-9d5d921ea1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-24b4d7f0-2de3-415b-b2eb-f0616019fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-b4ff64fc-53e6-4457-9f89-e913062cada7,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-072d315f-ca1c-4e8e-b6fe-e949356ff6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-5c8ea0c7-b1c6-4544-badb-c3f17bdc9269,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-443e0e3f-d6a3-4252-bb8c-08cb563a585c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214367364-172.17.0.10-1598507022565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-98641ffe-76d2-4469-a4d1-6392d8ba2711,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-5b135b9c-a4c8-4634-b433-a18f8e6999c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-bb0e4b47-34a9-40af-8729-9d5d921ea1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-24b4d7f0-2de3-415b-b2eb-f0616019fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-b4ff64fc-53e6-4457-9f89-e913062cada7,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-072d315f-ca1c-4e8e-b6fe-e949356ff6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-5c8ea0c7-b1c6-4544-badb-c3f17bdc9269,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-443e0e3f-d6a3-4252-bb8c-08cb563a585c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386957777-172.17.0.10-1598507064346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-fc91ff32-5fea-42f3-900b-8bd7dd74ecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-d80d82e7-bb6e-42f9-a9eb-00faed9fad47,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd2884fb-1562-4479-bfc3-3619d5051663,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-b90ec83e-6156-4b30-8151-2e60bcdaddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-f5c44786-a2fb-40e6-adf2-0069c84c50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-9afd7643-4aba-4b7e-894f-d08559af20dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-f6167bf7-e368-431f-ba31-ba8c85e7d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-66d2e909-430e-4c29-a0ba-4b32530c1282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386957777-172.17.0.10-1598507064346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-fc91ff32-5fea-42f3-900b-8bd7dd74ecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-d80d82e7-bb6e-42f9-a9eb-00faed9fad47,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd2884fb-1562-4479-bfc3-3619d5051663,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-b90ec83e-6156-4b30-8151-2e60bcdaddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-f5c44786-a2fb-40e6-adf2-0069c84c50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-9afd7643-4aba-4b7e-894f-d08559af20dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-f6167bf7-e368-431f-ba31-ba8c85e7d2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-66d2e909-430e-4c29-a0ba-4b32530c1282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799044194-172.17.0.10-1598507098318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-945c4d94-78f7-48ac-a664-80ee7c53e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-70b7aa78-19ab-4e02-a78a-e4c8ef23f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-23a5cbd5-670d-4452-bb57-5ac600b48c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-ef18df90-7397-4906-8f67-7fd87469d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-eabfb42a-353a-4ba0-8a01-2586137412e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-5a538aca-4118-4936-9cf8-bd65f81335b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-eb6bb5c0-6aca-447a-9dc1-da010b2e388d,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-7a558bbc-8d7a-43d6-8ce6-6c8532909cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799044194-172.17.0.10-1598507098318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-945c4d94-78f7-48ac-a664-80ee7c53e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-70b7aa78-19ab-4e02-a78a-e4c8ef23f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-23a5cbd5-670d-4452-bb57-5ac600b48c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-ef18df90-7397-4906-8f67-7fd87469d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-eabfb42a-353a-4ba0-8a01-2586137412e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-5a538aca-4118-4936-9cf8-bd65f81335b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-eb6bb5c0-6aca-447a-9dc1-da010b2e388d,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-7a558bbc-8d7a-43d6-8ce6-6c8532909cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939382191-172.17.0.10-1598507126150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-65b46260-be8e-4c6b-8a7a-87c336f85798,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d4a15052-ae3f-45cd-a975-a288a1aea98c,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-7afce4f2-ad20-4002-ae35-d995c8fff355,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-8094299b-853f-4197-abc4-a77ae7e3a342,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-a59de3b8-818c-478b-8dd8-ff4a96838d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d707800b-d263-4e41-ac03-9c7b2feb47ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-63c88e23-9993-4f19-9a76-1be6bac68b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-c8b4eefe-4c37-4265-b53e-f68ea096c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939382191-172.17.0.10-1598507126150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-65b46260-be8e-4c6b-8a7a-87c336f85798,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d4a15052-ae3f-45cd-a975-a288a1aea98c,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-7afce4f2-ad20-4002-ae35-d995c8fff355,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-8094299b-853f-4197-abc4-a77ae7e3a342,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-a59de3b8-818c-478b-8dd8-ff4a96838d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d707800b-d263-4e41-ac03-9c7b2feb47ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-63c88e23-9993-4f19-9a76-1be6bac68b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-c8b4eefe-4c37-4265-b53e-f68ea096c930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184175589-172.17.0.10-1598507234113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-ca26348e-b5cc-472d-9071-b1997b8f9772,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-9bd6b9ff-e9c0-4d6b-b718-e434602009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-8048dd1a-69e1-4fe0-bf01-38863dc07851,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-584dded1-649a-4179-9a73-e9ba4e7991f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-596988a1-381e-467e-bbc8-3ef33e8bb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-fc34ce41-1aa2-464f-9b11-012f987e2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e248713a-cb94-48ff-867f-c7680959ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f960f75e-f3b1-4fa9-b8cf-5fb6789d979a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184175589-172.17.0.10-1598507234113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-ca26348e-b5cc-472d-9071-b1997b8f9772,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-9bd6b9ff-e9c0-4d6b-b718-e434602009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-8048dd1a-69e1-4fe0-bf01-38863dc07851,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-584dded1-649a-4179-9a73-e9ba4e7991f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-596988a1-381e-467e-bbc8-3ef33e8bb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-fc34ce41-1aa2-464f-9b11-012f987e2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e248713a-cb94-48ff-867f-c7680959ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f960f75e-f3b1-4fa9-b8cf-5fb6789d979a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114592023-172.17.0.10-1598507264887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-42a28bf2-2bf0-421c-bbec-d67eca5ac368,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-76c4edc6-83b1-4a64-852c-cba738ecce32,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-71def720-3755-40b5-82e9-05bf4f914209,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e3a242c1-55ac-4ce9-a155-f6e53e855270,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e8f74842-58bb-4db1-82e6-010f88b8da29,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c1fa668c-7928-47eb-bd53-1a6fad6b7525,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-90c75448-228b-4ef9-92bb-e0c16dc56ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f19b183e-8426-4eee-85eb-1777b9f83f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114592023-172.17.0.10-1598507264887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-42a28bf2-2bf0-421c-bbec-d67eca5ac368,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-76c4edc6-83b1-4a64-852c-cba738ecce32,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-71def720-3755-40b5-82e9-05bf4f914209,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-e3a242c1-55ac-4ce9-a155-f6e53e855270,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e8f74842-58bb-4db1-82e6-010f88b8da29,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c1fa668c-7928-47eb-bd53-1a6fad6b7525,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-90c75448-228b-4ef9-92bb-e0c16dc56ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f19b183e-8426-4eee-85eb-1777b9f83f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315851584-172.17.0.10-1598508141854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-54c57dd5-9ea3-4cfa-84fa-bacff6b91af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-4f6b1478-6ecd-4a66-8cfd-7d4d14089b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-1ff44000-9e79-4646-99fc-f4a09de7a593,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-da7213a3-168b-4020-9de1-0841613aa953,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-c5148aff-77ef-4a45-ba73-417827c40565,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-dec03e6a-8ba3-4ef5-97d3-c6d6136d54e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-42046470-b1b1-4a84-bf24-7b2d771e7b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-00697c12-ca9b-4a76-948e-d1a2f5c40557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315851584-172.17.0.10-1598508141854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-54c57dd5-9ea3-4cfa-84fa-bacff6b91af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-4f6b1478-6ecd-4a66-8cfd-7d4d14089b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-1ff44000-9e79-4646-99fc-f4a09de7a593,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-da7213a3-168b-4020-9de1-0841613aa953,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-c5148aff-77ef-4a45-ba73-417827c40565,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-dec03e6a-8ba3-4ef5-97d3-c6d6136d54e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-42046470-b1b1-4a84-bf24-7b2d771e7b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-00697c12-ca9b-4a76-948e-d1a2f5c40557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272672522-172.17.0.10-1598508174983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-4728ff47-b579-4741-83d3-bb4f9205f5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-e70e1352-dc25-4cd8-bf08-1bc1e4c2ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-ec3056ca-b550-4abb-b2da-f12b586983a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-591d0198-b464-4660-9e4b-c99801147343,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-fb56ffca-4fb3-45ae-a742-3bc588e5bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-4320c4bb-6300-4f44-aa2d-712bb896c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-b4b7edfa-e860-4cd9-af07-b47e2b3bc7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-eb3125cb-b33d-48a9-8d5f-96c4f698084e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272672522-172.17.0.10-1598508174983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-4728ff47-b579-4741-83d3-bb4f9205f5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-e70e1352-dc25-4cd8-bf08-1bc1e4c2ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-ec3056ca-b550-4abb-b2da-f12b586983a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-591d0198-b464-4660-9e4b-c99801147343,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-fb56ffca-4fb3-45ae-a742-3bc588e5bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-4320c4bb-6300-4f44-aa2d-712bb896c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-b4b7edfa-e860-4cd9-af07-b47e2b3bc7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-eb3125cb-b33d-48a9-8d5f-96c4f698084e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568981183-172.17.0.10-1598508206511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-b6779e73-e5ec-48c0-9523-aa0a48479b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-db38a6f4-9d62-4054-bebc-0b01559e954e,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6d209441-f3fe-4ca7-991d-28366e81b638,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-c9b017f4-f422-4dd6-96de-50929006cf57,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-4c30a27b-986d-405d-a73e-6142d344c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0b72d12b-0a49-485a-8353-ac6c3fa00d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6dae28eb-e75b-4725-a1e6-97c5d74a2312,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-3508636f-0003-4083-914f-57f6312bf029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568981183-172.17.0.10-1598508206511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-b6779e73-e5ec-48c0-9523-aa0a48479b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-db38a6f4-9d62-4054-bebc-0b01559e954e,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6d209441-f3fe-4ca7-991d-28366e81b638,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-c9b017f4-f422-4dd6-96de-50929006cf57,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-4c30a27b-986d-405d-a73e-6142d344c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0b72d12b-0a49-485a-8353-ac6c3fa00d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-6dae28eb-e75b-4725-a1e6-97c5d74a2312,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-3508636f-0003-4083-914f-57f6312bf029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798831380-172.17.0.10-1598508721815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-4e9eb06d-9f2d-4bdd-a47d-71918f7e66c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d0e6df86-e696-4932-8dc9-149302461cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-80eca8db-4c28-4453-bf45-00b15fae6335,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-9c5fc1e9-cc8c-48be-8ea8-987365d7a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-2172c810-49fd-412c-a1b5-068880ab383c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-374c3044-bbf2-4364-b6ce-9468c6f96b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a787f5e4-37de-4f87-81f3-6b5bcb5b3152,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-90bbcef4-318e-4a76-8ae8-e05bc7e3f3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798831380-172.17.0.10-1598508721815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38857,DS-4e9eb06d-9f2d-4bdd-a47d-71918f7e66c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d0e6df86-e696-4932-8dc9-149302461cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-80eca8db-4c28-4453-bf45-00b15fae6335,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-9c5fc1e9-cc8c-48be-8ea8-987365d7a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-2172c810-49fd-412c-a1b5-068880ab383c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-374c3044-bbf2-4364-b6ce-9468c6f96b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a787f5e4-37de-4f87-81f3-6b5bcb5b3152,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-90bbcef4-318e-4a76-8ae8-e05bc7e3f3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190086217-172.17.0.10-1598509146785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-7b852606-dea8-4298-b2ad-bd2763d82c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-9a0a0b81-29cb-49ff-8e00-3844b619f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-5983c433-5366-4f53-a471-cd91a0759e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ffd621c3-a6e7-416b-b435-339be63e0fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-a3227f58-61e2-44ff-9d88-5b00efc7d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-4d618157-2d45-41ea-a6ff-85e589958f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-26e56b3b-644a-4f40-a331-44d8f49eccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-bbc57aae-0dde-41db-bf54-b44898e213b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190086217-172.17.0.10-1598509146785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-7b852606-dea8-4298-b2ad-bd2763d82c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-9a0a0b81-29cb-49ff-8e00-3844b619f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-5983c433-5366-4f53-a471-cd91a0759e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ffd621c3-a6e7-416b-b435-339be63e0fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-a3227f58-61e2-44ff-9d88-5b00efc7d0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-4d618157-2d45-41ea-a6ff-85e589958f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-26e56b3b-644a-4f40-a331-44d8f49eccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-bbc57aae-0dde-41db-bf54-b44898e213b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206293760-172.17.0.10-1598509454441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-1bcea29a-eab5-430a-b9bb-fa47ac71a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-76eda5e6-4aa6-4a49-8dbf-3333cf8e7634,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-263be565-2f0d-47df-ad04-81abf7c8c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-a220baa7-0a03-41d5-b788-c8404c6df9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-54ea628a-83c9-4644-91fd-bbdfd073e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-75a5e0bd-b22d-4cdc-a2e8-f77856d7a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e2e66778-3cda-476c-8fd5-56e52db916d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-18ce73fe-c0f4-4f91-9eb7-fb110c28e403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206293760-172.17.0.10-1598509454441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-1bcea29a-eab5-430a-b9bb-fa47ac71a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-76eda5e6-4aa6-4a49-8dbf-3333cf8e7634,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-263be565-2f0d-47df-ad04-81abf7c8c37c,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-a220baa7-0a03-41d5-b788-c8404c6df9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-54ea628a-83c9-4644-91fd-bbdfd073e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-75a5e0bd-b22d-4cdc-a2e8-f77856d7a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e2e66778-3cda-476c-8fd5-56e52db916d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-18ce73fe-c0f4-4f91-9eb7-fb110c28e403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700766152-172.17.0.10-1598510239958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33927,DS-9430ccf0-16f2-4656-af32-971b58248567,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-28aa49e0-971d-4753-8d29-f0a25fb6c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-cf437d85-e5b4-4053-8800-8f3708c1ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-80e208cc-9a7d-41a5-80c4-5c2e3101de84,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-02bff5ce-9e8a-43cf-af5b-fbfd03a4cef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-50c2a16f-cc60-4837-8825-3b840665b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-8df4bfa3-f264-4952-acd1-f43f8e858c33,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-674fbf44-374f-4ff5-a5cf-02388be9c377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700766152-172.17.0.10-1598510239958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33927,DS-9430ccf0-16f2-4656-af32-971b58248567,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-28aa49e0-971d-4753-8d29-f0a25fb6c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-cf437d85-e5b4-4053-8800-8f3708c1ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-80e208cc-9a7d-41a5-80c4-5c2e3101de84,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-02bff5ce-9e8a-43cf-af5b-fbfd03a4cef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-50c2a16f-cc60-4837-8825-3b840665b1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-8df4bfa3-f264-4952-acd1-f43f8e858c33,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-674fbf44-374f-4ff5-a5cf-02388be9c377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538536058-172.17.0.10-1598510318444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-2497038d-965e-4ead-9bea-97a689c8e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6de5ed4c-9985-4a99-b57c-de113abe3bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-9c4a6c42-503e-4cb7-953c-fc0463551b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2ae43517-5b42-4014-8df8-c73aa7aa9c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-d72ee66c-f235-40b2-8363-186743bffb41,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-e66d7490-b8f7-489f-a8af-44fa522f470e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-72e7af04-de47-4a47-8637-3c34a37ae8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-6317c3aa-c093-4ad4-bce2-b7b6140d5410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538536058-172.17.0.10-1598510318444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-2497038d-965e-4ead-9bea-97a689c8e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-6de5ed4c-9985-4a99-b57c-de113abe3bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-9c4a6c42-503e-4cb7-953c-fc0463551b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-2ae43517-5b42-4014-8df8-c73aa7aa9c71,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-d72ee66c-f235-40b2-8363-186743bffb41,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-e66d7490-b8f7-489f-a8af-44fa522f470e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-72e7af04-de47-4a47-8637-3c34a37ae8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-6317c3aa-c093-4ad4-bce2-b7b6140d5410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990507559-172.17.0.10-1598510349585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-d0f04777-c9ca-4c08-8398-525f566c284d,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-fa324130-bb28-4b65-b4f2-51cb08f298e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-2ee1566a-bd6f-48c8-a58c-6c461a97da81,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-8ba30769-6f23-4873-abfd-e7d8b1617a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-9515f253-a830-4c74-b25c-2357b1d3eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-4c5082c1-5ff2-4e17-814b-0605dc65aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-28f11541-d63e-4a12-a2d8-1754af71e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-74ae133f-ba7d-4d79-8fc5-df50c14d38e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990507559-172.17.0.10-1598510349585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-d0f04777-c9ca-4c08-8398-525f566c284d,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-fa324130-bb28-4b65-b4f2-51cb08f298e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-2ee1566a-bd6f-48c8-a58c-6c461a97da81,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-8ba30769-6f23-4873-abfd-e7d8b1617a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-9515f253-a830-4c74-b25c-2357b1d3eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-4c5082c1-5ff2-4e17-814b-0605dc65aaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-28f11541-d63e-4a12-a2d8-1754af71e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-74ae133f-ba7d-4d79-8fc5-df50c14d38e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5484
