reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231944077-172.17.0.17-1598638313675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-33f16bcc-fa83-4683-9260-7d935697263c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-314cfb50-f491-4d69-ae96-d4cbf316068a,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e7b21e05-7629-4b66-bfa0-c77181b04875,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-760b3607-b6d7-42b8-81a6-4d49310a24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-3d75e797-bc52-428e-be98-09de4bc1b445,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-90ed7cf3-433d-435b-8773-9fb7764246ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-b9525039-273b-4d53-a229-044392826088,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-a7fae313-8828-4377-b470-59b35c3cd276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231944077-172.17.0.17-1598638313675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-33f16bcc-fa83-4683-9260-7d935697263c,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-314cfb50-f491-4d69-ae96-d4cbf316068a,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-e7b21e05-7629-4b66-bfa0-c77181b04875,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-760b3607-b6d7-42b8-81a6-4d49310a24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-3d75e797-bc52-428e-be98-09de4bc1b445,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-90ed7cf3-433d-435b-8773-9fb7764246ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-b9525039-273b-4d53-a229-044392826088,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-a7fae313-8828-4377-b470-59b35c3cd276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929990655-172.17.0.17-1598638412281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-70ec4e11-463d-4034-bb06-b43d58aec0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-ea9dc79f-1b67-4abe-8cf3-149924ac4e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-99e505b5-24a3-4086-b5c1-cb11a2149838,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-3782f7b5-064b-4b7c-9bcd-0abe392532c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-b8bd8068-81ea-41fe-aa32-c83474da3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-d09d2bbf-7611-41f7-9245-c535618611af,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-724ca9c3-6e13-4d35-8b02-404e2d028696,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-b3587a5a-e7ff-4d2d-8d44-e7895f44bc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929990655-172.17.0.17-1598638412281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-70ec4e11-463d-4034-bb06-b43d58aec0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-ea9dc79f-1b67-4abe-8cf3-149924ac4e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-99e505b5-24a3-4086-b5c1-cb11a2149838,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-3782f7b5-064b-4b7c-9bcd-0abe392532c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-b8bd8068-81ea-41fe-aa32-c83474da3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-d09d2bbf-7611-41f7-9245-c535618611af,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-724ca9c3-6e13-4d35-8b02-404e2d028696,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-b3587a5a-e7ff-4d2d-8d44-e7895f44bc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181051864-172.17.0.17-1598638449278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-0907b9ea-a06d-4985-98d7-3b75a4e093ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-508b8840-216b-4f27-8089-0ae5661e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-a58b9f66-9571-461c-a173-f7cf3ddafa79,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-37376410-d307-4752-896f-29c33fcb51ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-356796cf-df3d-4848-a651-4de810f62935,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-c05497f7-b663-4cc2-9752-8b7859469bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-94f7ffc2-5358-4e69-911e-fb1ef14ca67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c6bbb4b7-dfd4-4441-bf62-2c6ed4984df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181051864-172.17.0.17-1598638449278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-0907b9ea-a06d-4985-98d7-3b75a4e093ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-508b8840-216b-4f27-8089-0ae5661e7014,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-a58b9f66-9571-461c-a173-f7cf3ddafa79,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-37376410-d307-4752-896f-29c33fcb51ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-356796cf-df3d-4848-a651-4de810f62935,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-c05497f7-b663-4cc2-9752-8b7859469bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-94f7ffc2-5358-4e69-911e-fb1ef14ca67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c6bbb4b7-dfd4-4441-bf62-2c6ed4984df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523388572-172.17.0.17-1598639141953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43353,DS-4121adf4-2282-4b0a-9d9f-1ffb0819a823,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-d42d5351-df40-4741-add7-a98c7c30e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-07501d14-e147-48f2-9d59-94e84ec12ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1cebc745-b94d-4ce7-a331-1af604fd4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-0f3c1761-1335-4691-82e0-662e220c3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-3ad9fda4-27f8-437c-aed6-89e7451b319b,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-8791085a-c790-40db-ba34-878774b2bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-a5052931-4184-40c4-b2e4-fbe9be747fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523388572-172.17.0.17-1598639141953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43353,DS-4121adf4-2282-4b0a-9d9f-1ffb0819a823,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-d42d5351-df40-4741-add7-a98c7c30e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-07501d14-e147-48f2-9d59-94e84ec12ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1cebc745-b94d-4ce7-a331-1af604fd4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-0f3c1761-1335-4691-82e0-662e220c3b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-3ad9fda4-27f8-437c-aed6-89e7451b319b,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-8791085a-c790-40db-ba34-878774b2bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-a5052931-4184-40c4-b2e4-fbe9be747fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101965606-172.17.0.17-1598639768306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-df0e6c34-e672-43bc-941e-44b24de7f1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-a3a5a9da-6622-4d1c-9517-28acefda59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-fe97dd58-7574-4195-ac6f-e988f2a82fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-27ce562a-93e4-42f0-9ac2-eb1c8de05226,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-773005e7-6fc7-4d4d-9218-8223cd40a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f9dfeb0e-0868-46bd-b2ee-97cc7af76489,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32ee4ba0-cb49-4b41-8540-56575275042c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-c6d2bb4a-8244-4cb0-969c-0f5953f49e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101965606-172.17.0.17-1598639768306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-df0e6c34-e672-43bc-941e-44b24de7f1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-a3a5a9da-6622-4d1c-9517-28acefda59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-fe97dd58-7574-4195-ac6f-e988f2a82fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-27ce562a-93e4-42f0-9ac2-eb1c8de05226,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-773005e7-6fc7-4d4d-9218-8223cd40a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f9dfeb0e-0868-46bd-b2ee-97cc7af76489,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32ee4ba0-cb49-4b41-8540-56575275042c,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-c6d2bb4a-8244-4cb0-969c-0f5953f49e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683868937-172.17.0.17-1598640073216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41287,DS-69058cf4-2310-4722-a555-ced7dcc0e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-87614c9b-56dd-4f83-be82-44a7e2bc1326,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-d66c2233-4d6a-4b61-8e3d-fa7c7ea831b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-bd3c7456-27f0-4ab8-93b8-385a03b117ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-39a18cdf-6c68-494e-90e9-1343f2a8bdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-27b0ae06-8296-4b42-bdb9-5f3db0170967,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-1e009ca5-c577-4f0b-a739-fca6131945ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-9403f817-6558-43c0-ac3c-a14e5c647df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683868937-172.17.0.17-1598640073216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41287,DS-69058cf4-2310-4722-a555-ced7dcc0e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-87614c9b-56dd-4f83-be82-44a7e2bc1326,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-d66c2233-4d6a-4b61-8e3d-fa7c7ea831b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-bd3c7456-27f0-4ab8-93b8-385a03b117ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-39a18cdf-6c68-494e-90e9-1343f2a8bdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-27b0ae06-8296-4b42-bdb9-5f3db0170967,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-1e009ca5-c577-4f0b-a739-fca6131945ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-9403f817-6558-43c0-ac3c-a14e5c647df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021202026-172.17.0.17-1598640523207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-fad3870a-4f4a-4123-a5ed-3b370e7d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-be5bf175-0063-4fa0-968d-ab944de8ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-e7b67d91-ff85-4eb2-b191-5e32563d0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-369bba89-4a64-42b7-a86c-ce3fe383acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-264dc527-0e32-4762-a0d0-dbdb40a38b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-64b48316-db19-47e6-8af8-e39969aeb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-0a0cfefe-e5d7-4a0e-8c6e-9e7e3e630369,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-7c9f0762-731e-4b01-a6b8-ce57d525d946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021202026-172.17.0.17-1598640523207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-fad3870a-4f4a-4123-a5ed-3b370e7d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-be5bf175-0063-4fa0-968d-ab944de8ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-e7b67d91-ff85-4eb2-b191-5e32563d0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-369bba89-4a64-42b7-a86c-ce3fe383acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-264dc527-0e32-4762-a0d0-dbdb40a38b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-64b48316-db19-47e6-8af8-e39969aeb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-0a0cfefe-e5d7-4a0e-8c6e-9e7e3e630369,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-7c9f0762-731e-4b01-a6b8-ce57d525d946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965594748-172.17.0.17-1598641131096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43404,DS-3095bb37-a528-4cc6-918a-aed4a3b2c4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-06dbef3d-2b91-4df3-a68d-79a7a6fd8582,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-7b3c3d54-9d08-42be-a762-4b447b4af3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-fec88012-35e4-46fd-92e7-987c7da2d640,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-368c393f-1e48-42c0-bd25-de76e1e34a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c719f847-a00d-4594-aab5-1e6e0c81c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-4193f72f-550b-4d85-9df7-ef09c9fd438d,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-7997b410-84c6-427a-9a31-6f034c4c2852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965594748-172.17.0.17-1598641131096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43404,DS-3095bb37-a528-4cc6-918a-aed4a3b2c4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-06dbef3d-2b91-4df3-a68d-79a7a6fd8582,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-7b3c3d54-9d08-42be-a762-4b447b4af3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-fec88012-35e4-46fd-92e7-987c7da2d640,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-368c393f-1e48-42c0-bd25-de76e1e34a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-c719f847-a00d-4594-aab5-1e6e0c81c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-4193f72f-550b-4d85-9df7-ef09c9fd438d,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-7997b410-84c6-427a-9a31-6f034c4c2852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034608906-172.17.0.17-1598642178158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-6be78ab4-5d65-420b-b269-a6f3af562700,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-da2e59ae-6dcf-4060-9ffa-f989ab15efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-1aa3a36a-90d2-408b-8939-6e3edeea2df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-dc31d0ec-8797-434e-9bb0-4d5b9a34ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-8d8cca1e-efa2-4349-8d61-737b38a82128,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-67250865-a372-46fe-a583-f994ad877d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-c275fb5f-eebf-4982-9e6e-7f53cbc08153,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-4e723d1f-1cc6-45a5-99e4-965ee4f2a699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034608906-172.17.0.17-1598642178158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-6be78ab4-5d65-420b-b269-a6f3af562700,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-da2e59ae-6dcf-4060-9ffa-f989ab15efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-1aa3a36a-90d2-408b-8939-6e3edeea2df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-dc31d0ec-8797-434e-9bb0-4d5b9a34ac2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-8d8cca1e-efa2-4349-8d61-737b38a82128,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-67250865-a372-46fe-a583-f994ad877d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-c275fb5f-eebf-4982-9e6e-7f53cbc08153,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-4e723d1f-1cc6-45a5-99e4-965ee4f2a699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433697717-172.17.0.17-1598642324529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-1ee58136-e667-4e8e-ad21-d4abc137817f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-3e76a9c2-6ab4-422a-9e05-ff196b73d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-9ee62c3e-2a4b-4071-a99f-881cf35ce8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b0874bcc-205b-453d-b01c-7cc352f982af,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-1cfee84e-ef05-4046-817c-d11dbd7e4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-c3d6c3da-625c-4c88-98d4-8097a97ae7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-4ae9e590-a062-43fb-9f0a-419018e71135,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-92c43524-5084-44e8-8345-40bd7b38bcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433697717-172.17.0.17-1598642324529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-1ee58136-e667-4e8e-ad21-d4abc137817f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-3e76a9c2-6ab4-422a-9e05-ff196b73d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-9ee62c3e-2a4b-4071-a99f-881cf35ce8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-b0874bcc-205b-453d-b01c-7cc352f982af,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-1cfee84e-ef05-4046-817c-d11dbd7e4c29,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-c3d6c3da-625c-4c88-98d4-8097a97ae7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-4ae9e590-a062-43fb-9f0a-419018e71135,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-92c43524-5084-44e8-8345-40bd7b38bcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787627933-172.17.0.17-1598642770134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-b9745679-d8a1-46f0-946f-228e1e0dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-c49d2b4c-c9f7-4594-a0d7-6a42a6d1907f,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-1e986283-01eb-4c0a-87ea-3bb46f5e406b,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a884978d-5690-4715-8967-0f6f54f734df,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-8550e268-a7c8-4d07-bccb-c0f9b0ecf326,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-260ada74-593a-4c1c-98e4-9f510629570a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-0d4cc20b-c52c-48be-9ce7-675753e6b420,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-49097621-77c6-44db-b178-65ee79dc1f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787627933-172.17.0.17-1598642770134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-b9745679-d8a1-46f0-946f-228e1e0dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-c49d2b4c-c9f7-4594-a0d7-6a42a6d1907f,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-1e986283-01eb-4c0a-87ea-3bb46f5e406b,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a884978d-5690-4715-8967-0f6f54f734df,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-8550e268-a7c8-4d07-bccb-c0f9b0ecf326,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-260ada74-593a-4c1c-98e4-9f510629570a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-0d4cc20b-c52c-48be-9ce7-675753e6b420,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-49097621-77c6-44db-b178-65ee79dc1f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107359392-172.17.0.17-1598642875531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-fc799c30-284a-4e7d-b3c8-df3b282fcce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-e501972a-8a25-46eb-b8eb-508bb106bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-93272ae7-bfe0-43c6-ab92-947b609db2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-13b4286b-1ad1-4446-a34a-efd96d528d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-2fd78baa-8d7f-4522-9ed9-1d71309720b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-d7a8090e-da8a-4243-bba0-4eb93fa898f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-8792befb-e113-4a57-833b-29cf98ee6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-3814cde2-c520-4caf-81bf-d63d95a1afb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107359392-172.17.0.17-1598642875531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-fc799c30-284a-4e7d-b3c8-df3b282fcce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-e501972a-8a25-46eb-b8eb-508bb106bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-93272ae7-bfe0-43c6-ab92-947b609db2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-13b4286b-1ad1-4446-a34a-efd96d528d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-2fd78baa-8d7f-4522-9ed9-1d71309720b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-d7a8090e-da8a-4243-bba0-4eb93fa898f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-8792befb-e113-4a57-833b-29cf98ee6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-3814cde2-c520-4caf-81bf-d63d95a1afb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707298844-172.17.0.17-1598643045720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-e702e796-004b-4c01-9f71-71e51342030f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-1bf7a86e-a2b2-4c8a-9984-028a90776a41,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e3c778ab-7a8a-47eb-89bb-c2e07f4a0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-8857d763-8a4b-428b-ac99-bff010ec26e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-8b947b1d-733b-4781-a841-898811e284aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ccf2af9f-012e-4c50-bb63-f6fecba7d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-e63b34fe-5af8-4092-8049-54eeaa28c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-0ac8a36b-0f33-470f-8d24-e52f4f1267f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707298844-172.17.0.17-1598643045720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-e702e796-004b-4c01-9f71-71e51342030f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-1bf7a86e-a2b2-4c8a-9984-028a90776a41,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e3c778ab-7a8a-47eb-89bb-c2e07f4a0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-8857d763-8a4b-428b-ac99-bff010ec26e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-8b947b1d-733b-4781-a841-898811e284aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ccf2af9f-012e-4c50-bb63-f6fecba7d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-e63b34fe-5af8-4092-8049-54eeaa28c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-0ac8a36b-0f33-470f-8d24-e52f4f1267f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5333
