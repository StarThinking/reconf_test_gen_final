reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672707056-172.17.0.17-1598679122099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46179,DS-936f2960-21ec-4095-9312-682596a92e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-5a4009d4-5151-4d69-bed2-fa6a28b11b59,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-62eb21cc-ab07-4a96-ba3b-19afc418f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-b66434ea-ee0a-44de-a03e-8a35ed34c3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-65faa345-63ed-4272-9db7-4904b7921fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-179aa3d2-5217-4351-bdcd-7df496024be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-21a4995c-1833-416b-88ca-4d5892c40740,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-91a5ed73-6639-4e67-9f73-6b4e1a0405f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672707056-172.17.0.17-1598679122099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46179,DS-936f2960-21ec-4095-9312-682596a92e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-5a4009d4-5151-4d69-bed2-fa6a28b11b59,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-62eb21cc-ab07-4a96-ba3b-19afc418f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-b66434ea-ee0a-44de-a03e-8a35ed34c3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-65faa345-63ed-4272-9db7-4904b7921fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-179aa3d2-5217-4351-bdcd-7df496024be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-21a4995c-1833-416b-88ca-4d5892c40740,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-91a5ed73-6639-4e67-9f73-6b4e1a0405f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944897300-172.17.0.17-1598680940405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-b5492c5d-5b75-4223-81c2-dbae895f4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-05c7070d-8e9a-4677-b387-3750cfc0ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-83bedd10-b48d-4586-b33c-2b03bfe69891,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-dec963ad-6521-45a0-a266-8cfd58e6ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-14fce8ac-74b1-40ee-b55b-ec5a50db64e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-74c7417f-5254-4fe7-9e66-d3c2fd1c6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-b64f4da9-5052-4fbf-89df-19ac832585e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-55d6f556-00f9-41a9-a8a7-fab34370ad0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944897300-172.17.0.17-1598680940405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-b5492c5d-5b75-4223-81c2-dbae895f4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-05c7070d-8e9a-4677-b387-3750cfc0ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-83bedd10-b48d-4586-b33c-2b03bfe69891,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-dec963ad-6521-45a0-a266-8cfd58e6ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-14fce8ac-74b1-40ee-b55b-ec5a50db64e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-74c7417f-5254-4fe7-9e66-d3c2fd1c6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-b64f4da9-5052-4fbf-89df-19ac832585e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-55d6f556-00f9-41a9-a8a7-fab34370ad0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100669059-172.17.0.17-1598681355416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-02d19312-1b30-481f-9337-5098c9db8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-bf5a7bde-9021-45ea-8ecd-9e91ae7840ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-402d4404-a046-4d6d-80d2-4d10cdb22295,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-eff28a73-3204-4851-8247-009f04b8a146,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-63fb4a90-eb38-4c32-876e-541a26c7bd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-50f82870-e6a8-42c5-8e28-c448a586fd94,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-b395b839-62c0-41f4-a712-224164e94635,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-594d23db-4a4c-47c1-b2cf-945e447c1370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100669059-172.17.0.17-1598681355416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-02d19312-1b30-481f-9337-5098c9db8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-bf5a7bde-9021-45ea-8ecd-9e91ae7840ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-402d4404-a046-4d6d-80d2-4d10cdb22295,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-eff28a73-3204-4851-8247-009f04b8a146,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-63fb4a90-eb38-4c32-876e-541a26c7bd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-50f82870-e6a8-42c5-8e28-c448a586fd94,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-b395b839-62c0-41f4-a712-224164e94635,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-594d23db-4a4c-47c1-b2cf-945e447c1370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145258738-172.17.0.17-1598681507091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-cb880bbc-5189-47e4-9b57-b6eedfe86380,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-841d749b-3c96-4713-abd6-fcc8bada9abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-b20a5b07-d4f0-448b-9b95-6a3979c16bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-a46fe805-5f63-4e2e-907d-1cd404c875a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-e0c288b8-6982-4785-ab26-618a47ffa3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e3dea7ab-f591-4073-9053-669d5c6e4923,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-05ef8aa5-b078-4679-a274-10b7e8d8db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-593b2849-b641-415d-9b74-b02263e1b291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145258738-172.17.0.17-1598681507091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41293,DS-cb880bbc-5189-47e4-9b57-b6eedfe86380,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-841d749b-3c96-4713-abd6-fcc8bada9abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-b20a5b07-d4f0-448b-9b95-6a3979c16bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-a46fe805-5f63-4e2e-907d-1cd404c875a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-e0c288b8-6982-4785-ab26-618a47ffa3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e3dea7ab-f591-4073-9053-669d5c6e4923,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-05ef8aa5-b078-4679-a274-10b7e8d8db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-593b2849-b641-415d-9b74-b02263e1b291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128092333-172.17.0.17-1598681642329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-96685227-caf6-4c72-a990-bf33031a85c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-60e6645c-c544-4bf0-8df4-9f3f6fcb7048,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-51e0990f-0c82-42a8-9aaa-64a037806af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-f6fa5d79-40cc-41d0-a3f7-f827bb6f0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-7416eddb-04f6-4d69-bb82-0109e68d43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-566536ce-f5fa-444d-bb61-e20bd442063f,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-101f9134-e195-4c8f-8878-e0814e585639,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-d9fe5d95-150c-4d11-b790-ebafb7447a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128092333-172.17.0.17-1598681642329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-96685227-caf6-4c72-a990-bf33031a85c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-60e6645c-c544-4bf0-8df4-9f3f6fcb7048,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-51e0990f-0c82-42a8-9aaa-64a037806af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-f6fa5d79-40cc-41d0-a3f7-f827bb6f0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-7416eddb-04f6-4d69-bb82-0109e68d43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-566536ce-f5fa-444d-bb61-e20bd442063f,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-101f9134-e195-4c8f-8878-e0814e585639,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-d9fe5d95-150c-4d11-b790-ebafb7447a52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676374585-172.17.0.17-1598681785911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-e77cdb20-9c62-4796-bca5-fb7c21d86326,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-02db8fe8-5096-4de0-b279-1a30cea4ebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-6abd851b-9ee0-4e73-a36d-304a6b555bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-f86c302d-c89e-4dc8-9c7a-4327d08eec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-7abac1fa-ba47-4a3c-abe0-3c0763df819a,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-10e744f3-89c5-4a4a-8246-fe56d7b38e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-4f6dbd06-7c17-46e0-b4b0-cad6241aaebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b98f445b-193f-46e0-abbe-80f7e28ca5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676374585-172.17.0.17-1598681785911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-e77cdb20-9c62-4796-bca5-fb7c21d86326,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-02db8fe8-5096-4de0-b279-1a30cea4ebe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-6abd851b-9ee0-4e73-a36d-304a6b555bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-f86c302d-c89e-4dc8-9c7a-4327d08eec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-7abac1fa-ba47-4a3c-abe0-3c0763df819a,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-10e744f3-89c5-4a4a-8246-fe56d7b38e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-4f6dbd06-7c17-46e0-b4b0-cad6241aaebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b98f445b-193f-46e0-abbe-80f7e28ca5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717721523-172.17.0.17-1598682122106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-efd43933-839a-44a6-b281-12b35aeda9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-ddd7a774-b5ae-4b24-b0aa-ef5269603348,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-6a737089-8e6a-419d-8f46-cb3fe7b62ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-078e13b6-f9c4-4800-ae84-d8e7a8a5b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-ccda6ac7-6269-4a39-9a64-a171632c9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-86502555-5a8a-464e-946b-cd85307232c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-554b1940-a9c4-44fd-bedd-45b572227bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-869a0575-54e8-4306-a9b8-77873ed12f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717721523-172.17.0.17-1598682122106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-efd43933-839a-44a6-b281-12b35aeda9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-ddd7a774-b5ae-4b24-b0aa-ef5269603348,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-6a737089-8e6a-419d-8f46-cb3fe7b62ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-078e13b6-f9c4-4800-ae84-d8e7a8a5b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-ccda6ac7-6269-4a39-9a64-a171632c9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-86502555-5a8a-464e-946b-cd85307232c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-554b1940-a9c4-44fd-bedd-45b572227bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-869a0575-54e8-4306-a9b8-77873ed12f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598490768-172.17.0.17-1598683071058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-56894213-494e-43db-b629-45bbd490f625,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-dde206a5-a49f-4a01-a62d-3d5f3cad77df,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1111389e-fb12-419d-b21f-36c283ca48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-80110b71-8677-4112-a754-f7fe412759b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-7b7c8d1a-59b0-4917-9111-700b9da57d16,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-27e3a21d-a344-4c88-b8d2-706719a16455,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-0a562990-1f65-48f6-bd41-328168a9ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-4ee81998-265d-4fce-ba0c-d41abef184ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598490768-172.17.0.17-1598683071058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-56894213-494e-43db-b629-45bbd490f625,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-dde206a5-a49f-4a01-a62d-3d5f3cad77df,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1111389e-fb12-419d-b21f-36c283ca48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-80110b71-8677-4112-a754-f7fe412759b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-7b7c8d1a-59b0-4917-9111-700b9da57d16,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-27e3a21d-a344-4c88-b8d2-706719a16455,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-0a562990-1f65-48f6-bd41-328168a9ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-4ee81998-265d-4fce-ba0c-d41abef184ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19746215-172.17.0.17-1598683104854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-75969dd4-124a-45d7-97aa-41d8642d94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-ef891285-ebc5-4bc8-9252-0ee8d0c953e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-459456d0-2e7c-4274-bf7c-6abc55bb32f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-711df438-d45e-461e-8170-4b4dda50afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-1f5beea2-dda4-40e3-ace7-4d0d375b1107,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-d0f44d8b-4f04-42de-bcf7-bf976bb1a176,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-ab774aaf-7c6e-437f-af68-4aef1e3a3a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c0c140e5-ff70-41dd-97ad-850358bd071a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19746215-172.17.0.17-1598683104854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-75969dd4-124a-45d7-97aa-41d8642d94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-ef891285-ebc5-4bc8-9252-0ee8d0c953e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-459456d0-2e7c-4274-bf7c-6abc55bb32f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-711df438-d45e-461e-8170-4b4dda50afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-1f5beea2-dda4-40e3-ace7-4d0d375b1107,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-d0f44d8b-4f04-42de-bcf7-bf976bb1a176,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-ab774aaf-7c6e-437f-af68-4aef1e3a3a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c0c140e5-ff70-41dd-97ad-850358bd071a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152098613-172.17.0.17-1598683411403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-b00c6803-8059-4e87-b39f-4b0795815a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-730949c7-82af-4c52-935a-a7773dedeb83,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-601a7dce-bf44-4c91-861a-a159f350d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-f8850737-7a19-47a2-b4c8-c032078ae06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-3c1715fd-68c9-436a-afe4-8d5843945a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-5359fc33-3af8-4659-8820-1d676d665340,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-34da3a3e-f662-45f3-951e-cb19c2f0f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-40765c9e-fe53-41ec-afde-65e330b99119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152098613-172.17.0.17-1598683411403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-b00c6803-8059-4e87-b39f-4b0795815a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-730949c7-82af-4c52-935a-a7773dedeb83,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-601a7dce-bf44-4c91-861a-a159f350d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-f8850737-7a19-47a2-b4c8-c032078ae06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-3c1715fd-68c9-436a-afe4-8d5843945a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-5359fc33-3af8-4659-8820-1d676d665340,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-34da3a3e-f662-45f3-951e-cb19c2f0f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-40765c9e-fe53-41ec-afde-65e330b99119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301419287-172.17.0.17-1598683481502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-0fd1b8f3-edcf-45b4-8e56-0f3411b6752d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-d616a8a0-319e-47e8-bd62-41e57a16e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0ea88560-623c-41f3-ab5d-7ce930fd2710,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-52aa134f-8204-4fd3-b5c1-93ab96a8b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-fbbdc930-9b73-4cec-8c8f-ce855c86a5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-f7579dea-8e82-431b-9813-e35a5e11e193,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ff5c0160-beb8-43e2-a86b-b7081e20a0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-8739d616-e422-40b5-a348-0f362b462df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301419287-172.17.0.17-1598683481502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-0fd1b8f3-edcf-45b4-8e56-0f3411b6752d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-d616a8a0-319e-47e8-bd62-41e57a16e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0ea88560-623c-41f3-ab5d-7ce930fd2710,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-52aa134f-8204-4fd3-b5c1-93ab96a8b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-fbbdc930-9b73-4cec-8c8f-ce855c86a5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-f7579dea-8e82-431b-9813-e35a5e11e193,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ff5c0160-beb8-43e2-a86b-b7081e20a0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-8739d616-e422-40b5-a348-0f362b462df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237665174-172.17.0.17-1598683514438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-21180435-4969-4237-ae0e-66f3c0817507,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-cc75d779-8025-4a64-9a6e-fcf276cf5999,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-c62c356b-2ec2-4898-9ab1-5d4b6fcf7d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7b4fc223-3044-46fd-97fc-65e8d68efb11,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-939ae1ad-936c-4e56-9cef-b0fb2fd673be,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-a7000491-7103-49fb-a416-5832fd360696,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-f0130b91-55ce-438c-9100-4532464d9807,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-cf469da3-3973-4ae2-a171-35f0751f00f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237665174-172.17.0.17-1598683514438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-21180435-4969-4237-ae0e-66f3c0817507,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-cc75d779-8025-4a64-9a6e-fcf276cf5999,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-c62c356b-2ec2-4898-9ab1-5d4b6fcf7d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7b4fc223-3044-46fd-97fc-65e8d68efb11,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-939ae1ad-936c-4e56-9cef-b0fb2fd673be,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-a7000491-7103-49fb-a416-5832fd360696,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-f0130b91-55ce-438c-9100-4532464d9807,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-cf469da3-3973-4ae2-a171-35f0751f00f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484723315-172.17.0.17-1598683726589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-2ed6ef92-a24d-47fc-8431-3b471921933c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-de3d1d7b-a45c-49f4-8f11-2bb9f91ca8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a9b975f4-b5ee-47c4-9c89-cba7dbc1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-1065dede-16b6-484d-9e4f-b3ffa8220503,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-a85795b6-31f1-404f-92b2-b48e15d1b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-100c7d27-2b36-4eb4-979d-ae9bb0bcaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-27f43609-a5c1-4161-ab39-aa0ec6f3d190,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-0864b8ae-f7dd-48ef-9522-91fe094109eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484723315-172.17.0.17-1598683726589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-2ed6ef92-a24d-47fc-8431-3b471921933c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-de3d1d7b-a45c-49f4-8f11-2bb9f91ca8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-a9b975f4-b5ee-47c4-9c89-cba7dbc1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-1065dede-16b6-484d-9e4f-b3ffa8220503,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-a85795b6-31f1-404f-92b2-b48e15d1b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-100c7d27-2b36-4eb4-979d-ae9bb0bcaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-27f43609-a5c1-4161-ab39-aa0ec6f3d190,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-0864b8ae-f7dd-48ef-9522-91fe094109eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722875854-172.17.0.17-1598684017620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-ed9f9068-6623-4035-be39-88b270d979b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-1cf0e6fb-babb-43cf-b48f-cf774311b720,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-776d9a06-774c-4248-8964-41a398ffc9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-9de6de26-9662-452b-8e40-1b28865fee79,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-adda8f38-2783-45d8-85b8-0f5ed070e058,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-18761f1b-51d7-4b19-a78a-97d5f38de95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-b5cf1db1-419f-4be5-8e18-661cf17c153a,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-9e033b60-da10-4424-ae8b-c71925ba2d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722875854-172.17.0.17-1598684017620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-ed9f9068-6623-4035-be39-88b270d979b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-1cf0e6fb-babb-43cf-b48f-cf774311b720,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-776d9a06-774c-4248-8964-41a398ffc9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-9de6de26-9662-452b-8e40-1b28865fee79,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-adda8f38-2783-45d8-85b8-0f5ed070e058,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-18761f1b-51d7-4b19-a78a-97d5f38de95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-b5cf1db1-419f-4be5-8e18-661cf17c153a,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-9e033b60-da10-4424-ae8b-c71925ba2d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969982578-172.17.0.17-1598684125825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-14205659-4ea2-4f95-b80c-d9cb83713ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-1ae648e6-7705-47e9-8216-4d38419a390c,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c42d0181-d56f-45e2-b3ca-a3c9aecbf470,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-804a51b7-ec58-479d-8674-9dc55646c548,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-41d18e30-d2c6-499e-9334-c3cecf77d3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-1bd7855d-f434-4ed3-99d6-1c848d979cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-a9a9e8ac-8617-4c54-b07c-cbc1a7456329,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-7a271fa3-129e-4fea-9e62-4bbffb38a680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969982578-172.17.0.17-1598684125825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-14205659-4ea2-4f95-b80c-d9cb83713ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-1ae648e6-7705-47e9-8216-4d38419a390c,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c42d0181-d56f-45e2-b3ca-a3c9aecbf470,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-804a51b7-ec58-479d-8674-9dc55646c548,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-41d18e30-d2c6-499e-9334-c3cecf77d3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-1bd7855d-f434-4ed3-99d6-1c848d979cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-a9a9e8ac-8617-4c54-b07c-cbc1a7456329,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-7a271fa3-129e-4fea-9e62-4bbffb38a680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965203207-172.17.0.17-1598684192146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-dccc049f-84e8-483c-9032-2c80be9a1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-e93ba370-cb0d-4a1e-9e9a-e3a68ef2cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-65d0afae-6c8f-4bbe-82bb-4e2a06cc1f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-bee18bbe-e232-45d1-9cad-505bb559a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-24d53f1d-7f42-4b64-9deb-88d3f4b51d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-46b399eb-21af-43b9-9d8f-36565fe5c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-355987e8-bef8-4583-a33d-cc0c8f55f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-81631362-3c5b-491b-84ef-ca0b0b2b7113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965203207-172.17.0.17-1598684192146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-dccc049f-84e8-483c-9032-2c80be9a1a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-e93ba370-cb0d-4a1e-9e9a-e3a68ef2cfae,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-65d0afae-6c8f-4bbe-82bb-4e2a06cc1f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-bee18bbe-e232-45d1-9cad-505bb559a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-24d53f1d-7f42-4b64-9deb-88d3f4b51d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-46b399eb-21af-43b9-9d8f-36565fe5c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-355987e8-bef8-4583-a33d-cc0c8f55f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-81631362-3c5b-491b-84ef-ca0b0b2b7113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103662935-172.17.0.17-1598684233004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-10d308ef-629a-4b89-87f7-24114e45ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-4615b81f-0191-4e97-9586-633a05a08593,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-f32cd248-ef13-412b-ac06-a970d3d57aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-4e6da5a6-940b-4459-a1df-e8abf8c0747c,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-73bd7fee-c600-4b70-a8ad-435f628e7082,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-9fea6395-14f0-449a-877d-66e60c8a8581,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-b0fac28b-566b-4a61-9775-99e77341b638,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-dad9e8d7-b46d-4ac4-8146-7b48ba9fc995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103662935-172.17.0.17-1598684233004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-10d308ef-629a-4b89-87f7-24114e45ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-4615b81f-0191-4e97-9586-633a05a08593,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-f32cd248-ef13-412b-ac06-a970d3d57aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-4e6da5a6-940b-4459-a1df-e8abf8c0747c,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-73bd7fee-c600-4b70-a8ad-435f628e7082,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-9fea6395-14f0-449a-877d-66e60c8a8581,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-b0fac28b-566b-4a61-9775-99e77341b638,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-dad9e8d7-b46d-4ac4-8146-7b48ba9fc995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5146
