reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249211699-172.17.0.7-1598642830402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-c805d79a-cbb7-47cf-a615-52af79c597dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-1361a61f-ebed-4451-8553-c893fc32a53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-84c36136-c24a-4c92-8812-d084698829f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-322e7ba7-37d2-4b2f-a694-bd7351e3c911,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-609f5d95-6f40-488d-a40b-ea7a0a3e77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5171cc39-3cae-4ca4-a55a-6c80ce1f5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-421de759-abb8-4278-a844-a22051b40a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-0c9fbf7d-027d-4cc9-b97f-0e89a56d1b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249211699-172.17.0.7-1598642830402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-c805d79a-cbb7-47cf-a615-52af79c597dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-1361a61f-ebed-4451-8553-c893fc32a53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-84c36136-c24a-4c92-8812-d084698829f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-322e7ba7-37d2-4b2f-a694-bd7351e3c911,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-609f5d95-6f40-488d-a40b-ea7a0a3e77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5171cc39-3cae-4ca4-a55a-6c80ce1f5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-421de759-abb8-4278-a844-a22051b40a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-0c9fbf7d-027d-4cc9-b97f-0e89a56d1b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380159000-172.17.0.7-1598643216296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-9de0a813-b727-4492-9157-77f80284f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-c006e979-b7ce-4786-b383-f50551613e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-2f7d4ce3-263e-4702-9dc6-2a7186990549,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-ed695e6b-d9c6-42cd-8c53-50d0bcf154c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-901e8af1-8670-4136-943a-16ec52a8b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-9d41cb96-65a7-44e3-912d-6f0c399dc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-9da8f73b-6bfb-4c82-8ab9-0fa4546ebf36,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-45298002-1a9a-48c0-99b2-2db015111c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380159000-172.17.0.7-1598643216296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-9de0a813-b727-4492-9157-77f80284f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-c006e979-b7ce-4786-b383-f50551613e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-2f7d4ce3-263e-4702-9dc6-2a7186990549,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-ed695e6b-d9c6-42cd-8c53-50d0bcf154c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-901e8af1-8670-4136-943a-16ec52a8b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-9d41cb96-65a7-44e3-912d-6f0c399dc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-9da8f73b-6bfb-4c82-8ab9-0fa4546ebf36,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-45298002-1a9a-48c0-99b2-2db015111c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946973341-172.17.0.7-1598643442031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-0b81da85-ecfe-456c-b879-0b4d9a93e880,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-50e751cd-f964-4de1-85df-540c842059b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-297ebb1f-4bcd-46e6-8eaa-270a78a2100a,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-7b898d02-af8a-4bbb-83b9-5297641a7043,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-816c6620-b30f-4f02-a915-aff56d9a4514,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-6f768568-11a1-4e7c-bf36-fd830e800d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-d8c4ad8e-e9b2-4634-ba95-10740dee45a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-79a388ff-7b40-49f6-903e-289a134d3a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946973341-172.17.0.7-1598643442031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-0b81da85-ecfe-456c-b879-0b4d9a93e880,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-50e751cd-f964-4de1-85df-540c842059b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-297ebb1f-4bcd-46e6-8eaa-270a78a2100a,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-7b898d02-af8a-4bbb-83b9-5297641a7043,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-816c6620-b30f-4f02-a915-aff56d9a4514,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-6f768568-11a1-4e7c-bf36-fd830e800d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-d8c4ad8e-e9b2-4634-ba95-10740dee45a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-79a388ff-7b40-49f6-903e-289a134d3a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601621538-172.17.0.7-1598644422889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-3c6a7492-b025-4e2a-ad62-24ab8db82a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-b5cc35b9-f612-4713-ba22-8d1777e393cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-9456e013-1550-4aaf-99db-1a7a9d3680ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-1233b8b5-b3c2-4eff-ac17-48299804c401,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-f8efcbf5-8968-4f63-9ac5-9c62c103616a,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-92b2dd61-92a5-4270-baea-f6fbc207d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-a959d382-8d07-4d38-a597-32e68062d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-ee3c702c-d14e-4120-8cf5-7168807664b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601621538-172.17.0.7-1598644422889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-3c6a7492-b025-4e2a-ad62-24ab8db82a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-b5cc35b9-f612-4713-ba22-8d1777e393cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-9456e013-1550-4aaf-99db-1a7a9d3680ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-1233b8b5-b3c2-4eff-ac17-48299804c401,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-f8efcbf5-8968-4f63-9ac5-9c62c103616a,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-92b2dd61-92a5-4270-baea-f6fbc207d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-a959d382-8d07-4d38-a597-32e68062d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-ee3c702c-d14e-4120-8cf5-7168807664b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881804235-172.17.0.7-1598644599104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-a3a253bb-6bc5-43a6-8fb1-e5cf4d6fb403,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-6eb5ad28-296b-4edf-ab08-026fe3fcd021,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-d3b541be-63bd-4c3a-ba06-75401e12a3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-75987f39-85bf-4d2e-8740-45713f15ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-cec74c71-6f84-49cc-9114-9b5ae09edcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-998fdd68-22f7-4e0d-af9e-328e619ad10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-744c1369-b734-4929-ab3a-5171054df200,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fdcd5854-ca14-47d5-aefe-5c8022818d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881804235-172.17.0.7-1598644599104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-a3a253bb-6bc5-43a6-8fb1-e5cf4d6fb403,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-6eb5ad28-296b-4edf-ab08-026fe3fcd021,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-d3b541be-63bd-4c3a-ba06-75401e12a3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-75987f39-85bf-4d2e-8740-45713f15ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-cec74c71-6f84-49cc-9114-9b5ae09edcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-998fdd68-22f7-4e0d-af9e-328e619ad10e,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-744c1369-b734-4929-ab3a-5171054df200,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fdcd5854-ca14-47d5-aefe-5c8022818d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533157948-172.17.0.7-1598645114868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-b56ed38a-0c1f-4b5a-ac19-9700bc1defa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-07f4572a-3489-4c69-91fa-f007a314886a,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-385d645f-45c4-4d93-9e67-93d2d4a1e141,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-eab55646-be18-4281-8584-2503d603c714,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-c95bbd76-129e-4c7e-a20f-995319b3fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-bf2389ca-2f2f-4d01-ba5a-e596bc49660a,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-cf76f7fe-1e13-4d66-8e7e-282c898ff97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-c2c8f773-3e79-47f2-97dc-f665b2ac9f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533157948-172.17.0.7-1598645114868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-b56ed38a-0c1f-4b5a-ac19-9700bc1defa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-07f4572a-3489-4c69-91fa-f007a314886a,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-385d645f-45c4-4d93-9e67-93d2d4a1e141,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-eab55646-be18-4281-8584-2503d603c714,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-c95bbd76-129e-4c7e-a20f-995319b3fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-bf2389ca-2f2f-4d01-ba5a-e596bc49660a,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-cf76f7fe-1e13-4d66-8e7e-282c898ff97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-c2c8f773-3e79-47f2-97dc-f665b2ac9f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949891784-172.17.0.7-1598645686087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-b1bd93cb-acdf-427c-bf67-deb435fbddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-5615e0d8-daf7-437a-9ad7-d47f0e5d0639,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-d40c7c0d-1b55-48e2-a592-bcae19cef1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e3c4ba31-2207-4e06-9b8d-1ddc5081625c,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-7720eba9-2590-4fb4-a79b-51d7a41a542e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-8679151d-4f85-40b0-b93a-ecd00c58579f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-5b4e92a3-e9e5-4246-a671-69d25a80ae6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-16b8578b-3e6b-46f8-b546-d69a4d4cd7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949891784-172.17.0.7-1598645686087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-b1bd93cb-acdf-427c-bf67-deb435fbddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-5615e0d8-daf7-437a-9ad7-d47f0e5d0639,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-d40c7c0d-1b55-48e2-a592-bcae19cef1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e3c4ba31-2207-4e06-9b8d-1ddc5081625c,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-7720eba9-2590-4fb4-a79b-51d7a41a542e,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-8679151d-4f85-40b0-b93a-ecd00c58579f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-5b4e92a3-e9e5-4246-a671-69d25a80ae6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-16b8578b-3e6b-46f8-b546-d69a4d4cd7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346136824-172.17.0.7-1598646415711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-39366160-769c-4db5-a415-8787ae8f2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-835cdcc6-fca3-40b3-8f7b-b0abeaeff659,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-a34426cf-e80e-43d6-b5cd-0b1f67122b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-b8404118-9571-49dc-9e40-37c480983c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c4742639-1f2e-4639-af22-97144c5d8923,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-24494d38-d20d-4fec-aa93-a4791f392b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-3b75b9dd-eb59-46ed-818a-f81798d12ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-98a08640-c00f-4f71-96f2-b270df7e3ec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346136824-172.17.0.7-1598646415711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-39366160-769c-4db5-a415-8787ae8f2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-835cdcc6-fca3-40b3-8f7b-b0abeaeff659,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-a34426cf-e80e-43d6-b5cd-0b1f67122b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-b8404118-9571-49dc-9e40-37c480983c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c4742639-1f2e-4639-af22-97144c5d8923,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-24494d38-d20d-4fec-aa93-a4791f392b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-3b75b9dd-eb59-46ed-818a-f81798d12ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-98a08640-c00f-4f71-96f2-b270df7e3ec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896220635-172.17.0.7-1598646707981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-9fcbcb9e-3b19-4857-8a96-d45f46a2b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f15f3a35-a3c6-45fb-8550-ed893433e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-c6893da5-139d-4796-8692-c4091c09bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-3ace7980-6bbe-4065-8517-0db071b0de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-d0ca8fe3-7e07-4494-a75c-0256c01ac31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-e49a06f2-0160-4d4b-8217-6feeb47b1675,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-7a802fcf-6f17-4fbd-8fe5-b0597fd1a324,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-d67af451-7fd5-42da-a7ba-2d79d0574042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896220635-172.17.0.7-1598646707981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-9fcbcb9e-3b19-4857-8a96-d45f46a2b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f15f3a35-a3c6-45fb-8550-ed893433e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-c6893da5-139d-4796-8692-c4091c09bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-3ace7980-6bbe-4065-8517-0db071b0de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-d0ca8fe3-7e07-4494-a75c-0256c01ac31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-e49a06f2-0160-4d4b-8217-6feeb47b1675,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-7a802fcf-6f17-4fbd-8fe5-b0597fd1a324,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-d67af451-7fd5-42da-a7ba-2d79d0574042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424290187-172.17.0.7-1598647572495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-8bcd1ebf-8512-4122-a519-112dbad70444,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-353ef592-b943-461e-b8e1-3ba6f3a0653c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-21e24678-f0a7-492d-9bbe-f0f215f6e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-2e12ffb9-cdc1-4ed6-a96d-82412587b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-641d7309-a690-42b8-aea7-4dcc04962506,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-03bf0370-0e08-4536-95fa-56a99966ec13,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-f9a22ce3-c88d-4494-bba5-25176afcae57,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9027a337-cf7e-4899-b49f-159f57361246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424290187-172.17.0.7-1598647572495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-8bcd1ebf-8512-4122-a519-112dbad70444,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-353ef592-b943-461e-b8e1-3ba6f3a0653c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-21e24678-f0a7-492d-9bbe-f0f215f6e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-2e12ffb9-cdc1-4ed6-a96d-82412587b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-641d7309-a690-42b8-aea7-4dcc04962506,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-03bf0370-0e08-4536-95fa-56a99966ec13,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-f9a22ce3-c88d-4494-bba5-25176afcae57,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9027a337-cf7e-4899-b49f-159f57361246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310262670-172.17.0.7-1598647721377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-8326171e-9298-425b-b08d-8d0196c1058e,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-36c3965b-096f-44a9-bde3-2bec43ac07ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-a8b199b4-ec8d-420c-ae75-26e5cc8fae96,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-766a512a-2b1f-4e14-b361-324047de1426,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-1b36f72f-2c19-4175-bf94-1bc492077e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-358a3859-7ece-4624-a0af-676c84a717a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-75ebdf7e-c929-4f6b-8e31-d9ac1fd6b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-3121d9a1-4c23-4ca7-a817-0b3b236e15b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310262670-172.17.0.7-1598647721377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-8326171e-9298-425b-b08d-8d0196c1058e,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-36c3965b-096f-44a9-bde3-2bec43ac07ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-a8b199b4-ec8d-420c-ae75-26e5cc8fae96,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-766a512a-2b1f-4e14-b361-324047de1426,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-1b36f72f-2c19-4175-bf94-1bc492077e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-358a3859-7ece-4624-a0af-676c84a717a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-75ebdf7e-c929-4f6b-8e31-d9ac1fd6b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-3121d9a1-4c23-4ca7-a817-0b3b236e15b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5378
