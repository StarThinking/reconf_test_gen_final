reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144004608-172.17.0.2-1598525738686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-9c13273c-5171-4bae-9f9c-ee40137ff03d,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-943b60db-48e8-4b8b-8106-5088880ba8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-28dd9194-4e7a-4f7c-acc6-15b802c24856,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0b1ebd24-7477-4250-a3ff-3ca44b0423d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a4cfdf64-7469-4f7d-9403-c5a36cc9eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-73939a45-6b02-46ad-a210-29479cbb4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-45a3120e-7881-46fc-b3d9-768382f32c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-5e0ea64f-294b-4c32-a672-932af1e27047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144004608-172.17.0.2-1598525738686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-9c13273c-5171-4bae-9f9c-ee40137ff03d,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-943b60db-48e8-4b8b-8106-5088880ba8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-28dd9194-4e7a-4f7c-acc6-15b802c24856,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0b1ebd24-7477-4250-a3ff-3ca44b0423d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a4cfdf64-7469-4f7d-9403-c5a36cc9eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-73939a45-6b02-46ad-a210-29479cbb4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-45a3120e-7881-46fc-b3d9-768382f32c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-5e0ea64f-294b-4c32-a672-932af1e27047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51461804-172.17.0.2-1598525816317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-dc16f041-70f9-4e51-a734-717e934c601a,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-fe47eb3e-1dc0-4fb8-84fa-076c20531525,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-e4d78270-b7e6-4fd2-8e04-ce84b71ef723,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9276590b-ae71-4ba3-9732-11f78410411c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-9142d7f4-c145-4d4f-b0bb-fdf03f59d9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-7571a22d-3439-4d9d-a8ef-ad5d40190455,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-7ed78083-e9ac-4333-88a7-a570ef47728c,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-513c12b5-28ce-42d3-8e10-4987676501de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51461804-172.17.0.2-1598525816317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-dc16f041-70f9-4e51-a734-717e934c601a,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-fe47eb3e-1dc0-4fb8-84fa-076c20531525,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-e4d78270-b7e6-4fd2-8e04-ce84b71ef723,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9276590b-ae71-4ba3-9732-11f78410411c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-9142d7f4-c145-4d4f-b0bb-fdf03f59d9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-7571a22d-3439-4d9d-a8ef-ad5d40190455,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-7ed78083-e9ac-4333-88a7-a570ef47728c,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-513c12b5-28ce-42d3-8e10-4987676501de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372132221-172.17.0.2-1598525931684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-d59e5924-a58e-4cb8-a890-b188e5736d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-5af41e71-e0d7-4bf3-97a0-170bf67a8215,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-9a3fc5f0-3bd6-4c02-9fd5-83dfd8922e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-e1a54c10-3d63-42d5-afce-c3a541cacae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-09978caf-ee9a-4023-9f11-ac9a2f27e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-e9c478b5-5991-4a0b-940e-1806182fa00b,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-30f132e7-985e-487b-9974-489b3b983d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-68f77878-5168-4145-8a0b-b69b6344d2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372132221-172.17.0.2-1598525931684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-d59e5924-a58e-4cb8-a890-b188e5736d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-5af41e71-e0d7-4bf3-97a0-170bf67a8215,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-9a3fc5f0-3bd6-4c02-9fd5-83dfd8922e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-e1a54c10-3d63-42d5-afce-c3a541cacae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-09978caf-ee9a-4023-9f11-ac9a2f27e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-e9c478b5-5991-4a0b-940e-1806182fa00b,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-30f132e7-985e-487b-9974-489b3b983d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-68f77878-5168-4145-8a0b-b69b6344d2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089538550-172.17.0.2-1598526202389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-c9af3577-d8e6-49c7-9dd1-7ddcd368f915,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-67ff1874-35b4-463a-82f1-e57612e86f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-68436cb2-65f6-4192-9f59-026e22b2e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-aac9cb72-fad3-4bd8-bc48-eab63c0ad9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-1215aeee-4d1e-4276-9159-2947a23047dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-ccdbf909-35ca-4dd6-a84d-426ebee787bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-5aa9f668-b15f-4405-8719-c1445c911c97,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-819f9079-f4db-42ad-94ae-0344d1f76144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089538550-172.17.0.2-1598526202389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-c9af3577-d8e6-49c7-9dd1-7ddcd368f915,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-67ff1874-35b4-463a-82f1-e57612e86f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-68436cb2-65f6-4192-9f59-026e22b2e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-aac9cb72-fad3-4bd8-bc48-eab63c0ad9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-1215aeee-4d1e-4276-9159-2947a23047dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-ccdbf909-35ca-4dd6-a84d-426ebee787bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-5aa9f668-b15f-4405-8719-c1445c911c97,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-819f9079-f4db-42ad-94ae-0344d1f76144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124350918-172.17.0.2-1598527119361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-51ebd17e-58da-4a50-886b-17b4062e2b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-658ba0e4-09e3-4513-b804-a19f37d55b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-03f7c4ce-1157-45ef-b184-bd629358c904,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-b003ad16-f17e-48c2-b1fc-9514edc14471,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-db8ff578-3dbb-45dc-880b-54f26221db05,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-62b64b48-a0ca-43e9-80cc-fc82c4a1a17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-9c9e4622-f4a4-4635-88c6-59c4a84c8bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-51f29c47-461c-4903-89b3-f6180af75209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124350918-172.17.0.2-1598527119361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-51ebd17e-58da-4a50-886b-17b4062e2b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-658ba0e4-09e3-4513-b804-a19f37d55b90,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-03f7c4ce-1157-45ef-b184-bd629358c904,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-b003ad16-f17e-48c2-b1fc-9514edc14471,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-db8ff578-3dbb-45dc-880b-54f26221db05,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-62b64b48-a0ca-43e9-80cc-fc82c4a1a17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-9c9e4622-f4a4-4635-88c6-59c4a84c8bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-51f29c47-461c-4903-89b3-f6180af75209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765543953-172.17.0.2-1598527865837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-ce5538e8-4634-4cbe-8916-3317cb9b0c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-23395fc4-39df-41f6-a822-641cf7d76686,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-f15bc239-24dc-48ec-816f-e1eec974adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-723be138-da9e-40a6-a9ad-8cb2f6bbc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-3dead1c4-7d8d-44fd-830c-1eb53489fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-8dbceb97-747f-43ba-9d88-755b218da40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-e54990eb-d940-4a01-a6bb-bb52eabe1c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e4295f1f-3b3a-4f57-9eb0-b32f0d0e7175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765543953-172.17.0.2-1598527865837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-ce5538e8-4634-4cbe-8916-3317cb9b0c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-23395fc4-39df-41f6-a822-641cf7d76686,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-f15bc239-24dc-48ec-816f-e1eec974adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-723be138-da9e-40a6-a9ad-8cb2f6bbc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-3dead1c4-7d8d-44fd-830c-1eb53489fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-8dbceb97-747f-43ba-9d88-755b218da40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-e54990eb-d940-4a01-a6bb-bb52eabe1c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e4295f1f-3b3a-4f57-9eb0-b32f0d0e7175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837903344-172.17.0.2-1598527969228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-e0682ae2-bc97-4a67-a7f9-8a132b64d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-892015a5-631c-452f-9fd9-b66191f6980c,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-cfd4ae22-1a75-4167-a657-f5f7e116378e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-269036fb-b8e7-4b0e-93a1-c5aac5f9ab95,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-6de5eab9-9ec6-40a9-be25-ec0baffd8229,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-bc9ab5ea-bc1b-428d-b706-b825f602ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-5aed8562-674b-4908-a19e-3bd9ceaa501d,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-9f7fc214-e34e-4222-87ba-eb4ba16a92f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837903344-172.17.0.2-1598527969228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-e0682ae2-bc97-4a67-a7f9-8a132b64d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-892015a5-631c-452f-9fd9-b66191f6980c,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-cfd4ae22-1a75-4167-a657-f5f7e116378e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-269036fb-b8e7-4b0e-93a1-c5aac5f9ab95,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-6de5eab9-9ec6-40a9-be25-ec0baffd8229,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-bc9ab5ea-bc1b-428d-b706-b825f602ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-5aed8562-674b-4908-a19e-3bd9ceaa501d,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-9f7fc214-e34e-4222-87ba-eb4ba16a92f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128388989-172.17.0.2-1598528695709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-82d157eb-c6fd-4013-bd26-9397cefb1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-ba2d987e-4891-4c27-a8d1-ea3a12674991,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b46d9622-47db-426a-b471-c617940c6508,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-09d89223-c024-4a72-8b15-2e472bac915d,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-a4c28bf8-bed0-4a03-a08d-e26de73206ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-116ff4e9-8dfb-4a47-8356-e4346e9b8957,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-da26ad67-768c-49d7-bd33-461b33715bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c32e11aa-be21-4961-92a2-26a47c485365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128388989-172.17.0.2-1598528695709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45319,DS-82d157eb-c6fd-4013-bd26-9397cefb1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-ba2d987e-4891-4c27-a8d1-ea3a12674991,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-b46d9622-47db-426a-b471-c617940c6508,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-09d89223-c024-4a72-8b15-2e472bac915d,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-a4c28bf8-bed0-4a03-a08d-e26de73206ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-116ff4e9-8dfb-4a47-8356-e4346e9b8957,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-da26ad67-768c-49d7-bd33-461b33715bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c32e11aa-be21-4961-92a2-26a47c485365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208858358-172.17.0.2-1598528857772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-03b3a5ac-fa0f-4f5f-8949-26c2904c54dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-091820ac-a352-40e5-8ccd-b3c9a1f5e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-6237fb30-b243-403e-9763-4ac14ae5885a,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-581f377b-6738-45e6-bbe7-f27413e46baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-fdb95b3e-2e4d-4445-ad5f-2b752cdb6939,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-0f54d479-1f70-4aa1-a2df-beb08171a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-7ab2a0e4-7836-4668-a0ff-8694ec614a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-5bea49c8-f9e9-4ec0-8c75-2dc0a512e386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208858358-172.17.0.2-1598528857772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45111,DS-03b3a5ac-fa0f-4f5f-8949-26c2904c54dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-091820ac-a352-40e5-8ccd-b3c9a1f5e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-6237fb30-b243-403e-9763-4ac14ae5885a,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-581f377b-6738-45e6-bbe7-f27413e46baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-fdb95b3e-2e4d-4445-ad5f-2b752cdb6939,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-0f54d479-1f70-4aa1-a2df-beb08171a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-7ab2a0e4-7836-4668-a0ff-8694ec614a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-5bea49c8-f9e9-4ec0-8c75-2dc0a512e386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114298577-172.17.0.2-1598528894547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-ed89ad8d-b677-405e-bd8c-57502632f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-92bfb705-13d2-4165-8717-7d121c3797d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-e7cfa743-e5d3-4ea6-b3d0-1f5f3897bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-9aa36914-88ba-406e-9b93-3c211a458090,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-817298c0-d1c4-455c-8cd7-e11ee1dabc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-3cb196fd-f5fc-48d1-9655-f8e78e7b08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-1580fa73-3476-4788-b46c-edc36e4d6459,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-90dca027-6e94-4a91-99f5-b541af22714a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114298577-172.17.0.2-1598528894547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-ed89ad8d-b677-405e-bd8c-57502632f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-92bfb705-13d2-4165-8717-7d121c3797d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-e7cfa743-e5d3-4ea6-b3d0-1f5f3897bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-9aa36914-88ba-406e-9b93-3c211a458090,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-817298c0-d1c4-455c-8cd7-e11ee1dabc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-3cb196fd-f5fc-48d1-9655-f8e78e7b08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-1580fa73-3476-4788-b46c-edc36e4d6459,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-90dca027-6e94-4a91-99f5-b541af22714a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586535219-172.17.0.2-1598530038968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-2a29f986-e434-4a39-bdc4-a6b8da26bade,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9826ec4c-fee3-4974-a8a6-81f262fd05b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-e07c0d1d-8f8d-4927-bb0a-a627afec8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-2944c5a9-66bc-4fbb-a6a2-814e59d5b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-399f8133-2b01-47f2-a09d-49bfa1e059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8eb465e2-4473-416b-891f-8d6e68cbe1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-91e6c61a-331c-4710-be8d-641b4a75671c,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-beeddc62-b20d-48e9-a66c-59dcd033a1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586535219-172.17.0.2-1598530038968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-2a29f986-e434-4a39-bdc4-a6b8da26bade,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9826ec4c-fee3-4974-a8a6-81f262fd05b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-e07c0d1d-8f8d-4927-bb0a-a627afec8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-2944c5a9-66bc-4fbb-a6a2-814e59d5b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-399f8133-2b01-47f2-a09d-49bfa1e059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8eb465e2-4473-416b-891f-8d6e68cbe1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-91e6c61a-331c-4710-be8d-641b4a75671c,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-beeddc62-b20d-48e9-a66c-59dcd033a1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968169022-172.17.0.2-1598530341078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38130,DS-a05dae05-2495-435f-9b54-eac91b3399fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1276d878-861c-4903-8049-91faf7d80ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-849858e2-d4cc-4811-b85e-5eeb1639ca93,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-dd40dbd6-5266-4796-a7cd-1f86661903df,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-112594ed-b6fb-4c3e-824c-82cda26fa4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-72cb63d8-3430-4f6a-b99b-d3ed78c9fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-4ef64d3a-47a1-4f6c-8eb0-566612cc9d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-9bccb041-b6c4-47f9-988d-1b0733d0c5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968169022-172.17.0.2-1598530341078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38130,DS-a05dae05-2495-435f-9b54-eac91b3399fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-1276d878-861c-4903-8049-91faf7d80ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-849858e2-d4cc-4811-b85e-5eeb1639ca93,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-dd40dbd6-5266-4796-a7cd-1f86661903df,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-112594ed-b6fb-4c3e-824c-82cda26fa4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-72cb63d8-3430-4f6a-b99b-d3ed78c9fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-4ef64d3a-47a1-4f6c-8eb0-566612cc9d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-9bccb041-b6c4-47f9-988d-1b0733d0c5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.max.size
component: hdfs:NameNode
v1: 128
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050972624-172.17.0.2-1598531342334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-1a8a7a30-fd4f-4dd1-abc8-ed6196732ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-08b281af-0778-4857-809e-a47f16d92e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-72d36f1d-6a4f-473b-a543-9fe0cc771f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-864d54e1-39f0-4b90-80d2-47d56d3db215,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-71bd18c1-19cc-4775-9da6-8391336c8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-fbd84ce7-dbc1-45f6-9141-8af0e3b9185d,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-9143c207-8374-4b4f-9138-7e2b942f0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-fd4f4cc5-022e-4b21-b472-02c158c0e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050972624-172.17.0.2-1598531342334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-1a8a7a30-fd4f-4dd1-abc8-ed6196732ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-08b281af-0778-4857-809e-a47f16d92e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-72d36f1d-6a4f-473b-a543-9fe0cc771f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-864d54e1-39f0-4b90-80d2-47d56d3db215,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-71bd18c1-19cc-4775-9da6-8391336c8dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-fbd84ce7-dbc1-45f6-9141-8af0e3b9185d,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-9143c207-8374-4b4f-9138-7e2b942f0736,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-fd4f4cc5-022e-4b21-b472-02c158c0e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5752
