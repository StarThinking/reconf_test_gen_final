reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218215716-172.17.0.9-1598626285045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-60a54b76-1650-41e6-b280-56ac10d23faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a9ca3d47-be0c-4af6-8de7-34e24a08225c,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8b2efb9b-0d97-44fa-8432-b8a5c2a562b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-f820e9c9-db82-4fee-9cd4-90caf705cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-d3ebd9a0-0cdc-44f4-a953-a48a101c3c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-76bbffaa-8261-4435-a5f0-233870f15b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-b17ea194-5acc-4ffe-be09-3409dd8b4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-111322fa-85cf-4d87-82d4-3bb9962233a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218215716-172.17.0.9-1598626285045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-60a54b76-1650-41e6-b280-56ac10d23faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a9ca3d47-be0c-4af6-8de7-34e24a08225c,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8b2efb9b-0d97-44fa-8432-b8a5c2a562b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-f820e9c9-db82-4fee-9cd4-90caf705cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-d3ebd9a0-0cdc-44f4-a953-a48a101c3c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-76bbffaa-8261-4435-a5f0-233870f15b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-b17ea194-5acc-4ffe-be09-3409dd8b4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-111322fa-85cf-4d87-82d4-3bb9962233a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108005136-172.17.0.9-1598626611482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-b7dd4ae8-d0d3-4cc4-bf94-deafe1c8a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8745a289-86d0-4dc7-8b03-6706ca431abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-124088c6-5df8-499f-8f76-1bf0f4083d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3a69b144-53e4-4e4b-a35d-c11d1e8428f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-fab309c2-d6ea-4b3a-b70f-aece8cbea1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-8d728146-ec89-4cf3-843a-8354a5224aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7d83ead0-f30a-4d92-97ad-399fc06cd7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-69b19d88-e666-4518-bf83-514591fe1cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108005136-172.17.0.9-1598626611482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-b7dd4ae8-d0d3-4cc4-bf94-deafe1c8a7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8745a289-86d0-4dc7-8b03-6706ca431abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-124088c6-5df8-499f-8f76-1bf0f4083d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3a69b144-53e4-4e4b-a35d-c11d1e8428f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-fab309c2-d6ea-4b3a-b70f-aece8cbea1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-8d728146-ec89-4cf3-843a-8354a5224aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7d83ead0-f30a-4d92-97ad-399fc06cd7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-69b19d88-e666-4518-bf83-514591fe1cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994548859-172.17.0.9-1598626951816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-42315d10-e84f-4ebe-87eb-ea577dc532ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-584cb98f-d524-4a00-b9f5-b43751f834f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7d5506e6-2b50-4612-9823-486d1c846de1,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-b9bfc45c-cba0-4423-9095-ca4a3e67bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-027e6073-0e50-48fa-ac0c-1e854eb25b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-1dadc399-4b09-4a0d-94e2-fea8cbe24a24,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-127b40d8-1c7e-45f8-a3ca-84ce1b54ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-fe91e8bc-53e0-4af0-8c86-7829bb232d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994548859-172.17.0.9-1598626951816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-42315d10-e84f-4ebe-87eb-ea577dc532ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-584cb98f-d524-4a00-b9f5-b43751f834f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7d5506e6-2b50-4612-9823-486d1c846de1,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-b9bfc45c-cba0-4423-9095-ca4a3e67bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-027e6073-0e50-48fa-ac0c-1e854eb25b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-1dadc399-4b09-4a0d-94e2-fea8cbe24a24,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-127b40d8-1c7e-45f8-a3ca-84ce1b54ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-fe91e8bc-53e0-4af0-8c86-7829bb232d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342022999-172.17.0.9-1598627097488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-b650e0f9-1e0f-464f-9bec-9a59736e8782,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-bb74fa5d-4e68-403e-8ca1-8043a7096f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-efe10bb2-b784-4749-846f-1edfea49d250,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-f222070b-a863-41d3-b44f-26a03170f608,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-eb05f648-ed46-4c24-a9ff-d6e75a3deb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-9805b6cf-6bda-4c59-857f-16119d244c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-fef08a27-ff9b-4fa6-9fb5-bdce18f5dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-77caa172-c684-4287-86c2-94927f4827ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342022999-172.17.0.9-1598627097488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-b650e0f9-1e0f-464f-9bec-9a59736e8782,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-bb74fa5d-4e68-403e-8ca1-8043a7096f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-efe10bb2-b784-4749-846f-1edfea49d250,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-f222070b-a863-41d3-b44f-26a03170f608,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-eb05f648-ed46-4c24-a9ff-d6e75a3deb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-9805b6cf-6bda-4c59-857f-16119d244c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-fef08a27-ff9b-4fa6-9fb5-bdce18f5dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-77caa172-c684-4287-86c2-94927f4827ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966920217-172.17.0.9-1598627378286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-e27c9598-0df1-4386-8521-f34af327534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5be5314d-e5f4-4f28-a799-fe975a1c1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-88c99141-79a6-41dd-9b19-49d391925a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-c36aaecf-ed2e-467c-8934-545c003b8a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-20180ebb-04f3-4db2-a149-9d77883dc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-67c0f3df-b66a-4629-901e-bb4b99b0649d,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b0ceb062-d7d8-4317-b0e8-066da3bf3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-f67d3444-69bf-4f13-88fc-f69a6653e151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966920217-172.17.0.9-1598627378286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-e27c9598-0df1-4386-8521-f34af327534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5be5314d-e5f4-4f28-a799-fe975a1c1f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-88c99141-79a6-41dd-9b19-49d391925a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-c36aaecf-ed2e-467c-8934-545c003b8a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-20180ebb-04f3-4db2-a149-9d77883dc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-67c0f3df-b66a-4629-901e-bb4b99b0649d,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b0ceb062-d7d8-4317-b0e8-066da3bf3f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-f67d3444-69bf-4f13-88fc-f69a6653e151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016816875-172.17.0.9-1598627482630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-1734e893-3854-45e9-9cdc-cd4b096a249d,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7ebc69c3-4ba7-4638-992f-d16f85649da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-78cfef2b-a181-40b4-9914-5f56b62765fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-2c7bd862-02a3-4343-8a2d-76c842a68878,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b0b082a7-36e4-43a0-9099-cdffcea88c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-06550fa0-e246-4f57-93a4-23a1402b07e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-eacac3a8-b44a-4d84-9e69-10e46636e660,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c6bbf0d8-901d-4d6a-8c4d-7deff340cd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016816875-172.17.0.9-1598627482630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-1734e893-3854-45e9-9cdc-cd4b096a249d,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-7ebc69c3-4ba7-4638-992f-d16f85649da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-78cfef2b-a181-40b4-9914-5f56b62765fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-2c7bd862-02a3-4343-8a2d-76c842a68878,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b0b082a7-36e4-43a0-9099-cdffcea88c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-06550fa0-e246-4f57-93a4-23a1402b07e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-eacac3a8-b44a-4d84-9e69-10e46636e660,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c6bbf0d8-901d-4d6a-8c4d-7deff340cd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819441694-172.17.0.9-1598627657088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-13db03b9-8e05-4b6d-b582-30c3591375ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-411f7742-04bc-4058-8f41-ad36f0553be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-2dc39982-97d0-4626-8469-f3c78373fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-1e063b2c-886d-495d-a8f8-df623755e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7ab7bac3-fd38-4530-ba35-511fb819174a,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-f237148f-23a5-42e8-b908-60f859bfa3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b78ef021-d12c-4cc5-b55a-d477cde452a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-d6b31021-9a9f-4434-b4d7-2e5d813df426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819441694-172.17.0.9-1598627657088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-13db03b9-8e05-4b6d-b582-30c3591375ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-411f7742-04bc-4058-8f41-ad36f0553be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-2dc39982-97d0-4626-8469-f3c78373fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-1e063b2c-886d-495d-a8f8-df623755e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7ab7bac3-fd38-4530-ba35-511fb819174a,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-f237148f-23a5-42e8-b908-60f859bfa3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-b78ef021-d12c-4cc5-b55a-d477cde452a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-d6b31021-9a9f-4434-b4d7-2e5d813df426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985469061-172.17.0.9-1598628572073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-36347663-e27a-46d7-a9a8-a05c5f42f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-7660c4f5-cb23-40c9-a802-31433c982ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-3d1048bd-0679-429b-8536-3446c3c99649,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-bf88e099-6d73-434b-ae78-c974df1feb67,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-01de2d73-ab6f-42d8-924f-af597d5aa304,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-de9618b7-d08c-40e3-b609-b5344da18b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-317738f0-5d44-4176-a0ea-093d0acaf700,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-61c4892e-8bf4-4f6a-9523-cbac6a4b2be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985469061-172.17.0.9-1598628572073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-36347663-e27a-46d7-a9a8-a05c5f42f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-7660c4f5-cb23-40c9-a802-31433c982ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-3d1048bd-0679-429b-8536-3446c3c99649,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-bf88e099-6d73-434b-ae78-c974df1feb67,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-01de2d73-ab6f-42d8-924f-af597d5aa304,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-de9618b7-d08c-40e3-b609-b5344da18b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-317738f0-5d44-4176-a0ea-093d0acaf700,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-61c4892e-8bf4-4f6a-9523-cbac6a4b2be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061925910-172.17.0.9-1598628829181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-6c2debda-f241-40ab-bf65-37404ea783cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-7536d513-aa48-4789-bc45-5640a607596b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c569e634-ff62-47f2-a557-4f71f3423569,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-41c1f760-d76e-474e-acfc-9c3757eceaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-2fbe9abc-2ee5-41c6-bc61-00c65c1e8c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-65f4ee1c-a08c-4a29-9e7c-792775f89107,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-6b5ef967-4181-4374-b653-e5eb5887f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-52ddeaed-316e-4cfb-8d00-42d5378f0192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061925910-172.17.0.9-1598628829181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-6c2debda-f241-40ab-bf65-37404ea783cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-7536d513-aa48-4789-bc45-5640a607596b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-c569e634-ff62-47f2-a557-4f71f3423569,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-41c1f760-d76e-474e-acfc-9c3757eceaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-2fbe9abc-2ee5-41c6-bc61-00c65c1e8c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-65f4ee1c-a08c-4a29-9e7c-792775f89107,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-6b5ef967-4181-4374-b653-e5eb5887f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-52ddeaed-316e-4cfb-8d00-42d5378f0192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75948998-172.17.0.9-1598628901682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-73ccfa65-acdd-4fff-bec5-07fc6d00b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-bf6e6b16-9c8c-4e6d-82e8-22f6b82c3959,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-34c5c0b4-fbb4-4053-9e03-30f2b4a04932,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-233110bd-d6e5-4194-924f-4d596841cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-e6d862b1-6ab6-49a9-a0a3-ddf1c15e5522,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-4354c9a3-4c20-4b8d-a902-1232d4272606,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-5571c9f0-26ed-4ef8-bf48-13ea72eb4782,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-29e54153-b5c7-447f-8987-005c0e2d44b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75948998-172.17.0.9-1598628901682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-73ccfa65-acdd-4fff-bec5-07fc6d00b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-bf6e6b16-9c8c-4e6d-82e8-22f6b82c3959,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-34c5c0b4-fbb4-4053-9e03-30f2b4a04932,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-233110bd-d6e5-4194-924f-4d596841cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-e6d862b1-6ab6-49a9-a0a3-ddf1c15e5522,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-4354c9a3-4c20-4b8d-a902-1232d4272606,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-5571c9f0-26ed-4ef8-bf48-13ea72eb4782,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-29e54153-b5c7-447f-8987-005c0e2d44b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282612917-172.17.0.9-1598629052728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-68050d57-3ca0-451d-ad79-90209e40921e,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-6566ccd9-e559-40f8-95c3-e2087182123d,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-9fa89e2c-41b1-48b8-8c6c-8e5da0358733,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-99b240b4-4345-4cfb-9415-96cf41e4b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-3c868365-b10c-46cc-8818-c3a2153126e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-a555a5ee-066f-4f80-a772-b9194315a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-a3b76a89-cb14-493b-82cc-8049beb08835,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-db78c6c8-7601-4119-9ceb-720a45099623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282612917-172.17.0.9-1598629052728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-68050d57-3ca0-451d-ad79-90209e40921e,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-6566ccd9-e559-40f8-95c3-e2087182123d,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-9fa89e2c-41b1-48b8-8c6c-8e5da0358733,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-99b240b4-4345-4cfb-9415-96cf41e4b45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-3c868365-b10c-46cc-8818-c3a2153126e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-a555a5ee-066f-4f80-a772-b9194315a1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-a3b76a89-cb14-493b-82cc-8049beb08835,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-db78c6c8-7601-4119-9ceb-720a45099623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277982451-172.17.0.9-1598629366552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-8a83c2c4-4083-4319-bd54-645362df1218,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-384ebc02-1d0c-4a4f-9736-43ec7695ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-1e5623ed-e1dc-4115-8df7-4320402dcf95,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-f06b07d0-dd2f-4e2d-b5d3-275bb5a6c46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-2e809329-9e74-4f97-8f9c-c1d3953719c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-847367f6-b9e7-429b-a025-930a8099aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-0e81f8ec-a2c7-450a-9a08-cdc32779e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-af49a716-af13-4acb-8048-92fee43f87a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277982451-172.17.0.9-1598629366552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-8a83c2c4-4083-4319-bd54-645362df1218,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-384ebc02-1d0c-4a4f-9736-43ec7695ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-1e5623ed-e1dc-4115-8df7-4320402dcf95,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-f06b07d0-dd2f-4e2d-b5d3-275bb5a6c46f,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-2e809329-9e74-4f97-8f9c-c1d3953719c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-847367f6-b9e7-429b-a025-930a8099aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-0e81f8ec-a2c7-450a-9a08-cdc32779e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-af49a716-af13-4acb-8048-92fee43f87a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173162131-172.17.0.9-1598629441707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-0ec1bf63-ca4c-4a00-b440-d288606ae390,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-19cc1b9e-ed89-4c23-afbd-dbd41befab62,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-6aac5bd3-4a95-4062-8996-744598c03280,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f5a29e8a-f3c4-450e-91b7-a12fe5773632,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-9bc5274e-9b62-41ca-a903-f7c21554d965,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-74cbe484-5a2e-4f99-8dc0-73848b19bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-3713baa9-bb61-40ca-8ed2-ea4592622c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-c58c527e-0483-410d-ab1f-07f2126e4a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173162131-172.17.0.9-1598629441707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-0ec1bf63-ca4c-4a00-b440-d288606ae390,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-19cc1b9e-ed89-4c23-afbd-dbd41befab62,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-6aac5bd3-4a95-4062-8996-744598c03280,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f5a29e8a-f3c4-450e-91b7-a12fe5773632,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-9bc5274e-9b62-41ca-a903-f7c21554d965,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-74cbe484-5a2e-4f99-8dc0-73848b19bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-3713baa9-bb61-40ca-8ed2-ea4592622c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-c58c527e-0483-410d-ab1f-07f2126e4a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407137781-172.17.0.9-1598629471630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-6dd598d9-44ce-4892-b6c8-3b57fdeb156b,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-af5b8b56-f62e-433a-a585-8f284134ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-48f5bb1b-2742-490d-9c8c-772ffcd04294,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-43d66217-da0a-41fb-ad27-39e440e43bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-d7309d96-0272-44a9-8101-c14dd16e1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-412dfee9-ba73-4f4e-9720-ad71498ae3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-1e55373e-4cf1-4a9f-a997-7296097b1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-bf9fac48-9b67-4707-836b-cfaad8115fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407137781-172.17.0.9-1598629471630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-6dd598d9-44ce-4892-b6c8-3b57fdeb156b,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-af5b8b56-f62e-433a-a585-8f284134ce94,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-48f5bb1b-2742-490d-9c8c-772ffcd04294,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-43d66217-da0a-41fb-ad27-39e440e43bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-d7309d96-0272-44a9-8101-c14dd16e1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-412dfee9-ba73-4f4e-9720-ad71498ae3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-1e55373e-4cf1-4a9f-a997-7296097b1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-bf9fac48-9b67-4707-836b-cfaad8115fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971060902-172.17.0.9-1598629575415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-8cf75b63-fb01-4b8b-968d-42edd7b73b72,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-bcf2c343-50b2-464f-9aa4-8f11082df814,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-d7dcbd69-93fa-432a-a070-40f121a70fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-3f1c9bb7-5549-4985-813b-119c5bca1152,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-d74facaf-d15a-4393-bab5-283fa81c216f,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-0d457c7c-0794-4cbc-8a5e-ed8900832669,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-bfa1fa79-dc0c-442f-b7fa-a2aeac688be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-f3525b8b-ea1a-4507-a00f-571cc0e68549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971060902-172.17.0.9-1598629575415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-8cf75b63-fb01-4b8b-968d-42edd7b73b72,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-bcf2c343-50b2-464f-9aa4-8f11082df814,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-d7dcbd69-93fa-432a-a070-40f121a70fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-3f1c9bb7-5549-4985-813b-119c5bca1152,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-d74facaf-d15a-4393-bab5-283fa81c216f,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-0d457c7c-0794-4cbc-8a5e-ed8900832669,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-bfa1fa79-dc0c-442f-b7fa-a2aeac688be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-f3525b8b-ea1a-4507-a00f-571cc0e68549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009520023-172.17.0.9-1598629685113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41899,DS-6ebf2c56-5b1a-4459-a045-7323e81ca8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-660fd91f-b434-40b9-bb73-3eeaf703861f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-63daf46a-ece2-4476-855c-977852c9329a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-543fc2a2-8eda-43f2-8c42-0973c159006a,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-5802277a-895a-4129-ba76-cff977c82697,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e8a62637-2370-4e54-ab8e-25a60f4ebee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-e5efee59-6be2-4efd-aaeb-90af0bda3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-acd15335-679a-4706-991c-7de3f0807179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009520023-172.17.0.9-1598629685113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41899,DS-6ebf2c56-5b1a-4459-a045-7323e81ca8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-660fd91f-b434-40b9-bb73-3eeaf703861f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-63daf46a-ece2-4476-855c-977852c9329a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-543fc2a2-8eda-43f2-8c42-0973c159006a,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-5802277a-895a-4129-ba76-cff977c82697,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e8a62637-2370-4e54-ab8e-25a60f4ebee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-e5efee59-6be2-4efd-aaeb-90af0bda3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-acd15335-679a-4706-991c-7de3f0807179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913238135-172.17.0.9-1598629785007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-9f5fb9c9-9a0d-4e13-9a02-6cc4bae54416,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-7986822d-5dda-44e2-8a01-6290879761a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-82ef11ee-28a2-4494-8266-d295b81eb6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-ac14cea9-47b7-4244-aef2-16aa428b8884,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-c091df9c-b353-4c1b-a434-370a29976c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0bbdb4a0-e009-4deb-984e-79f3c1ace73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-830f8274-0a50-447c-8d44-53fa5163bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-72093337-4dfe-4411-ac24-a7d17e853350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913238135-172.17.0.9-1598629785007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-9f5fb9c9-9a0d-4e13-9a02-6cc4bae54416,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-7986822d-5dda-44e2-8a01-6290879761a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-82ef11ee-28a2-4494-8266-d295b81eb6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-ac14cea9-47b7-4244-aef2-16aa428b8884,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-c091df9c-b353-4c1b-a434-370a29976c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0bbdb4a0-e009-4deb-984e-79f3c1ace73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-830f8274-0a50-447c-8d44-53fa5163bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-72093337-4dfe-4411-ac24-a7d17e853350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410846145-172.17.0.9-1598629824305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-397d3b4f-cce5-4b6b-8556-2bf054125e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-b5613c32-e08f-4f5c-b485-8fff70abf64d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-810efde5-ca94-4124-82ac-eed68a2f9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-f46eb6f9-03ff-4c6e-a1fb-68573711efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-32760296-c0e0-4f8b-8615-7777203c815d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-37cde27b-8073-4590-9e49-4fa240371b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-2a22dc13-7f41-46ca-9ec3-6e63aeac9350,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d3142dcd-bf63-4dfb-8d4c-bc3640f67b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410846145-172.17.0.9-1598629824305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-397d3b4f-cce5-4b6b-8556-2bf054125e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-b5613c32-e08f-4f5c-b485-8fff70abf64d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-810efde5-ca94-4124-82ac-eed68a2f9f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-f46eb6f9-03ff-4c6e-a1fb-68573711efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-32760296-c0e0-4f8b-8615-7777203c815d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-37cde27b-8073-4590-9e49-4fa240371b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-2a22dc13-7f41-46ca-9ec3-6e63aeac9350,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d3142dcd-bf63-4dfb-8d4c-bc3640f67b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615694306-172.17.0.9-1598630417132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-9dc870d7-4754-4741-a57d-45c86d703212,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-0de5b2b4-1f70-4982-983f-39e90281602b,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-eb95d346-0dd8-4af8-bad3-6630b78ae953,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9a593f3d-ae29-420a-98b9-d3d9139d0efc,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-274ed4c6-1465-46d3-a83a-c56b88721bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-bfa2defb-f8eb-4e3e-a88e-52695da182f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-b8ce7c3d-5135-49ed-8841-8c94e91b0159,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-2283642e-c01f-47a2-a965-fe1c8cb30fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615694306-172.17.0.9-1598630417132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-9dc870d7-4754-4741-a57d-45c86d703212,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-0de5b2b4-1f70-4982-983f-39e90281602b,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-eb95d346-0dd8-4af8-bad3-6630b78ae953,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-9a593f3d-ae29-420a-98b9-d3d9139d0efc,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-274ed4c6-1465-46d3-a83a-c56b88721bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-bfa2defb-f8eb-4e3e-a88e-52695da182f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-b8ce7c3d-5135-49ed-8841-8c94e91b0159,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-2283642e-c01f-47a2-a965-fe1c8cb30fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231259838-172.17.0.9-1598630509345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37524,DS-a6508864-6c63-4856-a5ae-7265d0ec840f,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-688afb2c-440b-4aac-8011-f7afe15be793,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ad7f662b-8605-4c24-af98-e16c294f9a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-94f739a0-0b27-4baa-b9af-f9767dc1dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-2bbfe018-500f-4c5d-823c-65e0d6138d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-aa3ed478-b273-49f4-ad57-59642ceb5587,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-13c39b3a-4e4e-49d3-9f8c-b7ccc04bb5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-097fb8c5-6faf-443a-9cb1-f1eda5c0b34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231259838-172.17.0.9-1598630509345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37524,DS-a6508864-6c63-4856-a5ae-7265d0ec840f,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-688afb2c-440b-4aac-8011-f7afe15be793,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-ad7f662b-8605-4c24-af98-e16c294f9a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-94f739a0-0b27-4baa-b9af-f9767dc1dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-2bbfe018-500f-4c5d-823c-65e0d6138d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-aa3ed478-b273-49f4-ad57-59642ceb5587,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-13c39b3a-4e4e-49d3-9f8c-b7ccc04bb5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-097fb8c5-6faf-443a-9cb1-f1eda5c0b34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162088311-172.17.0.9-1598630541420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45940,DS-9fca3f2c-1675-4a63-85dc-97d95dd50c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-55903af0-1d83-41e9-b9da-cbc1ffcfb3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-b313aa52-e804-4947-854a-4ed0fff3c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-16415ab0-9997-4afc-8f86-861777aca9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-cd75a01a-5085-4f1f-b72d-43d54d4b9cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-84c48426-cf3b-4bfe-b814-426134c7f640,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-af069d51-a516-4edd-9d14-997ac13aa63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-e78fe0f0-6a9b-4a49-bbda-05054d9b8872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162088311-172.17.0.9-1598630541420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45940,DS-9fca3f2c-1675-4a63-85dc-97d95dd50c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-55903af0-1d83-41e9-b9da-cbc1ffcfb3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-b313aa52-e804-4947-854a-4ed0fff3c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-16415ab0-9997-4afc-8f86-861777aca9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-cd75a01a-5085-4f1f-b72d-43d54d4b9cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-84c48426-cf3b-4bfe-b814-426134c7f640,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-af069d51-a516-4edd-9d14-997ac13aa63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-e78fe0f0-6a9b-4a49-bbda-05054d9b8872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846525608-172.17.0.9-1598630686052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-0b063cd2-4d86-4b4f-aa2d-d1b220c08bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-46113700-69a1-46e7-ba31-d4212fde2589,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-50320436-918d-4074-9259-be253d5df8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-feedc38c-7b2d-4394-b0e4-2df0bfeb61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-14e338d7-af53-4276-80de-0a181a3e77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8d67f03a-e7b8-4ebf-9a66-5f7dec6df6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-4ee61e91-4f87-4771-92f0-89845effb0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-e8218637-00f2-40e7-91ee-9e76d0fef211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846525608-172.17.0.9-1598630686052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-0b063cd2-4d86-4b4f-aa2d-d1b220c08bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-46113700-69a1-46e7-ba31-d4212fde2589,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-50320436-918d-4074-9259-be253d5df8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-feedc38c-7b2d-4394-b0e4-2df0bfeb61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-14e338d7-af53-4276-80de-0a181a3e77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8d67f03a-e7b8-4ebf-9a66-5f7dec6df6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-4ee61e91-4f87-4771-92f0-89845effb0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-e8218637-00f2-40e7-91ee-9e76d0fef211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5264
