reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181126276-172.17.0.10-1598672811999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-11a6256a-9579-489b-91ff-4afaea3d6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a3530e1c-13ef-4922-94ef-bfa55cf8f179,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-6225d86c-e63a-4522-9e35-67bd25ba9c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-c4dc0cc1-4768-4f7a-a4bd-a9de49796030,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f11b27ed-7dcc-42ff-ad30-d4a1310b090b,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-806016dd-b162-4c22-b9a0-bf304d54ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-286441db-cd40-46d3-a209-ee6230b42043,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-0b4552f2-0eac-49ef-8120-e1840ea6a461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181126276-172.17.0.10-1598672811999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-11a6256a-9579-489b-91ff-4afaea3d6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a3530e1c-13ef-4922-94ef-bfa55cf8f179,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-6225d86c-e63a-4522-9e35-67bd25ba9c44,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-c4dc0cc1-4768-4f7a-a4bd-a9de49796030,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f11b27ed-7dcc-42ff-ad30-d4a1310b090b,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-806016dd-b162-4c22-b9a0-bf304d54ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-286441db-cd40-46d3-a209-ee6230b42043,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-0b4552f2-0eac-49ef-8120-e1840ea6a461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408053046-172.17.0.10-1598673149865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-1b975dbc-6305-4647-85c2-4ac4002e5de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8fe474a9-c326-431c-8629-c48fb5cfa562,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c6e17dab-3e19-4737-b643-1a8be4611bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-b63023f9-3931-41b2-9a2c-60df09c1d66a,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-5bdc7d82-56b3-443a-b46c-a8d4c581bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e649965e-a5b2-48f7-931c-706a92ab794c,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-14d6ce0a-654c-4ab3-aadd-95f4c9db2826,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-c7602996-193f-4ba7-b860-c394ca5e43f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408053046-172.17.0.10-1598673149865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-1b975dbc-6305-4647-85c2-4ac4002e5de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-8fe474a9-c326-431c-8629-c48fb5cfa562,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c6e17dab-3e19-4737-b643-1a8be4611bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-b63023f9-3931-41b2-9a2c-60df09c1d66a,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-5bdc7d82-56b3-443a-b46c-a8d4c581bb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e649965e-a5b2-48f7-931c-706a92ab794c,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-14d6ce0a-654c-4ab3-aadd-95f4c9db2826,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-c7602996-193f-4ba7-b860-c394ca5e43f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206718149-172.17.0.10-1598673495104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-d8860d2a-3163-42d8-a417-bfc27952b263,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c460273c-008f-417f-89b6-8857c4cce4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-9259e30c-739d-4482-8a74-8e356e583d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b90e9cd9-2f27-4b49-87cc-1f0cd16fa85d,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-e3d5f49e-95d8-4005-864b-7f94a5a63306,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-d99b944c-f464-4852-abc5-9dfdd8939221,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-38f6b7f1-dc6c-49b3-a5f3-aaa842807fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-7fd75dd6-aaa5-4831-9c03-fe366b2056e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206718149-172.17.0.10-1598673495104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-d8860d2a-3163-42d8-a417-bfc27952b263,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c460273c-008f-417f-89b6-8857c4cce4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-9259e30c-739d-4482-8a74-8e356e583d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-b90e9cd9-2f27-4b49-87cc-1f0cd16fa85d,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-e3d5f49e-95d8-4005-864b-7f94a5a63306,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-d99b944c-f464-4852-abc5-9dfdd8939221,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-38f6b7f1-dc6c-49b3-a5f3-aaa842807fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-7fd75dd6-aaa5-4831-9c03-fe366b2056e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462495865-172.17.0.10-1598673658395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-327cf324-5ae1-4fd6-ae64-7e1f0cdf00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-51037b76-2746-43fb-a6e6-b414f2f5c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-1438b3cc-5c75-49a0-934c-da99bedec78e,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-bc57898a-2b65-4366-903e-eff06ebcd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-adb658dc-83e6-4780-a86e-27d3c7a6e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-7df9ff1f-14cb-4cef-8cc4-3120850a9b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-95630b10-7ff0-4925-a8b0-73e9afedad34,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-8c18e860-5304-470a-ad50-ad8fcebd9282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462495865-172.17.0.10-1598673658395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-327cf324-5ae1-4fd6-ae64-7e1f0cdf00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-51037b76-2746-43fb-a6e6-b414f2f5c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-1438b3cc-5c75-49a0-934c-da99bedec78e,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-bc57898a-2b65-4366-903e-eff06ebcd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-adb658dc-83e6-4780-a86e-27d3c7a6e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-7df9ff1f-14cb-4cef-8cc4-3120850a9b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-95630b10-7ff0-4925-a8b0-73e9afedad34,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-8c18e860-5304-470a-ad50-ad8fcebd9282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236038149-172.17.0.10-1598673949717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-daca5b0f-cdc1-4f1c-9379-cc1dd9f8fce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-52e48d03-b437-4099-aa81-6627e3cb2119,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-c3ff75e2-b61c-4b6b-a8ff-a6a08e60a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-bb73c0d9-8e6c-4598-9fe3-30049b9b4a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-fbb6b434-5ed8-4b16-9b0c-fa05711e122d,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-dc6170d0-ddd1-4824-af1a-0b2b960f8b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-93e0783c-82c1-4d99-83df-d8e7799944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-c6612537-a937-4d33-aa93-cd0fbd7e11a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236038149-172.17.0.10-1598673949717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-daca5b0f-cdc1-4f1c-9379-cc1dd9f8fce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-52e48d03-b437-4099-aa81-6627e3cb2119,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-c3ff75e2-b61c-4b6b-a8ff-a6a08e60a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-bb73c0d9-8e6c-4598-9fe3-30049b9b4a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-fbb6b434-5ed8-4b16-9b0c-fa05711e122d,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-dc6170d0-ddd1-4824-af1a-0b2b960f8b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-93e0783c-82c1-4d99-83df-d8e7799944e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-c6612537-a937-4d33-aa93-cd0fbd7e11a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360655893-172.17.0.10-1598673982275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34275,DS-104d707b-34b7-45cc-a4ff-dc334e18e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-9a18bfbf-4d64-4be3-b265-3d885b85bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-960fda69-a776-40d2-8973-0066296e817a,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-3cc64f21-0f2d-4442-9d8b-0e4d4f3ab902,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-021a6efb-b4f8-4824-94d7-2a401b98d080,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-92251bed-c829-4924-96f3-d03eeb623413,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-e50d4831-4a54-443a-9369-c4d295b9daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-c30529fb-8549-4f2d-b7c2-575aeabcf415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360655893-172.17.0.10-1598673982275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34275,DS-104d707b-34b7-45cc-a4ff-dc334e18e2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-9a18bfbf-4d64-4be3-b265-3d885b85bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-960fda69-a776-40d2-8973-0066296e817a,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-3cc64f21-0f2d-4442-9d8b-0e4d4f3ab902,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-021a6efb-b4f8-4824-94d7-2a401b98d080,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-92251bed-c829-4924-96f3-d03eeb623413,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-e50d4831-4a54-443a-9369-c4d295b9daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-c30529fb-8549-4f2d-b7c2-575aeabcf415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561413441-172.17.0.10-1598674048514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-5ee10969-051a-45ba-9c01-5efc455349f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-2707820a-c32f-4e15-9b31-96ef58eb083a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-b1742c5e-8830-4a73-846e-c3f4e3b96697,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-a6c47f58-7b60-4ca4-805d-91ee182d14ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-32881b44-e774-4abc-be0e-a946bbeb02e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d6dea8b9-420a-4cc2-aa44-3d1731afef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-44da3365-e146-408c-8684-47748b82a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-c56a920b-1961-4a8e-ac48-13546ac9abc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561413441-172.17.0.10-1598674048514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-5ee10969-051a-45ba-9c01-5efc455349f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-2707820a-c32f-4e15-9b31-96ef58eb083a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-b1742c5e-8830-4a73-846e-c3f4e3b96697,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-a6c47f58-7b60-4ca4-805d-91ee182d14ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-32881b44-e774-4abc-be0e-a946bbeb02e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-d6dea8b9-420a-4cc2-aa44-3d1731afef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-44da3365-e146-408c-8684-47748b82a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-c56a920b-1961-4a8e-ac48-13546ac9abc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119411897-172.17.0.10-1598674190612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-be283a5a-8924-4765-95fc-ed4c83204603,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-3b9a0036-909a-4464-b2f3-f87256a23fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-4fad6eb8-61c3-443f-a5fb-de5eae026559,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-eb4472d2-736d-4520-ac1e-ad4ce9fd342e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-21b941d3-171b-4d18-8cb4-bb04d9bb53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-7a587a79-4953-43c2-8e83-e36e63979ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-a7cc1c42-4dd7-4cc1-b093-9e6a8a69bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-9149ebb6-2e53-40f7-bd4a-1f8f0b950335,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119411897-172.17.0.10-1598674190612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34518,DS-be283a5a-8924-4765-95fc-ed4c83204603,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-3b9a0036-909a-4464-b2f3-f87256a23fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-4fad6eb8-61c3-443f-a5fb-de5eae026559,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-eb4472d2-736d-4520-ac1e-ad4ce9fd342e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-21b941d3-171b-4d18-8cb4-bb04d9bb53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-7a587a79-4953-43c2-8e83-e36e63979ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-a7cc1c42-4dd7-4cc1-b093-9e6a8a69bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-9149ebb6-2e53-40f7-bd4a-1f8f0b950335,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575323674-172.17.0.10-1598674417090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-f3f52416-c7ce-464e-b095-c7e17326d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-ba191afe-17d7-48db-953f-3167827db195,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-385a422a-ceb0-4a45-baf5-d36e1df32eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-f5ebe36c-e9a3-46df-a0a5-e233b29b5b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1bac5890-07e7-4808-a911-8eaa68a5c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-d49144d5-5a7b-473f-9e53-bae1331a28de,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-5621767b-1fd6-4b7d-81fa-77d9f7e7726b,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bf780ab8-4113-484f-8219-9f516ae1d5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575323674-172.17.0.10-1598674417090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-f3f52416-c7ce-464e-b095-c7e17326d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-ba191afe-17d7-48db-953f-3167827db195,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-385a422a-ceb0-4a45-baf5-d36e1df32eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-f5ebe36c-e9a3-46df-a0a5-e233b29b5b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1bac5890-07e7-4808-a911-8eaa68a5c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-d49144d5-5a7b-473f-9e53-bae1331a28de,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-5621767b-1fd6-4b7d-81fa-77d9f7e7726b,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-bf780ab8-4113-484f-8219-9f516ae1d5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721435160-172.17.0.10-1598674499192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-4c74a459-b312-43ce-94f9-430f4dca1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-d9e4e8fe-bb34-4eb3-a892-415d08ac2c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-588c821c-cf93-4605-909e-c78e502652a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-d8dbc670-095f-4cf3-8f12-b2a3ce096623,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-9dc9306a-113e-4af0-8dea-a4d5a37d3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-a2bc763f-dc6d-482e-b405-a83821041a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-4fae0ed2-f77c-4136-8ec3-81f6eb0f10c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-86c2eb39-6242-49bc-83f1-2074926cd069,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721435160-172.17.0.10-1598674499192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-4c74a459-b312-43ce-94f9-430f4dca1d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-d9e4e8fe-bb34-4eb3-a892-415d08ac2c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-588c821c-cf93-4605-909e-c78e502652a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-d8dbc670-095f-4cf3-8f12-b2a3ce096623,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-9dc9306a-113e-4af0-8dea-a4d5a37d3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-a2bc763f-dc6d-482e-b405-a83821041a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-4fae0ed2-f77c-4136-8ec3-81f6eb0f10c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-86c2eb39-6242-49bc-83f1-2074926cd069,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698620415-172.17.0.10-1598674683688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-dc1118d2-d8b3-446b-99e4-24f4cc21a464,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-1029b52f-31a4-4e32-94f8-1416019a597c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-32bd7898-db7c-473c-acb2-9ef96b1d943f,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-93ae1e77-b850-490a-a839-bf3ba0641a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-39b338b1-cc65-4d1e-a056-8cc7dc1fb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-5aa8180c-f247-4340-90b3-08506cdc1b70,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-963194c8-dd60-4679-9af6-9f2babfd1266,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e12e8f43-8b45-4999-9ae1-381799f0cac2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698620415-172.17.0.10-1598674683688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-dc1118d2-d8b3-446b-99e4-24f4cc21a464,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-1029b52f-31a4-4e32-94f8-1416019a597c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-32bd7898-db7c-473c-acb2-9ef96b1d943f,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-93ae1e77-b850-490a-a839-bf3ba0641a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-39b338b1-cc65-4d1e-a056-8cc7dc1fb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-5aa8180c-f247-4340-90b3-08506cdc1b70,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-963194c8-dd60-4679-9af6-9f2babfd1266,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e12e8f43-8b45-4999-9ae1-381799f0cac2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097932536-172.17.0.10-1598674825334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-3c661357-a6a1-4ccd-89e0-2da0a32df59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a67acb46-2dff-44a2-9538-0a23c11099b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-60abac07-9a2c-48e6-8e07-24166b79811e,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-ba037208-cb88-4ff6-8930-86b608547076,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-c7e0019b-6329-4c79-aaee-4c01775ca4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-487888f2-b5f1-426b-8d65-3d685c376147,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-be9bf060-6e7b-43f7-8171-b5b2caa17c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-7e4ceae3-1a95-4100-bdd0-4cd348acbfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097932536-172.17.0.10-1598674825334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-3c661357-a6a1-4ccd-89e0-2da0a32df59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a67acb46-2dff-44a2-9538-0a23c11099b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-60abac07-9a2c-48e6-8e07-24166b79811e,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-ba037208-cb88-4ff6-8930-86b608547076,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-c7e0019b-6329-4c79-aaee-4c01775ca4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-487888f2-b5f1-426b-8d65-3d685c376147,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-be9bf060-6e7b-43f7-8171-b5b2caa17c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-7e4ceae3-1a95-4100-bdd0-4cd348acbfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078730542-172.17.0.10-1598674872985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-e80e9eff-5880-4252-8a63-c5d44e79a655,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-6c1af4e6-27c3-42bc-8be0-6d47925f8882,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-6bf392c3-61e1-4d7a-842a-a72fa20950ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-336433ab-d596-46a4-ac96-86bbe366b417,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2e5de6cd-8582-48c2-8a75-86f2ada1a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-5eac0aa7-1f68-48a2-ab4c-859baadf2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-d8403ddc-9d30-4e44-886f-d55335bf54c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-529e26bf-5b3c-4f74-aadd-bcf17c1568ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078730542-172.17.0.10-1598674872985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-e80e9eff-5880-4252-8a63-c5d44e79a655,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-6c1af4e6-27c3-42bc-8be0-6d47925f8882,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-6bf392c3-61e1-4d7a-842a-a72fa20950ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-336433ab-d596-46a4-ac96-86bbe366b417,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-2e5de6cd-8582-48c2-8a75-86f2ada1a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-5eac0aa7-1f68-48a2-ab4c-859baadf2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-d8403ddc-9d30-4e44-886f-d55335bf54c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-529e26bf-5b3c-4f74-aadd-bcf17c1568ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743915785-172.17.0.10-1598674992677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-1aeb6e53-5dec-4c55-b495-09368b607898,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-7075e1c5-73ac-4aa6-8c01-4edabe195cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-34dcfb7b-1095-432c-be7a-1e5919cee2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-ef6a2c27-73e6-449b-8c53-bc5121100bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-52847c8c-e3d0-48c0-a107-c40ae7a1de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-81c4af0e-5591-4ee4-9969-62a808796129,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-97c31228-3c94-4230-ae3d-538005c43cee,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-63abac14-c42f-40de-93c8-360e7f177873,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743915785-172.17.0.10-1598674992677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-1aeb6e53-5dec-4c55-b495-09368b607898,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-7075e1c5-73ac-4aa6-8c01-4edabe195cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-34dcfb7b-1095-432c-be7a-1e5919cee2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-ef6a2c27-73e6-449b-8c53-bc5121100bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-52847c8c-e3d0-48c0-a107-c40ae7a1de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-81c4af0e-5591-4ee4-9969-62a808796129,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-97c31228-3c94-4230-ae3d-538005c43cee,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-63abac14-c42f-40de-93c8-360e7f177873,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515735317-172.17.0.10-1598675072382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-613f7092-f68f-408e-8584-de54da1b2ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-96d1dee6-f9df-4499-967f-c455de9d7344,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-2bd61b1f-ac41-4277-b0d7-7ed874c1e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-abb36c59-9d3e-443f-8c52-c1b97dc23022,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-d3ca5c8a-a27e-4a88-b926-5d90e69d1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-7c21cf39-40bc-4208-8016-5238fa879f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-8dd338dc-3598-4322-86f7-c543d9b7887d,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-5107d0f5-27bc-4c7c-98d7-87b2e6cacf94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515735317-172.17.0.10-1598675072382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-613f7092-f68f-408e-8584-de54da1b2ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-96d1dee6-f9df-4499-967f-c455de9d7344,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-2bd61b1f-ac41-4277-b0d7-7ed874c1e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-abb36c59-9d3e-443f-8c52-c1b97dc23022,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-d3ca5c8a-a27e-4a88-b926-5d90e69d1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-7c21cf39-40bc-4208-8016-5238fa879f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-8dd338dc-3598-4322-86f7-c543d9b7887d,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-5107d0f5-27bc-4c7c-98d7-87b2e6cacf94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561783660-172.17.0.10-1598675185203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-0604da34-5606-4a23-a7ce-b8895759c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-a6c20b68-481a-4355-ae34-0701e9f7920f,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-d3774ee2-f946-4557-8e19-369613a77c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-9f2c9750-6bcd-4de7-b57b-2d49af565ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-3d757005-ad4b-47c9-8629-2334255496e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-939ff736-3b1c-4cdd-bea8-3ccd501c772b,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-7ef7345d-9d6b-47a8-86a7-e293fb40d042,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-e9607669-642a-41b7-b3b3-b186c2db7acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561783660-172.17.0.10-1598675185203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-0604da34-5606-4a23-a7ce-b8895759c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-a6c20b68-481a-4355-ae34-0701e9f7920f,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-d3774ee2-f946-4557-8e19-369613a77c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-9f2c9750-6bcd-4de7-b57b-2d49af565ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-3d757005-ad4b-47c9-8629-2334255496e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-939ff736-3b1c-4cdd-bea8-3ccd501c772b,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-7ef7345d-9d6b-47a8-86a7-e293fb40d042,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-e9607669-642a-41b7-b3b3-b186c2db7acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363688076-172.17.0.10-1598675364325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-cc840809-f37f-41ea-b2c5-735c9dc3fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-ecc59515-2753-4492-836a-9ce797adcb19,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-02a9c6d7-5cce-4fbc-b8ab-60b1fa7550ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-cfceaa9b-8498-437e-8678-f706d3292e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-921d3eff-caca-43f2-8ec7-c7695fae4169,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bcb2f107-2c96-40c7-8cc0-00159f92ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c1c08db8-e261-4770-a79e-15b2db783298,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-624c9462-7754-457f-bae6-9825c4fbfc5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363688076-172.17.0.10-1598675364325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-cc840809-f37f-41ea-b2c5-735c9dc3fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-ecc59515-2753-4492-836a-9ce797adcb19,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-02a9c6d7-5cce-4fbc-b8ab-60b1fa7550ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-cfceaa9b-8498-437e-8678-f706d3292e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-921d3eff-caca-43f2-8ec7-c7695fae4169,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bcb2f107-2c96-40c7-8cc0-00159f92ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c1c08db8-e261-4770-a79e-15b2db783298,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-624c9462-7754-457f-bae6-9825c4fbfc5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267257952-172.17.0.10-1598675405589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-779c7e8c-e4e6-4ac8-9428-3db4eaf8fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-0d104f5e-6a7d-42b3-8391-1725dca264ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-8488b86f-2a19-4f6d-9fac-c55427cafc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-a4664bd1-fc53-4fa9-abbd-b4c5a3f1c644,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-b388b533-5362-4a90-acd9-d47584eb6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-82f08bf3-e737-4b14-966f-c25f6b4006b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e93577b0-b2d4-46fb-9065-73ed3bbfb8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b5fec2bf-e773-4cc4-b221-c00df7e26363,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267257952-172.17.0.10-1598675405589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-779c7e8c-e4e6-4ac8-9428-3db4eaf8fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-0d104f5e-6a7d-42b3-8391-1725dca264ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-8488b86f-2a19-4f6d-9fac-c55427cafc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-a4664bd1-fc53-4fa9-abbd-b4c5a3f1c644,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-b388b533-5362-4a90-acd9-d47584eb6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-82f08bf3-e737-4b14-966f-c25f6b4006b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-e93577b0-b2d4-46fb-9065-73ed3bbfb8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b5fec2bf-e773-4cc4-b221-c00df7e26363,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685487878-172.17.0.10-1598675545037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-2df8d957-e70c-48c5-b78d-50eb0b06c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-dbc012be-ddf3-43cb-a043-c486d9639c80,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-2c79bc30-16e1-4113-9bdc-d256990da49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-3d403448-77a5-4eb7-912a-315d0e50aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-54f865d2-6b30-4eb8-ab85-d1ab9a8e21f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-22f1792b-7e0b-4d54-8315-95342ee6a061,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-920daa71-b5b0-443f-a03e-a918b7958704,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-c8d3b4fc-c70a-4564-852a-4174862c7339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685487878-172.17.0.10-1598675545037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-2df8d957-e70c-48c5-b78d-50eb0b06c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-dbc012be-ddf3-43cb-a043-c486d9639c80,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-2c79bc30-16e1-4113-9bdc-d256990da49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-3d403448-77a5-4eb7-912a-315d0e50aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-54f865d2-6b30-4eb8-ab85-d1ab9a8e21f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-22f1792b-7e0b-4d54-8315-95342ee6a061,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-920daa71-b5b0-443f-a03e-a918b7958704,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-c8d3b4fc-c70a-4564-852a-4174862c7339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840453214-172.17.0.10-1598675707359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-df9979f9-fa4b-4b34-9f4c-6c1abb8481ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-41384471-5c63-44d5-a2ed-d06a60cfdf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-9aa148b8-d609-4bad-92b7-85deee955147,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-48646dfb-f483-4c15-891a-9a6f19bfd888,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-d0d4855b-086c-42b6-a359-440f2f60963f,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-e8e45a70-b259-46d7-890b-1e34b0873be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-f6549b48-e5b6-4630-970e-1b2447877903,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-87d80583-2e49-4aad-b3e1-4c4691c50200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840453214-172.17.0.10-1598675707359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-df9979f9-fa4b-4b34-9f4c-6c1abb8481ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-41384471-5c63-44d5-a2ed-d06a60cfdf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-9aa148b8-d609-4bad-92b7-85deee955147,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-48646dfb-f483-4c15-891a-9a6f19bfd888,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-d0d4855b-086c-42b6-a359-440f2f60963f,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-e8e45a70-b259-46d7-890b-1e34b0873be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-f6549b48-e5b6-4630-970e-1b2447877903,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-87d80583-2e49-4aad-b3e1-4c4691c50200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476573897-172.17.0.10-1598676242163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-cbc13994-5c94-4956-918a-57f0c256cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-0af592ae-be9d-442e-b93e-520af9305262,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-8d0e5635-db06-4cb3-9896-345fed827ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-49e10667-a28f-43e0-a83d-53d42d67dae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-94d96996-0d16-4438-b9bd-ef85b4704bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e478296d-c6f1-4a14-8c0e-5be387132221,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-12f9d130-3668-444f-b4fd-2adc11fb024f,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-98df1d42-f22f-44c7-948c-1eacf00f959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476573897-172.17.0.10-1598676242163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-cbc13994-5c94-4956-918a-57f0c256cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-0af592ae-be9d-442e-b93e-520af9305262,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-8d0e5635-db06-4cb3-9896-345fed827ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-49e10667-a28f-43e0-a83d-53d42d67dae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-94d96996-0d16-4438-b9bd-ef85b4704bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e478296d-c6f1-4a14-8c0e-5be387132221,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-12f9d130-3668-444f-b4fd-2adc11fb024f,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-98df1d42-f22f-44c7-948c-1eacf00f959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677015843-172.17.0.10-1598676379075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-2a7db667-1acb-49d0-a24c-42cf0ef764e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-f50f8adb-f88c-4658-8e0a-bfc70962b702,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-b7171a1e-5e13-4c18-a84f-033d23510923,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-5115d6ed-710b-42c8-9758-7f6058159868,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-586e8e14-3b1c-4634-bdd8-f5841de784b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-c7fcf139-e872-40df-b372-0eb862227748,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-be7d4647-a741-4fab-bf5f-58956fe8944b,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-36a3eb75-cd68-4375-876b-0b5aaf8bc507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677015843-172.17.0.10-1598676379075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-2a7db667-1acb-49d0-a24c-42cf0ef764e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-f50f8adb-f88c-4658-8e0a-bfc70962b702,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-b7171a1e-5e13-4c18-a84f-033d23510923,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-5115d6ed-710b-42c8-9758-7f6058159868,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-586e8e14-3b1c-4634-bdd8-f5841de784b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-c7fcf139-e872-40df-b372-0eb862227748,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-be7d4647-a741-4fab-bf5f-58956fe8944b,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-36a3eb75-cd68-4375-876b-0b5aaf8bc507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247039225-172.17.0.10-1598676472079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-edef7979-a224-4e19-811b-843bdde2f723,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-7afca06f-6c90-4478-b1bc-314fb46431b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-8b5a0699-24f5-4332-bd59-21faae3ecdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-4d0b0fb5-b7bb-4487-b86c-ff12cdaa9558,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f2eacf8b-0af7-43f0-aa6a-347aa72da10c,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-efcee8c4-80c3-4a62-ae03-a1c56316cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-3e9cdcb4-7aca-46c8-929b-35eb7a7d1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-230d149c-6f99-41ba-abcf-151b4c05d0b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247039225-172.17.0.10-1598676472079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-edef7979-a224-4e19-811b-843bdde2f723,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-7afca06f-6c90-4478-b1bc-314fb46431b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-8b5a0699-24f5-4332-bd59-21faae3ecdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-4d0b0fb5-b7bb-4487-b86c-ff12cdaa9558,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f2eacf8b-0af7-43f0-aa6a-347aa72da10c,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-efcee8c4-80c3-4a62-ae03-a1c56316cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-3e9cdcb4-7aca-46c8-929b-35eb7a7d1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-230d149c-6f99-41ba-abcf-151b4c05d0b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988834002-172.17.0.10-1598676741882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-3d35a0ae-1333-4c2a-ba23-8cd2aefd16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-c5c520f1-4766-48ca-86da-b7f82784ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-ee46817c-e86f-4c45-af29-95728a10785f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-f12b802f-c178-4594-bd34-db785bc99751,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-06085743-115e-4a1e-93b5-62496467c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-d5b357c3-bc24-406c-b136-7a6ef61e9948,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-bf36465d-7b92-4f80-a3c7-c5b355f7f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-bf3a7ee3-b91c-4cd7-91f5-b9aa8f37b590,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988834002-172.17.0.10-1598676741882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35659,DS-3d35a0ae-1333-4c2a-ba23-8cd2aefd16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-c5c520f1-4766-48ca-86da-b7f82784ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-ee46817c-e86f-4c45-af29-95728a10785f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-f12b802f-c178-4594-bd34-db785bc99751,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-06085743-115e-4a1e-93b5-62496467c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-d5b357c3-bc24-406c-b136-7a6ef61e9948,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-bf36465d-7b92-4f80-a3c7-c5b355f7f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-bf3a7ee3-b91c-4cd7-91f5-b9aa8f37b590,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135597583-172.17.0.10-1598676818870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-bd268c85-323f-4d1a-ae17-ce2b5624c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-dce1e906-7de4-479f-9a25-a9c599800607,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-f55628b2-9b79-43e5-bf9e-d0abe0d251ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-431514a3-2517-485f-be66-c396840b25ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-29ce39cd-3925-4f77-a3f2-a8efb10d9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b962d0fd-ff5a-4c63-ab6a-ebb7cd1e7471,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-a9993e0a-84b4-48f3-99c2-619d3882ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c47d3b9a-ad52-4c52-a354-792f38e1a329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135597583-172.17.0.10-1598676818870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-bd268c85-323f-4d1a-ae17-ce2b5624c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-dce1e906-7de4-479f-9a25-a9c599800607,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-f55628b2-9b79-43e5-bf9e-d0abe0d251ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-431514a3-2517-485f-be66-c396840b25ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-29ce39cd-3925-4f77-a3f2-a8efb10d9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b962d0fd-ff5a-4c63-ab6a-ebb7cd1e7471,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-a9993e0a-84b4-48f3-99c2-619d3882ba50,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c47d3b9a-ad52-4c52-a354-792f38e1a329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863844632-172.17.0.10-1598676893981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-ef4a640a-144a-432b-a95d-06846ae681b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f761e725-94ff-4589-ae33-460e8f2000e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-8eb5bb99-929b-4b18-beff-a7ec26fd0787,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-c4898dd9-eafe-402d-b635-4639935cf8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-94145761-2329-40b2-95e9-83e26a9806c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-57c7dcc8-bc8c-4ab6-830a-a9942235a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-8d7e2a16-0d69-4dcc-b9f9-e43dada39ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-8ff548b0-7192-4419-aa0d-999b9dab196d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863844632-172.17.0.10-1598676893981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-ef4a640a-144a-432b-a95d-06846ae681b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-f761e725-94ff-4589-ae33-460e8f2000e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-8eb5bb99-929b-4b18-beff-a7ec26fd0787,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-c4898dd9-eafe-402d-b635-4639935cf8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-94145761-2329-40b2-95e9-83e26a9806c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-57c7dcc8-bc8c-4ab6-830a-a9942235a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-8d7e2a16-0d69-4dcc-b9f9-e43dada39ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-8ff548b0-7192-4419-aa0d-999b9dab196d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795744248-172.17.0.10-1598676978297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-9895b9bd-710f-4d3f-99c5-27600eb7bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-2b82c8a3-1d7e-475b-b247-24b0c9b010c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8ff302f5-4581-4c96-9a31-317267ab9467,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-2115018d-2e00-44a4-acd1-0078fb0f6775,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-b9c9efae-7e22-4c40-837c-8603981cf07f,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-6604f718-0ae8-4b77-bd60-31d391e5a7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-94d0ab1b-f28d-4470-9e30-c84026e58f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-5aa17a4d-8baf-4328-bf9e-dbc3d08882b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795744248-172.17.0.10-1598676978297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-9895b9bd-710f-4d3f-99c5-27600eb7bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-2b82c8a3-1d7e-475b-b247-24b0c9b010c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8ff302f5-4581-4c96-9a31-317267ab9467,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-2115018d-2e00-44a4-acd1-0078fb0f6775,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-b9c9efae-7e22-4c40-837c-8603981cf07f,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-6604f718-0ae8-4b77-bd60-31d391e5a7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-94d0ab1b-f28d-4470-9e30-c84026e58f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-5aa17a4d-8baf-4328-bf9e-dbc3d08882b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697254944-172.17.0.10-1598677091498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-a03e284d-2929-40e0-964d-a1640ac82b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-9b0f9944-5ad9-43b0-87a1-e66c99c431fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-c4a868c9-2cbb-4fb5-83a7-71a1e3563247,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-1a75dc20-266d-4985-91d1-ff20ce2e7108,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-c98b1be9-0a7d-4d98-8a1c-c73fc7489adf,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-1860b8ab-2eeb-4ef8-8fa8-2a8695859610,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-87aa4e2c-71c2-4e30-b51f-205fc6e5c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-5f88d630-da29-4b52-abc2-033d7b02b66e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697254944-172.17.0.10-1598677091498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-a03e284d-2929-40e0-964d-a1640ac82b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-9b0f9944-5ad9-43b0-87a1-e66c99c431fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-c4a868c9-2cbb-4fb5-83a7-71a1e3563247,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-1a75dc20-266d-4985-91d1-ff20ce2e7108,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-c98b1be9-0a7d-4d98-8a1c-c73fc7489adf,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-1860b8ab-2eeb-4ef8-8fa8-2a8695859610,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-87aa4e2c-71c2-4e30-b51f-205fc6e5c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-5f88d630-da29-4b52-abc2-033d7b02b66e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130473476-172.17.0.10-1598677134349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43260,DS-1abea0b5-9d9b-44c7-8595-7cc8399921b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-83211ff0-82a6-438d-bc43-aa1378d99bee,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5c275c9d-ef05-410e-896f-d781dac02c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-179276a0-83a7-4c33-8707-f3efe685f669,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c4e5a9dd-d69e-4c18-9716-ea6e1f3dfbec,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-cb10b954-bf45-4450-872c-5eeb61abb4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-232e203a-f48e-48fc-8416-d575681667b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-1a34752a-b17e-4a76-9aa4-f96d355bd6cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130473476-172.17.0.10-1598677134349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43260,DS-1abea0b5-9d9b-44c7-8595-7cc8399921b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-83211ff0-82a6-438d-bc43-aa1378d99bee,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5c275c9d-ef05-410e-896f-d781dac02c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-179276a0-83a7-4c33-8707-f3efe685f669,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c4e5a9dd-d69e-4c18-9716-ea6e1f3dfbec,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-cb10b954-bf45-4450-872c-5eeb61abb4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-232e203a-f48e-48fc-8416-d575681667b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-1a34752a-b17e-4a76-9aa4-f96d355bd6cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113928936-172.17.0.10-1598677210323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-de26968a-89b6-4a4c-b3c7-a54c09ff9b49,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-157a4eb4-212c-4570-9bf6-be8dccc5b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-99e72b0a-530a-40a5-b0d2-153335a71398,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-af5bcfa2-fbe3-4cf1-99a3-5ebfd88b298f,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-32f57df3-4f37-4787-ab22-c2401a2d0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-95fa1f03-936d-4730-a645-7d19b11c3d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-c60ccfe8-4359-4701-b3b5-899714db0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-0a9911cb-a012-4169-b69b-5a2d4062381b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113928936-172.17.0.10-1598677210323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-de26968a-89b6-4a4c-b3c7-a54c09ff9b49,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-157a4eb4-212c-4570-9bf6-be8dccc5b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-99e72b0a-530a-40a5-b0d2-153335a71398,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-af5bcfa2-fbe3-4cf1-99a3-5ebfd88b298f,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-32f57df3-4f37-4787-ab22-c2401a2d0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-95fa1f03-936d-4730-a645-7d19b11c3d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-c60ccfe8-4359-4701-b3b5-899714db0d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-0a9911cb-a012-4169-b69b-5a2d4062381b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086320720-172.17.0.10-1598677400768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33519,DS-32cbabb7-8c10-47ac-bb54-a41921529e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-1ac90aea-3f01-4524-a899-340d6c6c61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-6fc4058f-a21e-41b7-96b1-07df48257119,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-4d15c1bb-5f1f-496b-b4b7-7498b7eecc41,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-5cb6b5c0-3c6b-46ae-8839-2ae3b5fcdb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-5a8cc371-ed3d-4e1a-a754-4f7b5bf4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-29341f2e-f9ac-4228-bdae-971b06f0b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-2cf77cda-2592-404c-9a24-0049e13fec19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086320720-172.17.0.10-1598677400768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33519,DS-32cbabb7-8c10-47ac-bb54-a41921529e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-1ac90aea-3f01-4524-a899-340d6c6c61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-6fc4058f-a21e-41b7-96b1-07df48257119,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-4d15c1bb-5f1f-496b-b4b7-7498b7eecc41,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-5cb6b5c0-3c6b-46ae-8839-2ae3b5fcdb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-5a8cc371-ed3d-4e1a-a754-4f7b5bf4fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-29341f2e-f9ac-4228-bdae-971b06f0b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-2cf77cda-2592-404c-9a24-0049e13fec19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209754669-172.17.0.10-1598677472668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-cc2b5643-1aa0-4965-9c43-74557577932f,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3502f0be-1a54-47b5-ad2d-de4e8e5ffd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-81f89898-cf48-47e7-a495-48235af107fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-034745fd-acc1-4f09-8842-cbb2b15717f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-81a153e6-1ab9-4439-9933-38e098741a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-80857358-7033-4ace-b0fd-4e8832038897,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-8c34c548-172b-40e4-83f3-8e095b7b0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-83e5861d-4460-4fef-a8e4-f94360901c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209754669-172.17.0.10-1598677472668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-cc2b5643-1aa0-4965-9c43-74557577932f,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3502f0be-1a54-47b5-ad2d-de4e8e5ffd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-81f89898-cf48-47e7-a495-48235af107fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-034745fd-acc1-4f09-8842-cbb2b15717f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-81a153e6-1ab9-4439-9933-38e098741a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-80857358-7033-4ace-b0fd-4e8832038897,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-8c34c548-172b-40e4-83f3-8e095b7b0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-83e5861d-4460-4fef-a8e4-f94360901c0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196338792-172.17.0.10-1598677511534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-19811f4c-51ca-4820-8506-8908633d2749,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-3c2b9c70-1a53-43a8-a264-dc711efe3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-5fb48cfd-e62e-4457-a75d-9b123157231d,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-c1d2fa22-5b30-498c-b0d8-e7552a0af0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-46d56735-58aa-4f88-af00-0624fd3c05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-8374d9f5-f774-4210-a6e8-f1fef089014d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b40c27a2-af9e-45b0-9105-cad154466118,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-5d74e4d8-a68f-407b-a056-988cf2581d08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196338792-172.17.0.10-1598677511534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-19811f4c-51ca-4820-8506-8908633d2749,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-3c2b9c70-1a53-43a8-a264-dc711efe3d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-5fb48cfd-e62e-4457-a75d-9b123157231d,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-c1d2fa22-5b30-498c-b0d8-e7552a0af0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-46d56735-58aa-4f88-af00-0624fd3c05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-8374d9f5-f774-4210-a6e8-f1fef089014d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b40c27a2-af9e-45b0-9105-cad154466118,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-5d74e4d8-a68f-407b-a056-988cf2581d08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382211249-172.17.0.10-1598677556209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-f5eafd64-20e4-4c39-8108-647dbeb0ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9f09b51e-dee8-4d1b-9cf0-1777674751d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-bdccdd34-24e6-4586-a4c1-26c1f6f147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-bb84e96e-11a6-4a1c-8367-a4d0736c9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-40171a7e-d198-4d98-a95d-8dec9ada335e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-c03b0188-d917-4e6a-b7a8-59cc5db6794c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-6036ee33-504a-4411-b4dc-060c332c7305,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-98b00d05-4b3f-4d0d-aa6b-480c9ea83ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382211249-172.17.0.10-1598677556209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-f5eafd64-20e4-4c39-8108-647dbeb0ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-9f09b51e-dee8-4d1b-9cf0-1777674751d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-bdccdd34-24e6-4586-a4c1-26c1f6f147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-bb84e96e-11a6-4a1c-8367-a4d0736c9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-40171a7e-d198-4d98-a95d-8dec9ada335e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-c03b0188-d917-4e6a-b7a8-59cc5db6794c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-6036ee33-504a-4411-b4dc-060c332c7305,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-98b00d05-4b3f-4d0d-aa6b-480c9ea83ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57723049-172.17.0.10-1598677672994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-e004d784-89c4-434f-8fc7-0650eb023924,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-ac93d4be-3174-4fdf-b729-2f784cffcce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-9493c79f-8623-442a-9961-23f46b0e2369,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7b171888-f67a-4e75-b311-5f428ceb6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-e66daf70-c712-4771-a8f6-12083c26eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-7b04fdbc-4283-4588-bf37-cc73e5d837e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-a07bf063-5bfa-43b8-bbd8-bf6db262819b,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-0119608a-a351-4b18-88eb-fa625daf5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57723049-172.17.0.10-1598677672994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-e004d784-89c4-434f-8fc7-0650eb023924,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-ac93d4be-3174-4fdf-b729-2f784cffcce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-9493c79f-8623-442a-9961-23f46b0e2369,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7b171888-f67a-4e75-b311-5f428ceb6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-e66daf70-c712-4771-a8f6-12083c26eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-7b04fdbc-4283-4588-bf37-cc73e5d837e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-a07bf063-5bfa-43b8-bbd8-bf6db262819b,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-0119608a-a351-4b18-88eb-fa625daf5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8093557-172.17.0.10-1598677824741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-3b9de134-96d7-44e3-ab89-0bf37ba09102,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0fb2f5fe-f5d5-4c94-b5ec-361e63105a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-3fe893fd-b2ec-4e7b-97c5-f8166ed82334,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-4b07bc42-dd44-4a72-8896-e5a47ebdb818,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-a918857e-1078-406c-93cf-e0b6972decd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e6e6cd8c-acbc-416e-9ea4-32de426501c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-f44d850e-79cd-4c16-b7fc-77a264de3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-4be345b3-f6b8-45e5-9e7f-8f89af6d7f7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8093557-172.17.0.10-1598677824741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-3b9de134-96d7-44e3-ab89-0bf37ba09102,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0fb2f5fe-f5d5-4c94-b5ec-361e63105a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-3fe893fd-b2ec-4e7b-97c5-f8166ed82334,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-4b07bc42-dd44-4a72-8896-e5a47ebdb818,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-a918857e-1078-406c-93cf-e0b6972decd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-e6e6cd8c-acbc-416e-9ea4-32de426501c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-f44d850e-79cd-4c16-b7fc-77a264de3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-4be345b3-f6b8-45e5-9e7f-8f89af6d7f7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5605
