reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192726359-172.17.0.13-1598669587300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-d0d76573-9c37-43e7-bbe6-fc59a714db35,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-6301b703-5807-4b6e-bc23-2d0d73897bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d0fe32e3-125f-4037-9720-fcbe53f1a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-6fadd7bf-fd4e-46d7-ba9e-e2b9d926f93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-dff8614f-d254-48d8-9bc3-7cd398c4e366,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-804257b8-e4cc-4c5b-86d8-5ea0cc168f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-afbf92c7-cd49-43f6-9065-d11cd756f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-296e6408-cb43-4f14-87ea-7e9e1d560b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192726359-172.17.0.13-1598669587300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-d0d76573-9c37-43e7-bbe6-fc59a714db35,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-6301b703-5807-4b6e-bc23-2d0d73897bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d0fe32e3-125f-4037-9720-fcbe53f1a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-6fadd7bf-fd4e-46d7-ba9e-e2b9d926f93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-dff8614f-d254-48d8-9bc3-7cd398c4e366,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-804257b8-e4cc-4c5b-86d8-5ea0cc168f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-afbf92c7-cd49-43f6-9065-d11cd756f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-296e6408-cb43-4f14-87ea-7e9e1d560b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441109047-172.17.0.13-1598669651869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-8646839e-bb9e-476d-a134-9c50518d398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-e5463f60-e853-471b-8c1e-fe0f91738d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-aa5bea6b-883c-4255-bea7-147b0de99a07,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-3ed60087-4b8d-453f-9ea5-c17eb528ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-ee0f22c1-6dc5-4e4d-9ced-f4f43d50ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-bccd71c1-b34f-4b2d-a85b-14fabe95ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-cd91e241-8904-4449-95ee-4da3f45fe183,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-99ae3bc2-bc07-4cb5-9ee4-743f90eb050a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441109047-172.17.0.13-1598669651869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-8646839e-bb9e-476d-a134-9c50518d398f,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-e5463f60-e853-471b-8c1e-fe0f91738d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-aa5bea6b-883c-4255-bea7-147b0de99a07,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-3ed60087-4b8d-453f-9ea5-c17eb528ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-ee0f22c1-6dc5-4e4d-9ced-f4f43d50ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-bccd71c1-b34f-4b2d-a85b-14fabe95ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-cd91e241-8904-4449-95ee-4da3f45fe183,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-99ae3bc2-bc07-4cb5-9ee4-743f90eb050a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648456801-172.17.0.13-1598669790548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-3e788f77-774e-4d19-b5d1-64f9a7acb10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-2a22868e-d12b-4e65-a710-afd0f5fea7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-9fe61c1b-ce95-43dd-96a9-50c44ac697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-c024c4d1-ef69-47ac-b42d-0d97b5d109b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-8924e7e8-a9c5-4bae-ae72-44d9241c5d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-284105ac-0130-459d-9929-af6f473b874f,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-62f32f32-2eff-4795-83c5-7c2ce5c93267,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-fa4a5d87-9e40-452f-8374-712ea561c11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648456801-172.17.0.13-1598669790548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-3e788f77-774e-4d19-b5d1-64f9a7acb10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-2a22868e-d12b-4e65-a710-afd0f5fea7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-9fe61c1b-ce95-43dd-96a9-50c44ac697b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-c024c4d1-ef69-47ac-b42d-0d97b5d109b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-8924e7e8-a9c5-4bae-ae72-44d9241c5d08,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-284105ac-0130-459d-9929-af6f473b874f,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-62f32f32-2eff-4795-83c5-7c2ce5c93267,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-fa4a5d87-9e40-452f-8374-712ea561c11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505797336-172.17.0.13-1598670027062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-2e70ba49-df30-41d4-8cf1-b94909af7796,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-848fdf68-f871-4eb7-928e-b07f8245b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-9ca64cc9-abbe-433e-9805-e3d5396f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-2b9fa0ba-c75d-4cc0-91f0-083e16839838,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-46f1ea2d-339c-447b-8b43-8580a6220ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-a8ee0b12-200b-41b7-8de3-e6ecf8ba42c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-07ccafcf-6bd9-4d35-8388-3220d1f24a92,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-b2067d21-eabe-4a1c-855d-73e259861e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505797336-172.17.0.13-1598670027062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-2e70ba49-df30-41d4-8cf1-b94909af7796,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-848fdf68-f871-4eb7-928e-b07f8245b39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-9ca64cc9-abbe-433e-9805-e3d5396f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-2b9fa0ba-c75d-4cc0-91f0-083e16839838,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-46f1ea2d-339c-447b-8b43-8580a6220ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-a8ee0b12-200b-41b7-8de3-e6ecf8ba42c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-07ccafcf-6bd9-4d35-8388-3220d1f24a92,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-b2067d21-eabe-4a1c-855d-73e259861e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901489503-172.17.0.13-1598670359378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-fc7824de-c759-4d79-b3c6-61b66377a546,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-4983696e-28b9-488b-b5ed-b4790438f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-bfd87a5a-49c4-430d-a39b-57cb64fbe2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-2a6733ec-5e67-44b5-abab-b9c1d863ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1158f66a-cfb1-4036-aed6-f2cf6ef4001b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-5a3765a9-a35e-40c7-ae18-96414c24d237,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-0438bad1-90f4-4117-a09e-e6a1025eaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-d56ec0f1-85c4-42b7-8ce6-6da51e7fa95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901489503-172.17.0.13-1598670359378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-fc7824de-c759-4d79-b3c6-61b66377a546,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-4983696e-28b9-488b-b5ed-b4790438f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-bfd87a5a-49c4-430d-a39b-57cb64fbe2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-2a6733ec-5e67-44b5-abab-b9c1d863ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1158f66a-cfb1-4036-aed6-f2cf6ef4001b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-5a3765a9-a35e-40c7-ae18-96414c24d237,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-0438bad1-90f4-4117-a09e-e6a1025eaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-d56ec0f1-85c4-42b7-8ce6-6da51e7fa95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000577076-172.17.0.13-1598670396668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-3dd22fb9-0832-46ae-a500-e45bfefed8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-60b7cfbd-c68e-4815-8aff-7dd2f9fa4b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-226d64b8-48fe-468c-b32f-ca3cbcf5ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-54d185f0-7139-42ac-a5f7-30ac24282517,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0b984fbd-5b15-43b7-8cf1-0df779134106,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-77e9c9e1-bf32-4ea7-9364-c801cc4f9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-d8344b10-acaf-420b-80f8-2e24686000d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8916ff4f-3c4d-465a-b197-3f4e79afdb56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000577076-172.17.0.13-1598670396668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-3dd22fb9-0832-46ae-a500-e45bfefed8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-60b7cfbd-c68e-4815-8aff-7dd2f9fa4b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-226d64b8-48fe-468c-b32f-ca3cbcf5ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-54d185f0-7139-42ac-a5f7-30ac24282517,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0b984fbd-5b15-43b7-8cf1-0df779134106,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-77e9c9e1-bf32-4ea7-9364-c801cc4f9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-d8344b10-acaf-420b-80f8-2e24686000d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-8916ff4f-3c4d-465a-b197-3f4e79afdb56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458616266-172.17.0.13-1598670426345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-c9902add-7bf0-4c9b-ba8e-ed96fe8a0ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-3182b653-38eb-4388-a3e6-7b591c34a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b8972b1a-145e-4351-b2ac-c6f8c759f3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-54edd085-4bc0-49ca-8465-a147857a968e,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-e9df7c7e-1fc5-4e6c-83f6-c78717a72df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-a04bc416-393f-49ad-b96e-2111ccabf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-c845a9b9-56ff-4a21-bed2-b2ef2ba2c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-c1f82670-3059-4885-b57b-c91ff1b70cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458616266-172.17.0.13-1598670426345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-c9902add-7bf0-4c9b-ba8e-ed96fe8a0ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-3182b653-38eb-4388-a3e6-7b591c34a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b8972b1a-145e-4351-b2ac-c6f8c759f3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-54edd085-4bc0-49ca-8465-a147857a968e,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-e9df7c7e-1fc5-4e6c-83f6-c78717a72df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-a04bc416-393f-49ad-b96e-2111ccabf3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-c845a9b9-56ff-4a21-bed2-b2ef2ba2c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-c1f82670-3059-4885-b57b-c91ff1b70cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541722891-172.17.0.13-1598670459196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-d4fb585d-797f-4229-bb81-428f6b0a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-feb91425-4578-4027-b7cd-5373cc348c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-6413854f-50d5-4949-b952-6d95b2cfc9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-20937a00-db90-40f7-a520-9eb5c939c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-74552401-704a-444d-a707-32e04b4b58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-1829a8b2-8c29-46ba-8658-c8a7c84d8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d20df31e-a034-4430-82f5-ee60a5714a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-064b5f22-44c1-47ae-b2a6-53c9060c1e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541722891-172.17.0.13-1598670459196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-d4fb585d-797f-4229-bb81-428f6b0a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-feb91425-4578-4027-b7cd-5373cc348c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-6413854f-50d5-4949-b952-6d95b2cfc9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-20937a00-db90-40f7-a520-9eb5c939c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-74552401-704a-444d-a707-32e04b4b58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-1829a8b2-8c29-46ba-8658-c8a7c84d8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d20df31e-a034-4430-82f5-ee60a5714a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-064b5f22-44c1-47ae-b2a6-53c9060c1e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170953158-172.17.0.13-1598670841802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-f07dbd84-8c45-4a13-9ee5-6292524b0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-a9243cf2-cfbd-4dbc-a009-e1380a8406b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-1d89bf21-167d-47f4-9800-3834d4379537,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-323a0d2f-b029-4779-8cd6-0476850e5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-143616f4-0615-4a0f-90e9-62bea4c6e015,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-76575348-542a-4966-9b7a-1a730913a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e41e1390-1116-4e1d-8af1-2d820a6939fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-7348000d-75a8-490c-9efc-5928c24ecf03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170953158-172.17.0.13-1598670841802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-f07dbd84-8c45-4a13-9ee5-6292524b0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-a9243cf2-cfbd-4dbc-a009-e1380a8406b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-1d89bf21-167d-47f4-9800-3834d4379537,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-323a0d2f-b029-4779-8cd6-0476850e5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-143616f4-0615-4a0f-90e9-62bea4c6e015,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-76575348-542a-4966-9b7a-1a730913a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e41e1390-1116-4e1d-8af1-2d820a6939fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-7348000d-75a8-490c-9efc-5928c24ecf03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209171064-172.17.0.13-1598671507766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-cef54977-5776-491d-9d14-afa7517e96d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-3eafd46e-7122-4f7d-9280-a207cf599559,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-0fe39a14-95c9-4d39-b4ac-21074bdfc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b6083316-c0b6-4576-9bd9-f397dd36ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-9ae8b4d4-4f17-4248-b2db-2c36b4f5d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-0ff31b66-91fd-4b00-a254-93b7bf6943d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-1f2509e9-edd1-48f2-9d11-816db42b5357,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-afb284d2-b4e2-4b6e-8289-623cd71df4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209171064-172.17.0.13-1598671507766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-cef54977-5776-491d-9d14-afa7517e96d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-3eafd46e-7122-4f7d-9280-a207cf599559,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-0fe39a14-95c9-4d39-b4ac-21074bdfc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b6083316-c0b6-4576-9bd9-f397dd36ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-9ae8b4d4-4f17-4248-b2db-2c36b4f5d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-0ff31b66-91fd-4b00-a254-93b7bf6943d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-1f2509e9-edd1-48f2-9d11-816db42b5357,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-afb284d2-b4e2-4b6e-8289-623cd71df4b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566922490-172.17.0.13-1598671610597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-e744c2bb-2d94-4ae9-bc26-e617f9297a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-07ead5af-7456-48d1-8e30-ea63727eee21,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-34f57c6c-9dd2-402e-a361-a43434d67d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-9c078325-5b25-4ff3-a93b-671165489234,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-51a6b9bc-a410-4141-8ad7-13f4f436a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-2744c2a0-a425-4a9c-9a56-33403c20a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-2fa9cd54-1074-4e10-827d-0613b8b6a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-5830a7cb-809c-4407-a505-e54d234bdb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566922490-172.17.0.13-1598671610597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-e744c2bb-2d94-4ae9-bc26-e617f9297a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-07ead5af-7456-48d1-8e30-ea63727eee21,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-34f57c6c-9dd2-402e-a361-a43434d67d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-9c078325-5b25-4ff3-a93b-671165489234,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-51a6b9bc-a410-4141-8ad7-13f4f436a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-2744c2a0-a425-4a9c-9a56-33403c20a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-2fa9cd54-1074-4e10-827d-0613b8b6a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-5830a7cb-809c-4407-a505-e54d234bdb17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212325087-172.17.0.13-1598671710747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-05f66868-54e9-4e8a-8f60-799ec20dc2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-78d891d7-5d7b-415a-9f12-e0b9f5eaac35,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-6abfad43-f445-4d50-a5c7-1a85ce47f347,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-ed9a4887-bbd1-4e69-b989-b66180c31cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-b9431fbf-d9ae-4970-9cef-59f67075202c,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-317e8679-4ce0-4e18-93b4-6d98089bc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-5297e0f7-c95b-4707-a1f6-2341f3e55fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-c1530fc2-24ce-4b37-877e-42caa1e7b744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212325087-172.17.0.13-1598671710747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-05f66868-54e9-4e8a-8f60-799ec20dc2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-78d891d7-5d7b-415a-9f12-e0b9f5eaac35,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-6abfad43-f445-4d50-a5c7-1a85ce47f347,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-ed9a4887-bbd1-4e69-b989-b66180c31cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-b9431fbf-d9ae-4970-9cef-59f67075202c,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-317e8679-4ce0-4e18-93b4-6d98089bc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-5297e0f7-c95b-4707-a1f6-2341f3e55fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-c1530fc2-24ce-4b37-877e-42caa1e7b744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009978183-172.17.0.13-1598671813170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-2ad18c55-3b68-43b8-ada8-eef4aee256d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-7bb99a52-fad2-467e-be36-0c367624977c,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-136a01ab-4ff0-4f16-96e3-8ed2973ad9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-ff5178b4-ee70-4f93-a50f-5ecf85e7a703,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-f63472e5-5cbd-4099-82dc-2daf9f94b046,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-767b9bcd-3d5f-4a4b-815d-ec2c5623417b,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-01d5e025-d2eb-4b32-ae8b-7fdb50307f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-ade14129-f096-4512-9793-2bb6248c9b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009978183-172.17.0.13-1598671813170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-2ad18c55-3b68-43b8-ada8-eef4aee256d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-7bb99a52-fad2-467e-be36-0c367624977c,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-136a01ab-4ff0-4f16-96e3-8ed2973ad9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-ff5178b4-ee70-4f93-a50f-5ecf85e7a703,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-f63472e5-5cbd-4099-82dc-2daf9f94b046,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-767b9bcd-3d5f-4a4b-815d-ec2c5623417b,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-01d5e025-d2eb-4b32-ae8b-7fdb50307f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-ade14129-f096-4512-9793-2bb6248c9b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218702049-172.17.0.13-1598671879513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-ce31ae1b-6349-469c-8da9-5f53e7812b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-ee6b7851-e21d-4154-8bcf-6d55da5fe09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-b364446f-7f6e-4bb4-ac75-917711ddaee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ad2685a4-8928-45de-991e-846fe61934bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1be83092-c927-4a82-9714-3a30f0f18154,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-e530ad7d-35f1-4828-a7e2-b3096bb70336,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-90c3e9f7-da23-4e8d-b7c4-ae52c4439112,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-efe01969-30cf-4fb6-bbca-a3546fae440d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218702049-172.17.0.13-1598671879513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-ce31ae1b-6349-469c-8da9-5f53e7812b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-ee6b7851-e21d-4154-8bcf-6d55da5fe09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-b364446f-7f6e-4bb4-ac75-917711ddaee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ad2685a4-8928-45de-991e-846fe61934bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1be83092-c927-4a82-9714-3a30f0f18154,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-e530ad7d-35f1-4828-a7e2-b3096bb70336,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-90c3e9f7-da23-4e8d-b7c4-ae52c4439112,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-efe01969-30cf-4fb6-bbca-a3546fae440d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875627108-172.17.0.13-1598672645198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45602,DS-984df0f9-a37d-4b71-a544-ac2c22468913,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-014c5740-ebda-4309-8564-2e21371132c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-1c3458bf-0625-408a-8804-1e8eca14b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-5bd3cc8e-1f7f-4c63-b4c8-97ffbc75a521,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-bebd8d47-15a8-42c7-a7bb-f0e24f729ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-138361ce-fa64-40e1-a3a6-f535d0d753f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c8c4b45f-48c7-4b9b-8e49-2b524b1000d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-9b65c474-8e10-4089-a3aa-205c50cf0fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875627108-172.17.0.13-1598672645198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45602,DS-984df0f9-a37d-4b71-a544-ac2c22468913,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-014c5740-ebda-4309-8564-2e21371132c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-1c3458bf-0625-408a-8804-1e8eca14b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-5bd3cc8e-1f7f-4c63-b4c8-97ffbc75a521,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-bebd8d47-15a8-42c7-a7bb-f0e24f729ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-138361ce-fa64-40e1-a3a6-f535d0d753f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c8c4b45f-48c7-4b9b-8e49-2b524b1000d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-9b65c474-8e10-4089-a3aa-205c50cf0fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024264591-172.17.0.13-1598672781222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-96338f52-9f5c-4dd0-9cdd-163a93129d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-342d249c-1dfe-44a6-ad50-be71cc33a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-af264000-2afb-40a5-ab69-5d08dd6db494,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-ee142197-4fb9-4b8a-b47d-b8707ed37173,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c5783be1-9817-4674-b0d0-a5e8e08f6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-e0d516dd-6ddf-4fcb-9861-5750517aafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-4f350d26-e300-448b-ab47-a459a8e361c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-9bd475c8-a904-42ad-bac3-5fabe93481dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024264591-172.17.0.13-1598672781222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46677,DS-96338f52-9f5c-4dd0-9cdd-163a93129d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-342d249c-1dfe-44a6-ad50-be71cc33a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-af264000-2afb-40a5-ab69-5d08dd6db494,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-ee142197-4fb9-4b8a-b47d-b8707ed37173,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-c5783be1-9817-4674-b0d0-a5e8e08f6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-e0d516dd-6ddf-4fcb-9861-5750517aafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-4f350d26-e300-448b-ab47-a459a8e361c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-9bd475c8-a904-42ad-bac3-5fabe93481dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791721030-172.17.0.13-1598673415264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-f18bbc1b-f47b-43d5-8bb3-93229782756c,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-036f8d15-f20b-48e7-b1e7-7062da77f373,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-691e0fa3-1ce1-44c8-bbe4-f0bef8eef603,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-6cc28d23-27b2-4236-ba1c-e78955183d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-b0cb07e7-e099-4898-ba57-d003f9807efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-1b72c011-3eb8-461b-a5ca-40b3b1c41eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-45991160-bd17-4f1f-b2ed-ffe86ccd2a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-56ac855d-ad4b-415a-9fec-080a5d165c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791721030-172.17.0.13-1598673415264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-f18bbc1b-f47b-43d5-8bb3-93229782756c,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-036f8d15-f20b-48e7-b1e7-7062da77f373,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-691e0fa3-1ce1-44c8-bbe4-f0bef8eef603,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-6cc28d23-27b2-4236-ba1c-e78955183d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-b0cb07e7-e099-4898-ba57-d003f9807efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-1b72c011-3eb8-461b-a5ca-40b3b1c41eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-45991160-bd17-4f1f-b2ed-ffe86ccd2a98,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-56ac855d-ad4b-415a-9fec-080a5d165c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874832961-172.17.0.13-1598673482177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-886283fe-f6f4-48f7-b603-9e6ab3df908e,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-b8ae5f08-4c4a-4c8f-8581-7a9d3f66df64,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-382a6d49-0acd-4e2a-9cf9-5e95ae30317b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1497ce5b-33b7-45d3-b29f-d341b6a757e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-99fcd156-1854-4503-9c2f-693edbe6af89,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-d0d87af0-8594-45c2-b74c-640650c476ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-15bab333-76db-4d20-af62-43acc4bb425f,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b0c165d3-070b-43b1-bd7c-de2bff88a293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874832961-172.17.0.13-1598673482177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-886283fe-f6f4-48f7-b603-9e6ab3df908e,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-b8ae5f08-4c4a-4c8f-8581-7a9d3f66df64,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-382a6d49-0acd-4e2a-9cf9-5e95ae30317b,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1497ce5b-33b7-45d3-b29f-d341b6a757e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-99fcd156-1854-4503-9c2f-693edbe6af89,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-d0d87af0-8594-45c2-b74c-640650c476ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-15bab333-76db-4d20-af62-43acc4bb425f,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-b0c165d3-070b-43b1-bd7c-de2bff88a293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761608477-172.17.0.13-1598673614846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-73244401-dce1-4157-b9fa-bd520c2be43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9ee08eb4-a82d-4a68-8d72-3b307727f900,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-a407d89e-0058-4a5e-adea-58dac9763bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-d41f0e75-753f-4611-9a2b-7cac71e2611d,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d6067984-d4b3-469d-bbbd-3638902c388a,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-890c500b-68d6-42e1-b371-bcc1df48d392,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-8af38cf5-b655-4a4b-aec1-cfdbf6e15e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4b44168c-2c28-4898-b03b-1b51e298bea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761608477-172.17.0.13-1598673614846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-73244401-dce1-4157-b9fa-bd520c2be43d,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9ee08eb4-a82d-4a68-8d72-3b307727f900,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-a407d89e-0058-4a5e-adea-58dac9763bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-d41f0e75-753f-4611-9a2b-7cac71e2611d,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-d6067984-d4b3-469d-bbbd-3638902c388a,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-890c500b-68d6-42e1-b371-bcc1df48d392,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-8af38cf5-b655-4a4b-aec1-cfdbf6e15e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4b44168c-2c28-4898-b03b-1b51e298bea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422105370-172.17.0.13-1598674029807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37829,DS-65876a43-1047-4413-b38a-bab8be0ca69f,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-1667302f-6f90-49b7-af71-1afb3c5445c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a608d14f-a665-4d1c-a5d6-b821320f89de,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-d1a804bf-c3a4-4cd7-b6a5-fac3c6ee998d,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cec6def3-1acd-46cc-8424-e3045bdf4adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-f79ab610-de9d-4390-a17e-51e8050dc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f5b0c628-fd24-4fba-ba9d-c98181fe2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-32f623a9-8e03-46e5-9f5b-490e37f4e98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422105370-172.17.0.13-1598674029807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37829,DS-65876a43-1047-4413-b38a-bab8be0ca69f,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-1667302f-6f90-49b7-af71-1afb3c5445c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a608d14f-a665-4d1c-a5d6-b821320f89de,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-d1a804bf-c3a4-4cd7-b6a5-fac3c6ee998d,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-cec6def3-1acd-46cc-8424-e3045bdf4adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-f79ab610-de9d-4390-a17e-51e8050dc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f5b0c628-fd24-4fba-ba9d-c98181fe2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-32f623a9-8e03-46e5-9f5b-490e37f4e98c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39528561-172.17.0.13-1598674426516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-7c43b0b7-cd3a-4de2-9302-dbef653ae229,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-38619607-284e-4994-8327-8a53c10ef754,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-6944a1c0-cee2-414d-ba55-66a9a02c1afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-957a3d1b-d8cb-48e2-93a9-75f2c10e359b,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0c5fdef7-ade8-4d9a-94ac-4655be856949,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-24ba9649-e62e-4673-b0f1-4aa494a9baac,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-fca2b78d-e48a-4064-87d5-512aa9d78cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-52f6c626-8ccd-4e9a-bffd-957b105f1610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39528561-172.17.0.13-1598674426516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45651,DS-7c43b0b7-cd3a-4de2-9302-dbef653ae229,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-38619607-284e-4994-8327-8a53c10ef754,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-6944a1c0-cee2-414d-ba55-66a9a02c1afb,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-957a3d1b-d8cb-48e2-93a9-75f2c10e359b,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0c5fdef7-ade8-4d9a-94ac-4655be856949,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-24ba9649-e62e-4673-b0f1-4aa494a9baac,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-fca2b78d-e48a-4064-87d5-512aa9d78cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-52f6c626-8ccd-4e9a-bffd-957b105f1610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503421491-172.17.0.13-1598674524954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-cd6a15b3-e0b1-43ec-bb94-ebcf1531b462,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f258c14c-9091-43e1-8443-6a6b5dff1972,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a20a7053-c7ad-47e5-8e4a-e5988e2cae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-113ce87f-5e50-4140-9753-8305b5c30051,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-176346df-089d-42fd-97b0-90b4108ace37,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-dda24f62-ca65-4a6f-b47c-801cb2ba02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-7ba0639e-a3ee-4c55-bf38-1cb845d76dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-eb37b0f0-89bd-4f05-b9d9-ced4c85c32f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503421491-172.17.0.13-1598674524954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-cd6a15b3-e0b1-43ec-bb94-ebcf1531b462,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-f258c14c-9091-43e1-8443-6a6b5dff1972,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a20a7053-c7ad-47e5-8e4a-e5988e2cae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-113ce87f-5e50-4140-9753-8305b5c30051,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-176346df-089d-42fd-97b0-90b4108ace37,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-dda24f62-ca65-4a6f-b47c-801cb2ba02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-7ba0639e-a3ee-4c55-bf38-1cb845d76dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-eb37b0f0-89bd-4f05-b9d9-ced4c85c32f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5043
