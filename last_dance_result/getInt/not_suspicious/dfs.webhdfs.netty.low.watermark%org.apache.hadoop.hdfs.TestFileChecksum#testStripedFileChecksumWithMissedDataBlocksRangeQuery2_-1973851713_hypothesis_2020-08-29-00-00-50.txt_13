reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814728676-172.17.0.16-1598660469538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44036,DS-37125f58-6632-408e-92c7-1a96b79985b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-4385a39d-651b-47f9-8c8e-5c7802e7ae25,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b790f6cb-4677-4dea-ab4c-288352bfb30f,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-b886914b-11bd-4003-a7c4-3bfc8601c886,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-e1b88471-ebb0-4154-b84a-edf380f4eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-cd8dcef7-59fa-49ae-b535-8bb59705a153,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5d8e8626-e13e-4340-92e6-b67b40243480,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7db32024-0683-48a8-862f-511cee9480ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814728676-172.17.0.16-1598660469538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44036,DS-37125f58-6632-408e-92c7-1a96b79985b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-4385a39d-651b-47f9-8c8e-5c7802e7ae25,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b790f6cb-4677-4dea-ab4c-288352bfb30f,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-b886914b-11bd-4003-a7c4-3bfc8601c886,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-e1b88471-ebb0-4154-b84a-edf380f4eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-cd8dcef7-59fa-49ae-b535-8bb59705a153,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-5d8e8626-e13e-4340-92e6-b67b40243480,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-7db32024-0683-48a8-862f-511cee9480ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809520967-172.17.0.16-1598660875579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-b1696cb6-33aa-45c8-94d2-15b29d997840,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-0bd1b3f6-dd86-4826-91b1-ffae3b799fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-2c103a01-7290-43fc-a867-74a5847543e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-edb704f7-6370-4e6f-8300-288f309cd35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-b0d88f89-3198-488b-bfef-f3bdd6190a14,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ebe5b663-313e-469e-85db-cb3f055500f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-0656fd27-db4e-4b4c-8eb4-469016de3679,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-02381c0c-b07f-4d89-8af7-5e0e6720d518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809520967-172.17.0.16-1598660875579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-b1696cb6-33aa-45c8-94d2-15b29d997840,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-0bd1b3f6-dd86-4826-91b1-ffae3b799fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-2c103a01-7290-43fc-a867-74a5847543e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-edb704f7-6370-4e6f-8300-288f309cd35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-b0d88f89-3198-488b-bfef-f3bdd6190a14,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ebe5b663-313e-469e-85db-cb3f055500f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-0656fd27-db4e-4b4c-8eb4-469016de3679,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-02381c0c-b07f-4d89-8af7-5e0e6720d518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462338591-172.17.0.16-1598661031084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-d5d7b9b6-c7b1-49fd-b50e-b510f6b845f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-f3bc03aa-7e04-45ac-91b9-3743d5604788,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-4fc7451d-a525-4c37-b097-0f1e05617c40,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-cf5509b5-9314-4cc2-9c37-615d50fdabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8a2fe93e-cea2-4063-8e4e-f501370bc176,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-e6f69b5f-6d36-4bd0-9dd1-3ea494450e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-572eab40-3a0a-4c67-9238-62182799e619,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-7d004fd2-a156-41ed-a081-8792e7b064d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462338591-172.17.0.16-1598661031084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-d5d7b9b6-c7b1-49fd-b50e-b510f6b845f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-f3bc03aa-7e04-45ac-91b9-3743d5604788,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-4fc7451d-a525-4c37-b097-0f1e05617c40,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-cf5509b5-9314-4cc2-9c37-615d50fdabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8a2fe93e-cea2-4063-8e4e-f501370bc176,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-e6f69b5f-6d36-4bd0-9dd1-3ea494450e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-572eab40-3a0a-4c67-9238-62182799e619,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-7d004fd2-a156-41ed-a081-8792e7b064d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570685126-172.17.0.16-1598661141740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-446b0e35-9058-4f14-a9a6-293fad6b9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-f6656728-929a-41eb-8873-b95ad125e787,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-706c3622-842c-4aaa-9ae1-6f040139f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-cb56cf89-630f-4a1a-91d9-e142cb16da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-15fc100e-c685-43f9-bf34-f4a5960e0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-6828c9d4-9348-49ac-9ca1-0b872da7432e,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-3ee596b4-2464-4eca-b90c-594ec04f9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-199f836d-340d-45de-8df7-6c9265ae152e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570685126-172.17.0.16-1598661141740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-446b0e35-9058-4f14-a9a6-293fad6b9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-f6656728-929a-41eb-8873-b95ad125e787,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-706c3622-842c-4aaa-9ae1-6f040139f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-cb56cf89-630f-4a1a-91d9-e142cb16da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-15fc100e-c685-43f9-bf34-f4a5960e0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-6828c9d4-9348-49ac-9ca1-0b872da7432e,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-3ee596b4-2464-4eca-b90c-594ec04f9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-199f836d-340d-45de-8df7-6c9265ae152e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175648910-172.17.0.16-1598661452050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34419,DS-56b0d719-ca72-45dd-a73d-dce26e966978,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ff53179c-95f3-452d-88a0-8cb056fedc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-de0e5088-d5a3-4cea-b4af-5f43ece981e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-23b1e511-06f6-4f3f-9ec6-4027f6942a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-cbfec73e-51d6-479a-9681-738babd2b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-be56940e-7e2b-482b-9acd-73f2830b44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-d30d0247-4b83-40bf-882b-42c60eb745bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-a4374eb5-1e1d-4105-b118-ce6dc88a58b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175648910-172.17.0.16-1598661452050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34419,DS-56b0d719-ca72-45dd-a73d-dce26e966978,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ff53179c-95f3-452d-88a0-8cb056fedc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-de0e5088-d5a3-4cea-b4af-5f43ece981e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-23b1e511-06f6-4f3f-9ec6-4027f6942a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-cbfec73e-51d6-479a-9681-738babd2b4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-be56940e-7e2b-482b-9acd-73f2830b44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-d30d0247-4b83-40bf-882b-42c60eb745bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-a4374eb5-1e1d-4105-b118-ce6dc88a58b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315462806-172.17.0.16-1598661494902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-00c4fcd3-f4e5-46cf-b211-c6abd6f83b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-26052836-8a86-47d2-8a91-87adaf5b90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-e92743ad-af2f-4a30-9ad8-50c2b101d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-43dbedfa-f10b-457b-baf6-fe2dbf51e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1cb99692-dffa-47f7-9cbe-f9336f5f4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-62ae280b-6aaf-45f0-ac7a-78dcf881291f,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-e33d3cce-4016-4547-ab5e-90290ed74cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-b824a8e3-fb5d-4d38-ae9e-de24493bc574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315462806-172.17.0.16-1598661494902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-00c4fcd3-f4e5-46cf-b211-c6abd6f83b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-26052836-8a86-47d2-8a91-87adaf5b90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-e92743ad-af2f-4a30-9ad8-50c2b101d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-43dbedfa-f10b-457b-baf6-fe2dbf51e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-1cb99692-dffa-47f7-9cbe-f9336f5f4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-62ae280b-6aaf-45f0-ac7a-78dcf881291f,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-e33d3cce-4016-4547-ab5e-90290ed74cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-b824a8e3-fb5d-4d38-ae9e-de24493bc574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814768223-172.17.0.16-1598661648360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-a3b0424e-eb7a-4d5c-94d6-6a9993f2aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-e77580ea-d604-43a9-9e28-43d2f221311f,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-413d66d2-92b7-47c6-9150-ca01c3468187,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-5b6af773-5d2e-412c-a285-21daf2d28bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-253411da-2426-40b8-8c0e-4a116c41a968,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-2edb1095-3e2c-4659-9697-244a55251f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-83b992f8-05ee-4eb7-9962-61bc05a4ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-c01f8620-2524-46e0-8cc2-7572f7845dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814768223-172.17.0.16-1598661648360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-a3b0424e-eb7a-4d5c-94d6-6a9993f2aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-e77580ea-d604-43a9-9e28-43d2f221311f,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-413d66d2-92b7-47c6-9150-ca01c3468187,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-5b6af773-5d2e-412c-a285-21daf2d28bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-253411da-2426-40b8-8c0e-4a116c41a968,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-2edb1095-3e2c-4659-9697-244a55251f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-83b992f8-05ee-4eb7-9962-61bc05a4ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-c01f8620-2524-46e0-8cc2-7572f7845dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772296158-172.17.0.16-1598661818197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-de2048a6-2cf2-4eda-a13c-ad6e4934bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-db917412-dcad-44ee-9685-ec7c20fd940e,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9c70627c-50ff-4fc9-8fe6-5a1feac49ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-391c3edb-3d78-4d5c-ada9-2393411e6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-ece76a84-9556-4b0c-932a-72ac6d6ae179,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-9c7ab11f-d370-436a-bcc6-52481e9196c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-668fe6fe-c7ce-4566-9a62-ea8d53ad0abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d4a90620-ff56-4ff5-bcf3-9d26052405a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772296158-172.17.0.16-1598661818197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-de2048a6-2cf2-4eda-a13c-ad6e4934bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-db917412-dcad-44ee-9685-ec7c20fd940e,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-9c70627c-50ff-4fc9-8fe6-5a1feac49ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-391c3edb-3d78-4d5c-ada9-2393411e6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-ece76a84-9556-4b0c-932a-72ac6d6ae179,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-9c7ab11f-d370-436a-bcc6-52481e9196c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-668fe6fe-c7ce-4566-9a62-ea8d53ad0abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d4a90620-ff56-4ff5-bcf3-9d26052405a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843652477-172.17.0.16-1598661896143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35031,DS-6140bf9e-5c67-473e-8d20-9fb2a37a2a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8fd1db35-9639-4f9f-a669-cb6b2674d376,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-88d5ebf0-401c-4a30-8328-9e1de9758018,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d07dc920-c1c7-4e22-9afc-54f282a49461,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-3ba051ae-005d-434c-ae91-3e7c66e04e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-e87cbefd-08cb-48c9-a5dc-3f7eab385a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-013c5fad-2c98-40f5-8d6d-3a33630fb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-8a3ed893-1296-49c1-8f54-c17a51236409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843652477-172.17.0.16-1598661896143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35031,DS-6140bf9e-5c67-473e-8d20-9fb2a37a2a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8fd1db35-9639-4f9f-a669-cb6b2674d376,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-88d5ebf0-401c-4a30-8328-9e1de9758018,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d07dc920-c1c7-4e22-9afc-54f282a49461,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-3ba051ae-005d-434c-ae91-3e7c66e04e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-e87cbefd-08cb-48c9-a5dc-3f7eab385a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-013c5fad-2c98-40f5-8d6d-3a33630fb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-8a3ed893-1296-49c1-8f54-c17a51236409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195515852-172.17.0.16-1598663059053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-7e073d96-5270-45cd-993c-6fdcefdf915d,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-350d41bc-6268-4e97-82b1-392c1470c916,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-5e55a2bd-4735-42d9-a18b-cd54388784f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-fbba8532-d567-4170-958f-6e709aa97be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-473d190d-af63-4b25-a86b-203078f0de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-5d5f9d8f-094f-4bbe-893e-251e0080717d,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-13a44692-4882-43e5-a585-92a490dd583f,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-e5b84762-1119-4f55-a083-e4d68b71632d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195515852-172.17.0.16-1598663059053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-7e073d96-5270-45cd-993c-6fdcefdf915d,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-350d41bc-6268-4e97-82b1-392c1470c916,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-5e55a2bd-4735-42d9-a18b-cd54388784f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-fbba8532-d567-4170-958f-6e709aa97be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-473d190d-af63-4b25-a86b-203078f0de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-5d5f9d8f-094f-4bbe-893e-251e0080717d,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-13a44692-4882-43e5-a585-92a490dd583f,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-e5b84762-1119-4f55-a083-e4d68b71632d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601614230-172.17.0.16-1598663215903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-edc3b319-0131-4d80-ab9b-48b5f2b80a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-14fca189-65f2-4d49-9fd6-91b5c596f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-78ee809d-5f31-488d-8f10-62f47fc41bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-5488b146-3e02-42e6-af3d-5517ec80305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-5bbafafc-4ce9-4503-ae8c-03db3dfc6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-537ca00b-b712-4f08-8891-822e481ca7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-fda74a2e-f463-40b1-8161-c2ff9eecaeec,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-906556ee-d262-44f0-8303-da6546c44fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601614230-172.17.0.16-1598663215903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-edc3b319-0131-4d80-ab9b-48b5f2b80a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-14fca189-65f2-4d49-9fd6-91b5c596f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-78ee809d-5f31-488d-8f10-62f47fc41bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-5488b146-3e02-42e6-af3d-5517ec80305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-5bbafafc-4ce9-4503-ae8c-03db3dfc6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-537ca00b-b712-4f08-8891-822e481ca7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-fda74a2e-f463-40b1-8161-c2ff9eecaeec,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-906556ee-d262-44f0-8303-da6546c44fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108638451-172.17.0.16-1598664179213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-34960fad-c652-4dad-ba8c-8481d07babf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-bf76989d-15c3-497c-901d-ced56642d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-b7a32f92-6665-4155-b472-66a9d0241d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-5239b725-7941-4cef-95b7-a4e180761cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-7a0e11c8-2b8b-4c60-a872-42569f5463d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-0f205538-2547-413c-85d9-1df54c762fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-599dcf31-327d-4d98-8ecc-d6f10e5083d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-04b563b1-6432-4780-8612-c59746d4b6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108638451-172.17.0.16-1598664179213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-34960fad-c652-4dad-ba8c-8481d07babf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-bf76989d-15c3-497c-901d-ced56642d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-b7a32f92-6665-4155-b472-66a9d0241d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-5239b725-7941-4cef-95b7-a4e180761cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-7a0e11c8-2b8b-4c60-a872-42569f5463d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-0f205538-2547-413c-85d9-1df54c762fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-599dcf31-327d-4d98-8ecc-d6f10e5083d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-04b563b1-6432-4780-8612-c59746d4b6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236377104-172.17.0.16-1598664254741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-b4685616-651d-4657-b710-d0bb909be45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-3ea52347-a948-471c-a2c4-d32684dc1314,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-a0b31f38-7bba-4a71-8c6e-452f67f2c54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-50914513-e2b6-4825-9ad9-404650b16e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-fc6ed1f7-a25a-4a03-9d30-67d8513e0535,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-3076e588-047f-4926-8977-b06d4eca8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-e6e95fca-45c6-41f6-8b7e-a0337856820a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-7bfe3723-b9ca-4aef-90fa-71714334ac86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236377104-172.17.0.16-1598664254741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-b4685616-651d-4657-b710-d0bb909be45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-3ea52347-a948-471c-a2c4-d32684dc1314,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-a0b31f38-7bba-4a71-8c6e-452f67f2c54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-50914513-e2b6-4825-9ad9-404650b16e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-fc6ed1f7-a25a-4a03-9d30-67d8513e0535,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-3076e588-047f-4926-8977-b06d4eca8ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-e6e95fca-45c6-41f6-8b7e-a0337856820a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-7bfe3723-b9ca-4aef-90fa-71714334ac86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400359041-172.17.0.16-1598664338735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-a4dfa461-a045-4a50-8eb5-006dccbbbd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-8ba99c4c-1d8b-4112-93c9-26c39f02d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-f666de52-bb16-41da-bced-ccba3536ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-95698159-48a9-48ba-ba08-7582e7617b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-f0470698-5750-4f09-87b3-2d5148728e39,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-1ba3245e-9025-443b-a57d-92f238150fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-7fcddc5b-8724-4f3d-9d4a-c8959d47acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-98e4edf0-4d8a-47ee-9788-60142f2226a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400359041-172.17.0.16-1598664338735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-a4dfa461-a045-4a50-8eb5-006dccbbbd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-8ba99c4c-1d8b-4112-93c9-26c39f02d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-f666de52-bb16-41da-bced-ccba3536ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-95698159-48a9-48ba-ba08-7582e7617b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-f0470698-5750-4f09-87b3-2d5148728e39,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-1ba3245e-9025-443b-a57d-92f238150fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-7fcddc5b-8724-4f3d-9d4a-c8959d47acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-98e4edf0-4d8a-47ee-9788-60142f2226a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5741
