reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099789881-172.17.0.4-1598503786135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-b669c525-6e89-4a24-855b-49cee71ff8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-476d174b-d9e1-4af1-b809-f1e241fc41f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1a24b91a-d28c-44c7-b3d6-3189aaebcc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2d2402ce-6a1d-4c47-a254-2c681c12595d,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-897c03fd-5400-4dcc-8ca3-fa8dd45506dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-e41bdd6c-1ca7-4f18-9fc7-c7dcb000c877,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-f97cd4bb-38bb-491b-95b8-824bc1be3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-7e1c7da3-b9a9-4c2c-b0eb-ccbc6b39024e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099789881-172.17.0.4-1598503786135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-b669c525-6e89-4a24-855b-49cee71ff8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-476d174b-d9e1-4af1-b809-f1e241fc41f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-1a24b91a-d28c-44c7-b3d6-3189aaebcc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2d2402ce-6a1d-4c47-a254-2c681c12595d,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-897c03fd-5400-4dcc-8ca3-fa8dd45506dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-e41bdd6c-1ca7-4f18-9fc7-c7dcb000c877,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-f97cd4bb-38bb-491b-95b8-824bc1be3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-7e1c7da3-b9a9-4c2c-b0eb-ccbc6b39024e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051867425-172.17.0.4-1598504135219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-fe5996b2-1ec8-4e33-bab3-aa1a07224f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-3b8f4b72-fdde-48d0-91ca-bebfe9012a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-e48f7cf8-1210-45ba-81b6-cd230b528598,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-15c51560-3741-4955-baeb-3ad1f7cc1434,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-678c9829-0fea-4fc0-b978-6c2256501077,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-32b396a9-076c-416a-9a97-39d735b572d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3976ec9c-613b-4a1d-9294-bf5da33c6b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-610db4cf-d4e2-47c7-911d-597e745b3f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051867425-172.17.0.4-1598504135219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-fe5996b2-1ec8-4e33-bab3-aa1a07224f72,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-3b8f4b72-fdde-48d0-91ca-bebfe9012a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-e48f7cf8-1210-45ba-81b6-cd230b528598,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-15c51560-3741-4955-baeb-3ad1f7cc1434,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-678c9829-0fea-4fc0-b978-6c2256501077,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-32b396a9-076c-416a-9a97-39d735b572d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-3976ec9c-613b-4a1d-9294-bf5da33c6b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-610db4cf-d4e2-47c7-911d-597e745b3f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009609419-172.17.0.4-1598504364124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-2672fbd2-7859-4e06-9144-8bc71f97b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-51b37420-ff42-47ef-9caf-dce74aee5d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-f2c3effe-a298-41ab-a8fc-2d44d13fc252,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-d85a7335-9600-46ca-8291-9514676890af,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-d08b9f0e-a6ad-471a-a245-cd9a16911a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-f42bd9b6-7d88-4a8a-8ce5-5632256b3ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b58cfc77-cf4c-4416-93fe-cea1778cf706,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-eabac971-f1ba-407a-b9d4-0a21586c9029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009609419-172.17.0.4-1598504364124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-2672fbd2-7859-4e06-9144-8bc71f97b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-51b37420-ff42-47ef-9caf-dce74aee5d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-f2c3effe-a298-41ab-a8fc-2d44d13fc252,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-d85a7335-9600-46ca-8291-9514676890af,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-d08b9f0e-a6ad-471a-a245-cd9a16911a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-f42bd9b6-7d88-4a8a-8ce5-5632256b3ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-b58cfc77-cf4c-4416-93fe-cea1778cf706,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-eabac971-f1ba-407a-b9d4-0a21586c9029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9182453-172.17.0.4-1598504511063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-f9cd108c-3b35-43c8-a5e0-9110aa7d926b,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-c9b244eb-8c6f-4f43-8266-bde34430b731,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-961ec516-1467-4346-ab3e-8070e543523b,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-7838ccc9-cd9b-41f1-8031-97d76aabc970,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-10e52255-6fd0-4edb-a11e-f26cf359c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-b3cc0799-1198-464d-b159-16fe68881a67,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-96086312-8ec6-4d7f-bf31-a2da9e8fb966,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1e160149-d545-473f-b08f-7fba7ec24084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9182453-172.17.0.4-1598504511063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-f9cd108c-3b35-43c8-a5e0-9110aa7d926b,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-c9b244eb-8c6f-4f43-8266-bde34430b731,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-961ec516-1467-4346-ab3e-8070e543523b,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-7838ccc9-cd9b-41f1-8031-97d76aabc970,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-10e52255-6fd0-4edb-a11e-f26cf359c30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-b3cc0799-1198-464d-b159-16fe68881a67,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-96086312-8ec6-4d7f-bf31-a2da9e8fb966,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1e160149-d545-473f-b08f-7fba7ec24084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345634227-172.17.0.4-1598504585834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-36bdadfe-d48d-4e3e-b5e8-e7ea8f817756,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ac45fcfa-de83-4b8a-9cf7-1b6635154a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-9c4efbb5-3131-4443-9883-2eb63693d385,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-78a8ff05-dd9d-4a3d-9d42-aa43bbebd720,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-d502ee1e-e9f9-4451-9f8e-c923cd7fe007,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-53438ef2-58da-4815-a3e7-cde23e078092,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-5c325f93-460f-4a88-bab3-40f93fa9528c,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-36995674-537d-4c79-a5ef-b89720cbddde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345634227-172.17.0.4-1598504585834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-36bdadfe-d48d-4e3e-b5e8-e7ea8f817756,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-ac45fcfa-de83-4b8a-9cf7-1b6635154a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-9c4efbb5-3131-4443-9883-2eb63693d385,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-78a8ff05-dd9d-4a3d-9d42-aa43bbebd720,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-d502ee1e-e9f9-4451-9f8e-c923cd7fe007,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-53438ef2-58da-4815-a3e7-cde23e078092,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-5c325f93-460f-4a88-bab3-40f93fa9528c,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-36995674-537d-4c79-a5ef-b89720cbddde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914700934-172.17.0.4-1598505433613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-2a442d38-82e9-4e70-ab58-81a1eab2c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-f475effd-d94a-4b08-8786-519409ca3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-c982ec8c-face-4fe3-9935-aa99d18c4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-c8535032-1d0b-4c3d-ad90-91b88587cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-238ca8d4-b504-4a18-8382-3dc892a63caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-9d997c21-5e00-441f-9a55-a375b4684983,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-474d1dd4-fc7f-4155-9521-48f90826a037,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-183774f0-56ae-4e8b-ae29-f1fef98bcc70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914700934-172.17.0.4-1598505433613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-2a442d38-82e9-4e70-ab58-81a1eab2c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-f475effd-d94a-4b08-8786-519409ca3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-c982ec8c-face-4fe3-9935-aa99d18c4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-c8535032-1d0b-4c3d-ad90-91b88587cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-238ca8d4-b504-4a18-8382-3dc892a63caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-9d997c21-5e00-441f-9a55-a375b4684983,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-474d1dd4-fc7f-4155-9521-48f90826a037,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-183774f0-56ae-4e8b-ae29-f1fef98bcc70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255613463-172.17.0.4-1598505586794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-801e388b-72c6-4b41-9e42-7325b3b09363,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-e2bb8467-6862-42f2-8d69-3ce8dfdb1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-c5105fb4-ec82-42a9-83eb-da0e46d3cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-bfc0db78-0444-4fb1-be47-2b10e83558b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-dee743c3-bb1e-471f-8cc3-6b0534b1c875,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-557b34af-62e0-4f83-8784-dcaff14364f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-6c0af611-161f-4522-8acb-3581eb6d9e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-38cba99b-40fe-4e82-9163-7e9eee84cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255613463-172.17.0.4-1598505586794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39218,DS-801e388b-72c6-4b41-9e42-7325b3b09363,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-e2bb8467-6862-42f2-8d69-3ce8dfdb1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-c5105fb4-ec82-42a9-83eb-da0e46d3cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-bfc0db78-0444-4fb1-be47-2b10e83558b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-dee743c3-bb1e-471f-8cc3-6b0534b1c875,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-557b34af-62e0-4f83-8784-dcaff14364f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-6c0af611-161f-4522-8acb-3581eb6d9e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-38cba99b-40fe-4e82-9163-7e9eee84cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883352116-172.17.0.4-1598505858774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-164d65c7-8ba4-4591-b56c-bac853877241,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-20b82bee-546d-4801-92ac-1ed3aef86ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-bf81138d-840f-42dd-8288-96fea187bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-6d6389c3-611b-4e05-b217-4a3d6bba169e,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-0ef85e3e-61c4-44a6-93c9-5ef2435cd9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-3d514e82-e888-483f-af18-316cdbac1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-948b696b-6d98-4021-b236-86e1ca7583f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-a89106cb-c91f-4e43-8fd5-5488510a80f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883352116-172.17.0.4-1598505858774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-164d65c7-8ba4-4591-b56c-bac853877241,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-20b82bee-546d-4801-92ac-1ed3aef86ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-bf81138d-840f-42dd-8288-96fea187bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-6d6389c3-611b-4e05-b217-4a3d6bba169e,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-0ef85e3e-61c4-44a6-93c9-5ef2435cd9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-3d514e82-e888-483f-af18-316cdbac1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-948b696b-6d98-4021-b236-86e1ca7583f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-a89106cb-c91f-4e43-8fd5-5488510a80f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400363987-172.17.0.4-1598506100036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-22a08d1b-d78c-4bc6-b5db-b87ad7ee249a,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-e8c78f67-2db0-44c5-9836-86e9138b1a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ad95708a-966b-4bde-b7c5-d8c43bbf3d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-d5438db7-f247-4d8a-b66a-801096b39750,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-f835016f-5713-4281-8231-308a8fda7995,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-8971f66c-80c4-41ea-9562-58a77fe3dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-403d9ce1-615e-4331-a58a-b53d23373b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-91eb8ca4-120c-44a1-be21-394ed3f5b35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400363987-172.17.0.4-1598506100036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-22a08d1b-d78c-4bc6-b5db-b87ad7ee249a,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-e8c78f67-2db0-44c5-9836-86e9138b1a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-ad95708a-966b-4bde-b7c5-d8c43bbf3d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-d5438db7-f247-4d8a-b66a-801096b39750,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-f835016f-5713-4281-8231-308a8fda7995,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-8971f66c-80c4-41ea-9562-58a77fe3dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-403d9ce1-615e-4331-a58a-b53d23373b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-91eb8ca4-120c-44a1-be21-394ed3f5b35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757832041-172.17.0.4-1598506621753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33486,DS-9c361a6d-2ef9-4432-bae8-32530fc6fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-a585cc56-6c33-451f-8c29-d20d79f7a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-747195d6-4cfe-4e46-9996-71fd51e373de,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-6339da25-eadf-4942-88d1-16701da9c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c4566401-2177-42e2-8c22-a24d143853c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-594d481a-0e04-47e5-89ff-3bce11073b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-13d6c8b4-d195-4b0f-874c-1bf1641f076a,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-92c33358-c7fb-4ec7-9ed7-8386161ce51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757832041-172.17.0.4-1598506621753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33486,DS-9c361a6d-2ef9-4432-bae8-32530fc6fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-a585cc56-6c33-451f-8c29-d20d79f7a1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-747195d6-4cfe-4e46-9996-71fd51e373de,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-6339da25-eadf-4942-88d1-16701da9c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c4566401-2177-42e2-8c22-a24d143853c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-594d481a-0e04-47e5-89ff-3bce11073b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-13d6c8b4-d195-4b0f-874c-1bf1641f076a,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-92c33358-c7fb-4ec7-9ed7-8386161ce51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635699863-172.17.0.4-1598507024259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-397ab6b9-7566-4d67-86d7-514c398f9450,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-ec4cc37c-f408-4068-a224-c03cb4047299,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-aed44ff4-dc70-4ebd-aa96-26c846822ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-a9cf3d2b-77ed-47ad-a819-7b73bd6a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-3380c6fe-0610-45c3-a1dc-6762e8cfea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-d2945791-1f47-49eb-b627-9e75529a5b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-6e4ad471-b6ed-4e63-a3f1-c25f9869fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-1c0fde74-89b5-431d-843e-831d14e389f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635699863-172.17.0.4-1598507024259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-397ab6b9-7566-4d67-86d7-514c398f9450,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-ec4cc37c-f408-4068-a224-c03cb4047299,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-aed44ff4-dc70-4ebd-aa96-26c846822ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-a9cf3d2b-77ed-47ad-a819-7b73bd6a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-3380c6fe-0610-45c3-a1dc-6762e8cfea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-d2945791-1f47-49eb-b627-9e75529a5b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-6e4ad471-b6ed-4e63-a3f1-c25f9869fbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-1c0fde74-89b5-431d-843e-831d14e389f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 120000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457234949-172.17.0.4-1598507056841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-7f24366e-cec1-4e09-aea8-57a8b0b1e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-fd2e01d8-9f34-4067-adb0-85b4e08fe55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-617fb77f-525e-4ef7-bf77-689c3e3288f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-8effed7f-ed7d-483c-a0ca-1cf29c9f4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-c51f0342-c809-4ddd-ae42-8d762345e387,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-2e204d54-d7ad-4684-89da-6687d1db481c,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-dbff62d4-0d54-4eec-a8fc-8085e26c035e,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-6357f879-c80e-490f-93f0-9fe1298b415e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457234949-172.17.0.4-1598507056841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35824,DS-7f24366e-cec1-4e09-aea8-57a8b0b1e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-fd2e01d8-9f34-4067-adb0-85b4e08fe55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-617fb77f-525e-4ef7-bf77-689c3e3288f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-8effed7f-ed7d-483c-a0ca-1cf29c9f4e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-c51f0342-c809-4ddd-ae42-8d762345e387,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-2e204d54-d7ad-4684-89da-6687d1db481c,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-dbff62d4-0d54-4eec-a8fc-8085e26c035e,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-6357f879-c80e-490f-93f0-9fe1298b415e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5569
