reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630966225-172.17.0.16-1598489151277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-845e3048-a94e-4469-ab75-2e6f4d713a42,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-552bf6d8-3716-4418-a8f5-dd01d494dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-e70442ce-e16c-4f18-92cd-a7804d7a494d,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-deb82f57-8a85-4555-9473-ab28bf34b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-d748e5aa-668e-4814-8e6f-da713dca2db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-9898c434-ea49-4205-95ab-0bdc2ef0174e,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-fe579de9-b7f1-40d0-9b62-b8b40ab8a3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9d0f999f-f2d6-4c34-b663-64f1f57b20d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630966225-172.17.0.16-1598489151277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-845e3048-a94e-4469-ab75-2e6f4d713a42,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-552bf6d8-3716-4418-a8f5-dd01d494dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-e70442ce-e16c-4f18-92cd-a7804d7a494d,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-deb82f57-8a85-4555-9473-ab28bf34b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-d748e5aa-668e-4814-8e6f-da713dca2db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-9898c434-ea49-4205-95ab-0bdc2ef0174e,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-fe579de9-b7f1-40d0-9b62-b8b40ab8a3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-9d0f999f-f2d6-4c34-b663-64f1f57b20d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041906202-172.17.0.16-1598489226647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-65ab4939-2d8e-4912-8c47-09714e7ac87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-70711928-0238-45df-a43c-d85bd2421c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-dff8f7f7-5f02-4457-a701-795dbc8235e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-2e2044c0-0882-46ef-bad3-8c9aea117c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-87ccaa96-5597-4a78-90a8-333cc5f732d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-187fb0c9-8b04-4644-abc5-e55f39e7e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a7ed5c80-5056-4b11-8d03-7c0cab695dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-1d3284e4-ca3b-4032-a435-6fe679839957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041906202-172.17.0.16-1598489226647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-65ab4939-2d8e-4912-8c47-09714e7ac87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-70711928-0238-45df-a43c-d85bd2421c94,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-dff8f7f7-5f02-4457-a701-795dbc8235e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-2e2044c0-0882-46ef-bad3-8c9aea117c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-87ccaa96-5597-4a78-90a8-333cc5f732d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-187fb0c9-8b04-4644-abc5-e55f39e7e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-a7ed5c80-5056-4b11-8d03-7c0cab695dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-1d3284e4-ca3b-4032-a435-6fe679839957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775986682-172.17.0.16-1598489854060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-1046a908-ec19-4c4b-aa55-778b49af4771,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-73deb4f6-bd2d-44d0-bce3-845095bc85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f08d20e8-5907-4bf8-950a-769bb2a8e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-da1c34af-8319-4ed5-8c1b-db291d03ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c7219622-f61e-437b-b587-3f59822292da,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-dc70db61-be31-4ca1-979d-63da7a667979,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-5bac76b8-7b7d-4aeb-aa2e-d1c83911e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-629a9081-c146-4494-88c6-70acc46fd844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775986682-172.17.0.16-1598489854060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-1046a908-ec19-4c4b-aa55-778b49af4771,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-73deb4f6-bd2d-44d0-bce3-845095bc85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f08d20e8-5907-4bf8-950a-769bb2a8e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-da1c34af-8319-4ed5-8c1b-db291d03ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c7219622-f61e-437b-b587-3f59822292da,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-dc70db61-be31-4ca1-979d-63da7a667979,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-5bac76b8-7b7d-4aeb-aa2e-d1c83911e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-629a9081-c146-4494-88c6-70acc46fd844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159176443-172.17.0.16-1598490303686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-058ec651-d06b-4257-b87e-a5d3ea29fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-eac193ee-5412-49f1-919c-de6033e9d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-d0e11c3a-154e-4b18-a461-f3ea879296d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4014fcff-f5a5-4ee8-9385-e566d8a5be1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-bebc43aa-9594-4e02-85e8-2a3cc0c5d1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4f6735a1-5b27-4140-8586-9ff2d419c842,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e1afdc47-0597-4db4-8f23-200b16c8ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-c43f6250-5e2e-4a9e-8ea0-1b31f77efeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159176443-172.17.0.16-1598490303686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-058ec651-d06b-4257-b87e-a5d3ea29fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-eac193ee-5412-49f1-919c-de6033e9d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-d0e11c3a-154e-4b18-a461-f3ea879296d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4014fcff-f5a5-4ee8-9385-e566d8a5be1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-bebc43aa-9594-4e02-85e8-2a3cc0c5d1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4f6735a1-5b27-4140-8586-9ff2d419c842,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e1afdc47-0597-4db4-8f23-200b16c8ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-c43f6250-5e2e-4a9e-8ea0-1b31f77efeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602416580-172.17.0.16-1598490447176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-5dab7063-2950-4ca9-8219-03bfa6e453d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-dcd9dc85-2858-4e90-acc7-d4677a93975d,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-b3bc8807-174c-46a4-aece-b4b3d944b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-7a028230-5383-4313-b05e-1e899ad66e17,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-8648fedf-812b-4a84-b2db-b67e763a0503,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-3efbadbd-dfbe-4d61-9a0b-4efd95143fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-5c7270b0-c99e-416a-9755-1390f049832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-496910be-d0f8-486a-bec5-7559736f9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602416580-172.17.0.16-1598490447176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-5dab7063-2950-4ca9-8219-03bfa6e453d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-dcd9dc85-2858-4e90-acc7-d4677a93975d,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-b3bc8807-174c-46a4-aece-b4b3d944b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-7a028230-5383-4313-b05e-1e899ad66e17,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-8648fedf-812b-4a84-b2db-b67e763a0503,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-3efbadbd-dfbe-4d61-9a0b-4efd95143fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-5c7270b0-c99e-416a-9755-1390f049832d,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-496910be-d0f8-486a-bec5-7559736f9a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695590975-172.17.0.16-1598490952698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-64657887-132f-4d6b-b4a5-ffbd8d031964,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-c6557ddd-2872-480a-985e-8641f877f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-f6c396ab-d0a3-4abc-860a-8de08b456894,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-f4b40520-5994-49c8-ab15-64d14acefa18,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-22a366de-28bd-4a61-a6b8-46dbc42fd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-b202b3b7-ef2a-4cef-80ea-1eabddbbba45,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cde2ac69-c048-4941-81cf-f2db597550ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-67812bb7-ac0b-408d-8f33-a437dca4e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695590975-172.17.0.16-1598490952698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-64657887-132f-4d6b-b4a5-ffbd8d031964,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-c6557ddd-2872-480a-985e-8641f877f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-f6c396ab-d0a3-4abc-860a-8de08b456894,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-f4b40520-5994-49c8-ab15-64d14acefa18,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-22a366de-28bd-4a61-a6b8-46dbc42fd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-b202b3b7-ef2a-4cef-80ea-1eabddbbba45,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cde2ac69-c048-4941-81cf-f2db597550ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-67812bb7-ac0b-408d-8f33-a437dca4e557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: StopWatch is already running
stackTrace: java.lang.IllegalStateException: StopWatch is already running
	at org.apache.hadoop.util.StopWatch.start(StopWatch.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager.restartHeartbeatStopWatch(HeartbeatManager.java:317)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerTestUtil.checkHeartbeat(BlockManagerTestUtil.java:249)
	at org.apache.hadoop.hdfs.MiniDFSCluster.setDataNodeDead(MiniDFSCluster.java:2506)
	at org.apache.hadoop.hdfs.TestFileChecksum.shutdownDataNode(TestFileChecksum.java:613)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:577)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046326668-172.17.0.16-1598491763018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44395,DS-23a89b3f-c277-4d28-82b3-48e1025c6880,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-3eb5f6f3-d2bd-48ff-85d5-9ed3e0146dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-5288a55a-5243-4d1a-aa73-d82c827714a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c5d4545b-3d5d-4be4-895a-32753c431461,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-74dd8789-f567-4a90-b2c7-3ff0f9f08d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c2212674-d8e4-4322-b711-b998f6f316c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-936bfca1-cca2-436a-9deb-5c4a6a03152d,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-6dbcf699-2aa4-4243-a726-b98c737b2fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046326668-172.17.0.16-1598491763018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44395,DS-23a89b3f-c277-4d28-82b3-48e1025c6880,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-3eb5f6f3-d2bd-48ff-85d5-9ed3e0146dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-5288a55a-5243-4d1a-aa73-d82c827714a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-c5d4545b-3d5d-4be4-895a-32753c431461,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-74dd8789-f567-4a90-b2c7-3ff0f9f08d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-c2212674-d8e4-4322-b711-b998f6f316c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-936bfca1-cca2-436a-9deb-5c4a6a03152d,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-6dbcf699-2aa4-4243-a726-b98c737b2fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115481627-172.17.0.16-1598492014423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-c7a491bb-661d-4386-afa1-4dd90a149bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-9cab3fa7-9323-4b6e-a7b2-d44c0933ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-e00359f0-b74a-4a5c-a68a-9ba3fdc1f3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-91afe476-15fd-4126-9dc0-1ba5051d1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d3d882b4-a30b-4bc3-8a88-cbebda26376f,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b2b4fe6a-5f0c-4f41-aad7-fe579bcd52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bda3e1eb-b6d3-46eb-9f00-09924015cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-482d040d-32fe-4ac7-a871-73997a109d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115481627-172.17.0.16-1598492014423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-c7a491bb-661d-4386-afa1-4dd90a149bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-9cab3fa7-9323-4b6e-a7b2-d44c0933ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-e00359f0-b74a-4a5c-a68a-9ba3fdc1f3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-91afe476-15fd-4126-9dc0-1ba5051d1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d3d882b4-a30b-4bc3-8a88-cbebda26376f,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b2b4fe6a-5f0c-4f41-aad7-fe579bcd52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-bda3e1eb-b6d3-46eb-9f00-09924015cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-482d040d-32fe-4ac7-a871-73997a109d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516126154-172.17.0.16-1598492315997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-49d5e94e-f9d3-47bf-ab93-373ed45a35c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-d7f1dd2f-c89f-4815-97c4-4307f561e440,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d5037f85-c0a5-4986-9fc5-69135ef854e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-315fb52d-f419-4f49-b611-3b9f9ff5e742,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-10a3bba1-815d-46f9-b4d5-7925e3bf85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-8b67beba-05f7-4cb9-b375-e31c5a53284b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-077c6ecf-e996-439b-ae78-420447b7ba28,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-c49b1b9a-74f5-4a29-bcab-6c5532a34aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516126154-172.17.0.16-1598492315997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-49d5e94e-f9d3-47bf-ab93-373ed45a35c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-d7f1dd2f-c89f-4815-97c4-4307f561e440,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d5037f85-c0a5-4986-9fc5-69135ef854e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-315fb52d-f419-4f49-b611-3b9f9ff5e742,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-10a3bba1-815d-46f9-b4d5-7925e3bf85f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-8b67beba-05f7-4cb9-b375-e31c5a53284b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-077c6ecf-e996-439b-ae78-420447b7ba28,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-c49b1b9a-74f5-4a29-bcab-6c5532a34aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624063828-172.17.0.16-1598492415822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-6cfb4127-a226-4d35-a0c4-0165da68b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-6fb79428-2a5a-4871-95bc-989345528aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f48152a5-56fd-4bce-9878-b6c000394b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-227973bd-7ca4-4b85-b2ac-cd1acd343841,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-2f7b3ef8-ee53-4e7b-ac3b-1095efdc5913,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-78d3c4d2-a25d-4d30-9e83-55fd4a1d1d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-d80ccd35-90e1-41a5-9c94-6b22215f87eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-3e735d57-bf4c-4c0b-a821-8c3ca5509db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624063828-172.17.0.16-1598492415822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-6cfb4127-a226-4d35-a0c4-0165da68b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-6fb79428-2a5a-4871-95bc-989345528aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f48152a5-56fd-4bce-9878-b6c000394b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-227973bd-7ca4-4b85-b2ac-cd1acd343841,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-2f7b3ef8-ee53-4e7b-ac3b-1095efdc5913,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-78d3c4d2-a25d-4d30-9e83-55fd4a1d1d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-d80ccd35-90e1-41a5-9c94-6b22215f87eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-3e735d57-bf4c-4c0b-a821-8c3ca5509db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424962318-172.17.0.16-1598492713924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-97e045ec-6393-4769-8936-bf16f4844f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-f2b86ca9-5e4c-4725-be97-0cb9bd3b6395,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2c03d7a1-af41-4f11-92fe-dd70f001faec,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-c1001778-8151-404b-963c-ba1fc287e2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-73faf165-96df-4ed0-bc80-defe1abe9722,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-b208a414-1998-4154-82ec-d96d392bce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-eda2abc5-c501-4ec7-ae87-920c798dea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-dae04420-cc8e-45f3-aa08-16ca055d51ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424962318-172.17.0.16-1598492713924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-97e045ec-6393-4769-8936-bf16f4844f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-f2b86ca9-5e4c-4725-be97-0cb9bd3b6395,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2c03d7a1-af41-4f11-92fe-dd70f001faec,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-c1001778-8151-404b-963c-ba1fc287e2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-73faf165-96df-4ed0-bc80-defe1abe9722,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-b208a414-1998-4154-82ec-d96d392bce0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-eda2abc5-c501-4ec7-ae87-920c798dea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-dae04420-cc8e-45f3-aa08-16ca055d51ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854290516-172.17.0.16-1598492903863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-afc458ed-a40b-437e-bab2-b2804a512d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-aef32381-bb38-4404-a591-ed5bb697781f,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-0e25cb32-84d3-4220-88fc-7d6f6ea025f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-8db42b25-db6d-4b05-ac0a-d6ebf1348590,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-eb39495c-6564-4684-a40b-a87a474ef5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-4dfe8fab-3714-42e4-9dfc-a00e52d9bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-a7c5328c-8dbc-4c2b-b57c-7796bb9cdc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-736866ad-d821-4c26-b924-52a0a87eb543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854290516-172.17.0.16-1598492903863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-afc458ed-a40b-437e-bab2-b2804a512d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-aef32381-bb38-4404-a591-ed5bb697781f,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-0e25cb32-84d3-4220-88fc-7d6f6ea025f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-8db42b25-db6d-4b05-ac0a-d6ebf1348590,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-eb39495c-6564-4684-a40b-a87a474ef5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-4dfe8fab-3714-42e4-9dfc-a00e52d9bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-a7c5328c-8dbc-4c2b-b57c-7796bb9cdc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-736866ad-d821-4c26-b924-52a0a87eb543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726980409-172.17.0.16-1598492975156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-972943ea-18b2-4b83-bf4f-93b37d16beb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-95586c1c-2878-4b97-b6e7-9260acbd8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-ac038d0f-78cf-48f3-8f3b-4771fd19cf20,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-12b7a3fa-dab0-4a47-96d0-b968428dbfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-fed4a179-56f0-4641-87eb-528cad5e82be,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5a7030f2-a4e9-46e9-9cb3-44077f7a8add,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5c53f2f2-fb5b-4f1f-880b-03fd4026f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a150c986-a1db-44c8-b6e1-aed46be7fe9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726980409-172.17.0.16-1598492975156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-972943ea-18b2-4b83-bf4f-93b37d16beb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-95586c1c-2878-4b97-b6e7-9260acbd8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-ac038d0f-78cf-48f3-8f3b-4771fd19cf20,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-12b7a3fa-dab0-4a47-96d0-b968428dbfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-fed4a179-56f0-4641-87eb-528cad5e82be,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5a7030f2-a4e9-46e9-9cb3-44077f7a8add,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5c53f2f2-fb5b-4f1f-880b-03fd4026f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a150c986-a1db-44c8-b6e1-aed46be7fe9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155553042-172.17.0.16-1598493185624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-b9ddb4fa-407d-46fb-91ac-ea254c80341b,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-01f5580e-e86f-433f-a556-96181ccddde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-ca422f7b-9c6f-4f87-89d4-d84c51201958,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-e1684a5d-8519-4dfc-b7e2-7c032e0b91e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-0572019d-54ef-441d-8e01-dbaf8075d353,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-d2101390-c6b2-4efd-a97f-60a1945847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-12f3e388-eca6-4ca3-a2f4-825610404594,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-ee00a9db-adcc-4dda-8340-09612404485d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155553042-172.17.0.16-1598493185624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42828,DS-b9ddb4fa-407d-46fb-91ac-ea254c80341b,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-01f5580e-e86f-433f-a556-96181ccddde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-ca422f7b-9c6f-4f87-89d4-d84c51201958,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-e1684a5d-8519-4dfc-b7e2-7c032e0b91e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-0572019d-54ef-441d-8e01-dbaf8075d353,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-d2101390-c6b2-4efd-a97f-60a1945847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-12f3e388-eca6-4ca3-a2f4-825610404594,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-ee00a9db-adcc-4dda-8340-09612404485d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870997813-172.17.0.16-1598493227056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-c1627089-b42d-4f58-b03c-b8e358d6be01,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-e74c1fa5-41de-4a00-a898-2f6815b22d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-a6175a9b-8651-441e-a3f9-581a0d155bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-c41b57b6-f73c-40c4-8704-fd74394eacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-be5d1a27-d4cb-40af-84cb-afd68ff9c27a,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-fd8395ca-901d-453d-b0ea-722b51428ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-17be0934-1443-45ef-a1b6-0ddc373846c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-1d714b19-b7d9-4505-ab01-3f16f1edbf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870997813-172.17.0.16-1598493227056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-c1627089-b42d-4f58-b03c-b8e358d6be01,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-e74c1fa5-41de-4a00-a898-2f6815b22d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-a6175a9b-8651-441e-a3f9-581a0d155bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-c41b57b6-f73c-40c4-8704-fd74394eacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-be5d1a27-d4cb-40af-84cb-afd68ff9c27a,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-fd8395ca-901d-453d-b0ea-722b51428ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-17be0934-1443-45ef-a1b6-0ddc373846c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-1d714b19-b7d9-4505-ab01-3f16f1edbf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6915659-172.17.0.16-1598493331902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-9d620651-6eaf-4e8b-851c-7ab4b178bd76,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-4d56943c-8e9d-4623-a620-7e2ea1adb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-3c311f31-579b-4c9f-89d6-2019bff98ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e4fe6b0f-6970-4606-bb7b-8d0f38272c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-418083d7-1584-4fb3-b42c-1e48515d5a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-e51c31aa-b58e-4bc5-8864-507f0926bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-bd09d650-dcba-4b4e-b1dd-e76ee714935b,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-1244c56e-e990-4992-b2f9-aff5238293bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6915659-172.17.0.16-1598493331902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-9d620651-6eaf-4e8b-851c-7ab4b178bd76,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-4d56943c-8e9d-4623-a620-7e2ea1adb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-3c311f31-579b-4c9f-89d6-2019bff98ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e4fe6b0f-6970-4606-bb7b-8d0f38272c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-418083d7-1584-4fb3-b42c-1e48515d5a58,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-e51c31aa-b58e-4bc5-8864-507f0926bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-bd09d650-dcba-4b4e-b1dd-e76ee714935b,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-1244c56e-e990-4992-b2f9-aff5238293bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612066901-172.17.0.16-1598493405725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-259a418e-d037-4feb-b4b7-44df10116a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-b93ef3a4-a96a-43ac-9cd4-a2161dc9e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-45c7b4dd-16ab-4e15-af7b-2f0dbab00c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-c30a5e46-8c32-457d-8cad-c4e3aa2994b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ab2c5197-62f7-4285-a7f2-7a57d29648d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-62503b22-5008-4ef4-86df-41ada270b226,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-0100ee1f-564a-40b4-9b63-2502a6f9384d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-d9526673-8b53-44dc-81b8-13be31eba2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612066901-172.17.0.16-1598493405725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-259a418e-d037-4feb-b4b7-44df10116a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-b93ef3a4-a96a-43ac-9cd4-a2161dc9e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-45c7b4dd-16ab-4e15-af7b-2f0dbab00c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-c30a5e46-8c32-457d-8cad-c4e3aa2994b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-ab2c5197-62f7-4285-a7f2-7a57d29648d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-62503b22-5008-4ef4-86df-41ada270b226,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-0100ee1f-564a-40b4-9b63-2502a6f9384d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-d9526673-8b53-44dc-81b8-13be31eba2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926996606-172.17.0.16-1598493551541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33765,DS-d68f4495-c8d5-4b59-9883-313b7305b940,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-ef4156a1-0427-446c-8245-81858e924455,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-79d453ca-3e92-4126-a929-94b8b6a45b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-64ab9b10-36ed-4d27-bb4f-6d48492db2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-1387881a-63c7-440a-b065-b7897c1bff82,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-c6eef9a7-aefe-4872-9380-2df8374a298f,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-60e0e2a6-14e4-482f-97f8-f0cb2b4b3e35,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-25538a22-c3a6-4a89-95cc-6fcac9870c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926996606-172.17.0.16-1598493551541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33765,DS-d68f4495-c8d5-4b59-9883-313b7305b940,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-ef4156a1-0427-446c-8245-81858e924455,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-79d453ca-3e92-4126-a929-94b8b6a45b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-64ab9b10-36ed-4d27-bb4f-6d48492db2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-1387881a-63c7-440a-b065-b7897c1bff82,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-c6eef9a7-aefe-4872-9380-2df8374a298f,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-60e0e2a6-14e4-482f-97f8-f0cb2b4b3e35,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-25538a22-c3a6-4a89-95cc-6fcac9870c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5465
