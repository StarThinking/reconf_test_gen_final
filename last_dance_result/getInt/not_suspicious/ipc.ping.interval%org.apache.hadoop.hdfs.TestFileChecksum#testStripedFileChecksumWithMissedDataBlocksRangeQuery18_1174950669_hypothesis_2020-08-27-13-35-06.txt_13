reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554165369-172.17.0.7-1598535460249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-b6e17fc2-584d-4f12-b3d2-1fe7f02b2f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-30cb512b-9ae2-4f4f-b4f3-00d972c64993,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-331daa81-375a-4848-b07a-d102cc4d824b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-b9e07b3f-d318-4f34-8c85-1e5acde7e681,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-3340a298-2891-4921-93de-9174322e41b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0c8a20fc-2879-43da-a0c5-06931e2cd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-092a66db-0950-45c0-9d38-3c3aee6b5e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-0956caa9-1075-4d3b-b651-fee2f75753e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554165369-172.17.0.7-1598535460249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-b6e17fc2-584d-4f12-b3d2-1fe7f02b2f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-30cb512b-9ae2-4f4f-b4f3-00d972c64993,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-331daa81-375a-4848-b07a-d102cc4d824b,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-b9e07b3f-d318-4f34-8c85-1e5acde7e681,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-3340a298-2891-4921-93de-9174322e41b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0c8a20fc-2879-43da-a0c5-06931e2cd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-092a66db-0950-45c0-9d38-3c3aee6b5e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-0956caa9-1075-4d3b-b651-fee2f75753e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480244219-172.17.0.7-1598535571135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-4df58bb6-2194-4b71-a747-60e3718d9985,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-c462eeda-5889-4136-94fe-03b7b091f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d7956d08-68a2-4b07-a49f-0c1278e9ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-2759465c-500f-4310-84cb-3ea23878ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-67740641-9ac8-45e3-aba3-1635cf54235d,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-1b4bd23d-074b-469d-8076-6502bb681a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-ec3eb1bb-d7f0-42bd-8618-349d144f9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-22d6d94f-aa2a-4cc5-ab0e-351433eb61b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480244219-172.17.0.7-1598535571135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-4df58bb6-2194-4b71-a747-60e3718d9985,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-c462eeda-5889-4136-94fe-03b7b091f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d7956d08-68a2-4b07-a49f-0c1278e9ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-2759465c-500f-4310-84cb-3ea23878ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-67740641-9ac8-45e3-aba3-1635cf54235d,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-1b4bd23d-074b-469d-8076-6502bb681a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-ec3eb1bb-d7f0-42bd-8618-349d144f9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-22d6d94f-aa2a-4cc5-ab0e-351433eb61b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627453827-172.17.0.7-1598535744634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-767179bb-6681-45f4-abdb-38a3939d2714,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-63870c64-86a3-43bd-91bd-570f5f16ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-55d59b2f-2e73-4180-a117-a10ca01ffbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-ed8ef96f-e9f5-4818-a97d-edd8007f3076,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-f6150bd6-784d-4370-b0ec-46c67cc1f849,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-561ae4f9-1283-47e8-a282-c05d1529e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-6b335d7b-b2f5-4b7d-a83b-86346dc8112c,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-ca320234-e8bf-4383-bd20-db836003f85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627453827-172.17.0.7-1598535744634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-767179bb-6681-45f4-abdb-38a3939d2714,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-63870c64-86a3-43bd-91bd-570f5f16ce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-55d59b2f-2e73-4180-a117-a10ca01ffbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-ed8ef96f-e9f5-4818-a97d-edd8007f3076,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-f6150bd6-784d-4370-b0ec-46c67cc1f849,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-561ae4f9-1283-47e8-a282-c05d1529e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-6b335d7b-b2f5-4b7d-a83b-86346dc8112c,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-ca320234-e8bf-4383-bd20-db836003f85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289895960-172.17.0.7-1598535855248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-9a812f95-5ba9-470c-b534-a4ea6e5e55af,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-7f29872b-98b4-4d87-ae66-9722f01bd457,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-48ae39b1-e525-4370-9892-0e5b68a6cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-93bf10c1-b050-4b0d-a455-347358ec44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-2934505c-7fec-4a63-959d-188dee1c30aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-c2f1e81b-d298-4430-b84d-2cc168a3b34f,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-977e5451-09ce-48b9-a6fa-00a01eb389b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-65227f10-b203-4def-acd8-8b8596d5e816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289895960-172.17.0.7-1598535855248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-9a812f95-5ba9-470c-b534-a4ea6e5e55af,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-7f29872b-98b4-4d87-ae66-9722f01bd457,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-48ae39b1-e525-4370-9892-0e5b68a6cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-93bf10c1-b050-4b0d-a455-347358ec44a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-2934505c-7fec-4a63-959d-188dee1c30aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-c2f1e81b-d298-4430-b84d-2cc168a3b34f,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-977e5451-09ce-48b9-a6fa-00a01eb389b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-65227f10-b203-4def-acd8-8b8596d5e816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773944427-172.17.0.7-1598536058232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-a626cce0-c90f-46b4-828a-170342b0219c,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-096a81f2-ee31-43ad-8a8e-fa58afab5559,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-4d68ce85-2118-4ee4-8df8-d177112d7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-5b57a799-6823-4f39-9918-27158e296542,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-4c80ba1a-a8c3-4ec6-ab13-e8c8807c7899,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-4322d451-4e9e-45fa-a134-a32e3ea5c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-a11467a5-c4de-4e50-b4f0-1d2879353f35,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-826b7b50-9247-42ed-b676-b02eea107e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773944427-172.17.0.7-1598536058232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-a626cce0-c90f-46b4-828a-170342b0219c,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-096a81f2-ee31-43ad-8a8e-fa58afab5559,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-4d68ce85-2118-4ee4-8df8-d177112d7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-5b57a799-6823-4f39-9918-27158e296542,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-4c80ba1a-a8c3-4ec6-ab13-e8c8807c7899,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-4322d451-4e9e-45fa-a134-a32e3ea5c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-a11467a5-c4de-4e50-b4f0-1d2879353f35,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-826b7b50-9247-42ed-b676-b02eea107e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642573281-172.17.0.7-1598536686519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-77ca77ff-6554-4a2d-9558-e4389837e302,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-a09e141c-e7a6-49af-b8a3-3c15a03a4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-5cf48707-098d-41c8-ad77-32dede91ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-956dd576-f779-4026-8f12-9e05667e6479,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-88b90921-7742-4a28-b9ce-cfcb3d8c3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-79b82886-b10b-4488-ac2d-771a88dff5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-f6a81cf2-8b74-45ab-aaa7-b63fe92d741e,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-3d8fd401-de86-48ed-b3d8-fca892ce239e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642573281-172.17.0.7-1598536686519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-77ca77ff-6554-4a2d-9558-e4389837e302,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-a09e141c-e7a6-49af-b8a3-3c15a03a4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-5cf48707-098d-41c8-ad77-32dede91ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-956dd576-f779-4026-8f12-9e05667e6479,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-88b90921-7742-4a28-b9ce-cfcb3d8c3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-79b82886-b10b-4488-ac2d-771a88dff5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-f6a81cf2-8b74-45ab-aaa7-b63fe92d741e,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-3d8fd401-de86-48ed-b3d8-fca892ce239e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431100380-172.17.0.7-1598536867149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-da935410-dfde-463e-857d-e21b7f30162d,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-2114afda-4c94-427b-bf35-3d13fa4eaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-55997275-ee54-4df5-8268-b29dc17369b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-cd3c381f-4ce3-49c6-8688-d1489d4976ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-43fb3a1a-4df2-4f38-8282-6f273c1e9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-cf616579-f5d9-4c06-845d-52eb86ce78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6a4c0275-fbd0-4d24-811a-1121f5c1e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0515f7e9-ff28-40d8-837d-c1f4610b0800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431100380-172.17.0.7-1598536867149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-da935410-dfde-463e-857d-e21b7f30162d,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-2114afda-4c94-427b-bf35-3d13fa4eaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-55997275-ee54-4df5-8268-b29dc17369b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-cd3c381f-4ce3-49c6-8688-d1489d4976ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-43fb3a1a-4df2-4f38-8282-6f273c1e9c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-cf616579-f5d9-4c06-845d-52eb86ce78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-6a4c0275-fbd0-4d24-811a-1121f5c1e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0515f7e9-ff28-40d8-837d-c1f4610b0800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129844211-172.17.0.7-1598536959760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-59e5f811-3624-4738-921e-04b8ea44d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-34c66757-2150-4d55-94e9-a23b5d8491a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-3fbbd697-9fc9-43d6-9029-d12729ef6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-b8509214-825d-401c-984b-14fca5e02ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-dd523479-5388-47da-b58c-fd0e753cabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-6fde4534-0d9d-48cc-b738-22439264f485,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8dd091fe-fcb7-46bf-a63d-b6bac29a3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d5312dec-3958-4eeb-8cf5-68c4ee7e13e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129844211-172.17.0.7-1598536959760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-59e5f811-3624-4738-921e-04b8ea44d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-34c66757-2150-4d55-94e9-a23b5d8491a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-3fbbd697-9fc9-43d6-9029-d12729ef6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-b8509214-825d-401c-984b-14fca5e02ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-dd523479-5388-47da-b58c-fd0e753cabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-6fde4534-0d9d-48cc-b738-22439264f485,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8dd091fe-fcb7-46bf-a63d-b6bac29a3bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d5312dec-3958-4eeb-8cf5-68c4ee7e13e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422224129-172.17.0.7-1598537422481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-ba1dafc9-24db-4417-8aef-6bc12d23993b,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-fe2a2e4d-c921-449e-9f80-5be7708d5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-6b203f84-28c4-47f2-a258-e915f7943383,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-a5b0a8b3-2b1c-42e0-9321-13fcfdce09df,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-79527995-5162-4cd5-886e-ada46c74300c,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a4c3d176-386b-4f0f-b322-aa16e288e494,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-92e48510-ed3f-4735-9792-22ac54b56f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fcd0c266-0a40-4277-91d3-278d38778bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422224129-172.17.0.7-1598537422481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-ba1dafc9-24db-4417-8aef-6bc12d23993b,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-fe2a2e4d-c921-449e-9f80-5be7708d5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-6b203f84-28c4-47f2-a258-e915f7943383,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-a5b0a8b3-2b1c-42e0-9321-13fcfdce09df,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-79527995-5162-4cd5-886e-ada46c74300c,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a4c3d176-386b-4f0f-b322-aa16e288e494,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-92e48510-ed3f-4735-9792-22ac54b56f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fcd0c266-0a40-4277-91d3-278d38778bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135511260-172.17.0.7-1598538296643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-76d41b3d-05d1-4c42-b16f-3d29ef817ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-6682d912-bc7c-4849-91a6-6ee51a560764,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-ecdf8f5b-93bd-4c22-8a4a-dbbcc0f13a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-d1f7faa3-abb7-4cd9-b9f6-404aff4ee662,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-07d05093-9e5d-4edb-8d93-e1544c5aaa15,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-988fe2fd-1d9d-4ec8-b60a-99ae821bd914,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-0d125496-48ea-4f0f-b95b-64d7e638fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-c4a9d967-bb56-4217-9f51-f85aed1a5b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135511260-172.17.0.7-1598538296643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-76d41b3d-05d1-4c42-b16f-3d29ef817ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-6682d912-bc7c-4849-91a6-6ee51a560764,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-ecdf8f5b-93bd-4c22-8a4a-dbbcc0f13a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-d1f7faa3-abb7-4cd9-b9f6-404aff4ee662,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-07d05093-9e5d-4edb-8d93-e1544c5aaa15,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-988fe2fd-1d9d-4ec8-b60a-99ae821bd914,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-0d125496-48ea-4f0f-b95b-64d7e638fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-c4a9d967-bb56-4217-9f51-f85aed1a5b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320793502-172.17.0.7-1598538466418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-6a47eab6-41a5-44ae-b641-9d6d4408eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-d1df52e8-8781-485c-8fb5-1fb7c7f7fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-bb60d2e1-29da-4ac2-ae7b-01a3e843f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-a7a03710-9643-4c93-bc09-14a055beb2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-82d3fc32-9a01-4e0b-98e1-17fc2e0191a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-0b269f94-b75b-4eb4-89c3-d9c1d9bd1b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-1a952837-7b2d-4eb7-bb89-9458ca8e2999,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-fc7f2f9e-4b7c-4f45-bc97-af86505d105c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320793502-172.17.0.7-1598538466418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-6a47eab6-41a5-44ae-b641-9d6d4408eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-d1df52e8-8781-485c-8fb5-1fb7c7f7fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-bb60d2e1-29da-4ac2-ae7b-01a3e843f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-a7a03710-9643-4c93-bc09-14a055beb2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-82d3fc32-9a01-4e0b-98e1-17fc2e0191a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-0b269f94-b75b-4eb4-89c3-d9c1d9bd1b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-1a952837-7b2d-4eb7-bb89-9458ca8e2999,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-fc7f2f9e-4b7c-4f45-bc97-af86505d105c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259649306-172.17.0.7-1598538603338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-724010ac-33df-44db-a7cf-cfd852885a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ff6bf67e-8744-4a0f-9c4f-83c951085a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-fddf1271-2cc1-41c3-84ee-9edafcf72c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-a441dc52-a5e1-411d-a028-b0d01e4381d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c08c211e-d11e-4cbf-b187-6b507d5bfc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-b91a2aee-05e1-490b-bf7c-50ba3073d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-7d194820-7d91-46a0-9db2-f8a63d7be455,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-229ff083-0126-4fc8-9b14-d1a9527d1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259649306-172.17.0.7-1598538603338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-724010ac-33df-44db-a7cf-cfd852885a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ff6bf67e-8744-4a0f-9c4f-83c951085a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-fddf1271-2cc1-41c3-84ee-9edafcf72c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-a441dc52-a5e1-411d-a028-b0d01e4381d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c08c211e-d11e-4cbf-b187-6b507d5bfc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-b91a2aee-05e1-490b-bf7c-50ba3073d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-7d194820-7d91-46a0-9db2-f8a63d7be455,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-229ff083-0126-4fc8-9b14-d1a9527d1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506107977-172.17.0.7-1598538735809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-5fd08519-345d-4471-be27-eddae75b72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-f773cc3c-b39b-4bdd-9d4e-4c13ccf062f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-184def86-fc63-4c20-a6e3-286f20d7d4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-4f0356ef-8860-4bb5-9a37-e1e303842346,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-95219cbb-9966-40e3-a02f-fd51e4ffd8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-ca2a2e1b-6fee-41e7-9dd2-3065a838e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-25c7c5a9-ff80-4411-893b-0bd9288bc315,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-acc7148c-e245-4d7c-8752-8d622595d783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506107977-172.17.0.7-1598538735809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-5fd08519-345d-4471-be27-eddae75b72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-f773cc3c-b39b-4bdd-9d4e-4c13ccf062f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-184def86-fc63-4c20-a6e3-286f20d7d4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-4f0356ef-8860-4bb5-9a37-e1e303842346,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-95219cbb-9966-40e3-a02f-fd51e4ffd8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-ca2a2e1b-6fee-41e7-9dd2-3065a838e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-25c7c5a9-ff80-4411-893b-0bd9288bc315,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-acc7148c-e245-4d7c-8752-8d622595d783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933213533-172.17.0.7-1598539218081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-e29fd2d2-d9fc-4655-af7e-cabd73d50570,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-b7bbe753-50c6-43cf-b83c-0c9b9fe65845,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-908804ba-29d1-494f-9cfb-f56ceeb7bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-7c848566-9fa0-4507-8d27-75a51211b4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-5ffe0e42-1b03-447f-9983-800c27749478,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-266026c0-ff41-4830-a1cc-70ffc79da1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-61fe0389-37f6-4c5b-929c-e837b318bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-155d6dd2-df2e-4640-a827-525e78f6f69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933213533-172.17.0.7-1598539218081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-e29fd2d2-d9fc-4655-af7e-cabd73d50570,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-b7bbe753-50c6-43cf-b83c-0c9b9fe65845,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-908804ba-29d1-494f-9cfb-f56ceeb7bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-7c848566-9fa0-4507-8d27-75a51211b4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-5ffe0e42-1b03-447f-9983-800c27749478,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-266026c0-ff41-4830-a1cc-70ffc79da1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-61fe0389-37f6-4c5b-929c-e837b318bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-155d6dd2-df2e-4640-a827-525e78f6f69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640996164-172.17.0.7-1598539486605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-dad0f6e7-67bb-4129-a71e-1bf3760bcca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-27f1fe7e-6f76-458b-a5f8-33622e6647ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-5d034312-1770-448a-8bc8-22a3da654ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-a5cf30f4-b147-4c6e-88f6-b55eeef26f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-dda829b6-47c9-4449-9508-3d74497342d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-f57f3fd2-c552-4015-8352-970ae8088595,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-2171ad13-e692-4ad9-8319-d582771e5f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-6e6ba974-e6d4-4a8a-9589-dcc8f540ef9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640996164-172.17.0.7-1598539486605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-dad0f6e7-67bb-4129-a71e-1bf3760bcca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-27f1fe7e-6f76-458b-a5f8-33622e6647ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-5d034312-1770-448a-8bc8-22a3da654ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-a5cf30f4-b147-4c6e-88f6-b55eeef26f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-dda829b6-47c9-4449-9508-3d74497342d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-f57f3fd2-c552-4015-8352-970ae8088595,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-2171ad13-e692-4ad9-8319-d582771e5f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-6e6ba974-e6d4-4a8a-9589-dcc8f540ef9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430398949-172.17.0.7-1598539753669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-0b7108cf-8e63-4e98-96ff-db14ca350679,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-039e4fdc-258c-408f-b598-763abbab4abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-393a2ba2-f6cd-4525-8b64-5eab5a7e8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-12255165-2201-442f-87e8-50d28d66450b,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-7be25a2a-2b9b-4d31-9e06-937a01715aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-dedc50a8-5e79-4b6b-a0be-a2af01d835a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-843addb0-b9fe-426a-b00e-b4ba63a47f72,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-af64289e-68a8-4e2a-b20b-378a79644536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430398949-172.17.0.7-1598539753669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37758,DS-0b7108cf-8e63-4e98-96ff-db14ca350679,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-039e4fdc-258c-408f-b598-763abbab4abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-393a2ba2-f6cd-4525-8b64-5eab5a7e8f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-12255165-2201-442f-87e8-50d28d66450b,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-7be25a2a-2b9b-4d31-9e06-937a01715aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-dedc50a8-5e79-4b6b-a0be-a2af01d835a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-843addb0-b9fe-426a-b00e-b4ba63a47f72,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-af64289e-68a8-4e2a-b20b-378a79644536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946553656-172.17.0.7-1598540159316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-cd9d3c4b-e997-414f-bb16-b44a3a199211,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-4defe3b1-f370-4c0f-8052-89e3b5ae08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1521ab94-15c4-4f38-b39f-8288cd61772d,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-266bcbe7-108d-47c7-bee5-bfbe25bfdea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-2898a665-f666-4f9f-98ce-a03a15109f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-31181a0c-188b-4851-90a9-cb62fb12bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-44766e20-3212-487e-b38a-f4c4fc5db9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-2babb33e-4fa7-44bc-a54d-ea55e0036860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946553656-172.17.0.7-1598540159316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-cd9d3c4b-e997-414f-bb16-b44a3a199211,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-4defe3b1-f370-4c0f-8052-89e3b5ae08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1521ab94-15c4-4f38-b39f-8288cd61772d,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-266bcbe7-108d-47c7-bee5-bfbe25bfdea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-2898a665-f666-4f9f-98ce-a03a15109f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-31181a0c-188b-4851-90a9-cb62fb12bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-44766e20-3212-487e-b38a-f4c4fc5db9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-2babb33e-4fa7-44bc-a54d-ea55e0036860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752457077-172.17.0.7-1598540236205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37251,DS-f1b0d4f9-e349-4b41-a37c-06b86e18c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-70a3dc3c-ff7c-4a13-93c6-27a62ff45c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-0fd61a5f-68a0-4364-a20a-231d6a379f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-82e909ea-ba42-4d59-9003-1a8f50bb6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2a2efe2a-f05f-4203-a320-333c481d8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-22d4a28e-1599-4e8a-a60d-58a3ed3f67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5eb4d0b9-0991-407b-bd4a-30b34b8589cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-508dad8a-8bb7-4734-b7b0-cada2c8b8274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752457077-172.17.0.7-1598540236205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37251,DS-f1b0d4f9-e349-4b41-a37c-06b86e18c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-70a3dc3c-ff7c-4a13-93c6-27a62ff45c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-0fd61a5f-68a0-4364-a20a-231d6a379f60,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-82e909ea-ba42-4d59-9003-1a8f50bb6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2a2efe2a-f05f-4203-a320-333c481d8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-22d4a28e-1599-4e8a-a60d-58a3ed3f67bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5eb4d0b9-0991-407b-bd4a-30b34b8589cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-508dad8a-8bb7-4734-b7b0-cada2c8b8274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5025
