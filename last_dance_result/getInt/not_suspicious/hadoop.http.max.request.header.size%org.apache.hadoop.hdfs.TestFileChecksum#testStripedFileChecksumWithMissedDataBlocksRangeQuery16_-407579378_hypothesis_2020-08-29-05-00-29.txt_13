reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037516652-172.17.0.5-1598677971639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37274,DS-92821941-1a31-48a4-bfd6-ff8e09c2c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-1a718d6b-60da-46c1-872d-7e70d9adf975,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-f4e21a8f-bf72-43bf-8bb9-282b63553d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e5a3ed5e-a92d-4056-b518-876d287886ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-476a166f-56c8-4606-ba47-f260a54d33bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-5b110caa-e22f-4796-b4a5-0ef363097dee,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-bf678663-d4e4-4ab8-97f8-90b054809571,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-a034ca83-4a3f-40bb-b586-dc6a8c1f3f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037516652-172.17.0.5-1598677971639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37274,DS-92821941-1a31-48a4-bfd6-ff8e09c2c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-1a718d6b-60da-46c1-872d-7e70d9adf975,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-f4e21a8f-bf72-43bf-8bb9-282b63553d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e5a3ed5e-a92d-4056-b518-876d287886ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-476a166f-56c8-4606-ba47-f260a54d33bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-5b110caa-e22f-4796-b4a5-0ef363097dee,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-bf678663-d4e4-4ab8-97f8-90b054809571,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-a034ca83-4a3f-40bb-b586-dc6a8c1f3f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152854858-172.17.0.5-1598678007006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-a77c494a-a928-4438-9ad1-f16884fdea69,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-135c26df-0162-4251-94a9-f262f4127fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-1524b340-ca59-4adf-9c39-ae0912c1d7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-41ef9719-baf5-4082-a8ea-521f6269cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9cc917e3-0900-4348-9c19-1145d73ced31,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-c6d1a714-274c-4b23-bfc1-d508a2152661,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-111f5750-068c-45ed-bff4-8841ec208d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-62a71b84-121e-409c-9d6a-b02eb2211230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152854858-172.17.0.5-1598678007006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-a77c494a-a928-4438-9ad1-f16884fdea69,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-135c26df-0162-4251-94a9-f262f4127fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-1524b340-ca59-4adf-9c39-ae0912c1d7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-41ef9719-baf5-4082-a8ea-521f6269cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9cc917e3-0900-4348-9c19-1145d73ced31,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-c6d1a714-274c-4b23-bfc1-d508a2152661,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-111f5750-068c-45ed-bff4-8841ec208d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-62a71b84-121e-409c-9d6a-b02eb2211230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640569809-172.17.0.5-1598678039461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-26fa4d21-e63e-42bf-8916-3b42a02fe49b,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-fe58911d-23ff-4ac9-beb4-8877d6b1a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-1da56606-f365-4438-8cb5-df68f4e84b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-6ebd294f-19f8-408b-8ce7-5494e4efb084,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-02e0e94f-6903-40f8-9c5b-cd7430f40ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-63746b7d-6fb8-40db-9eea-1ea08a47bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-27689105-8713-41ba-82ef-3f5ee46e177e,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-7cb2fc7b-9794-4f1b-b874-8d61693a6b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640569809-172.17.0.5-1598678039461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-26fa4d21-e63e-42bf-8916-3b42a02fe49b,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-fe58911d-23ff-4ac9-beb4-8877d6b1a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-1da56606-f365-4438-8cb5-df68f4e84b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-6ebd294f-19f8-408b-8ce7-5494e4efb084,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-02e0e94f-6903-40f8-9c5b-cd7430f40ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-63746b7d-6fb8-40db-9eea-1ea08a47bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-27689105-8713-41ba-82ef-3f5ee46e177e,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-7cb2fc7b-9794-4f1b-b874-8d61693a6b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624636742-172.17.0.5-1598678224384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-3e02205e-8db9-4c9f-8349-ef1c75f7a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-d82c6fb5-89e2-4f9d-98da-06c212906f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-44278a27-92c9-4a76-9bc1-9e7241927a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-4919b7c5-f045-46ea-b4d4-98ad9f442406,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-239d1b76-708b-4bff-a9f2-024c4e23d498,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-27e4bf2f-585c-4860-aad9-74dfeb022667,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-78871171-b5ee-40e1-96a6-0b1b9e8b743c,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ac5808a4-b852-4b03-a583-b9448faec57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624636742-172.17.0.5-1598678224384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-3e02205e-8db9-4c9f-8349-ef1c75f7a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-d82c6fb5-89e2-4f9d-98da-06c212906f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-44278a27-92c9-4a76-9bc1-9e7241927a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-4919b7c5-f045-46ea-b4d4-98ad9f442406,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-239d1b76-708b-4bff-a9f2-024c4e23d498,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-27e4bf2f-585c-4860-aad9-74dfeb022667,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-78871171-b5ee-40e1-96a6-0b1b9e8b743c,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ac5808a4-b852-4b03-a583-b9448faec57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169591544-172.17.0.5-1598678514455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-e9442ca7-c478-43e5-af92-e07faba3098e,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-34f5e039-899c-4b28-a027-1e4cea36c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-14fde987-7535-4105-956c-2eaba4c038f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-5fec3bf2-a69f-45b1-9cfa-ec4fe3bc7440,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-97d711ba-48b1-4bee-b225-50b0046c2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-bde9a6a1-14f9-487f-a934-5e6c20673b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b685c209-4c3a-4dbe-8bd8-25802aed3f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-22654353-371a-4140-b13b-89d78d88ecdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169591544-172.17.0.5-1598678514455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-e9442ca7-c478-43e5-af92-e07faba3098e,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-34f5e039-899c-4b28-a027-1e4cea36c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-14fde987-7535-4105-956c-2eaba4c038f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-5fec3bf2-a69f-45b1-9cfa-ec4fe3bc7440,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-97d711ba-48b1-4bee-b225-50b0046c2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-bde9a6a1-14f9-487f-a934-5e6c20673b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-b685c209-4c3a-4dbe-8bd8-25802aed3f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-22654353-371a-4140-b13b-89d78d88ecdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199928551-172.17.0.5-1598678648180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-a7df876b-1274-4956-9f8c-c16992c129c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-6695a35a-bbfd-4b56-8fa6-7fd623c52131,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-af035692-15e6-4084-a3a2-5d76945ac293,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-89960916-14b0-4f7c-91f5-09ff60270f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-3a1c831d-6f81-4478-852f-eead0653b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-d6ea626b-4494-487f-bfbe-98d3fe59e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-0ab38d79-712a-48d3-87e6-0b03dc017f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-9821f496-5e8e-4650-ba1b-9f8222cc2a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199928551-172.17.0.5-1598678648180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-a7df876b-1274-4956-9f8c-c16992c129c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-6695a35a-bbfd-4b56-8fa6-7fd623c52131,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-af035692-15e6-4084-a3a2-5d76945ac293,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-89960916-14b0-4f7c-91f5-09ff60270f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-3a1c831d-6f81-4478-852f-eead0653b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-d6ea626b-4494-487f-bfbe-98d3fe59e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-0ab38d79-712a-48d3-87e6-0b03dc017f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-9821f496-5e8e-4650-ba1b-9f8222cc2a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661412980-172.17.0.5-1598678984982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-df1018b6-1f83-4f9b-b7be-e64d302e4613,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-1b635717-4d65-4bb7-b0a1-bdae24d66e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-19ab6406-befe-4928-996c-a22b0d6c4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-7d2b879d-9d68-4516-bb16-9363020b47dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-e1502ae3-c173-4037-8aa5-13a143ca77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-c9448c8f-619f-4460-9a1e-e86887759f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-26191162-cba9-4b70-88dc-d0683caaba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-3f9ed984-8762-47bb-a217-4612b026e907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661412980-172.17.0.5-1598678984982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-df1018b6-1f83-4f9b-b7be-e64d302e4613,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-1b635717-4d65-4bb7-b0a1-bdae24d66e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-19ab6406-befe-4928-996c-a22b0d6c4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-7d2b879d-9d68-4516-bb16-9363020b47dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-e1502ae3-c173-4037-8aa5-13a143ca77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-c9448c8f-619f-4460-9a1e-e86887759f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-26191162-cba9-4b70-88dc-d0683caaba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-3f9ed984-8762-47bb-a217-4612b026e907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918811265-172.17.0.5-1598679025504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-e9361eb7-fffb-40d7-94f5-8fec6026e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4e444642-f7c1-4216-a227-6b6b6e9544b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-cdad6581-2047-43b7-842b-731b9a293db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-fb44d933-abda-4449-9cb4-a04bb211f5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-ec7a175d-68cc-4142-8f5f-41e19510e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-eadcda36-0a01-4f37-82fb-7884412aede0,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-c44cec15-a0fc-4a7f-b3ee-e90802210cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-1755db69-da72-4fea-b1cd-24126978a09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918811265-172.17.0.5-1598679025504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-e9361eb7-fffb-40d7-94f5-8fec6026e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4e444642-f7c1-4216-a227-6b6b6e9544b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-cdad6581-2047-43b7-842b-731b9a293db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-fb44d933-abda-4449-9cb4-a04bb211f5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-ec7a175d-68cc-4142-8f5f-41e19510e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-eadcda36-0a01-4f37-82fb-7884412aede0,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-c44cec15-a0fc-4a7f-b3ee-e90802210cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-1755db69-da72-4fea-b1cd-24126978a09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675277304-172.17.0.5-1598679176610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45864,DS-0493e37a-a52f-40b1-a107-c7713e4756fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-fa6d8164-829d-4c5e-a88f-27572414f707,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-ecb5d64f-ddd9-4404-adf0-a6a991c52923,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-c1c7d73a-27d7-4df0-a617-ebdbee848310,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-2022a3da-a564-40ae-be72-472e42d15a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-ec80aa11-5479-4803-9ebc-6e2dc63ef1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-7a761d78-b03d-4243-80b8-4e0a87ea3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-a4c43a69-fd98-4b77-be3e-af8dd19e1be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675277304-172.17.0.5-1598679176610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45864,DS-0493e37a-a52f-40b1-a107-c7713e4756fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-fa6d8164-829d-4c5e-a88f-27572414f707,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-ecb5d64f-ddd9-4404-adf0-a6a991c52923,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-c1c7d73a-27d7-4df0-a617-ebdbee848310,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-2022a3da-a564-40ae-be72-472e42d15a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-ec80aa11-5479-4803-9ebc-6e2dc63ef1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-7a761d78-b03d-4243-80b8-4e0a87ea3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-a4c43a69-fd98-4b77-be3e-af8dd19e1be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029936520-172.17.0.5-1598679638355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-29b3f0a0-b4c8-45e2-981b-3011caa976a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-a0b595d6-4d9f-4edf-984c-84e3d761314a,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-fd828051-d100-4fbd-89d5-16f018715a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bea62176-db87-486a-818f-99cdc2d7cc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-61de6883-fb0c-41ef-afbb-12121ec2ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-083cfab1-d290-46ae-8c67-5feae6fcd846,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-a0c889b2-863f-41ad-8dd3-7b44bc4d7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-1c77b68f-289b-4617-8aed-eabdf5428bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029936520-172.17.0.5-1598679638355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-29b3f0a0-b4c8-45e2-981b-3011caa976a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-a0b595d6-4d9f-4edf-984c-84e3d761314a,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-fd828051-d100-4fbd-89d5-16f018715a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bea62176-db87-486a-818f-99cdc2d7cc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-61de6883-fb0c-41ef-afbb-12121ec2ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-083cfab1-d290-46ae-8c67-5feae6fcd846,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-a0c889b2-863f-41ad-8dd3-7b44bc4d7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-1c77b68f-289b-4617-8aed-eabdf5428bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769114346-172.17.0.5-1598679680485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-8044594a-6fc9-4774-960c-19bdeadaf5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-5e80a401-0b77-41a0-8989-c6c68cfe9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-a5b6ae1d-9808-43c5-8c51-533f70165f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-c4344c58-ca15-4dcb-ab38-ed6bfa250872,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-b8013d14-addc-4ceb-a091-7aed0e4c7933,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-8bfa0212-7a01-4aaa-b041-f3e08eab0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-50706d42-dcfe-44e0-a98d-3993009c4342,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-a5f4ff01-0dcc-402f-b14b-4248e912d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769114346-172.17.0.5-1598679680485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-8044594a-6fc9-4774-960c-19bdeadaf5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-5e80a401-0b77-41a0-8989-c6c68cfe9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-a5b6ae1d-9808-43c5-8c51-533f70165f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-c4344c58-ca15-4dcb-ab38-ed6bfa250872,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-b8013d14-addc-4ceb-a091-7aed0e4c7933,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-8bfa0212-7a01-4aaa-b041-f3e08eab0c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-50706d42-dcfe-44e0-a98d-3993009c4342,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-a5f4ff01-0dcc-402f-b14b-4248e912d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106283629-172.17.0.5-1598679717977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-c602f962-f199-457e-a625-113e0d9b3684,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-cd1d901d-7581-4272-b087-1fe3c2345ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-3d96b652-9866-4742-8ef2-f5064db063ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-77f491da-ebd4-4c5a-8d47-f4343a445c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-24bc7a2e-6d0d-47fc-a940-7882583411f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e753a240-6736-40b7-aa08-549f6da550d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-e15b1b76-5519-438c-95a6-830f38ce528c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-bd178424-9e74-443c-ae18-004bb8fcbe27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106283629-172.17.0.5-1598679717977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-c602f962-f199-457e-a625-113e0d9b3684,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-cd1d901d-7581-4272-b087-1fe3c2345ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-3d96b652-9866-4742-8ef2-f5064db063ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-77f491da-ebd4-4c5a-8d47-f4343a445c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-24bc7a2e-6d0d-47fc-a940-7882583411f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e753a240-6736-40b7-aa08-549f6da550d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-e15b1b76-5519-438c-95a6-830f38ce528c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-bd178424-9e74-443c-ae18-004bb8fcbe27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730907549-172.17.0.5-1598679961635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-c1468cd5-be60-4895-af4d-962eb5d591db,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-d9d42264-047f-49c1-9aa7-60ca33c20a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-83188fd3-1c0b-4dbb-9318-d681fc89b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-ab084c43-7af6-4859-80b8-f46c171b2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-e47e2245-50d5-48f7-bcf9-b4106bcb3a51,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-57b7f5f6-1712-494e-beec-898efba8be95,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-d96eb139-720d-4587-a29f-411735887b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-a30bbfb7-e25a-4c67-acc3-83db80517843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730907549-172.17.0.5-1598679961635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-c1468cd5-be60-4895-af4d-962eb5d591db,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-d9d42264-047f-49c1-9aa7-60ca33c20a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-83188fd3-1c0b-4dbb-9318-d681fc89b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-ab084c43-7af6-4859-80b8-f46c171b2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-e47e2245-50d5-48f7-bcf9-b4106bcb3a51,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-57b7f5f6-1712-494e-beec-898efba8be95,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-d96eb139-720d-4587-a29f-411735887b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-a30bbfb7-e25a-4c67-acc3-83db80517843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230472809-172.17.0.5-1598680390963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-c8d51171-e147-426f-9204-c155b28a42b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f9fd0ce0-65cf-4124-ac25-387e0743262a,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-d4c32719-6dd8-47b9-a33c-6747850d889a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-2a09e6e0-851f-4fab-b084-d7f050457fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-1d7898b3-1ceb-4fd2-a261-62025b1f916a,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-ec65bf79-549e-4a8f-878e-a63a8aebc1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-54689aa1-6ce5-4d0e-9e7c-24b00229fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-76fd8356-361f-45e7-ad3f-c93b6a7a89b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230472809-172.17.0.5-1598680390963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-c8d51171-e147-426f-9204-c155b28a42b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f9fd0ce0-65cf-4124-ac25-387e0743262a,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-d4c32719-6dd8-47b9-a33c-6747850d889a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-2a09e6e0-851f-4fab-b084-d7f050457fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-1d7898b3-1ceb-4fd2-a261-62025b1f916a,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-ec65bf79-549e-4a8f-878e-a63a8aebc1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-54689aa1-6ce5-4d0e-9e7c-24b00229fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-76fd8356-361f-45e7-ad3f-c93b6a7a89b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508040042-172.17.0.5-1598680638190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-b799937f-1cdd-4db1-83a3-377f1d913dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-cf262626-4f4d-4ca0-8b7c-6e2048cb390c,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-e7cb3886-14a6-4d11-b91b-e77069ed5583,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-97f48adc-2767-494d-a8ca-3ea2f7c4bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-984e9412-6410-4efc-a3e5-e02c8c7b391e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b4b2a0d6-cb25-487c-8c6d-3e676542a962,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-78d66abe-c293-4b89-b33f-754138726502,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-e6400b46-3fe3-41cf-b318-5ebbbe08651a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508040042-172.17.0.5-1598680638190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43214,DS-b799937f-1cdd-4db1-83a3-377f1d913dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-cf262626-4f4d-4ca0-8b7c-6e2048cb390c,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-e7cb3886-14a6-4d11-b91b-e77069ed5583,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-97f48adc-2767-494d-a8ca-3ea2f7c4bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-984e9412-6410-4efc-a3e5-e02c8c7b391e,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b4b2a0d6-cb25-487c-8c6d-3e676542a962,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-78d66abe-c293-4b89-b33f-754138726502,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-e6400b46-3fe3-41cf-b318-5ebbbe08651a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849528746-172.17.0.5-1598680884616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-e47b83ee-81fb-400f-89d7-2185ef37913f,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-8ee5366e-faa3-4a1c-8009-c6b65072b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-7f54ce51-2654-41b5-b10f-a02d3868af31,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-bb770595-397a-4583-afbf-6f9b3ba18845,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3d1ef0b4-a957-4c29-b38e-13716ae143d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-b5540087-8881-475f-a67e-851989ada136,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-dbc81886-fe31-492d-8974-47f869258c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-6ae1a9f9-5b9a-4b27-b705-9c3bd1402341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849528746-172.17.0.5-1598680884616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41005,DS-e47b83ee-81fb-400f-89d7-2185ef37913f,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-8ee5366e-faa3-4a1c-8009-c6b65072b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-7f54ce51-2654-41b5-b10f-a02d3868af31,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-bb770595-397a-4583-afbf-6f9b3ba18845,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3d1ef0b4-a957-4c29-b38e-13716ae143d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-b5540087-8881-475f-a67e-851989ada136,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-dbc81886-fe31-492d-8974-47f869258c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-6ae1a9f9-5b9a-4b27-b705-9c3bd1402341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526514986-172.17.0.5-1598681075150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-28694cb0-3ca5-4686-81d3-9079c7a709fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-a43383c8-dce3-4b4f-9d43-135e7e2dd8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-d8eebefe-2581-476d-bfdd-9dcf6eae8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-36977584-6a87-44e6-80cb-2e10af7ffb42,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-ab453d15-5f06-4045-bcf5-e80770630866,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a378daad-149d-4ca3-b8a1-c5e1bdb84241,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-2704b251-6531-497c-9240-171456b2a054,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-c6f6656f-28d1-4e4b-bea1-0ea995e9419b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526514986-172.17.0.5-1598681075150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-28694cb0-3ca5-4686-81d3-9079c7a709fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-a43383c8-dce3-4b4f-9d43-135e7e2dd8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-d8eebefe-2581-476d-bfdd-9dcf6eae8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-36977584-6a87-44e6-80cb-2e10af7ffb42,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-ab453d15-5f06-4045-bcf5-e80770630866,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-a378daad-149d-4ca3-b8a1-c5e1bdb84241,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-2704b251-6531-497c-9240-171456b2a054,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-c6f6656f-28d1-4e4b-bea1-0ea995e9419b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65440790-172.17.0.5-1598681155547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-0b0e4ab9-07a8-4459-b416-d700c68c50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-a02e554b-b909-4cc7-8f89-6c11bda3aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-87a9a651-4b0c-46b9-80ab-c0c1db684776,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-72deaec5-279a-4303-90cd-fa39cf870866,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7bde762e-40f1-467d-ad88-7bcd9ebecfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-5542a8dd-9833-478d-9678-4bf97eb86f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-68f183cb-ff7d-420c-acef-fb340363737d,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-4bc49005-0a1c-43d9-9563-4de0bb8eaced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65440790-172.17.0.5-1598681155547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-0b0e4ab9-07a8-4459-b416-d700c68c50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-a02e554b-b909-4cc7-8f89-6c11bda3aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-87a9a651-4b0c-46b9-80ab-c0c1db684776,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-72deaec5-279a-4303-90cd-fa39cf870866,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7bde762e-40f1-467d-ad88-7bcd9ebecfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-5542a8dd-9833-478d-9678-4bf97eb86f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-68f183cb-ff7d-420c-acef-fb340363737d,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-4bc49005-0a1c-43d9-9563-4de0bb8eaced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616950503-172.17.0.5-1598682043751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-312edbe5-cf40-46a3-b6c0-19154cc17161,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6680df82-f10e-403c-b6f5-1801c9536584,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-0cefd7e9-c45e-4734-bf22-565833c80413,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-a656378f-2590-45a4-817b-9750bcf35228,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-eec60b4e-dcd2-4ac2-acec-81ace9e1eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-52b848b0-1566-4238-b7e7-91ef549966bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0f7ddb88-1478-4cea-94e2-a505a548fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-65b7f95a-a262-405c-ba54-f5cd24457d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616950503-172.17.0.5-1598682043751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-312edbe5-cf40-46a3-b6c0-19154cc17161,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6680df82-f10e-403c-b6f5-1801c9536584,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-0cefd7e9-c45e-4734-bf22-565833c80413,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-a656378f-2590-45a4-817b-9750bcf35228,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-eec60b4e-dcd2-4ac2-acec-81ace9e1eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-52b848b0-1566-4238-b7e7-91ef549966bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0f7ddb88-1478-4cea-94e2-a505a548fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-65b7f95a-a262-405c-ba54-f5cd24457d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719099209-172.17.0.5-1598682574669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-3dc4388c-9cbd-457c-b81d-7cbaa2785930,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-42bf5ad8-c204-47c5-867f-82d34ac6dae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-4cd842e6-cda3-410e-9fc2-4d15119ccb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-1946db5e-cf58-42e4-80c4-e90fc5243f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7fd988ee-b3cc-461a-9507-b89721bc45c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-2fe4cc30-3cab-4158-a9a2-e0ed831b44ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-949b2000-a0fc-4025-864f-932daf9fb7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-5f9ee642-bbd1-4f14-9e38-11baddd049d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719099209-172.17.0.5-1598682574669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-3dc4388c-9cbd-457c-b81d-7cbaa2785930,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-42bf5ad8-c204-47c5-867f-82d34ac6dae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-4cd842e6-cda3-410e-9fc2-4d15119ccb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-1946db5e-cf58-42e4-80c4-e90fc5243f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7fd988ee-b3cc-461a-9507-b89721bc45c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-2fe4cc30-3cab-4158-a9a2-e0ed831b44ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-949b2000-a0fc-4025-864f-932daf9fb7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-5f9ee642-bbd1-4f14-9e38-11baddd049d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5431
