reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066662311-172.17.0.3-1598622827026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-6e0acab7-d0e1-4ef0-93e9-ff3d09a90d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-a8c6bd8b-5bc5-4eee-b855-c7131bfb6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-b66e659e-9f8e-4be8-ade5-bc3d6df9ff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-9c7f252e-cd41-4b39-aea7-0a02b2b7e348,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-767ca394-9c39-40cf-9ac5-355086d1a907,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-455eaacf-02fc-473a-bf47-d92fd3b96b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-d1a1a921-578c-452c-95f4-15b38e205a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-bb92f068-c59e-4680-b4f9-a96841da6f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066662311-172.17.0.3-1598622827026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-6e0acab7-d0e1-4ef0-93e9-ff3d09a90d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-a8c6bd8b-5bc5-4eee-b855-c7131bfb6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-b66e659e-9f8e-4be8-ade5-bc3d6df9ff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-9c7f252e-cd41-4b39-aea7-0a02b2b7e348,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-767ca394-9c39-40cf-9ac5-355086d1a907,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-455eaacf-02fc-473a-bf47-d92fd3b96b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-d1a1a921-578c-452c-95f4-15b38e205a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-bb92f068-c59e-4680-b4f9-a96841da6f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473399004-172.17.0.3-1598624129480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-76592884-f099-4240-a44d-e76b8ff8516d,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-b0b70ad7-6c37-4680-ad1f-65b3a884ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-74c5f8ca-af72-4bea-847c-c7c9d56c8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-37f67fa5-f261-4c49-81c2-923959115479,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-0cad9d0e-05e4-4283-87fe-8327b09389d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5552f6c4-fc96-404a-9208-b693cf8e0472,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-7f8afab0-226e-44ba-aaf8-e28366ba0253,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-b89f9c93-2379-4c88-90bc-de7181c6319d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473399004-172.17.0.3-1598624129480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-76592884-f099-4240-a44d-e76b8ff8516d,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-b0b70ad7-6c37-4680-ad1f-65b3a884ecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-74c5f8ca-af72-4bea-847c-c7c9d56c8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-37f67fa5-f261-4c49-81c2-923959115479,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-0cad9d0e-05e4-4283-87fe-8327b09389d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5552f6c4-fc96-404a-9208-b693cf8e0472,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-7f8afab0-226e-44ba-aaf8-e28366ba0253,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-b89f9c93-2379-4c88-90bc-de7181c6319d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088535782-172.17.0.3-1598625009743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-c745c404-bb05-4ba4-bcb4-1adf9d0957ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-0344c7da-d2b2-4d20-87f3-c51fc9fc9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-a9a3ee59-6604-4577-8765-847cba5036a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f4f4b21a-3b82-48d4-aa9c-bf3f9654c484,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-b61d6065-d0ff-40de-a356-f29b185fe15b,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-ab428aa9-9189-4342-b573-e1cbc913f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-857a225b-7551-4df0-a678-129d30548571,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-7a805469-4b1f-4151-a49f-19c7ffa66a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088535782-172.17.0.3-1598625009743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-c745c404-bb05-4ba4-bcb4-1adf9d0957ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-0344c7da-d2b2-4d20-87f3-c51fc9fc9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-a9a3ee59-6604-4577-8765-847cba5036a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f4f4b21a-3b82-48d4-aa9c-bf3f9654c484,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-b61d6065-d0ff-40de-a356-f29b185fe15b,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-ab428aa9-9189-4342-b573-e1cbc913f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-857a225b-7551-4df0-a678-129d30548571,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-7a805469-4b1f-4151-a49f-19c7ffa66a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312516762-172.17.0.3-1598625470217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-9b65926f-41ee-47ae-a6ef-5db21668993d,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-e3594a40-8b0b-4ee8-8b52-ebefb9855ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ca727110-0aea-4323-9fe3-05f63320bad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-52d39dbd-2b41-4e00-b6f8-b733d2bc5070,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-cf581829-71c4-4970-96f7-8402c43a9999,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-e60ace72-d65c-4593-ab47-1ae0c36563e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-b4403586-333d-4109-947e-372bdd04d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ab0e46f3-7da0-493c-8d32-b367c06746fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312516762-172.17.0.3-1598625470217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-9b65926f-41ee-47ae-a6ef-5db21668993d,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-e3594a40-8b0b-4ee8-8b52-ebefb9855ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ca727110-0aea-4323-9fe3-05f63320bad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-52d39dbd-2b41-4e00-b6f8-b733d2bc5070,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-cf581829-71c4-4970-96f7-8402c43a9999,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-e60ace72-d65c-4593-ab47-1ae0c36563e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-b4403586-333d-4109-947e-372bdd04d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ab0e46f3-7da0-493c-8d32-b367c06746fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480159757-172.17.0.3-1598625686207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-aebf20bb-5aa1-4bc3-b1d6-1a054e1504e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-ccf81b85-5dfb-441f-9025-4a2c0f55a59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-fbfbedd8-f253-4290-a0d2-6dd53f245d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-58896bb8-8196-46af-9304-0797c670a244,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-eee01668-fab4-4def-8e6b-e0886c070d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-82d957a1-2c53-4e6a-9036-380305f04422,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-af1f4c19-127a-4f70-92c2-ff55f5690c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-c0cb4e61-8dad-450c-90eb-9fa6b6bd830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480159757-172.17.0.3-1598625686207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-aebf20bb-5aa1-4bc3-b1d6-1a054e1504e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-ccf81b85-5dfb-441f-9025-4a2c0f55a59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-fbfbedd8-f253-4290-a0d2-6dd53f245d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-58896bb8-8196-46af-9304-0797c670a244,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-eee01668-fab4-4def-8e6b-e0886c070d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-82d957a1-2c53-4e6a-9036-380305f04422,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-af1f4c19-127a-4f70-92c2-ff55f5690c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-c0cb4e61-8dad-450c-90eb-9fa6b6bd830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942666889-172.17.0.3-1598625767232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-cc1b4917-043f-40ba-bc58-17a1cca06005,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-eac99b1a-203d-4247-bac8-6ed92e2964e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-fc3c7fa7-7e07-4ee3-aaaf-f8f1c375ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-0f17e5a1-fe78-4959-99d3-d314ccd8d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-193299c8-d5bc-471c-aa12-58b21b7a32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-74e3d405-e560-415c-b581-170787eedd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-6061104b-362e-4ae0-a422-ceadf4ae6395,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f5705061-25e1-4447-80bb-564efba61034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942666889-172.17.0.3-1598625767232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-cc1b4917-043f-40ba-bc58-17a1cca06005,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-eac99b1a-203d-4247-bac8-6ed92e2964e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-fc3c7fa7-7e07-4ee3-aaaf-f8f1c375ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-0f17e5a1-fe78-4959-99d3-d314ccd8d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-193299c8-d5bc-471c-aa12-58b21b7a32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-74e3d405-e560-415c-b581-170787eedd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-6061104b-362e-4ae0-a422-ceadf4ae6395,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f5705061-25e1-4447-80bb-564efba61034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005215692-172.17.0.3-1598625880983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-47516ae1-87a0-49d1-bfba-1089caef63cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-46ee643e-5cf6-4bbd-8f4a-56329c6b3a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-42097ce9-78f9-4023-8edc-4bce5c34da57,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bd38bf95-2329-4a4f-a375-ebff9ff41624,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-02c7880d-34b5-4c72-bde0-0008bdd9ed44,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-a62f2599-4efe-419c-8adb-8ae4605ca306,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-3dbd4d75-acba-4a40-ad43-82df64120fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-a8cd2c66-b113-4ba5-ab16-699ae95f9b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005215692-172.17.0.3-1598625880983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-47516ae1-87a0-49d1-bfba-1089caef63cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-46ee643e-5cf6-4bbd-8f4a-56329c6b3a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-42097ce9-78f9-4023-8edc-4bce5c34da57,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-bd38bf95-2329-4a4f-a375-ebff9ff41624,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-02c7880d-34b5-4c72-bde0-0008bdd9ed44,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-a62f2599-4efe-419c-8adb-8ae4605ca306,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-3dbd4d75-acba-4a40-ad43-82df64120fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-a8cd2c66-b113-4ba5-ab16-699ae95f9b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533294488-172.17.0.3-1598626762673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-b925e905-6744-4fe0-874b-68b1ea30c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-a131a7c7-ad96-40bd-95b9-312368d001d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-cd8099c8-49c1-4724-a251-c25f43115b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-7b6c08a7-701e-4e87-9391-c89ebd494049,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-47dd88dc-4453-4043-9719-f41058bda199,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-10fe5629-2645-469d-8323-390b18c4e691,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-341cc669-b514-4a57-8674-d05d1da6f3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-b008a48a-b580-4601-8275-7dbda662c249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533294488-172.17.0.3-1598626762673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-b925e905-6744-4fe0-874b-68b1ea30c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-a131a7c7-ad96-40bd-95b9-312368d001d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-cd8099c8-49c1-4724-a251-c25f43115b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-7b6c08a7-701e-4e87-9391-c89ebd494049,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-47dd88dc-4453-4043-9719-f41058bda199,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-10fe5629-2645-469d-8323-390b18c4e691,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-341cc669-b514-4a57-8674-d05d1da6f3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-b008a48a-b580-4601-8275-7dbda662c249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671089161-172.17.0.3-1598626925096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-8475d309-a018-478b-81fa-b9e0bc0ef8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-7bfbe89f-e028-41aa-9682-f51353374c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-8dffd057-6e6e-44c1-8d06-bb09cf768cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-e5801861-7706-40a8-b583-3fd3ff4f4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-5cc4e7ef-4985-4df1-aba5-a16d4db3aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e9c7d4ba-8c0b-4dcd-b435-c60826cdaa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-462718e7-cfaf-497a-950e-ebd4792ad68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0f282c6f-e62a-4262-b42b-7c831519ae2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671089161-172.17.0.3-1598626925096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-8475d309-a018-478b-81fa-b9e0bc0ef8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-7bfbe89f-e028-41aa-9682-f51353374c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-8dffd057-6e6e-44c1-8d06-bb09cf768cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-e5801861-7706-40a8-b583-3fd3ff4f4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-5cc4e7ef-4985-4df1-aba5-a16d4db3aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e9c7d4ba-8c0b-4dcd-b435-c60826cdaa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-462718e7-cfaf-497a-950e-ebd4792ad68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0f282c6f-e62a-4262-b42b-7c831519ae2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874603790-172.17.0.3-1598627059198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43674,DS-f4a5d3e8-a5ad-4d5d-8f14-c3bd902fcf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-d2f11951-b4f8-4003-964d-577942fb4738,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-f8f6abbe-21ab-48c8-a18e-ea98254525c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-6d8dbc61-0b71-4766-8e2d-ea70b33bf1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ed76d755-34f7-4520-8652-10a158eab230,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-8477d3cc-d26e-4dde-9a26-1f091ea722b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b9a07d19-cbdd-40c0-b75c-8f08562e2559,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-6a2d1c0e-16e4-481e-b95b-0cd4cc294cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874603790-172.17.0.3-1598627059198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43674,DS-f4a5d3e8-a5ad-4d5d-8f14-c3bd902fcf18,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-d2f11951-b4f8-4003-964d-577942fb4738,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-f8f6abbe-21ab-48c8-a18e-ea98254525c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-6d8dbc61-0b71-4766-8e2d-ea70b33bf1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-ed76d755-34f7-4520-8652-10a158eab230,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-8477d3cc-d26e-4dde-9a26-1f091ea722b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b9a07d19-cbdd-40c0-b75c-8f08562e2559,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-6a2d1c0e-16e4-481e-b95b-0cd4cc294cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971085142-172.17.0.3-1598627094212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-3c933c13-a1fd-4273-b1d5-6dec4ff1259e,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-6632bd40-47fe-417d-8ce3-9bbec2ebc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-2cdba2d8-668c-4607-9c83-ce973385b399,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-0bc06f3b-4c2d-4f13-8cc4-45741974b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-cf36283b-55c9-4918-9e5b-8b573474b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-2150d40b-3385-4883-8f49-9f361582f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-e5eb1a9c-9cce-4871-b4f8-639fb5936ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2884bbb9-6e6c-426c-8286-7b93786fc8c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971085142-172.17.0.3-1598627094212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-3c933c13-a1fd-4273-b1d5-6dec4ff1259e,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-6632bd40-47fe-417d-8ce3-9bbec2ebc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-2cdba2d8-668c-4607-9c83-ce973385b399,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-0bc06f3b-4c2d-4f13-8cc4-45741974b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-cf36283b-55c9-4918-9e5b-8b573474b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-2150d40b-3385-4883-8f49-9f361582f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-e5eb1a9c-9cce-4871-b4f8-639fb5936ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2884bbb9-6e6c-426c-8286-7b93786fc8c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993354578-172.17.0.3-1598627337569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-23d8cbc4-0cd8-48a4-8f8e-0cbc94b0ea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-47806625-eb05-4f99-a853-1b3003560d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-8058090e-03b7-4e18-8513-2973cd51451b,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-f1b6f4f1-ce6c-4758-8701-6959c67cd478,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-05a71725-3cdd-4fc2-91c5-7ad607a9dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-9671391e-e965-4db1-8600-c62d28d8dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-78176973-b89a-4587-840f-7fbf8b0233a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-fc41c3c5-e4fa-4d34-aeb8-5c4397b7486f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993354578-172.17.0.3-1598627337569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-23d8cbc4-0cd8-48a4-8f8e-0cbc94b0ea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-47806625-eb05-4f99-a853-1b3003560d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-8058090e-03b7-4e18-8513-2973cd51451b,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-f1b6f4f1-ce6c-4758-8701-6959c67cd478,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-05a71725-3cdd-4fc2-91c5-7ad607a9dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-9671391e-e965-4db1-8600-c62d28d8dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-78176973-b89a-4587-840f-7fbf8b0233a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-fc41c3c5-e4fa-4d34-aeb8-5c4397b7486f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681942926-172.17.0.3-1598627729098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38832,DS-e566657d-f1d2-4abd-94ca-a069f2c8da78,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-93e87196-7baf-4d28-b1ba-38e637646575,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-791ade32-8750-4855-b502-330e040f43b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-bed3ad7f-73f5-4944-a616-9cdebea79d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-3e57bb96-8cc8-459d-9094-fe05f27f03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-4f09ccb0-3994-479f-bb1f-7f3ef4e155f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-a4c75d3a-e0cc-4dd5-bd7c-2967e642ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-0412ce71-f4d1-4804-b955-b01e3902ab1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681942926-172.17.0.3-1598627729098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38832,DS-e566657d-f1d2-4abd-94ca-a069f2c8da78,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-93e87196-7baf-4d28-b1ba-38e637646575,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-791ade32-8750-4855-b502-330e040f43b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-bed3ad7f-73f5-4944-a616-9cdebea79d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-3e57bb96-8cc8-459d-9094-fe05f27f03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-4f09ccb0-3994-479f-bb1f-7f3ef4e155f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-a4c75d3a-e0cc-4dd5-bd7c-2967e642ee95,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-0412ce71-f4d1-4804-b955-b01e3902ab1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293999509-172.17.0.3-1598627847313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-132ccf13-e03e-4c59-a70d-6b17f2193cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fe2906bb-7371-48d2-b2c8-5fb31dd85d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-e73c9e97-38d0-4a25-9397-6711844e1163,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-c18b9f19-8cee-495e-a152-58aafd5b44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-865a8bce-d929-4c8d-ae3b-6d6558b61028,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-6b9e36dd-27e2-4d63-8fd6-36730e8c5425,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b9a88e83-028d-44c1-9986-1dbf19a92641,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-a94895fc-d45c-45c2-a801-d2cf517245b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293999509-172.17.0.3-1598627847313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44122,DS-132ccf13-e03e-4c59-a70d-6b17f2193cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fe2906bb-7371-48d2-b2c8-5fb31dd85d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-e73c9e97-38d0-4a25-9397-6711844e1163,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-c18b9f19-8cee-495e-a152-58aafd5b44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-865a8bce-d929-4c8d-ae3b-6d6558b61028,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-6b9e36dd-27e2-4d63-8fd6-36730e8c5425,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b9a88e83-028d-44c1-9986-1dbf19a92641,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-a94895fc-d45c-45c2-a801-d2cf517245b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5374
