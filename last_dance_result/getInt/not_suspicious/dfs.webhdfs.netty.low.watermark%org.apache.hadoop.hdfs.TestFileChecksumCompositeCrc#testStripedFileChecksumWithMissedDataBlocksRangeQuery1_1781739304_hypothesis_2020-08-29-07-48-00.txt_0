reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268496453-172.17.0.11-1598687394860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-26f91e6d-6b74-413d-b268-543d744266f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d9cf728d-8f86-417c-9270-0853f837bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f279bcad-f59f-48ab-8447-6665dcbcfabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-1415ce51-9d23-4958-b6d9-7018fb64bacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-c0c69dae-fd1e-42f7-97c1-870920883e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1f4f5d08-a16f-45e5-baad-a0b647e482eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5d35e686-ce94-4641-bc44-a2d50b3edb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-994df61f-8f2f-4944-8acd-6c481d4e468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268496453-172.17.0.11-1598687394860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-26f91e6d-6b74-413d-b268-543d744266f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d9cf728d-8f86-417c-9270-0853f837bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f279bcad-f59f-48ab-8447-6665dcbcfabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-1415ce51-9d23-4958-b6d9-7018fb64bacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-c0c69dae-fd1e-42f7-97c1-870920883e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1f4f5d08-a16f-45e5-baad-a0b647e482eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5d35e686-ce94-4641-bc44-a2d50b3edb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-994df61f-8f2f-4944-8acd-6c481d4e468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130169106-172.17.0.11-1598688003975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-4ea86113-7942-4783-a189-27a50354091a,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-14235648-a7e8-487c-9261-ec9e97f5c170,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-0bcff487-5a41-4c4a-b270-78b173eec214,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-64cd3587-ca0f-4b5f-901c-940db5ae68b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-b42489cd-32fe-40a8-b1ce-26ed5390b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-e8973610-8374-4e6f-b7c6-62c1d41b5730,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-3ad6f367-1c80-407f-b723-772a08e4a149,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e49f3eaa-1e79-463c-be7c-77bd7ef4a8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130169106-172.17.0.11-1598688003975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-4ea86113-7942-4783-a189-27a50354091a,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-14235648-a7e8-487c-9261-ec9e97f5c170,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-0bcff487-5a41-4c4a-b270-78b173eec214,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-64cd3587-ca0f-4b5f-901c-940db5ae68b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-b42489cd-32fe-40a8-b1ce-26ed5390b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-e8973610-8374-4e6f-b7c6-62c1d41b5730,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-3ad6f367-1c80-407f-b723-772a08e4a149,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e49f3eaa-1e79-463c-be7c-77bd7ef4a8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957154026-172.17.0.11-1598688336352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-9c9654f8-98fa-41ab-a81b-8a88074b3167,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1e93d529-385b-41d0-91eb-266ac6ae8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-8c0c20d4-0d67-4c10-882d-ae9c8f703c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-2f1eb3d7-7191-4a13-98d7-2cdec27669b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-c60d1eed-f7ca-41bb-b89b-1c952ff5dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-717e5a15-1497-4110-b062-90aaf8354e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-9f56f01e-ff53-4fff-a6e5-30d8137ead82,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-adb92b55-cba0-49db-99b8-896d23d5c9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957154026-172.17.0.11-1598688336352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-9c9654f8-98fa-41ab-a81b-8a88074b3167,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-1e93d529-385b-41d0-91eb-266ac6ae8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-8c0c20d4-0d67-4c10-882d-ae9c8f703c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-2f1eb3d7-7191-4a13-98d7-2cdec27669b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-c60d1eed-f7ca-41bb-b89b-1c952ff5dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-717e5a15-1497-4110-b062-90aaf8354e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-9f56f01e-ff53-4fff-a6e5-30d8137ead82,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-adb92b55-cba0-49db-99b8-896d23d5c9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997509657-172.17.0.11-1598688367559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39536,DS-82c5c19e-fe75-4d68-849e-ca297defed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-223a7f24-9a26-4162-841a-727ee860a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0c808276-6624-42ed-aea9-97c213b8c310,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-d1e35d92-c175-4ca4-8424-76c47f5ad2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-a827c8ae-fce3-4760-b2c1-b9a39d505bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-66ec2070-a85e-409c-932e-91254eaaf33b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-79484f7b-8550-4d36-99eb-24a7039cd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-45ba068f-1ca5-4357-8d37-46f32d2c91e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997509657-172.17.0.11-1598688367559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39536,DS-82c5c19e-fe75-4d68-849e-ca297defed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-223a7f24-9a26-4162-841a-727ee860a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0c808276-6624-42ed-aea9-97c213b8c310,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-d1e35d92-c175-4ca4-8424-76c47f5ad2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-a827c8ae-fce3-4760-b2c1-b9a39d505bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-66ec2070-a85e-409c-932e-91254eaaf33b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-79484f7b-8550-4d36-99eb-24a7039cd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-45ba068f-1ca5-4357-8d37-46f32d2c91e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145409378-172.17.0.11-1598688474818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43720,DS-ed3122b5-d0fa-4b1c-bcd6-8f48c2e44806,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-4c446350-69f5-4db5-bf2f-13ca501f0c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-d4a7ac4d-c8ec-47e5-9fb7-feab4438fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-09e90883-c746-4366-a1f7-27cbc307ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-fd02a43c-40e3-4040-9535-ab5dd000e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f71e2cb8-29bd-423f-83ae-a8de4c9277ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-26cc78cc-2ba8-46ee-9f67-651c9ecaf2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-9ac2ab61-c7e3-45fc-a82b-822d38f19277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145409378-172.17.0.11-1598688474818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43720,DS-ed3122b5-d0fa-4b1c-bcd6-8f48c2e44806,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-4c446350-69f5-4db5-bf2f-13ca501f0c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-d4a7ac4d-c8ec-47e5-9fb7-feab4438fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-09e90883-c746-4366-a1f7-27cbc307ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-fd02a43c-40e3-4040-9535-ab5dd000e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f71e2cb8-29bd-423f-83ae-a8de4c9277ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-26cc78cc-2ba8-46ee-9f67-651c9ecaf2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-9ac2ab61-c7e3-45fc-a82b-822d38f19277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883188102-172.17.0.11-1598689002737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-ca7d0460-c7f3-4d80-b8cc-623399c3ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-1429da67-7049-4d08-978a-824979d9d86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-b7f5a4b7-bf13-4d16-9e5a-48b8d94886e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-2cdaaca2-4411-4f4c-a3f0-c8759e13036c,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-2c7614bb-cbd9-46e3-82f7-aaef6225ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-c1875e77-2927-433e-a204-1f7884100ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-6a18c012-c2f9-427f-99aa-fd2e6a3b5823,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-654386e4-0413-4d57-9e0a-eb05ff9b7380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883188102-172.17.0.11-1598689002737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-ca7d0460-c7f3-4d80-b8cc-623399c3ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-1429da67-7049-4d08-978a-824979d9d86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-b7f5a4b7-bf13-4d16-9e5a-48b8d94886e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-2cdaaca2-4411-4f4c-a3f0-c8759e13036c,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-2c7614bb-cbd9-46e3-82f7-aaef6225ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-c1875e77-2927-433e-a204-1f7884100ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-6a18c012-c2f9-427f-99aa-fd2e6a3b5823,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-654386e4-0413-4d57-9e0a-eb05ff9b7380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596085225-172.17.0.11-1598689873950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-0d6c0719-48b8-4b33-b755-3ab31fc03e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-0ada0362-2aee-40bf-a1a5-52e16ace470e,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-39dd6b32-f6d6-4b5a-be29-dfbebc8f780a,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4fc97c97-5393-4dc4-a9b0-6819bae8e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-1c1aa56b-810d-4e6d-bfc9-71c4424f3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-65a8dd4a-a2a6-48f9-b8d2-ebed31ccbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-ee371901-4abf-4eff-b073-916b587ec385,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-c2c73aa0-022b-41df-aa62-8a429a938e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596085225-172.17.0.11-1598689873950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-0d6c0719-48b8-4b33-b755-3ab31fc03e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-0ada0362-2aee-40bf-a1a5-52e16ace470e,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-39dd6b32-f6d6-4b5a-be29-dfbebc8f780a,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4fc97c97-5393-4dc4-a9b0-6819bae8e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-1c1aa56b-810d-4e6d-bfc9-71c4424f3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-65a8dd4a-a2a6-48f9-b8d2-ebed31ccbcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-ee371901-4abf-4eff-b073-916b587ec385,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-c2c73aa0-022b-41df-aa62-8a429a938e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645245987-172.17.0.11-1598689953024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45513,DS-ce055343-3ab9-42d3-b1c6-c0ba359292e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-c060ebfe-bfb1-4709-8b6d-ba1c1e2463b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-8350ad53-515a-44c6-8159-fb993b77e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-2ef0644d-2137-4c35-b83d-b16581703b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-83d5e1df-8845-460b-90ea-832bef7fd3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-3fba3ee0-338d-470c-850f-71d71e6dde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-c98e531d-df3b-49c2-b34e-f1f7ed9bee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-597c8260-77d7-412b-93d4-a3214ce5397a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645245987-172.17.0.11-1598689953024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45513,DS-ce055343-3ab9-42d3-b1c6-c0ba359292e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-c060ebfe-bfb1-4709-8b6d-ba1c1e2463b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-8350ad53-515a-44c6-8159-fb993b77e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-2ef0644d-2137-4c35-b83d-b16581703b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-83d5e1df-8845-460b-90ea-832bef7fd3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-3fba3ee0-338d-470c-850f-71d71e6dde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-c98e531d-df3b-49c2-b34e-f1f7ed9bee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-597c8260-77d7-412b-93d4-a3214ce5397a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402308343-172.17.0.11-1598690238034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-0dd43c26-6aa6-4a8d-a9e9-8de9abd0f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-aa41dfe1-23cd-4ac2-8561-7f15a44c4baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-637695c9-864f-44f7-a4e3-203fef55e079,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-86e9aba3-db3b-4c7b-993f-2d5f6f1ebf39,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-023de614-f286-46ed-beff-fa5b7a0f6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-eb4e8112-1ba8-4ad2-bc60-ffe7dc23f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-dac5cdd4-558a-45b7-bc7b-22b2db9563e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-bb09e007-b108-46bb-834e-6608f30a3869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402308343-172.17.0.11-1598690238034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-0dd43c26-6aa6-4a8d-a9e9-8de9abd0f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-aa41dfe1-23cd-4ac2-8561-7f15a44c4baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-637695c9-864f-44f7-a4e3-203fef55e079,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-86e9aba3-db3b-4c7b-993f-2d5f6f1ebf39,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-023de614-f286-46ed-beff-fa5b7a0f6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-eb4e8112-1ba8-4ad2-bc60-ffe7dc23f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-dac5cdd4-558a-45b7-bc7b-22b2db9563e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-bb09e007-b108-46bb-834e-6608f30a3869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580493385-172.17.0.11-1598690546306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-8d7174cd-d8b2-4229-85c5-7c36d468908e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-a6026aa1-f8ed-4767-95b2-ec4e9db6b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-a60969ab-231c-4912-b9d6-28d7af0b36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-6554bf4d-5d41-4542-973b-adc9336621e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-338b432b-47cb-4abe-92be-22eae4e9082b,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-02c0e3a2-4fd6-472a-a922-214996a1e485,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-2d131c15-a8c0-4e95-8c36-2f322342bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-93b8a660-0b34-47be-95c4-ca055f066d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580493385-172.17.0.11-1598690546306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32791,DS-8d7174cd-d8b2-4229-85c5-7c36d468908e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-a6026aa1-f8ed-4767-95b2-ec4e9db6b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-a60969ab-231c-4912-b9d6-28d7af0b36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-6554bf4d-5d41-4542-973b-adc9336621e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-338b432b-47cb-4abe-92be-22eae4e9082b,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-02c0e3a2-4fd6-472a-a922-214996a1e485,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-2d131c15-a8c0-4e95-8c36-2f322342bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-93b8a660-0b34-47be-95c4-ca055f066d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985443375-172.17.0.11-1598691001345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-54a0be18-7667-45a4-8b55-d32321d221a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-c092597f-27d9-49ec-b8f7-20c844e39934,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-28080e8a-939f-4cf5-a90f-577c0505438a,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-9ac35f4a-1bb2-4348-a489-6784410f4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-ef9c2782-3664-4b0f-a8ee-1207e4543f96,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-e4ae8c4c-00da-41b1-b7eb-621102283dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-59e224bc-efaa-4bf5-990f-8dab482dbe57,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-fdc5fe44-dac0-41c6-ae27-0e79d7f82a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985443375-172.17.0.11-1598691001345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-54a0be18-7667-45a4-8b55-d32321d221a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-c092597f-27d9-49ec-b8f7-20c844e39934,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-28080e8a-939f-4cf5-a90f-577c0505438a,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-9ac35f4a-1bb2-4348-a489-6784410f4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-ef9c2782-3664-4b0f-a8ee-1207e4543f96,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-e4ae8c4c-00da-41b1-b7eb-621102283dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-59e224bc-efaa-4bf5-990f-8dab482dbe57,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-fdc5fe44-dac0-41c6-ae27-0e79d7f82a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488501707-172.17.0.11-1598691111101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-c538990f-bc24-40cc-b52c-ce8f29d7ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-3a181177-7571-4faa-bc2f-8ed4ba34bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-36648fab-71b4-4a50-9a2b-b42330f53178,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-5f6809b1-a4d6-447f-939d-622396b3fc92,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-5ed108f7-7ffc-406b-8860-dfebaaeed94b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-095b61dd-be41-48a1-a9bd-f19f11366b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-c37370eb-509a-4631-95fb-776ee0256d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-e9be7b8d-5076-404f-9641-7a1be92d3ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488501707-172.17.0.11-1598691111101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-c538990f-bc24-40cc-b52c-ce8f29d7ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-3a181177-7571-4faa-bc2f-8ed4ba34bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-36648fab-71b4-4a50-9a2b-b42330f53178,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-5f6809b1-a4d6-447f-939d-622396b3fc92,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-5ed108f7-7ffc-406b-8860-dfebaaeed94b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-095b61dd-be41-48a1-a9bd-f19f11366b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-c37370eb-509a-4631-95fb-776ee0256d55,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-e9be7b8d-5076-404f-9641-7a1be92d3ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148068329-172.17.0.11-1598691148579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-df0c7f88-29e5-4b6b-91e4-79e26db77138,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c729d9f3-2745-4cf2-991f-e0920850d7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-b0b3ff6c-331b-4c9b-9b10-2ead24b8248f,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a380ec80-687d-49b3-8ace-6687584bd66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-38271307-f0c4-44df-b803-5ee37ffaeb09,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-78c7c61a-aee2-4f88-a81e-5b23b6ee25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-96ff3ef3-f4fa-46db-8386-ed1a86734b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-35b5d096-c5df-4523-bda6-d41173aeccc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148068329-172.17.0.11-1598691148579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-df0c7f88-29e5-4b6b-91e4-79e26db77138,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-c729d9f3-2745-4cf2-991f-e0920850d7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-b0b3ff6c-331b-4c9b-9b10-2ead24b8248f,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-a380ec80-687d-49b3-8ace-6687584bd66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-38271307-f0c4-44df-b803-5ee37ffaeb09,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-78c7c61a-aee2-4f88-a81e-5b23b6ee25f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-96ff3ef3-f4fa-46db-8386-ed1a86734b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-35b5d096-c5df-4523-bda6-d41173aeccc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384119107-172.17.0.11-1598691285490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-ef3273ff-755c-4de1-924d-d6dabd1f5a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-9c15eff3-835e-44f8-a29a-796fd0fbe464,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-f8475d60-0a38-4656-ae5e-6c1a1cc4c050,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-02616840-8a24-4ad7-b914-d82a0ebe726e,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-ea2b4238-a9cd-4db7-9468-23aa6cf59b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-12f5e8c3-c9bb-4fc5-b2f4-125cb1d04f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-30764bb8-4e16-474a-93b6-de6ba69f1ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-d0e61f94-c899-472e-aebc-19ff060cfdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384119107-172.17.0.11-1598691285490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-ef3273ff-755c-4de1-924d-d6dabd1f5a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-9c15eff3-835e-44f8-a29a-796fd0fbe464,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-f8475d60-0a38-4656-ae5e-6c1a1cc4c050,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-02616840-8a24-4ad7-b914-d82a0ebe726e,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-ea2b4238-a9cd-4db7-9468-23aa6cf59b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-12f5e8c3-c9bb-4fc5-b2f4-125cb1d04f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-30764bb8-4e16-474a-93b6-de6ba69f1ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-d0e61f94-c899-472e-aebc-19ff060cfdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418914120-172.17.0.11-1598691562324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-cc60b9c6-4d82-4833-9130-8eccef861e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-082e5c9d-8e4b-4bf8-8525-d02b5c30e8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-c9398994-daba-4d2c-9fdd-c04d758743eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-962e9e66-74aa-41c3-8319-8d2cd868f998,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-2e15ba89-0840-450c-96f9-3f6c690edc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-49688744-7611-416d-ab13-432e6ef1e131,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-def743c6-641a-483a-ac51-8b356c95f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-2cbf5f26-9256-4a75-99fe-7fb8f0bf420c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418914120-172.17.0.11-1598691562324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-cc60b9c6-4d82-4833-9130-8eccef861e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-082e5c9d-8e4b-4bf8-8525-d02b5c30e8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-c9398994-daba-4d2c-9fdd-c04d758743eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-962e9e66-74aa-41c3-8319-8d2cd868f998,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-2e15ba89-0840-450c-96f9-3f6c690edc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-49688744-7611-416d-ab13-432e6ef1e131,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-def743c6-641a-483a-ac51-8b356c95f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-2cbf5f26-9256-4a75-99fe-7fb8f0bf420c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329680203-172.17.0.11-1598692049336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-4de19333-262d-409a-890b-abafcf8519d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-7fbefb8a-e169-4765-b68a-5c70cfa5e961,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-80e2c740-5568-4f28-91fd-5eb0b3cd7159,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-10f01524-5e97-4787-9b8d-164592e43fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-0769dad6-5b60-41d3-91f4-9ab84d2a01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-831965e1-7ea4-4e27-b653-ad65665de861,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-e0044c5c-9211-4f4b-b7cb-c4862949fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-d5014191-96d4-4247-9cc7-c9fa4664422d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329680203-172.17.0.11-1598692049336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-4de19333-262d-409a-890b-abafcf8519d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-7fbefb8a-e169-4765-b68a-5c70cfa5e961,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-80e2c740-5568-4f28-91fd-5eb0b3cd7159,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-10f01524-5e97-4787-9b8d-164592e43fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-0769dad6-5b60-41d3-91f4-9ab84d2a01b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-831965e1-7ea4-4e27-b653-ad65665de861,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-e0044c5c-9211-4f4b-b7cb-c4862949fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-d5014191-96d4-4247-9cc7-c9fa4664422d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760908820-172.17.0.11-1598692471876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-39dc315b-ec6f-4af6-a8d0-b3e2d454dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b25945ce-fa63-4e8e-80a0-3b1c23a50968,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-a8ba66da-ba73-4623-a156-e37e89f11178,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-f584dd43-34bc-47d3-a26a-b87a04c16599,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-09a67940-d730-441e-bbdf-c57281746ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-2c2c3cee-407b-4c27-8689-49b0be1e7377,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-9f713be1-fea7-4814-b095-9b2b7350857e,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-ff9d1046-7892-4122-88a7-9bc609450eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760908820-172.17.0.11-1598692471876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-39dc315b-ec6f-4af6-a8d0-b3e2d454dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-b25945ce-fa63-4e8e-80a0-3b1c23a50968,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-a8ba66da-ba73-4623-a156-e37e89f11178,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-f584dd43-34bc-47d3-a26a-b87a04c16599,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-09a67940-d730-441e-bbdf-c57281746ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-2c2c3cee-407b-4c27-8689-49b0be1e7377,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-9f713be1-fea7-4814-b095-9b2b7350857e,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-ff9d1046-7892-4122-88a7-9bc609450eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171770834-172.17.0.11-1598692506306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45431,DS-173dd173-dff4-44d8-945f-8d7a412bac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-66491a41-1425-45db-a44e-62116fbdb87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-bcb275b2-1fcb-4aa0-aa56-b13aa75c3c25,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-093816e5-adc8-46cf-a0b3-787652d8eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-d151ae02-83c5-44a8-b141-ded9c81d6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-89e00f45-0fec-43b3-a51d-a575fd74de34,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1e94299f-7806-4597-b68d-587747302556,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-577b77a1-87d2-4333-8791-9a140cff99bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171770834-172.17.0.11-1598692506306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45431,DS-173dd173-dff4-44d8-945f-8d7a412bac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-66491a41-1425-45db-a44e-62116fbdb87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-bcb275b2-1fcb-4aa0-aa56-b13aa75c3c25,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-093816e5-adc8-46cf-a0b3-787652d8eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-d151ae02-83c5-44a8-b141-ded9c81d6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-89e00f45-0fec-43b3-a51d-a575fd74de34,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-1e94299f-7806-4597-b68d-587747302556,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-577b77a1-87d2-4333-8791-9a140cff99bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622750010-172.17.0.11-1598692575947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-9a44356f-92a8-4dc5-886c-6a0b86495949,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-c64e0cf3-b5a5-4146-a9b5-b7a35a22e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-a94f47db-f982-41f3-b58a-5a7a96ebb255,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-6f64b631-9c84-4adb-bb66-15f7592a84df,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-dd5ea20f-5e52-446a-8964-9a7811a161dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-0c70c500-d8c4-457c-a82a-81d024b6c576,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-a9e8a01d-1791-4d49-91e0-eafbc63f79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-8f560ceb-1e1d-4439-8a11-ff3dc3184248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622750010-172.17.0.11-1598692575947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-9a44356f-92a8-4dc5-886c-6a0b86495949,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-c64e0cf3-b5a5-4146-a9b5-b7a35a22e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-a94f47db-f982-41f3-b58a-5a7a96ebb255,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-6f64b631-9c84-4adb-bb66-15f7592a84df,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-dd5ea20f-5e52-446a-8964-9a7811a161dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-0c70c500-d8c4-457c-a82a-81d024b6c576,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-a9e8a01d-1791-4d49-91e0-eafbc63f79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-8f560ceb-1e1d-4439-8a11-ff3dc3184248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5424
