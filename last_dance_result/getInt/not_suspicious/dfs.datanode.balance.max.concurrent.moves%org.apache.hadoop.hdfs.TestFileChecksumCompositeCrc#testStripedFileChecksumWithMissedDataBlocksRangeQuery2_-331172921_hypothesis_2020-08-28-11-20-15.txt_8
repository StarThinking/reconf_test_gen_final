reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860677789-172.17.0.18-1598613967906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-4063487f-cde3-4e7b-accd-00030fe1cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-2f6e0f16-85d8-49ca-8d02-8051be439b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-5d504796-ab8e-46c5-8428-4b624585138f,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-fbfd1892-b408-48c5-9e02-14300c855a53,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-9c88e6df-b94b-453e-9932-9fd0eca03b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-bedc0852-fca4-442f-a43d-702de2209e58,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-b556c384-b09c-426e-adc4-88702fa9f093,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-0f6279e1-9aaa-4055-956a-1716b7ca4f72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860677789-172.17.0.18-1598613967906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-4063487f-cde3-4e7b-accd-00030fe1cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-2f6e0f16-85d8-49ca-8d02-8051be439b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-5d504796-ab8e-46c5-8428-4b624585138f,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-fbfd1892-b408-48c5-9e02-14300c855a53,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-9c88e6df-b94b-453e-9932-9fd0eca03b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-bedc0852-fca4-442f-a43d-702de2209e58,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-b556c384-b09c-426e-adc4-88702fa9f093,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-0f6279e1-9aaa-4055-956a-1716b7ca4f72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585353063-172.17.0.18-1598614862863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-ab2896c8-6f34-4400-93ad-bba2ba2d2216,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-4c892571-7be1-4bc7-a285-0d925442603c,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-64fe2378-4c91-4b6c-9314-4216b9108db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-7c87dcb4-a42e-4422-a728-d160184d2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-aa8b93f3-64c8-4fc7-a6e1-df3ddcb55341,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-c0c2c941-a3a2-459d-b2f7-9ea48e787af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-0bd97874-1743-475f-8b48-6b429f6b0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-9509ba6b-6b01-469f-844a-d5c5af89e8fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585353063-172.17.0.18-1598614862863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-ab2896c8-6f34-4400-93ad-bba2ba2d2216,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-4c892571-7be1-4bc7-a285-0d925442603c,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-64fe2378-4c91-4b6c-9314-4216b9108db6,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-7c87dcb4-a42e-4422-a728-d160184d2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-aa8b93f3-64c8-4fc7-a6e1-df3ddcb55341,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-c0c2c941-a3a2-459d-b2f7-9ea48e787af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-0bd97874-1743-475f-8b48-6b429f6b0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-9509ba6b-6b01-469f-844a-d5c5af89e8fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027616115-172.17.0.18-1598615819813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-95f1c910-d8f4-40e7-86c6-d8832c430098,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-182b2c1c-5083-4643-834c-d0d413d49d77,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-a1724231-f7b6-466e-aa70-daa368d22346,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-3735d65c-0529-4c37-98d4-454bbbaa81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-4c1ebfd2-bf7e-41d1-ae49-177b60754186,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-ade12e3b-8b54-4fa8-ab75-0c6df7a5a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-6936576e-1d24-4912-ae58-fea846d2bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-e37b6386-e4d3-495b-92a7-9b1d11c78d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027616115-172.17.0.18-1598615819813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-95f1c910-d8f4-40e7-86c6-d8832c430098,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-182b2c1c-5083-4643-834c-d0d413d49d77,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-a1724231-f7b6-466e-aa70-daa368d22346,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-3735d65c-0529-4c37-98d4-454bbbaa81c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-4c1ebfd2-bf7e-41d1-ae49-177b60754186,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-ade12e3b-8b54-4fa8-ab75-0c6df7a5a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-6936576e-1d24-4912-ae58-fea846d2bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-e37b6386-e4d3-495b-92a7-9b1d11c78d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782798614-172.17.0.18-1598616189626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-31d44b68-64b9-4384-9b83-309b3cc175cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-7a161e8a-c79b-4fab-b698-8e0b338616d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-907acd57-25ba-4eb8-9de4-2281de200790,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-f6abf8d9-c7d6-40b8-be24-03d03cb005ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-7794a27d-7f96-4bdf-a470-a466b370842e,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-5c86cf15-a41c-4c09-bca0-03cf5420004e,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-4ba0d2a9-bd50-47e9-9919-a99295fbb356,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-8e982e23-147d-4644-8d81-0c838ee4ab7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782798614-172.17.0.18-1598616189626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-31d44b68-64b9-4384-9b83-309b3cc175cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-7a161e8a-c79b-4fab-b698-8e0b338616d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-907acd57-25ba-4eb8-9de4-2281de200790,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-f6abf8d9-c7d6-40b8-be24-03d03cb005ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-7794a27d-7f96-4bdf-a470-a466b370842e,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-5c86cf15-a41c-4c09-bca0-03cf5420004e,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-4ba0d2a9-bd50-47e9-9919-a99295fbb356,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-8e982e23-147d-4644-8d81-0c838ee4ab7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790119715-172.17.0.18-1598616367258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-ad781834-d9d4-4105-8da8-0d7575796721,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-b39e20c4-6d4d-4916-8bb7-2156636456e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-5353e137-1dad-4ded-9746-af84a003922d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-27eb09ca-4f71-4689-a10c-08b4010a0143,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-9b8d547b-7c9e-41fc-b2f3-aaa71198708a,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-b3ac2a92-5f90-49f8-97ea-f3d3ee09f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-d5cfa373-f207-46cc-b2a7-93c7d8bbdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-c8233555-0e79-4acf-8d48-930b4bc51c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790119715-172.17.0.18-1598616367258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-ad781834-d9d4-4105-8da8-0d7575796721,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-b39e20c4-6d4d-4916-8bb7-2156636456e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-5353e137-1dad-4ded-9746-af84a003922d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-27eb09ca-4f71-4689-a10c-08b4010a0143,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-9b8d547b-7c9e-41fc-b2f3-aaa71198708a,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-b3ac2a92-5f90-49f8-97ea-f3d3ee09f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-d5cfa373-f207-46cc-b2a7-93c7d8bbdf33,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-c8233555-0e79-4acf-8d48-930b4bc51c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150051167-172.17.0.18-1598616523161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-a21ee7a5-7e8d-444f-b9da-7e6f9b4f9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-3a7fdc2c-4789-4c71-9fda-d0c7e8e5109d,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-edddff07-fb03-4253-a448-cdc60de49775,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-49f89cec-c508-45f4-83b1-f71654065b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-81db8760-a946-427b-913f-aad6ca251754,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cf045e85-82ac-4b08-9a66-d9b6bb4b10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-9f2e6755-8365-4ea6-a44b-e39d5ad231c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-c4b15b80-c009-4507-bcba-a262101777f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150051167-172.17.0.18-1598616523161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-a21ee7a5-7e8d-444f-b9da-7e6f9b4f9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-3a7fdc2c-4789-4c71-9fda-d0c7e8e5109d,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-edddff07-fb03-4253-a448-cdc60de49775,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-49f89cec-c508-45f4-83b1-f71654065b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-81db8760-a946-427b-913f-aad6ca251754,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cf045e85-82ac-4b08-9a66-d9b6bb4b10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-9f2e6755-8365-4ea6-a44b-e39d5ad231c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-c4b15b80-c009-4507-bcba-a262101777f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901410125-172.17.0.18-1598616728928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-501d89be-69d7-43b5-954d-bc0b24c46842,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-f08ba3eb-08ab-445e-844a-f91eae778b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-a57381d9-5982-4e00-81be-95b2574fb368,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-d12b9a66-0e66-4b0b-8486-9dfe180de330,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-28a292e1-7adf-4752-9518-9ddf1d342dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-6b6b2708-8bed-48cd-b4e0-dd3f58432dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-8c3ff636-341e-42e9-9769-0d621eab9894,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-181b3bb3-9653-49b1-830c-15351ab586a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901410125-172.17.0.18-1598616728928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-501d89be-69d7-43b5-954d-bc0b24c46842,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-f08ba3eb-08ab-445e-844a-f91eae778b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-a57381d9-5982-4e00-81be-95b2574fb368,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-d12b9a66-0e66-4b0b-8486-9dfe180de330,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-28a292e1-7adf-4752-9518-9ddf1d342dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-6b6b2708-8bed-48cd-b4e0-dd3f58432dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-8c3ff636-341e-42e9-9769-0d621eab9894,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-181b3bb3-9653-49b1-830c-15351ab586a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563994998-172.17.0.18-1598617262246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-f7799b6f-98cc-4614-b25b-ef55aa28d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-e8504cc6-1460-4ce8-854a-ae353a2b8520,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-753c5bad-0761-475e-a1e4-557e9c1c35ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-f295faba-9d19-48fb-a173-0c3cdd695bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-ad04a7e1-bee6-4b74-b2e6-f18a59d3ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-7f935d8a-b475-4069-96b8-6f2a75978ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-fefa557b-c506-4735-875f-c900582e542c,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-4a79cc44-9216-4beb-b937-a624776a108b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563994998-172.17.0.18-1598617262246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-f7799b6f-98cc-4614-b25b-ef55aa28d2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-e8504cc6-1460-4ce8-854a-ae353a2b8520,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-753c5bad-0761-475e-a1e4-557e9c1c35ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-f295faba-9d19-48fb-a173-0c3cdd695bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-ad04a7e1-bee6-4b74-b2e6-f18a59d3ff12,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-7f935d8a-b475-4069-96b8-6f2a75978ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-fefa557b-c506-4735-875f-c900582e542c,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-4a79cc44-9216-4beb-b937-a624776a108b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542901397-172.17.0.18-1598617337765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-6c6c4776-0fd2-4234-90aa-a2bbc655e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-ee623ce8-526e-4fd4-9db2-935d77e7d507,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f12c5d3d-988c-4e17-8f81-1ddc39dccf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-bc221ae1-9257-4be2-a4c3-701bfc45b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-866efd48-69a9-4e62-955b-72ef93e31898,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-47a72fcc-c09a-4b39-a327-303b1489b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-431665de-b500-401e-bef0-dab67e327f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d94092fa-2a1d-4814-93f2-19dc5f1de40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542901397-172.17.0.18-1598617337765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-6c6c4776-0fd2-4234-90aa-a2bbc655e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-ee623ce8-526e-4fd4-9db2-935d77e7d507,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f12c5d3d-988c-4e17-8f81-1ddc39dccf68,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-bc221ae1-9257-4be2-a4c3-701bfc45b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-866efd48-69a9-4e62-955b-72ef93e31898,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-47a72fcc-c09a-4b39-a327-303b1489b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-431665de-b500-401e-bef0-dab67e327f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d94092fa-2a1d-4814-93f2-19dc5f1de40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050557111-172.17.0.18-1598617372667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-c0e75b91-e237-47ee-a3e8-8c0014166c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-dae66dee-5417-441a-a507-8d6ece505c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-da6b3a4f-0f1f-49be-81ef-1098c81947bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-f5d1038f-6dc0-4c42-ba18-e0785efd9856,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-14638eb0-675a-4495-a62d-667178842a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-45d9a428-fa1c-4bb4-b426-e9166d3ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-af48592e-7b9b-424b-8aaf-bf453627ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-41a874a5-1fe1-4730-beb7-795d0c4667f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050557111-172.17.0.18-1598617372667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-c0e75b91-e237-47ee-a3e8-8c0014166c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-dae66dee-5417-441a-a507-8d6ece505c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-da6b3a4f-0f1f-49be-81ef-1098c81947bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-f5d1038f-6dc0-4c42-ba18-e0785efd9856,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-14638eb0-675a-4495-a62d-667178842a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-45d9a428-fa1c-4bb4-b426-e9166d3ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-af48592e-7b9b-424b-8aaf-bf453627ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-41a874a5-1fe1-4730-beb7-795d0c4667f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509214277-172.17.0.18-1598617986193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35675,DS-0e6c9ad7-ece9-45f8-84ca-e749aa19111f,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-727aac05-5412-4c05-a0db-744972a3ec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-84cef742-6b56-4ef4-a18a-a7ce0530a0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-cafc9d28-9015-4394-a2ad-d728e7e72013,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-5f13236b-add4-407d-b1eb-e1780f628c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-b9a6f0e4-93cb-4230-9044-1c2e68b6f972,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-61c56c6e-6389-4467-8fb2-06484fa04732,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f4a4b149-d842-4171-be72-221112719fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509214277-172.17.0.18-1598617986193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35675,DS-0e6c9ad7-ece9-45f8-84ca-e749aa19111f,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-727aac05-5412-4c05-a0db-744972a3ec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-84cef742-6b56-4ef4-a18a-a7ce0530a0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-cafc9d28-9015-4394-a2ad-d728e7e72013,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-5f13236b-add4-407d-b1eb-e1780f628c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-b9a6f0e4-93cb-4230-9044-1c2e68b6f972,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-61c56c6e-6389-4467-8fb2-06484fa04732,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f4a4b149-d842-4171-be72-221112719fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264406337-172.17.0.18-1598618067349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-557b2a23-cefe-4dab-9a66-039b2fb29167,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-46863cb0-ecad-4c2e-a62a-975c56428d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-b10c68aa-a9af-4ac1-80f5-e6efe47c9688,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-abe6a89a-5bd8-4d6d-8c8e-b71583292302,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-77023b07-8c07-41a0-8a01-3cd1f242a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-70bb669e-b409-46d6-af9d-01ebe9fecbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-f28f5e1a-e2d9-41f7-82dc-f873ccd0322d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-8a283df4-2c6f-4f3a-908e-0fd5a1e2b83a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264406337-172.17.0.18-1598618067349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-557b2a23-cefe-4dab-9a66-039b2fb29167,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-46863cb0-ecad-4c2e-a62a-975c56428d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-b10c68aa-a9af-4ac1-80f5-e6efe47c9688,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-abe6a89a-5bd8-4d6d-8c8e-b71583292302,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-77023b07-8c07-41a0-8a01-3cd1f242a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-70bb669e-b409-46d6-af9d-01ebe9fecbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-f28f5e1a-e2d9-41f7-82dc-f873ccd0322d,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-8a283df4-2c6f-4f3a-908e-0fd5a1e2b83a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960696781-172.17.0.18-1598618256990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-99b06bae-ad6a-4635-91a6-d9ac2a08ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-ed8480ad-6b74-455c-b75d-14005962a64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-a85bee6f-ffba-4250-8d58-1aeb7a76250b,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-0f99a9cb-24d6-463d-ae87-5b156c88468f,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-37a3fbcd-7275-4cf0-ad2f-aa36344cf414,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-9c68adcb-56f7-4eae-b401-ac92c0192e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-5debff51-923a-44f5-9ad6-8b8077c9568d,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-7e593cb5-9249-4282-8fb3-c148479bcfdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960696781-172.17.0.18-1598618256990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-99b06bae-ad6a-4635-91a6-d9ac2a08ce66,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-ed8480ad-6b74-455c-b75d-14005962a64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-a85bee6f-ffba-4250-8d58-1aeb7a76250b,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-0f99a9cb-24d6-463d-ae87-5b156c88468f,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-37a3fbcd-7275-4cf0-ad2f-aa36344cf414,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-9c68adcb-56f7-4eae-b401-ac92c0192e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-5debff51-923a-44f5-9ad6-8b8077c9568d,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-7e593cb5-9249-4282-8fb3-c148479bcfdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520968307-172.17.0.18-1598618335926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-bf320731-6d71-414f-a483-5cbc19b8c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-7e0d8e15-8d83-41d4-a7ac-5fea90256e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-2723746c-1438-4b17-997b-d28d2a11186e,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-e00531d5-6f83-45a1-b314-a1972a6dd527,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-a816f9d5-f545-4384-ba51-0b2be84660ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-0fa238eb-1c33-48c3-9e8e-dd815b38b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-43cad546-1bf2-4315-b563-b9e16dfa078d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-0e8f2a60-63c2-4901-ac2a-02c5726deefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520968307-172.17.0.18-1598618335926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-bf320731-6d71-414f-a483-5cbc19b8c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-7e0d8e15-8d83-41d4-a7ac-5fea90256e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-2723746c-1438-4b17-997b-d28d2a11186e,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-e00531d5-6f83-45a1-b314-a1972a6dd527,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-a816f9d5-f545-4384-ba51-0b2be84660ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-0fa238eb-1c33-48c3-9e8e-dd815b38b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-43cad546-1bf2-4315-b563-b9e16dfa078d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-0e8f2a60-63c2-4901-ac2a-02c5726deefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495275539-172.17.0.18-1598618376770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-fa5a8bdc-791c-429e-bb55-515d0d32326d,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-6bdb76fa-bc8d-445a-941a-2e11a2b0b9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-aa68733a-0e98-4040-98dd-106528d3e864,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-224cc364-56d5-4de8-b2bd-330418e1c943,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-b821b783-048d-49e8-8bd0-4cba6259544b,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-94a52e19-dab0-4aa7-a2fe-8bd04dce6802,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-35d88428-ec61-42ca-a83d-a41d91105212,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-e313146d-4b10-488e-bead-c9028959994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495275539-172.17.0.18-1598618376770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-fa5a8bdc-791c-429e-bb55-515d0d32326d,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-6bdb76fa-bc8d-445a-941a-2e11a2b0b9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-aa68733a-0e98-4040-98dd-106528d3e864,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-224cc364-56d5-4de8-b2bd-330418e1c943,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-b821b783-048d-49e8-8bd0-4cba6259544b,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-94a52e19-dab0-4aa7-a2fe-8bd04dce6802,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-35d88428-ec61-42ca-a83d-a41d91105212,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-e313146d-4b10-488e-bead-c9028959994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859568298-172.17.0.18-1598618742991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-a2dbda5d-9075-4b46-bee6-771be5e0da06,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-fa644a92-9746-40e7-9e71-2e005c220c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-9440d692-1976-4974-be35-8aa8118e7465,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-e7cd89df-f3ab-4bc0-9c30-baf3194eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-7ad0783a-c0f4-435b-ae15-225cac3fcc92,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-50bee010-e5d0-4472-a585-6b9d4e081d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9292fb23-d972-4a4e-b1ac-4835db9b8ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-a9c0accb-4a7e-42ac-b33e-f46fdce36be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859568298-172.17.0.18-1598618742991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40245,DS-a2dbda5d-9075-4b46-bee6-771be5e0da06,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-fa644a92-9746-40e7-9e71-2e005c220c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-9440d692-1976-4974-be35-8aa8118e7465,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-e7cd89df-f3ab-4bc0-9c30-baf3194eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-7ad0783a-c0f4-435b-ae15-225cac3fcc92,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-50bee010-e5d0-4472-a585-6b9d4e081d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9292fb23-d972-4a4e-b1ac-4835db9b8ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-a9c0accb-4a7e-42ac-b33e-f46fdce36be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5422
