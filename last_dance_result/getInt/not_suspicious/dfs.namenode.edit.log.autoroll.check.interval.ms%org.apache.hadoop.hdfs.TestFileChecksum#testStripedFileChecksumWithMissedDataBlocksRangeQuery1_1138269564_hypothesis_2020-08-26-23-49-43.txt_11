reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443036543-172.17.0.13-1598485965957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-d68b7a30-8f05-4d91-939e-2497a383451b,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c0865929-9581-44ba-8abb-9bb30790b473,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-1e6560ca-68a1-44eb-b1aa-546aeb23aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e6c87008-7e86-4d1c-8e41-fd7d847d18c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-8442b877-4017-4f81-b5d8-d25393b780e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-327a77c5-669b-4e87-ad49-9cec3f8f7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-4dc3b2c0-85aa-4704-9a42-2e8a454c2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-10f9affb-168d-4987-957b-3700667e64f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443036543-172.17.0.13-1598485965957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-d68b7a30-8f05-4d91-939e-2497a383451b,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-c0865929-9581-44ba-8abb-9bb30790b473,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-1e6560ca-68a1-44eb-b1aa-546aeb23aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e6c87008-7e86-4d1c-8e41-fd7d847d18c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-8442b877-4017-4f81-b5d8-d25393b780e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-327a77c5-669b-4e87-ad49-9cec3f8f7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-4dc3b2c0-85aa-4704-9a42-2e8a454c2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-10f9affb-168d-4987-957b-3700667e64f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46041164-172.17.0.13-1598486313391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-617032f7-a920-4feb-a6af-4e3b8d8db50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-d1501450-16e2-4a8f-b083-9f67bd5a4ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-cbebb79d-be6b-47eb-9027-6b3ff9c8d069,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-d2aed2b1-c19a-4cff-a296-07cacec1feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-5fdb282a-3900-4015-b436-abae03edf80a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-3b057412-ef30-494b-a0fa-9e8265ea0685,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-dd68700e-f56c-4e07-9e6b-66abb1faa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4d8b148a-cec8-4b77-a1e2-84a702352079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46041164-172.17.0.13-1598486313391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-617032f7-a920-4feb-a6af-4e3b8d8db50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-d1501450-16e2-4a8f-b083-9f67bd5a4ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-cbebb79d-be6b-47eb-9027-6b3ff9c8d069,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-d2aed2b1-c19a-4cff-a296-07cacec1feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-5fdb282a-3900-4015-b436-abae03edf80a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-3b057412-ef30-494b-a0fa-9e8265ea0685,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-dd68700e-f56c-4e07-9e6b-66abb1faa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4d8b148a-cec8-4b77-a1e2-84a702352079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134552842-172.17.0.13-1598486512007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-6ac13123-a6cd-46b5-906a-cc011bb1566d,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-e5a7fd77-40a1-4f04-87d7-b505bc4bd2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-d1b37006-20d6-46a6-944d-b9ed0e10e91a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-b21bc569-365b-4134-88f1-07e496eb45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-f195202f-9cce-48ce-b03d-8892d5f335b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-f7853738-5285-4cd3-92cd-7d7778dc8164,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-309b1c9d-41ab-403b-a39f-86f7aab7fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-47ec91ad-6be1-4134-a297-2dc087be60f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134552842-172.17.0.13-1598486512007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-6ac13123-a6cd-46b5-906a-cc011bb1566d,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-e5a7fd77-40a1-4f04-87d7-b505bc4bd2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-d1b37006-20d6-46a6-944d-b9ed0e10e91a,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-b21bc569-365b-4134-88f1-07e496eb45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-f195202f-9cce-48ce-b03d-8892d5f335b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-f7853738-5285-4cd3-92cd-7d7778dc8164,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-309b1c9d-41ab-403b-a39f-86f7aab7fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-47ec91ad-6be1-4134-a297-2dc087be60f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835109323-172.17.0.13-1598486609976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-4cd6f75d-3333-462a-b2ee-709be1d4c478,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-46ab678b-eabb-44e4-965b-5c4dce16bb80,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ada23440-2d0f-44a5-9a80-761e2e727a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-a3db97fa-0c55-47cb-9572-d4df3c8dff33,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b18be901-ae59-4cc7-a3f2-b707df71a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-1555c528-865c-4b1a-8cf8-5f32e0d3d086,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-69011a65-5a85-4a15-ab4e-b7884578f175,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-09a5d4b7-b126-434e-af46-0e80f8b2cf23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835109323-172.17.0.13-1598486609976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-4cd6f75d-3333-462a-b2ee-709be1d4c478,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-46ab678b-eabb-44e4-965b-5c4dce16bb80,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ada23440-2d0f-44a5-9a80-761e2e727a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-a3db97fa-0c55-47cb-9572-d4df3c8dff33,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b18be901-ae59-4cc7-a3f2-b707df71a5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-1555c528-865c-4b1a-8cf8-5f32e0d3d086,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-69011a65-5a85-4a15-ab4e-b7884578f175,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-09a5d4b7-b126-434e-af46-0e80f8b2cf23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375855234-172.17.0.13-1598486863864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-9f4ffc72-02d2-4930-9e46-d8d83115323a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-b62bbc9c-3f18-4a84-876f-26ce3019692b,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-3806970d-718e-4e73-b948-11fa59dff70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-e2640e3d-5ec3-447c-ae16-ccba56bd1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-0aeef744-8ccf-4a94-8e18-b1b2c7963a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-28caacfe-2269-4c3f-86da-4f3404ea904b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4b8575b2-da06-43fa-9e0d-bd76533d9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-f4b805bf-4f4b-46d9-b6ad-b3160a285761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375855234-172.17.0.13-1598486863864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-9f4ffc72-02d2-4930-9e46-d8d83115323a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-b62bbc9c-3f18-4a84-876f-26ce3019692b,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-3806970d-718e-4e73-b948-11fa59dff70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-e2640e3d-5ec3-447c-ae16-ccba56bd1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-0aeef744-8ccf-4a94-8e18-b1b2c7963a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-28caacfe-2269-4c3f-86da-4f3404ea904b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4b8575b2-da06-43fa-9e0d-bd76533d9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-f4b805bf-4f4b-46d9-b6ad-b3160a285761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032193964-172.17.0.13-1598487523724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-cdfb04f6-3fd4-485e-a00d-3b15368c1c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-47859f26-2567-45c6-8966-d52ef1b4f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-daa7a1d0-943b-42d7-a139-703beba09bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8ac164df-fbc8-4778-9adf-3d2673dcc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6dd50445-5268-415b-8153-62847f401ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-19702305-208a-4b0f-ac88-654e181b6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-934b444d-a912-450e-9bfa-153b84943bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-d413dc81-9b79-4146-b72d-f2336f19dafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032193964-172.17.0.13-1598487523724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-cdfb04f6-3fd4-485e-a00d-3b15368c1c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-47859f26-2567-45c6-8966-d52ef1b4f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-daa7a1d0-943b-42d7-a139-703beba09bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8ac164df-fbc8-4778-9adf-3d2673dcc9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6dd50445-5268-415b-8153-62847f401ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-19702305-208a-4b0f-ac88-654e181b6be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-934b444d-a912-450e-9bfa-153b84943bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-d413dc81-9b79-4146-b72d-f2336f19dafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72807891-172.17.0.13-1598487980372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-65ee890a-06f7-4a8a-94e2-e9770e21f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-0ba45388-e811-45d9-a9f8-fc33d6310f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9450efb4-9b43-4090-a821-846d41d64fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-c6d474a0-20f2-4df3-9215-0b1d220a02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-520ace42-e360-420c-968f-5d05ebdeb35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-96b2c229-40b2-4ee6-ab0d-a66b0f42a1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-606803da-7732-4e8b-a86a-93f2d2ffccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-37a77236-9031-4d94-b531-03487601ca87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72807891-172.17.0.13-1598487980372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-65ee890a-06f7-4a8a-94e2-e9770e21f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-0ba45388-e811-45d9-a9f8-fc33d6310f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9450efb4-9b43-4090-a821-846d41d64fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-c6d474a0-20f2-4df3-9215-0b1d220a02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-520ace42-e360-420c-968f-5d05ebdeb35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-96b2c229-40b2-4ee6-ab0d-a66b0f42a1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-606803da-7732-4e8b-a86a-93f2d2ffccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-37a77236-9031-4d94-b531-03487601ca87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688412511-172.17.0.13-1598488018608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42170,DS-7e22a407-8ca2-414a-a971-6aff775e1490,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-fc239f61-1f79-49f9-8479-d05412cff5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-77b9e477-07b6-424f-b254-d744a3277114,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-0bba6050-0301-4c84-a9ce-36a83e8ce4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-f84ecfa5-3bbc-4478-be5d-4d7f938e2b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-2af8796c-853f-4eb6-9a98-19aef7c757e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-be7709f8-5450-4ddc-8d19-31c665cef1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-0041c9df-c59d-408f-8f51-87acbcb4cafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688412511-172.17.0.13-1598488018608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42170,DS-7e22a407-8ca2-414a-a971-6aff775e1490,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-fc239f61-1f79-49f9-8479-d05412cff5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-77b9e477-07b6-424f-b254-d744a3277114,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-0bba6050-0301-4c84-a9ce-36a83e8ce4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-f84ecfa5-3bbc-4478-be5d-4d7f938e2b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-2af8796c-853f-4eb6-9a98-19aef7c757e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-be7709f8-5450-4ddc-8d19-31c665cef1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-0041c9df-c59d-408f-8f51-87acbcb4cafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085022700-172.17.0.13-1598488627385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-6358fce2-57f9-4be7-aec6-2aee7793490f,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-465e6f3b-8012-4f28-bff1-05647885705b,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-46adbc0e-bc89-4822-8290-f3803270bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3f3cf954-9828-4926-9dc5-8b3b907d6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-c80c46cb-372c-4fbf-a3e3-c5ac8eff2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-b7ce3aa0-e341-46e0-b787-bf2e1301e068,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-3c6949be-963c-42bd-aed4-c23170ce9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-38a24c13-5e60-48e6-bfc6-21f9e4c8756e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085022700-172.17.0.13-1598488627385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-6358fce2-57f9-4be7-aec6-2aee7793490f,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-465e6f3b-8012-4f28-bff1-05647885705b,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-46adbc0e-bc89-4822-8290-f3803270bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-3f3cf954-9828-4926-9dc5-8b3b907d6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-c80c46cb-372c-4fbf-a3e3-c5ac8eff2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-b7ce3aa0-e341-46e0-b787-bf2e1301e068,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-3c6949be-963c-42bd-aed4-c23170ce9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-38a24c13-5e60-48e6-bfc6-21f9e4c8756e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139719604-172.17.0.13-1598489102368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-697ebae6-63ea-450a-a069-3adfee811db9,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-059e52ea-684a-49fa-b360-a9f8ddb72e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-84db2d23-ee99-4444-996b-9996871465ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-d3d970bb-880a-481b-8847-2aa0d8230b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-44cf6336-4233-4c6c-a990-4e6f7991ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-27b01c69-3a3e-4c7e-ada6-229565f111d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-d3437a24-e3f5-47ef-acf5-89e6054b4154,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-2bf4912d-e36a-4169-a19a-0935f96a20b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139719604-172.17.0.13-1598489102368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-697ebae6-63ea-450a-a069-3adfee811db9,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-059e52ea-684a-49fa-b360-a9f8ddb72e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-84db2d23-ee99-4444-996b-9996871465ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-d3d970bb-880a-481b-8847-2aa0d8230b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-44cf6336-4233-4c6c-a990-4e6f7991ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-27b01c69-3a3e-4c7e-ada6-229565f111d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-d3437a24-e3f5-47ef-acf5-89e6054b4154,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-2bf4912d-e36a-4169-a19a-0935f96a20b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051315333-172.17.0.13-1598489307083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-b2c31c78-86b0-44d3-8850-3e5a65f9e89f,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-922bb9f3-ca92-4a16-a058-b39301d000b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-c7de9ed1-99bb-4c9c-8082-bd2c89ad9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-ace80642-b597-42bc-a725-c3e2f822c5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-a22a5808-0df6-4e40-a2bd-34fef0fe9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-f492b57a-d1c2-4f8f-94c6-d319c5fab949,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-6769da79-3f80-472a-abdc-41b61f698720,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b408bb81-7f16-4144-9235-6713b0992196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051315333-172.17.0.13-1598489307083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35777,DS-b2c31c78-86b0-44d3-8850-3e5a65f9e89f,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-922bb9f3-ca92-4a16-a058-b39301d000b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-c7de9ed1-99bb-4c9c-8082-bd2c89ad9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-ace80642-b597-42bc-a725-c3e2f822c5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-a22a5808-0df6-4e40-a2bd-34fef0fe9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-f492b57a-d1c2-4f8f-94c6-d319c5fab949,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-6769da79-3f80-472a-abdc-41b61f698720,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-b408bb81-7f16-4144-9235-6713b0992196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936083569-172.17.0.13-1598489621815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-fbe19c57-16fd-479c-ba84-f7308baf0109,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-c0e18dad-caad-45fb-a6fa-0c6b9f2eedde,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-9301c7df-f379-49d3-a186-6c5f9020b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-3b4d2dde-4e49-4a5c-80c5-68d0ebedada1,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-fa7506d6-9bd8-49ef-bfb6-ec6c152eee16,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-98c1ef7f-0c80-405b-b09a-14bdeea9e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-09a450a1-bf42-4f25-9d7b-fe5c9142f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-456ec6ac-dd8f-421a-823e-f9602d16d00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936083569-172.17.0.13-1598489621815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-fbe19c57-16fd-479c-ba84-f7308baf0109,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-c0e18dad-caad-45fb-a6fa-0c6b9f2eedde,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-9301c7df-f379-49d3-a186-6c5f9020b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-3b4d2dde-4e49-4a5c-80c5-68d0ebedada1,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-fa7506d6-9bd8-49ef-bfb6-ec6c152eee16,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-98c1ef7f-0c80-405b-b09a-14bdeea9e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-09a450a1-bf42-4f25-9d7b-fe5c9142f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-456ec6ac-dd8f-421a-823e-f9602d16d00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339802555-172.17.0.13-1598490441836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38797,DS-8f80b635-261e-46cd-b921-34af79138a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-77739f3a-bc92-4554-bf9e-989c1cdad7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-98dbd48b-bdc9-479e-8614-2bb7e36eb40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-39576c35-863b-4b84-9df0-c97f901ad6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f236ad87-8f4e-4b0e-b7d0-4b9e5b09e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-748daa5a-0a35-49f5-97f0-4e707a4124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fd9282f9-4b07-4ce0-ad28-da843192b999,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-ef2ff17b-085c-4839-9790-87d36d1b730a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339802555-172.17.0.13-1598490441836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38797,DS-8f80b635-261e-46cd-b921-34af79138a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-77739f3a-bc92-4554-bf9e-989c1cdad7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-98dbd48b-bdc9-479e-8614-2bb7e36eb40c,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-39576c35-863b-4b84-9df0-c97f901ad6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f236ad87-8f4e-4b0e-b7d0-4b9e5b09e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-748daa5a-0a35-49f5-97f0-4e707a4124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fd9282f9-4b07-4ce0-ad28-da843192b999,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-ef2ff17b-085c-4839-9790-87d36d1b730a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183266490-172.17.0.13-1598490602855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-1711cfcf-4ae1-4935-a28c-bda9028c019b,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-92336970-1ef4-4114-9b3e-e6abf2840916,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-5c7565a8-fbc9-408a-b1b2-567c36ca667b,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-087fe78c-7ca6-4f4a-9da8-6fb060e4a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-257a097b-bb3d-4b31-a66a-760b5e724028,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-fbbebbb5-0083-4d5c-8bd5-b8e38d2bf3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-25c2104e-ae7b-4234-b219-71ffd08819a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-e41d9bc1-302b-4a42-9a32-838355e6bade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183266490-172.17.0.13-1598490602855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-1711cfcf-4ae1-4935-a28c-bda9028c019b,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-92336970-1ef4-4114-9b3e-e6abf2840916,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-5c7565a8-fbc9-408a-b1b2-567c36ca667b,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-087fe78c-7ca6-4f4a-9da8-6fb060e4a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-257a097b-bb3d-4b31-a66a-760b5e724028,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-fbbebbb5-0083-4d5c-8bd5-b8e38d2bf3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-25c2104e-ae7b-4234-b219-71ffd08819a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-e41d9bc1-302b-4a42-9a32-838355e6bade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044424141-172.17.0.13-1598490672452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-55bf86de-74f6-4016-9ffe-cb9fdc8b4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-52165b4a-41d8-4b7c-86ea-cfb16d44e627,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-b5278600-667c-48e6-8248-453d975ceabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-f1785d3d-58ed-45cf-96d2-8dc78d2373cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-1723e80d-d2d2-49ed-94f4-f0fd531984c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-4aba75bc-8aad-47ba-84fa-49ba97292bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-ebf9efca-8369-4f5c-9e5a-608eaf3bdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-cc374d9b-5693-4b61-a59e-c7b6d342c49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044424141-172.17.0.13-1598490672452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-55bf86de-74f6-4016-9ffe-cb9fdc8b4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-52165b4a-41d8-4b7c-86ea-cfb16d44e627,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-b5278600-667c-48e6-8248-453d975ceabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-f1785d3d-58ed-45cf-96d2-8dc78d2373cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-1723e80d-d2d2-49ed-94f4-f0fd531984c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-4aba75bc-8aad-47ba-84fa-49ba97292bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-ebf9efca-8369-4f5c-9e5a-608eaf3bdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-cc374d9b-5693-4b61-a59e-c7b6d342c49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659934861-172.17.0.13-1598490703702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-852d2afa-4e4b-4cf9-85f1-9f790a7b0279,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-ac263921-71d3-43e4-a797-82a39c16d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-17529db7-f9a3-4221-b2f3-2433886ff103,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-9ab6d9d9-903b-4571-937d-1fc4d5c263de,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-beb84d92-6603-46ee-9367-3719d2399a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-5d2be8b1-b008-41aa-af05-84b2951da3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0e76089b-6a15-4a74-b57c-c6e06fd714ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a79ffa89-c272-44dd-85c6-9c2e251bb1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659934861-172.17.0.13-1598490703702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-852d2afa-4e4b-4cf9-85f1-9f790a7b0279,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-ac263921-71d3-43e4-a797-82a39c16d2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-17529db7-f9a3-4221-b2f3-2433886ff103,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-9ab6d9d9-903b-4571-937d-1fc4d5c263de,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-beb84d92-6603-46ee-9367-3719d2399a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-5d2be8b1-b008-41aa-af05-84b2951da3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0e76089b-6a15-4a74-b57c-c6e06fd714ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a79ffa89-c272-44dd-85c6-9c2e251bb1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094596858-172.17.0.13-1598490766131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-97b79fdc-4820-462e-97b2-80045d7fb7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-3cda0b28-4ec0-4e19-bff7-bdca38026d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-1941745b-d392-4ea7-8e05-3dd5caea42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-cac7ba9d-16de-4920-8fb4-220f9c214266,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-727bf647-99a9-4ec4-b0ea-b6fc1b877dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-19ea04a1-7f22-445c-8930-af77b0c66acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-9ce4e9d0-34c5-4bc6-b6d9-cf6308aa4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-bb8d23f6-8d28-4cc0-9385-4e04cd202bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094596858-172.17.0.13-1598490766131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-97b79fdc-4820-462e-97b2-80045d7fb7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-3cda0b28-4ec0-4e19-bff7-bdca38026d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-1941745b-d392-4ea7-8e05-3dd5caea42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-cac7ba9d-16de-4920-8fb4-220f9c214266,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-727bf647-99a9-4ec4-b0ea-b6fc1b877dde,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-19ea04a1-7f22-445c-8930-af77b0c66acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-9ce4e9d0-34c5-4bc6-b6d9-cf6308aa4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-bb8d23f6-8d28-4cc0-9385-4e04cd202bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167539107-172.17.0.13-1598490807260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-2b0cc6c6-3531-46d8-b1fd-dad4b39ea108,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-7ca262ef-4589-4620-8173-deea79b5fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-9e7aa047-43c2-49b3-b443-f1af32e1cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-cc282f93-ed56-4cfe-b0e9-871965ec459b,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-5fe603f0-0be2-452c-a75d-96dd15b90573,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-83d1b642-6b14-4e95-9b13-1310fba8e710,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-dbd526fa-06a6-437f-95e8-6931fe8cdd99,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-ffe17bcd-fde9-412f-abac-051dca950d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167539107-172.17.0.13-1598490807260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-2b0cc6c6-3531-46d8-b1fd-dad4b39ea108,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-7ca262ef-4589-4620-8173-deea79b5fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-9e7aa047-43c2-49b3-b443-f1af32e1cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-cc282f93-ed56-4cfe-b0e9-871965ec459b,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-5fe603f0-0be2-452c-a75d-96dd15b90573,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-83d1b642-6b14-4e95-9b13-1310fba8e710,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-dbd526fa-06a6-437f-95e8-6931fe8cdd99,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-ffe17bcd-fde9-412f-abac-051dca950d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830042235-172.17.0.13-1598490905928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-bf0657e5-8129-412b-8f5c-9c08245422e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-e452fe78-0f64-4157-8187-bf7b696b367f,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-8ebb4a56-6ab9-404c-a9d4-8958d7ffab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-fa867131-d2d1-4a72-ad65-41a553bacd37,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-f3c37b3d-991a-4dd0-9a1e-66c7f50e2604,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-9ad535b9-c79c-45ae-8355-99511654920c,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-887c9a92-1605-4373-a994-832dfc162b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-ba6fb54c-172d-4bc7-82b3-68c67ad80f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830042235-172.17.0.13-1598490905928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-bf0657e5-8129-412b-8f5c-9c08245422e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-e452fe78-0f64-4157-8187-bf7b696b367f,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-8ebb4a56-6ab9-404c-a9d4-8958d7ffab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-fa867131-d2d1-4a72-ad65-41a553bacd37,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-f3c37b3d-991a-4dd0-9a1e-66c7f50e2604,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-9ad535b9-c79c-45ae-8355-99511654920c,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-887c9a92-1605-4373-a994-832dfc162b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-ba6fb54c-172d-4bc7-82b3-68c67ad80f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5311
