reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116536708-172.17.0.20-1598542907161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-1393c5c0-a13f-4093-b51e-44bea5bbdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-f156f198-73b3-48a5-98af-95a3385834ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-bab79168-6e64-42b3-8f54-6350495ca9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-4cc40dbc-75dd-434f-b59f-9f319c68b920,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-5b969e0d-5828-4656-945c-057d11199977,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-588fb588-6368-447d-9484-29b2c0a09343,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-71d0ceec-4c5d-47a2-8f59-4087743a20fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-3aae015c-9036-4d81-9d07-cbe9ac64c11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116536708-172.17.0.20-1598542907161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-1393c5c0-a13f-4093-b51e-44bea5bbdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-f156f198-73b3-48a5-98af-95a3385834ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-bab79168-6e64-42b3-8f54-6350495ca9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-4cc40dbc-75dd-434f-b59f-9f319c68b920,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-5b969e0d-5828-4656-945c-057d11199977,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-588fb588-6368-447d-9484-29b2c0a09343,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-71d0ceec-4c5d-47a2-8f59-4087743a20fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-3aae015c-9036-4d81-9d07-cbe9ac64c11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572270812-172.17.0.20-1598542974030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-a5c80d33-5cd0-4408-a734-ee33a49bb745,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-2a0e6717-ebbe-4339-b304-2287e76b3ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-97a53d1d-64d4-47f9-9336-3ab730dc525a,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-bf222219-2457-4e30-bc97-7c79003877bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-1a14b391-7427-45ab-ae25-5c1f0d35463b,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-0df183f7-778b-48de-9aeb-1b857f149b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-eb025924-6b64-41ce-87e5-ea0a97c23505,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e2f35391-b0f8-47ed-9be9-21766a499995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572270812-172.17.0.20-1598542974030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-a5c80d33-5cd0-4408-a734-ee33a49bb745,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-2a0e6717-ebbe-4339-b304-2287e76b3ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-97a53d1d-64d4-47f9-9336-3ab730dc525a,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-bf222219-2457-4e30-bc97-7c79003877bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-1a14b391-7427-45ab-ae25-5c1f0d35463b,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-0df183f7-778b-48de-9aeb-1b857f149b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-eb025924-6b64-41ce-87e5-ea0a97c23505,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e2f35391-b0f8-47ed-9be9-21766a499995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400877917-172.17.0.20-1598543069847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37794,DS-b5c4e07c-9c87-464f-83e4-d5fbff7bb809,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-7e7bfbda-9f55-47a8-b81b-36fe01da0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-d0f0489c-2576-4bb0-a061-8b754c729a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7582b000-0b26-4ec6-9e3f-3fce18084e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-1b23db73-9baf-4346-b8dc-e5458e9fb823,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-004b45be-836c-432f-b103-2c560c6de70e,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9010dd34-42f3-4c8b-9e09-2454789c622c,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-81f38b17-a0a5-47c2-94db-d694ec0114d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400877917-172.17.0.20-1598543069847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37794,DS-b5c4e07c-9c87-464f-83e4-d5fbff7bb809,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-7e7bfbda-9f55-47a8-b81b-36fe01da0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-d0f0489c-2576-4bb0-a061-8b754c729a90,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7582b000-0b26-4ec6-9e3f-3fce18084e05,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-1b23db73-9baf-4346-b8dc-e5458e9fb823,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-004b45be-836c-432f-b103-2c560c6de70e,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9010dd34-42f3-4c8b-9e09-2454789c622c,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-81f38b17-a0a5-47c2-94db-d694ec0114d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275535533-172.17.0.20-1598543306568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-4f9abbe5-b1e9-447f-973c-da9fe76701e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-22135ed6-8bdb-4041-a88c-96b6f9b953d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-e2501635-5ba7-44b9-a225-94f0287fa1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a2040d6d-3aa8-47fb-b474-44ef8f2ed479,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-d9934063-0f13-4fec-97bd-e5ee9978ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-bf75bebd-8bc9-4cec-8927-9bc73682cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-ab83ec71-cbe1-41ca-8dc1-56be016d6048,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-cf661a30-1f06-4deb-9ec1-d5210120d9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275535533-172.17.0.20-1598543306568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-4f9abbe5-b1e9-447f-973c-da9fe76701e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-22135ed6-8bdb-4041-a88c-96b6f9b953d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-e2501635-5ba7-44b9-a225-94f0287fa1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a2040d6d-3aa8-47fb-b474-44ef8f2ed479,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-d9934063-0f13-4fec-97bd-e5ee9978ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-bf75bebd-8bc9-4cec-8927-9bc73682cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-ab83ec71-cbe1-41ca-8dc1-56be016d6048,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-cf661a30-1f06-4deb-9ec1-d5210120d9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731212659-172.17.0.20-1598543342404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33855,DS-8a438598-185a-427d-ac60-cc9ae57e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-fb416676-712b-4cb7-841f-e093738e6169,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-fabf1b11-4bb9-41df-9a7c-65fd1b61dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-c3341aab-f593-453e-929c-81ccc17f1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ebb6972c-0f09-4b99-a6a0-53a0a90b315f,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-c42e05ee-d38b-4326-ba02-09f035a5de89,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-55793a22-c4e3-4c93-934d-10081e5c8929,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-2eda8229-1333-4f59-bc2f-9779eb5ae6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731212659-172.17.0.20-1598543342404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33855,DS-8a438598-185a-427d-ac60-cc9ae57e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-fb416676-712b-4cb7-841f-e093738e6169,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-fabf1b11-4bb9-41df-9a7c-65fd1b61dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-c3341aab-f593-453e-929c-81ccc17f1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ebb6972c-0f09-4b99-a6a0-53a0a90b315f,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-c42e05ee-d38b-4326-ba02-09f035a5de89,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-55793a22-c4e3-4c93-934d-10081e5c8929,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-2eda8229-1333-4f59-bc2f-9779eb5ae6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520311488-172.17.0.20-1598543407898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-77e8c1a1-0f26-4cfb-b3ba-0c5f71f107ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-97400c11-f63c-4389-af82-869f9d1f7305,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-e3950940-5502-4248-9e4a-23cc5104cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-80dbf4d7-cb56-4052-97a2-7e8f5f27f803,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-392c8278-b3ef-4d1d-93e0-3a9e43047e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-13482a8f-9545-490a-bd8d-e236bfd9e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e7403edf-d46b-4562-ad67-5653a99ae6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-b50a73f2-58da-47d3-86f0-bcd1b82b3579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520311488-172.17.0.20-1598543407898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-77e8c1a1-0f26-4cfb-b3ba-0c5f71f107ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-97400c11-f63c-4389-af82-869f9d1f7305,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-e3950940-5502-4248-9e4a-23cc5104cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-80dbf4d7-cb56-4052-97a2-7e8f5f27f803,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-392c8278-b3ef-4d1d-93e0-3a9e43047e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-13482a8f-9545-490a-bd8d-e236bfd9e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-e7403edf-d46b-4562-ad67-5653a99ae6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-b50a73f2-58da-47d3-86f0-bcd1b82b3579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116184386-172.17.0.20-1598543766800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-33d90f82-0659-4462-bc51-a59e59ad12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-4458cf3f-3917-47b2-b48c-89a546b475f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-d02322ae-54a4-4908-a234-07d9a01de9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-5676b68f-0860-48b9-bfa9-f9f193f2f228,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-5d5683dd-99aa-4894-833c-dfc7f6e112c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-a762efb8-fd61-494d-983c-42bcca23cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-bc58b0b8-18e5-4d46-b9c2-ff6d4f7ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-5e8c1d7a-6139-43fc-a9a5-3553a531336f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116184386-172.17.0.20-1598543766800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-33d90f82-0659-4462-bc51-a59e59ad12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-4458cf3f-3917-47b2-b48c-89a546b475f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-d02322ae-54a4-4908-a234-07d9a01de9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-5676b68f-0860-48b9-bfa9-f9f193f2f228,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-5d5683dd-99aa-4894-833c-dfc7f6e112c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-a762efb8-fd61-494d-983c-42bcca23cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-bc58b0b8-18e5-4d46-b9c2-ff6d4f7ef5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-5e8c1d7a-6139-43fc-a9a5-3553a531336f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598883987-172.17.0.20-1598544326285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-d7b8344a-1ba5-4cc8-8bb8-0a0c306c1f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-73028611-0a75-4405-adab-a6afb358d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-b4db19ce-f7dd-442d-9b83-3ca4cff3189f,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-75506a89-74ea-4d97-9068-4a8a41a3fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-66bfd848-bffc-4321-9a9b-51e417c9f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-c3b3ed8d-aba2-4034-b547-e018dbc5cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-395d312e-1cfb-4f8d-ae72-285a190e8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-abf8c57a-3c76-495b-aab0-81ad8cfe0a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598883987-172.17.0.20-1598544326285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-d7b8344a-1ba5-4cc8-8bb8-0a0c306c1f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-73028611-0a75-4405-adab-a6afb358d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-b4db19ce-f7dd-442d-9b83-3ca4cff3189f,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-75506a89-74ea-4d97-9068-4a8a41a3fe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-66bfd848-bffc-4321-9a9b-51e417c9f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-c3b3ed8d-aba2-4034-b547-e018dbc5cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-395d312e-1cfb-4f8d-ae72-285a190e8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-abf8c57a-3c76-495b-aab0-81ad8cfe0a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066033333-172.17.0.20-1598545152422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-4d2c0861-82d3-422f-a524-d7992bc4fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-1686f7f2-8cd9-4409-ba1a-fcda42b8f574,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-296a3d37-bd41-480a-b4f0-5dd0e0b50ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-7f570316-8dde-430c-957e-4bd1e1b08007,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-e3f5bae5-f911-4cf6-88eb-d1cce103deeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-152503e4-0b8d-4349-996a-fed5791cec10,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-63b877fa-10f4-4c7a-9679-c255c656af06,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-13dae814-8fa3-4fa0-907b-5f8036e83b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066033333-172.17.0.20-1598545152422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-4d2c0861-82d3-422f-a524-d7992bc4fd33,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-1686f7f2-8cd9-4409-ba1a-fcda42b8f574,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-296a3d37-bd41-480a-b4f0-5dd0e0b50ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-7f570316-8dde-430c-957e-4bd1e1b08007,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-e3f5bae5-f911-4cf6-88eb-d1cce103deeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-152503e4-0b8d-4349-996a-fed5791cec10,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-63b877fa-10f4-4c7a-9679-c255c656af06,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-13dae814-8fa3-4fa0-907b-5f8036e83b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165793255-172.17.0.20-1598546796175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-e186c989-c80b-4ebd-8073-85875bfb5444,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-6d1522e1-129c-42e8-ad69-acef72f04a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-772a05af-cb1a-4026-95d1-48e88f22aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-ac8c1b8f-c9bf-4e9d-9ce6-4ce9d01deb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-06df5a40-0e9b-4dc2-85bd-9f1c1b26403b,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-9af40979-e5f0-4358-9f2e-9a946e7332a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-42b439c0-b615-4008-b996-86ccfa97da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-12dfe2fb-2766-441d-88d6-10e367b066d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165793255-172.17.0.20-1598546796175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34838,DS-e186c989-c80b-4ebd-8073-85875bfb5444,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-6d1522e1-129c-42e8-ad69-acef72f04a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-772a05af-cb1a-4026-95d1-48e88f22aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-ac8c1b8f-c9bf-4e9d-9ce6-4ce9d01deb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-06df5a40-0e9b-4dc2-85bd-9f1c1b26403b,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-9af40979-e5f0-4358-9f2e-9a946e7332a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-42b439c0-b615-4008-b996-86ccfa97da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-12dfe2fb-2766-441d-88d6-10e367b066d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46511092-172.17.0.20-1598546833103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-15192e07-7290-4113-b2ca-ff02d7763a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-15f14c6d-ad44-47c5-919e-7820c6e27836,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-fc3e5a95-64ca-458a-8186-bdb579fe7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-e6483a50-b594-4435-a5fa-90e70a86ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-0dfa0adb-9a29-44f9-b7e2-b096839d34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-4d421b3b-f1af-4d3f-8335-af627dc10e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-ac60382e-10e3-4317-b345-151f23c668b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-c481d526-c017-4c3b-9e43-99a4e2d6b993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46511092-172.17.0.20-1598546833103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-15192e07-7290-4113-b2ca-ff02d7763a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-15f14c6d-ad44-47c5-919e-7820c6e27836,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-fc3e5a95-64ca-458a-8186-bdb579fe7e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-e6483a50-b594-4435-a5fa-90e70a86ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-0dfa0adb-9a29-44f9-b7e2-b096839d34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-4d421b3b-f1af-4d3f-8335-af627dc10e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-ac60382e-10e3-4317-b345-151f23c668b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-c481d526-c017-4c3b-9e43-99a4e2d6b993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117432596-172.17.0.20-1598547083811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-c0a60076-7926-4bd8-9996-a08e506d1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-9fa6879e-a0d7-414c-a815-75ed38244e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e9361f08-3197-42f5-8c32-874d8b2f91b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-95a91f2c-38f6-4cbb-84e7-234580c00f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-e29711a0-af63-43c7-beb7-cc57a999a007,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-6316c5fd-7c01-481b-89c6-6fb3d8208fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-79ea9453-e83a-4647-9d4c-0d9fca1ee9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-94452f6d-e651-4c57-ac57-5d3eaddccbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117432596-172.17.0.20-1598547083811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-c0a60076-7926-4bd8-9996-a08e506d1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-9fa6879e-a0d7-414c-a815-75ed38244e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e9361f08-3197-42f5-8c32-874d8b2f91b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-95a91f2c-38f6-4cbb-84e7-234580c00f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-e29711a0-af63-43c7-beb7-cc57a999a007,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-6316c5fd-7c01-481b-89c6-6fb3d8208fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-79ea9453-e83a-4647-9d4c-0d9fca1ee9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-94452f6d-e651-4c57-ac57-5d3eaddccbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616922845-172.17.0.20-1598547394535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-e9430da6-23ef-473c-acea-d7c6ceea9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-81b3d1bc-ebdf-41ce-ac33-41fee6e6d758,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-c83f123d-62c2-4d50-a729-cf8d675c65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-d10afd6e-c58e-44cd-8d07-bef308d9fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-f2ac8280-e912-4890-a999-f45cd41433d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-f2d2e437-a4aa-423c-b42d-0d70ce6d5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-6dcd6edf-59b6-4225-be12-00d2fe569c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-576f61dc-7294-406a-9994-532725462e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616922845-172.17.0.20-1598547394535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-e9430da6-23ef-473c-acea-d7c6ceea9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-81b3d1bc-ebdf-41ce-ac33-41fee6e6d758,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-c83f123d-62c2-4d50-a729-cf8d675c65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-d10afd6e-c58e-44cd-8d07-bef308d9fdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-f2ac8280-e912-4890-a999-f45cd41433d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-f2d2e437-a4aa-423c-b42d-0d70ce6d5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-6dcd6edf-59b6-4225-be12-00d2fe569c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-576f61dc-7294-406a-9994-532725462e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 4905
