reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937793431-172.17.0.10-1598618614200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-1574d5c7-c25b-4566-9f42-a55df68990d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-caba276b-d984-47a3-8875-a632cb36e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-42ae8dbc-c9e3-44c1-8bc4-3c2806ed0267,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-0f88df74-1c44-4c8d-a86d-8ba504a99002,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-6b90cc81-7cb6-46d3-96da-8d0f30d85db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-6dd34e1d-4a3f-4695-82af-62ed69f111b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-4d18f2d9-150d-427c-b5af-7126099c8798,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-03a1a210-4961-4fee-9bc6-346a6ef1d92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937793431-172.17.0.10-1598618614200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-1574d5c7-c25b-4566-9f42-a55df68990d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-caba276b-d984-47a3-8875-a632cb36e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-42ae8dbc-c9e3-44c1-8bc4-3c2806ed0267,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-0f88df74-1c44-4c8d-a86d-8ba504a99002,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-6b90cc81-7cb6-46d3-96da-8d0f30d85db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-6dd34e1d-4a3f-4695-82af-62ed69f111b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-4d18f2d9-150d-427c-b5af-7126099c8798,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-03a1a210-4961-4fee-9bc6-346a6ef1d92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031291421-172.17.0.10-1598620807607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-1c5b15de-db85-4333-a45e-fa9d9e6d5fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-52a9f217-92e6-4e10-8563-8605b5367101,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-ae0dbdb4-21a0-4493-8e9c-d36be5391b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6c35bd62-d049-4db8-ad2e-5070a65e1ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-326029ba-de24-4e3f-9e4d-9ff5c1fd4da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-66cb112b-d6b4-4bce-8bb1-37f7079cdaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-8f3cab36-3c19-4be6-8207-bba8c8f3972e,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-9456ecf1-c56d-4750-873b-204605deb7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031291421-172.17.0.10-1598620807607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-1c5b15de-db85-4333-a45e-fa9d9e6d5fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-52a9f217-92e6-4e10-8563-8605b5367101,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-ae0dbdb4-21a0-4493-8e9c-d36be5391b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6c35bd62-d049-4db8-ad2e-5070a65e1ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-326029ba-de24-4e3f-9e4d-9ff5c1fd4da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-66cb112b-d6b4-4bce-8bb1-37f7079cdaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-8f3cab36-3c19-4be6-8207-bba8c8f3972e,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-9456ecf1-c56d-4750-873b-204605deb7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922361602-172.17.0.10-1598620949922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-1a5ef4eb-b39b-4ca5-b3d7-9a073b418289,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-6fac4728-c583-4062-922c-a69326c7c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-6565365f-94ba-4424-b589-bb811660191b,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b6673b97-ed84-4086-ac66-b1d471d3e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-5f3fe214-240f-4c59-911e-fa53118aa730,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-c4088576-6fb4-4372-a94c-ee23bb3ee8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a9c63be9-bfd4-4284-83f4-b2077d3957a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-2c76a521-a3a4-4cef-be18-9d2b37733597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922361602-172.17.0.10-1598620949922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38584,DS-1a5ef4eb-b39b-4ca5-b3d7-9a073b418289,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-6fac4728-c583-4062-922c-a69326c7c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-6565365f-94ba-4424-b589-bb811660191b,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-b6673b97-ed84-4086-ac66-b1d471d3e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-5f3fe214-240f-4c59-911e-fa53118aa730,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-c4088576-6fb4-4372-a94c-ee23bb3ee8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a9c63be9-bfd4-4284-83f4-b2077d3957a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-2c76a521-a3a4-4cef-be18-9d2b37733597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992517162-172.17.0.10-1598621060613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40074,DS-78ea143c-06e0-42a9-9216-c2b8932328ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-8c21f02b-5d13-4e2f-ba02-f9717d82ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-d13e1f8a-39ee-430b-b595-0a4c726531f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-4e0bd0e0-386f-493d-bbc4-2c6f53888388,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-ed382f26-8014-437f-9a81-633997c7760f,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-87efbcdd-bde1-43e9-a4b6-17c96a93e472,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-22e8e7b9-1e86-421d-b506-b4af19094036,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-d8078cbe-1218-48b8-91e4-49f4b9bdf728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992517162-172.17.0.10-1598621060613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40074,DS-78ea143c-06e0-42a9-9216-c2b8932328ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-8c21f02b-5d13-4e2f-ba02-f9717d82ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-d13e1f8a-39ee-430b-b595-0a4c726531f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-4e0bd0e0-386f-493d-bbc4-2c6f53888388,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-ed382f26-8014-437f-9a81-633997c7760f,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-87efbcdd-bde1-43e9-a4b6-17c96a93e472,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-22e8e7b9-1e86-421d-b506-b4af19094036,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-d8078cbe-1218-48b8-91e4-49f4b9bdf728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687958420-172.17.0.10-1598621211337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-5d76694f-e26f-48f9-8f89-66282518f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-08850eae-f555-42aa-a9b6-5ad9fefa6480,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-572034f1-4402-429f-8f8f-59ae5218111c,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-cc4942f6-461e-4c8d-96f6-71a2dae185db,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-68d5994e-4c73-4c81-a5da-1603559cce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-c0a457ad-0a3f-44ca-9713-f10773ccbd04,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b6853a8d-418f-4774-be33-51fe80aff829,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-04c7b37b-6c3a-428f-a042-0aac1ec2ac88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687958420-172.17.0.10-1598621211337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-5d76694f-e26f-48f9-8f89-66282518f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-08850eae-f555-42aa-a9b6-5ad9fefa6480,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-572034f1-4402-429f-8f8f-59ae5218111c,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-cc4942f6-461e-4c8d-96f6-71a2dae185db,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-68d5994e-4c73-4c81-a5da-1603559cce4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-c0a457ad-0a3f-44ca-9713-f10773ccbd04,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b6853a8d-418f-4774-be33-51fe80aff829,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-04c7b37b-6c3a-428f-a042-0aac1ec2ac88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011105542-172.17.0.10-1598621243069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-e31d5b3e-0c98-4f9e-8d1a-99b9d77a48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-01fc9609-3139-45c2-8450-247a98e892a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-81c029d9-8d68-4853-ade0-300f51c2d921,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-6904d015-6c9a-4459-a53c-2e3bfce31369,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-59540c0b-33a4-45a4-b5b1-cced5f1707b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-d8471d5a-7ce8-4866-87e9-c3841143b351,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-60d4a133-55ec-4309-a03d-90afc29c0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-38366326-f2a2-48ce-a09e-ec5a3d511213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011105542-172.17.0.10-1598621243069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-e31d5b3e-0c98-4f9e-8d1a-99b9d77a48e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-01fc9609-3139-45c2-8450-247a98e892a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-81c029d9-8d68-4853-ade0-300f51c2d921,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-6904d015-6c9a-4459-a53c-2e3bfce31369,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-59540c0b-33a4-45a4-b5b1-cced5f1707b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-d8471d5a-7ce8-4866-87e9-c3841143b351,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-60d4a133-55ec-4309-a03d-90afc29c0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-38366326-f2a2-48ce-a09e-ec5a3d511213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156119508-172.17.0.10-1598622705451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32979,DS-c765f1ad-351c-4c64-bf02-68422eb46de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-e02269b7-418f-4e63-a179-f4ad3da68a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-dad967d8-448b-43b2-8dc6-251020406ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0b7dcb5b-92ee-4d72-9b8a-4cda8fa44584,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-cde4463a-7c7c-4cb1-8448-b0ea55d36b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-68b698de-fe6a-4d72-8ec4-afef86ced9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-0eb19e49-9a7b-4da8-98af-af84f58ccc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-e54b7389-b306-47a2-b2fc-96fe392bfa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156119508-172.17.0.10-1598622705451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32979,DS-c765f1ad-351c-4c64-bf02-68422eb46de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-e02269b7-418f-4e63-a179-f4ad3da68a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-dad967d8-448b-43b2-8dc6-251020406ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0b7dcb5b-92ee-4d72-9b8a-4cda8fa44584,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-cde4463a-7c7c-4cb1-8448-b0ea55d36b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-68b698de-fe6a-4d72-8ec4-afef86ced9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-0eb19e49-9a7b-4da8-98af-af84f58ccc46,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-e54b7389-b306-47a2-b2fc-96fe392bfa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709923916-172.17.0.10-1598623120070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-3f555552-0522-4218-a7e9-2315641b8237,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-185a960f-d0db-4c03-8463-21f3488f8dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-58af7fe6-58b7-43c3-9de1-ee79de6d3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-18b51bdc-8e19-4b8d-95ff-eb2ca38d459d,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-7ce804a4-f1e0-428c-bced-ae7b57913c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5ab2eb35-df92-4532-a4ed-555a51570406,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-e9b3f76f-1710-4908-845a-5b86f131ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-351678d4-9f2a-4240-8e8d-a0372564f135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709923916-172.17.0.10-1598623120070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-3f555552-0522-4218-a7e9-2315641b8237,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-185a960f-d0db-4c03-8463-21f3488f8dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-58af7fe6-58b7-43c3-9de1-ee79de6d3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-18b51bdc-8e19-4b8d-95ff-eb2ca38d459d,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-7ce804a4-f1e0-428c-bced-ae7b57913c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5ab2eb35-df92-4532-a4ed-555a51570406,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-e9b3f76f-1710-4908-845a-5b86f131ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-351678d4-9f2a-4240-8e8d-a0372564f135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5303
