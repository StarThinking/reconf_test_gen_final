reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708511704-172.17.0.10-1598642160455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-5a889d9e-a061-4cc1-80b1-dcba54d5079e,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-9adfbfa1-e104-4cd8-847f-1cd787c2871b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-4cec2c9d-6d7f-4bce-984b-eb4d9e2924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-961ca0e6-682a-4b11-bbc2-af650210eb83,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b2a34c62-6163-4581-bd34-a6fadfa116a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-9d19f272-be9f-4d05-99c6-a083c300d713,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-df6aa5e4-f8ff-486b-b8a5-0cdbb92dd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9c0dda19-ec86-4281-a86a-338451b25cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708511704-172.17.0.10-1598642160455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-5a889d9e-a061-4cc1-80b1-dcba54d5079e,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-9adfbfa1-e104-4cd8-847f-1cd787c2871b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-4cec2c9d-6d7f-4bce-984b-eb4d9e2924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-961ca0e6-682a-4b11-bbc2-af650210eb83,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b2a34c62-6163-4581-bd34-a6fadfa116a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-9d19f272-be9f-4d05-99c6-a083c300d713,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-df6aa5e4-f8ff-486b-b8a5-0cdbb92dd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9c0dda19-ec86-4281-a86a-338451b25cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764813645-172.17.0.10-1598642365468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-3903e98c-f9d3-431c-acf8-821837aa3396,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-55760a3e-fb17-4874-a2fa-b6277013fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-27ec0ebf-1b39-46d9-ab4d-aceebba0234d,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-8797cc8d-28ed-4b43-a9f4-23ec3b0b7110,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-8de9e1dd-740b-4c00-9d11-86639aeaa245,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-533c69f5-0238-4226-9ac1-019160df3189,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-59a461c8-6cbe-4a55-b40f-ae2816d5f445,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-524d4344-e1c7-4fa7-b849-e20868d99789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764813645-172.17.0.10-1598642365468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-3903e98c-f9d3-431c-acf8-821837aa3396,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-55760a3e-fb17-4874-a2fa-b6277013fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-27ec0ebf-1b39-46d9-ab4d-aceebba0234d,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-8797cc8d-28ed-4b43-a9f4-23ec3b0b7110,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-8de9e1dd-740b-4c00-9d11-86639aeaa245,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-533c69f5-0238-4226-9ac1-019160df3189,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-59a461c8-6cbe-4a55-b40f-ae2816d5f445,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-524d4344-e1c7-4fa7-b849-e20868d99789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016079099-172.17.0.10-1598642764443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-e3880370-ea86-4601-83e3-7e7144b3998e,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-fd76e870-e6b1-4cf6-8538-6d2da1447ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-a55353fa-e7ef-4962-b517-c7d96f8f710f,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-b5b82709-8039-42fe-b6e7-7f3361a3fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-0db09220-1a72-4386-b744-6102ec7a7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-981457c6-daed-4395-b427-bf0fd76ea56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-7c119adb-0ce0-4d5d-80ba-cf4c14c9d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-141490c3-1380-42ac-9cc0-7b04a677fb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016079099-172.17.0.10-1598642764443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-e3880370-ea86-4601-83e3-7e7144b3998e,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-fd76e870-e6b1-4cf6-8538-6d2da1447ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-a55353fa-e7ef-4962-b517-c7d96f8f710f,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-b5b82709-8039-42fe-b6e7-7f3361a3fecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-0db09220-1a72-4386-b744-6102ec7a7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-981457c6-daed-4395-b427-bf0fd76ea56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-7c119adb-0ce0-4d5d-80ba-cf4c14c9d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-141490c3-1380-42ac-9cc0-7b04a677fb89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796046654-172.17.0.10-1598642791768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-ee2ce508-cefb-46b2-9cee-34a0e431ce28,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-dd4f5006-ad07-448f-828c-6eab74cce14c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-290d00a9-f544-4bc1-b8b2-937ce1d2ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-86c49c2b-c7c6-4331-bc21-d78c34a7dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-7c0e6aaa-055a-4be5-8cec-4e56e3c40a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-edf72a7d-e9ba-4ab7-8860-c8de42a67596,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9154acd8-1f7d-43db-8f69-3268fe7775e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-050d84e5-31ac-4a0e-8210-97046802d5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796046654-172.17.0.10-1598642791768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-ee2ce508-cefb-46b2-9cee-34a0e431ce28,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-dd4f5006-ad07-448f-828c-6eab74cce14c,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-290d00a9-f544-4bc1-b8b2-937ce1d2ce6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-86c49c2b-c7c6-4331-bc21-d78c34a7dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-7c0e6aaa-055a-4be5-8cec-4e56e3c40a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-edf72a7d-e9ba-4ab7-8860-c8de42a67596,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9154acd8-1f7d-43db-8f69-3268fe7775e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-050d84e5-31ac-4a0e-8210-97046802d5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363105025-172.17.0.10-1598642818471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-711b0ce0-eb6d-47ae-800a-6f6c1091d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-876de32d-b224-4a2c-ba09-1e9d1d5d9a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-94e7614c-1f02-4a41-b923-64a6a091f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-b3bdde46-90cc-4a7d-81b9-23ff042ee166,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-ee6152db-6187-4304-bc09-2c64bd8c11ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-8712e3ea-c7dc-4969-81b2-afb4417ee5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-316ffde2-04b8-400a-8199-e227d1b73e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fdc80ff2-45e6-4f4d-92e2-415244313033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363105025-172.17.0.10-1598642818471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-711b0ce0-eb6d-47ae-800a-6f6c1091d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-876de32d-b224-4a2c-ba09-1e9d1d5d9a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-94e7614c-1f02-4a41-b923-64a6a091f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-b3bdde46-90cc-4a7d-81b9-23ff042ee166,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-ee6152db-6187-4304-bc09-2c64bd8c11ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-8712e3ea-c7dc-4969-81b2-afb4417ee5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-316ffde2-04b8-400a-8199-e227d1b73e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fdc80ff2-45e6-4f4d-92e2-415244313033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282173097-172.17.0.10-1598643389449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-104aa015-ae29-4b68-9d9a-38f029a058cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-2ebbc42b-aca7-4695-8d52-6338f7962025,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-404a7ea5-4b8f-480b-9171-1c17ef230c68,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ec162616-0337-46e1-9723-81f5bf3af60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-32f67959-1b75-4421-a2b3-0f824c4b9c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-1daf4598-b5f6-4e06-a8e7-cd6cfe334823,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-c1f55586-9641-44fc-920f-1a88e6e04d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-04bf7fc5-ffef-4f50-bb23-4a26f6c3c8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282173097-172.17.0.10-1598643389449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-104aa015-ae29-4b68-9d9a-38f029a058cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-2ebbc42b-aca7-4695-8d52-6338f7962025,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-404a7ea5-4b8f-480b-9171-1c17ef230c68,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ec162616-0337-46e1-9723-81f5bf3af60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-32f67959-1b75-4421-a2b3-0f824c4b9c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-1daf4598-b5f6-4e06-a8e7-cd6cfe334823,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-c1f55586-9641-44fc-920f-1a88e6e04d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-04bf7fc5-ffef-4f50-bb23-4a26f6c3c8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218191561-172.17.0.10-1598643420949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-feb94db6-b190-4261-8dde-49b72b7e7101,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-920a1511-55cd-412d-8fe5-89539684e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-ba2c54cd-1b74-4dcc-9d69-0928f744f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-6ca4f8cf-d518-4779-bc20-01a41dba6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-1c23bf40-60b5-4798-9e54-b74424697a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1a98cbf3-a155-475a-b66a-7a4d7e39a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-1f706980-c3c5-48a2-867f-a34883754b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-473b8eb3-b7f5-42b0-b026-8a05de2ce7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218191561-172.17.0.10-1598643420949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-feb94db6-b190-4261-8dde-49b72b7e7101,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-920a1511-55cd-412d-8fe5-89539684e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-ba2c54cd-1b74-4dcc-9d69-0928f744f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-6ca4f8cf-d518-4779-bc20-01a41dba6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-1c23bf40-60b5-4798-9e54-b74424697a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1a98cbf3-a155-475a-b66a-7a4d7e39a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-1f706980-c3c5-48a2-867f-a34883754b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-473b8eb3-b7f5-42b0-b026-8a05de2ce7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686509155-172.17.0.10-1598643480875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-ec2cc242-7564-4ad7-be78-69a090766ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-4f60a1bb-5a6d-4c07-8e3c-a267db3f2a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-60101fc8-8047-4f17-9300-60df69972eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-0583ec82-8071-4307-97f7-f477c7531a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-439ffcd8-fb39-42a7-87cd-8fa290fad249,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-3949e740-9910-4eb0-b46d-6d5dbbf2f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-903c53e6-5022-466e-97fb-8a84cb455447,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-689219f6-016f-456b-b1dc-b5bf918bf30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686509155-172.17.0.10-1598643480875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-ec2cc242-7564-4ad7-be78-69a090766ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-4f60a1bb-5a6d-4c07-8e3c-a267db3f2a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-60101fc8-8047-4f17-9300-60df69972eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-0583ec82-8071-4307-97f7-f477c7531a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-439ffcd8-fb39-42a7-87cd-8fa290fad249,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-3949e740-9910-4eb0-b46d-6d5dbbf2f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-903c53e6-5022-466e-97fb-8a84cb455447,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-689219f6-016f-456b-b1dc-b5bf918bf30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871807208-172.17.0.10-1598643981263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-971b6a10-0055-4f4c-af70-0a0d794d748d,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-896d4789-ed3d-443f-b095-1d513f22bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-e5b2c795-2f71-4ed1-99d3-68076e29d925,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-7c8e8dde-f189-434e-8173-9f3d04656ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-10f8a5d0-3cc2-4a36-b38d-d53de48f447e,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-5da920e1-36d2-4897-885b-60869f7fe53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-4ed94a7c-6da6-46f8-aef8-dfd62ed64eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-1425621b-1f95-4511-96a4-baaec244a0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871807208-172.17.0.10-1598643981263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-971b6a10-0055-4f4c-af70-0a0d794d748d,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-896d4789-ed3d-443f-b095-1d513f22bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-e5b2c795-2f71-4ed1-99d3-68076e29d925,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-7c8e8dde-f189-434e-8173-9f3d04656ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-10f8a5d0-3cc2-4a36-b38d-d53de48f447e,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-5da920e1-36d2-4897-885b-60869f7fe53f,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-4ed94a7c-6da6-46f8-aef8-dfd62ed64eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-1425621b-1f95-4511-96a4-baaec244a0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885360981-172.17.0.10-1598644070976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-64923534-3ec8-489e-82b7-e1c34eba4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8df0f6f3-1d3d-4570-8106-c11f346e4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-7a14a5c6-80c1-4c94-b470-b7105f652a82,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-9c9ea9f5-57c0-4432-b958-d7e5dcb5d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-129a39f0-68cd-4b8e-b364-af067b315b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-ced43afb-9f51-4bf2-9f0d-fafcfa6ecccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e6fc9ee4-1c81-4435-a293-aa73b0e4a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-cc1160ed-f9f5-414e-848a-115d03721d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885360981-172.17.0.10-1598644070976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-64923534-3ec8-489e-82b7-e1c34eba4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8df0f6f3-1d3d-4570-8106-c11f346e4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-7a14a5c6-80c1-4c94-b470-b7105f652a82,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-9c9ea9f5-57c0-4432-b958-d7e5dcb5d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-129a39f0-68cd-4b8e-b364-af067b315b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-ced43afb-9f51-4bf2-9f0d-fafcfa6ecccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e6fc9ee4-1c81-4435-a293-aa73b0e4a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-cc1160ed-f9f5-414e-848a-115d03721d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966599882-172.17.0.10-1598644168669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-880b1137-8018-402d-a003-9506d47c9a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-c843f633-2e88-4ba4-af9c-303d0a6076dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c661964a-1c77-4d0d-88a3-692509f8f655,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-4c0268f0-6177-4c11-a45c-0626dac43102,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-0af2ccb1-c413-4056-aa0c-2e8112b0d017,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-3b5df824-8a67-41b7-8d59-f8d0b367e181,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-ea087016-f327-4bca-ad97-75a7ec94e26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-c93bffc6-2c41-42c5-b5d1-1c08613d8a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966599882-172.17.0.10-1598644168669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-880b1137-8018-402d-a003-9506d47c9a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-c843f633-2e88-4ba4-af9c-303d0a6076dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c661964a-1c77-4d0d-88a3-692509f8f655,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-4c0268f0-6177-4c11-a45c-0626dac43102,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-0af2ccb1-c413-4056-aa0c-2e8112b0d017,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-3b5df824-8a67-41b7-8d59-f8d0b367e181,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-ea087016-f327-4bca-ad97-75a7ec94e26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-c93bffc6-2c41-42c5-b5d1-1c08613d8a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248549481-172.17.0.10-1598644333072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45688,DS-9aa4b40c-8e39-459e-bfdc-5a267014bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-80276097-aead-46b6-9d33-4f2d0a6864e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-02e03d52-4fcc-4b9f-b7dd-d443b5c44f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-48324886-b7b7-4845-bd2d-52af9ef0f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-fbeffcf0-b2cc-46aa-8c70-21a1bd923df3,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-8a734600-0c19-4e9d-ba0c-9a3179d94ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-dbe16751-1deb-416e-ac23-fd685a3165fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-76e353b7-b2ba-4cb7-a8f7-f4c5bcaeaf3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248549481-172.17.0.10-1598644333072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45688,DS-9aa4b40c-8e39-459e-bfdc-5a267014bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-80276097-aead-46b6-9d33-4f2d0a6864e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-02e03d52-4fcc-4b9f-b7dd-d443b5c44f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-48324886-b7b7-4845-bd2d-52af9ef0f0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-fbeffcf0-b2cc-46aa-8c70-21a1bd923df3,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-8a734600-0c19-4e9d-ba0c-9a3179d94ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-dbe16751-1deb-416e-ac23-fd685a3165fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-76e353b7-b2ba-4cb7-a8f7-f4c5bcaeaf3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227147508-172.17.0.10-1598644434504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-c8423d16-cfb3-41d5-9d82-dc12f064376f,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-9d8eaf8e-fa06-4619-8528-be212794d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-303cba5e-5367-47e3-be8f-bc9de9e56955,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-619034e2-f91e-445a-bb05-c8edfaf88688,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-5d3113bc-bc3b-488d-9e0b-8711abea571e,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-46340a8b-a67b-43d7-83ed-766e2a4472fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-c14718c0-3c99-429f-92c5-cb6177ca50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-9951771c-ecc1-4f1b-8b92-ceefe59cd58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227147508-172.17.0.10-1598644434504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-c8423d16-cfb3-41d5-9d82-dc12f064376f,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-9d8eaf8e-fa06-4619-8528-be212794d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-303cba5e-5367-47e3-be8f-bc9de9e56955,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-619034e2-f91e-445a-bb05-c8edfaf88688,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-5d3113bc-bc3b-488d-9e0b-8711abea571e,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-46340a8b-a67b-43d7-83ed-766e2a4472fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-c14718c0-3c99-429f-92c5-cb6177ca50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-9951771c-ecc1-4f1b-8b92-ceefe59cd58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537874249-172.17.0.10-1598644801949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-c2d315c8-ca09-4df0-abc2-85ff953a21e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-9071ccb1-d1b4-4c7b-9704-8880e045ed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-72e73f17-acfb-4a98-8ab9-a9ee42be67ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-dd8eef7a-8482-4be9-bea2-333e1e1240ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-97900347-a3c2-4964-995e-5065a71d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-92e996c7-2c0b-46cf-9bc4-cbdb5c18e411,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-bf6aaf1d-1c2a-40d3-a51d-1dc5a8b4b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-aebffa22-6ed1-4700-b48f-a855c322795e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537874249-172.17.0.10-1598644801949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-c2d315c8-ca09-4df0-abc2-85ff953a21e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-9071ccb1-d1b4-4c7b-9704-8880e045ed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-72e73f17-acfb-4a98-8ab9-a9ee42be67ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-dd8eef7a-8482-4be9-bea2-333e1e1240ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-97900347-a3c2-4964-995e-5065a71d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-92e996c7-2c0b-46cf-9bc4-cbdb5c18e411,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-bf6aaf1d-1c2a-40d3-a51d-1dc5a8b4b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-aebffa22-6ed1-4700-b48f-a855c322795e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850186222-172.17.0.10-1598645376214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44825,DS-1538a859-0919-4510-bab4-366bbd84c758,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-35f83fd2-3e1c-4b4c-a21f-c3265c7fd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-5d9239cd-b9a1-4ff7-86c0-34d21f31028f,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9ca7fc24-cf15-4ee9-80cf-5f6144712827,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-887dd8f0-2cd6-4186-b924-93e7902b7522,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d4f7533a-2460-423f-bbb8-59cde2b43600,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-7dda3a97-425e-4c36-9537-ff6e46e7e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-5524fcce-6ae8-434c-a9e2-19898b08dd11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850186222-172.17.0.10-1598645376214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44825,DS-1538a859-0919-4510-bab4-366bbd84c758,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-35f83fd2-3e1c-4b4c-a21f-c3265c7fd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-5d9239cd-b9a1-4ff7-86c0-34d21f31028f,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-9ca7fc24-cf15-4ee9-80cf-5f6144712827,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-887dd8f0-2cd6-4186-b924-93e7902b7522,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-d4f7533a-2460-423f-bbb8-59cde2b43600,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-7dda3a97-425e-4c36-9537-ff6e46e7e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-5524fcce-6ae8-434c-a9e2-19898b08dd11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466063401-172.17.0.10-1598645539535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-abe002f1-673f-4c4e-8a90-df88b9c55f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-9f8af3fc-c10e-4ae2-a9af-5453fde08e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-9bc4ab8a-6448-406c-ac81-587616fbc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-a21cdabb-90b2-4871-886d-93ef8ad478d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-b2c07949-e151-4c9e-af7e-2691ff06edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-79b44d0a-684e-4584-a604-035fb2890d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-f7ebaa3d-1d88-4268-87c4-d015174bb82d,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-dfb7ef08-cc15-4350-b321-9c53a16538ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466063401-172.17.0.10-1598645539535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-abe002f1-673f-4c4e-8a90-df88b9c55f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-9f8af3fc-c10e-4ae2-a9af-5453fde08e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-9bc4ab8a-6448-406c-ac81-587616fbc9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-a21cdabb-90b2-4871-886d-93ef8ad478d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-b2c07949-e151-4c9e-af7e-2691ff06edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-79b44d0a-684e-4584-a604-035fb2890d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-f7ebaa3d-1d88-4268-87c4-d015174bb82d,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-dfb7ef08-cc15-4350-b321-9c53a16538ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844836590-172.17.0.10-1598645673692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-6b03d7b3-8da4-4316-8172-be184ebfaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-ca9d4c1d-ef12-4887-926e-145ac72da39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-87ece30c-fb71-4210-b3f8-205e47f729cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-13d6cc40-85be-4403-a05f-4080855e5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-1acdbc61-678a-4264-9703-f9c2dc4f2747,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-53a5696b-99d7-415a-a0bb-18adca8701f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-cb1ccabb-6a19-46f7-b0c0-1db241a1422b,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-0d611d9a-9606-43a2-985f-545354510ad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844836590-172.17.0.10-1598645673692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-6b03d7b3-8da4-4316-8172-be184ebfaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-ca9d4c1d-ef12-4887-926e-145ac72da39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-87ece30c-fb71-4210-b3f8-205e47f729cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-13d6cc40-85be-4403-a05f-4080855e5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-1acdbc61-678a-4264-9703-f9c2dc4f2747,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-53a5696b-99d7-415a-a0bb-18adca8701f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-cb1ccabb-6a19-46f7-b0c0-1db241a1422b,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-0d611d9a-9606-43a2-985f-545354510ad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303421709-172.17.0.10-1598646294196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-eb5db610-6658-4665-a7fb-af88015ef7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-8be82681-f0a7-4cd5-a030-80f6460325d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a209e537-fa50-44c3-bd87-9504b5280776,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-0b182875-43c8-46af-968f-c8f0b5680858,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-24db5334-045d-4368-9244-e7aaeed10475,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-04d35aae-c3f2-46c4-acc0-965d47a7e111,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-e8187511-60fb-421e-93b8-e73a446f7c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-33a2fd4f-5e18-4b53-b51b-2cfc0739fdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303421709-172.17.0.10-1598646294196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-eb5db610-6658-4665-a7fb-af88015ef7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-8be82681-f0a7-4cd5-a030-80f6460325d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-a209e537-fa50-44c3-bd87-9504b5280776,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-0b182875-43c8-46af-968f-c8f0b5680858,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-24db5334-045d-4368-9244-e7aaeed10475,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-04d35aae-c3f2-46c4-acc0-965d47a7e111,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-e8187511-60fb-421e-93b8-e73a446f7c63,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-33a2fd4f-5e18-4b53-b51b-2cfc0739fdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933753468-172.17.0.10-1598646815248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-cd7dddec-d944-49c5-9d3b-9470f804b614,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-98978214-83f1-4834-a36a-ffa61181bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-6a465eee-1b24-4f11-abfd-792fb5e7a64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5fa39597-537b-448d-93bf-bdeb3703c962,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-df78129a-6824-4758-bbfa-ffd04ed8c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-ed72f447-6286-447c-88c2-35ae6230f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-58a3f90a-a352-44a5-832d-6969a7ea215b,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-8757fa70-5a03-4010-8f9e-957d79a0566b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933753468-172.17.0.10-1598646815248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-cd7dddec-d944-49c5-9d3b-9470f804b614,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-98978214-83f1-4834-a36a-ffa61181bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-6a465eee-1b24-4f11-abfd-792fb5e7a64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5fa39597-537b-448d-93bf-bdeb3703c962,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-df78129a-6824-4758-bbfa-ffd04ed8c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-ed72f447-6286-447c-88c2-35ae6230f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-58a3f90a-a352-44a5-832d-6969a7ea215b,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-8757fa70-5a03-4010-8f9e-957d79a0566b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5071
