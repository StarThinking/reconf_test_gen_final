reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998447476-172.17.0.20-1598561975351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-1d9de952-0459-43c4-9ccf-a57a229bf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-6198515c-634e-408b-9b03-505fdeb5faca,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-f14254d9-0ea0-4b38-9339-59e5ef297569,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-c4830ce0-3f95-4ae4-9cbb-ea65db6c7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b8ecd3db-ef0a-4984-ac70-4cdb0a788955,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-dc0733c9-7f4b-431c-b61f-f67fddb200d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-f29c621f-3c4b-446d-9c2e-1b9ed88ca45f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-d870f371-e328-4e08-9032-c104ba174fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998447476-172.17.0.20-1598561975351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-1d9de952-0459-43c4-9ccf-a57a229bf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-6198515c-634e-408b-9b03-505fdeb5faca,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-f14254d9-0ea0-4b38-9339-59e5ef297569,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-c4830ce0-3f95-4ae4-9cbb-ea65db6c7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b8ecd3db-ef0a-4984-ac70-4cdb0a788955,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-dc0733c9-7f4b-431c-b61f-f67fddb200d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-f29c621f-3c4b-446d-9c2e-1b9ed88ca45f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-d870f371-e328-4e08-9032-c104ba174fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894225760-172.17.0.20-1598562004454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-f3b11461-6222-4257-9723-0cbf19c90b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-0efad807-cb74-4cd7-b51a-00fc8c9b550f,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-713e073a-9d20-4b83-8c52-bddb67882d74,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-db3e4c0b-b0c1-442d-a303-6b011f8a9800,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-30d11127-c5de-45da-8f2c-c8fa0e7d21f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-237ca6db-3968-4252-b455-d258bbdc0d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-e0396b4f-02d5-4d96-a75c-004b4971b763,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-97271756-9994-49b5-ad56-e881e74f3b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894225760-172.17.0.20-1598562004454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-f3b11461-6222-4257-9723-0cbf19c90b68,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-0efad807-cb74-4cd7-b51a-00fc8c9b550f,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-713e073a-9d20-4b83-8c52-bddb67882d74,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-db3e4c0b-b0c1-442d-a303-6b011f8a9800,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-30d11127-c5de-45da-8f2c-c8fa0e7d21f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-237ca6db-3968-4252-b455-d258bbdc0d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-e0396b4f-02d5-4d96-a75c-004b4971b763,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-97271756-9994-49b5-ad56-e881e74f3b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564761280-172.17.0.20-1598562110974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-1b10bebc-1c51-4741-a80e-dc39411dcc40,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-aa8db1c8-ab8e-446c-86cd-fc51b50b2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-ea470766-e8c6-49d9-a641-370aaad99439,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-9b4eea10-094c-4499-8eee-3af10e65e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-cc465b9e-e6f8-459e-aa5a-8d91d97fda46,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-511a6910-c5ea-4e75-9800-6bda12532790,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4d33de0d-7379-4c13-9d42-c925aafb1191,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-694ec268-6a35-46c7-bad5-deaa3d428bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564761280-172.17.0.20-1598562110974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-1b10bebc-1c51-4741-a80e-dc39411dcc40,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-aa8db1c8-ab8e-446c-86cd-fc51b50b2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-ea470766-e8c6-49d9-a641-370aaad99439,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-9b4eea10-094c-4499-8eee-3af10e65e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-cc465b9e-e6f8-459e-aa5a-8d91d97fda46,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-511a6910-c5ea-4e75-9800-6bda12532790,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4d33de0d-7379-4c13-9d42-c925aafb1191,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-694ec268-6a35-46c7-bad5-deaa3d428bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807089549-172.17.0.20-1598562387884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-02b72eab-92cf-4ec7-a1b3-ce6542d095a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8293cf78-1dd8-4637-a514-e755b851f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-428c82e0-c77b-4c53-8fcc-8185b92f3904,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-5ec10c58-2258-411f-b6ea-603232e5af66,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-24c1229a-3e05-4e63-835f-5f92f4d3cb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-bd7566cf-05f3-4ff4-8213-e154703fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-9a0f2d39-23c6-477f-b083-e61b7b533de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-2e94fa3e-9f8a-40e8-8baf-bdc2dbcc4f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807089549-172.17.0.20-1598562387884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-02b72eab-92cf-4ec7-a1b3-ce6542d095a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8293cf78-1dd8-4637-a514-e755b851f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-428c82e0-c77b-4c53-8fcc-8185b92f3904,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-5ec10c58-2258-411f-b6ea-603232e5af66,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-24c1229a-3e05-4e63-835f-5f92f4d3cb99,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-bd7566cf-05f3-4ff4-8213-e154703fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-9a0f2d39-23c6-477f-b083-e61b7b533de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-2e94fa3e-9f8a-40e8-8baf-bdc2dbcc4f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214117361-172.17.0.20-1598562454648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-b4041d0a-0dbd-4bd0-943a-d0b80bff091d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8bd11faa-41c5-4eac-834b-90f62cd30c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-17bfa1b3-d17a-4799-b7cb-0f176851fc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-f404acaa-c74f-4dea-9cf0-21f72b07fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-d9fc46db-b371-4226-91c5-2e60950e9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-98f5d927-3ddb-413f-9372-60e20a35543e,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-b1d08ffb-4b3a-4615-9091-7cfc64bbb61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-5ff06870-55cc-478c-b888-ba9dd05046d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214117361-172.17.0.20-1598562454648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-b4041d0a-0dbd-4bd0-943a-d0b80bff091d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8bd11faa-41c5-4eac-834b-90f62cd30c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-17bfa1b3-d17a-4799-b7cb-0f176851fc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-f404acaa-c74f-4dea-9cf0-21f72b07fd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-d9fc46db-b371-4226-91c5-2e60950e9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-98f5d927-3ddb-413f-9372-60e20a35543e,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-b1d08ffb-4b3a-4615-9091-7cfc64bbb61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-5ff06870-55cc-478c-b888-ba9dd05046d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702324412-172.17.0.20-1598562484096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-92688490-b740-4f23-98c6-345659840728,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-dbf7f595-18a1-47ab-9ada-3842eacb7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-87a41e73-e572-49fa-9c8b-460a3c587607,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d86c844e-df5f-45ed-ac6a-7f074689fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-41e1725f-78f2-475e-8f68-773954363401,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-1a804880-6062-4503-b4a5-09713826b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-586f42e7-01eb-4d9e-8a9e-1faf702bd963,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-8cb8621d-dd59-4836-b57d-3ccfc1b4ccf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702324412-172.17.0.20-1598562484096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-92688490-b740-4f23-98c6-345659840728,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-dbf7f595-18a1-47ab-9ada-3842eacb7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-87a41e73-e572-49fa-9c8b-460a3c587607,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d86c844e-df5f-45ed-ac6a-7f074689fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-41e1725f-78f2-475e-8f68-773954363401,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-1a804880-6062-4503-b4a5-09713826b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-586f42e7-01eb-4d9e-8a9e-1faf702bd963,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-8cb8621d-dd59-4836-b57d-3ccfc1b4ccf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722674702-172.17.0.20-1598562730216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-760b20d8-c74a-42d0-afd6-698363c4a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-a122c601-93bf-4f29-aaf6-2e7e72602a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-364727d7-957e-46d2-bbe1-c79eb587f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-41ff0fb1-0bed-4824-9dc2-01946f412ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d3c16021-4a1f-4e59-aa18-a6aea5c1579c,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-ee320142-571d-4b15-88a3-61df7df7b593,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-a569ada3-4bcb-46e0-966c-5a87ed894d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-0ae2f718-f398-4ad8-8869-de517b74cc83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722674702-172.17.0.20-1598562730216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-760b20d8-c74a-42d0-afd6-698363c4a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-a122c601-93bf-4f29-aaf6-2e7e72602a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-364727d7-957e-46d2-bbe1-c79eb587f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-41ff0fb1-0bed-4824-9dc2-01946f412ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d3c16021-4a1f-4e59-aa18-a6aea5c1579c,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-ee320142-571d-4b15-88a3-61df7df7b593,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-a569ada3-4bcb-46e0-966c-5a87ed894d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-0ae2f718-f398-4ad8-8869-de517b74cc83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055558813-172.17.0.20-1598562787853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-ae645278-4fe4-45fa-a907-52e5fdcc3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-6d06b87d-fe9f-46cc-b988-39277f368b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-1ca75944-a6ad-44ed-8765-702948933c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0ebef56d-ba2d-4b5b-adc0-67fb3d40f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-1af74a2c-ca4a-4ff7-8547-e5ba9259fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-34377b4e-fae5-4042-ab3d-ba5017a55cae,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-3411c130-c076-4cde-9e58-b0e494d3172b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-c8c25589-5510-4b84-91dc-15d3e2f48d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055558813-172.17.0.20-1598562787853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-ae645278-4fe4-45fa-a907-52e5fdcc3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-6d06b87d-fe9f-46cc-b988-39277f368b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-1ca75944-a6ad-44ed-8765-702948933c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0ebef56d-ba2d-4b5b-adc0-67fb3d40f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-1af74a2c-ca4a-4ff7-8547-e5ba9259fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-34377b4e-fae5-4042-ab3d-ba5017a55cae,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-3411c130-c076-4cde-9e58-b0e494d3172b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-c8c25589-5510-4b84-91dc-15d3e2f48d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961893682-172.17.0.20-1598562967466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-7876b0a7-c74f-4049-beb4-8feec0ca0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-53a0ffdf-5f52-4470-b879-1f4de0ad5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9673fce9-80c9-4491-aa07-acb5831bdf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-681d0e59-86a8-42f9-aaa9-899fc7cb4923,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-fa4488a1-abf4-4296-a2fa-bf865c542f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-07335e7e-89b0-495f-94ee-148e995c7ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-f4a54edd-e4be-4b44-9561-9a67053a8205,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-2e95d8ea-6c71-48ce-ba1f-99d43aa371aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961893682-172.17.0.20-1598562967466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-7876b0a7-c74f-4049-beb4-8feec0ca0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-53a0ffdf-5f52-4470-b879-1f4de0ad5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9673fce9-80c9-4491-aa07-acb5831bdf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-681d0e59-86a8-42f9-aaa9-899fc7cb4923,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-fa4488a1-abf4-4296-a2fa-bf865c542f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-07335e7e-89b0-495f-94ee-148e995c7ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-f4a54edd-e4be-4b44-9561-9a67053a8205,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-2e95d8ea-6c71-48ce-ba1f-99d43aa371aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410515164-172.17.0.20-1598563002236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-b003fb4c-a221-4087-a919-6e50f93321fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0e1cfe08-0eb6-432f-91b6-775d6479f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-24de0749-d9bf-457f-98bd-5a9a5c5dbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-8f4926e8-8216-41f5-8052-04352b627024,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-37b08f89-7a21-4671-9f7b-44110fac246d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-2f24d5f7-4162-44e7-aa96-7f3fe6dd9f65,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-978b4c7b-574c-4b2e-a964-47e8c44ca27d,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-29c8b840-5f23-41ac-b285-614048eb5f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410515164-172.17.0.20-1598563002236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-b003fb4c-a221-4087-a919-6e50f93321fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0e1cfe08-0eb6-432f-91b6-775d6479f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-24de0749-d9bf-457f-98bd-5a9a5c5dbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-8f4926e8-8216-41f5-8052-04352b627024,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-37b08f89-7a21-4671-9f7b-44110fac246d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-2f24d5f7-4162-44e7-aa96-7f3fe6dd9f65,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-978b4c7b-574c-4b2e-a964-47e8c44ca27d,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-29c8b840-5f23-41ac-b285-614048eb5f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774615306-172.17.0.20-1598563226187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-7e497c4a-8f1a-406e-9786-3acca93a0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-a9aeea40-0cc4-458a-9465-261a115a4af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-3cdc37ef-2b38-4bf3-b40c-43ec2e93a190,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-4f45e53f-b7f5-4f03-bd5d-6d18dbc93606,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-053e1824-1814-4eba-b96a-0001cea28c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-a3e73719-e18b-4385-a558-65789a92b133,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-7c1049b1-59d3-4991-9428-a45cdc452dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-16a9672a-3624-4486-8e84-259c98a9bbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774615306-172.17.0.20-1598563226187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-7e497c4a-8f1a-406e-9786-3acca93a0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-a9aeea40-0cc4-458a-9465-261a115a4af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-3cdc37ef-2b38-4bf3-b40c-43ec2e93a190,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-4f45e53f-b7f5-4f03-bd5d-6d18dbc93606,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-053e1824-1814-4eba-b96a-0001cea28c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-a3e73719-e18b-4385-a558-65789a92b133,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-7c1049b1-59d3-4991-9428-a45cdc452dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-16a9672a-3624-4486-8e84-259c98a9bbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037248330-172.17.0.20-1598563440417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-c6c39799-f684-4afc-87b9-8918e13d1bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-94e4b734-06e1-4453-bd22-7bdfced64ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-4f34cc63-1461-40d3-a79e-0a5d180ce4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-31d90e27-3a80-4aef-8af0-e930ecd73fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-7d8daa4d-753e-4f88-9dca-2a201eec6779,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-71875661-25de-4d6e-a016-0f5804c6095f,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-8bd7adc3-e490-43d4-9b1e-cd7a0a914cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-f578072a-6b0e-429e-8376-c05d216182e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037248330-172.17.0.20-1598563440417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-c6c39799-f684-4afc-87b9-8918e13d1bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-94e4b734-06e1-4453-bd22-7bdfced64ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-4f34cc63-1461-40d3-a79e-0a5d180ce4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-31d90e27-3a80-4aef-8af0-e930ecd73fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-7d8daa4d-753e-4f88-9dca-2a201eec6779,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-71875661-25de-4d6e-a016-0f5804c6095f,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-8bd7adc3-e490-43d4-9b1e-cd7a0a914cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-f578072a-6b0e-429e-8376-c05d216182e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714841509-172.17.0.20-1598563471255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-6623c9b6-f037-4292-ad48-76eaceabc298,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-f8af88be-846e-4e6c-adf5-8bc475683687,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-00af3c6b-0150-4375-ba17-28fdea0c1455,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-b23338d6-da99-45ce-a522-8f78ea22bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-a506ded0-3412-4505-a48f-744b5bfbcf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-e1d5f0ba-8e7a-4f30-a73a-ddc0b3787e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2f2de8ae-58af-4935-ba2c-cd71bcffb9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-59c84ce8-9c69-4989-bb10-fc1105ef2791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714841509-172.17.0.20-1598563471255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-6623c9b6-f037-4292-ad48-76eaceabc298,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-f8af88be-846e-4e6c-adf5-8bc475683687,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-00af3c6b-0150-4375-ba17-28fdea0c1455,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-b23338d6-da99-45ce-a522-8f78ea22bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-a506ded0-3412-4505-a48f-744b5bfbcf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-e1d5f0ba-8e7a-4f30-a73a-ddc0b3787e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2f2de8ae-58af-4935-ba2c-cd71bcffb9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-59c84ce8-9c69-4989-bb10-fc1105ef2791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193596786-172.17.0.20-1598563570382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-16fb56c4-1ada-4cd3-8e52-520d8e8bc0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-15192d00-114a-449c-b5b8-6557271bd520,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-835ddfae-7da1-4a34-9896-0552ce814c47,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-10f2d28a-ea00-44d3-b3a8-e86c06f80b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-6ad72ca6-e1af-4db2-9b35-1498dfdd95a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-eacfd574-c1eb-4a1f-ba4c-c2f388ea0899,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7c0c94ae-4db1-4a13-9fa3-5e4d05f4aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-d1817c43-3958-4661-8d18-800c61f1d8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193596786-172.17.0.20-1598563570382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-16fb56c4-1ada-4cd3-8e52-520d8e8bc0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-15192d00-114a-449c-b5b8-6557271bd520,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-835ddfae-7da1-4a34-9896-0552ce814c47,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-10f2d28a-ea00-44d3-b3a8-e86c06f80b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-6ad72ca6-e1af-4db2-9b35-1498dfdd95a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-eacfd574-c1eb-4a1f-ba4c-c2f388ea0899,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7c0c94ae-4db1-4a13-9fa3-5e4d05f4aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-d1817c43-3958-4661-8d18-800c61f1d8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408266347-172.17.0.20-1598563925696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-9871266e-dba4-44b4-bc8c-91ab226d0535,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-1ec9d114-62e9-49fe-8993-d7dbe05e0297,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-ceb8300d-5e69-409a-bf98-f887eb490eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-53a4d009-081d-4aa9-b9ee-123f9e706a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-e534e18f-e051-4ccb-b475-4342a2bb4c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-20caf2c8-b1f8-47d6-8a91-ce1b82b4f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7a418536-ab78-44b8-9fd5-d6932bd0741c,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-f068572c-bdfb-4797-8b2f-08a18a366320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408266347-172.17.0.20-1598563925696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46040,DS-9871266e-dba4-44b4-bc8c-91ab226d0535,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-1ec9d114-62e9-49fe-8993-d7dbe05e0297,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-ceb8300d-5e69-409a-bf98-f887eb490eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-53a4d009-081d-4aa9-b9ee-123f9e706a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-e534e18f-e051-4ccb-b475-4342a2bb4c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-20caf2c8-b1f8-47d6-8a91-ce1b82b4f2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7a418536-ab78-44b8-9fd5-d6932bd0741c,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-f068572c-bdfb-4797-8b2f-08a18a366320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008022453-172.17.0.20-1598563963945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-c13f3ff2-4265-4b00-9ead-4b7e272ca95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5923d5cf-e0d6-4f26-9b2d-8733e25e8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2e1c1cee-510e-4fb0-b270-58f55e37cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-a0564d8c-d229-4e2f-b462-8d2d90d65dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-da036086-0063-4679-a626-39fb93b1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-e70f8636-85b8-478d-b2a5-b7183bd84cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-abb4974e-0343-4e9e-bbeb-762b68fe99de,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bdaa0fe8-114f-4251-b60b-564757a4ffdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008022453-172.17.0.20-1598563963945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-c13f3ff2-4265-4b00-9ead-4b7e272ca95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5923d5cf-e0d6-4f26-9b2d-8733e25e8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-2e1c1cee-510e-4fb0-b270-58f55e37cba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-a0564d8c-d229-4e2f-b462-8d2d90d65dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-da036086-0063-4679-a626-39fb93b1b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-e70f8636-85b8-478d-b2a5-b7183bd84cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-abb4974e-0343-4e9e-bbeb-762b68fe99de,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bdaa0fe8-114f-4251-b60b-564757a4ffdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369167148-172.17.0.20-1598564269886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-8b99ef12-68a0-4309-9ed6-1632a5afa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-1b9ac6de-9cc7-4aca-9a33-eb511521d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-5ed9e67d-8fa1-4ea6-a270-c23c21dd6450,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e8d4bd69-029a-4ae7-a056-18bd4bec3d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-455fa8ec-25ff-4339-bdfc-c2feeb0d52d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-cc932e58-5743-4405-bbf8-a1a543c51d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b6aa1127-320c-4242-b4b9-5b745f8483e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b771a33d-1cc3-4804-bcda-1bdd3ed6c3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369167148-172.17.0.20-1598564269886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-8b99ef12-68a0-4309-9ed6-1632a5afa1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-1b9ac6de-9cc7-4aca-9a33-eb511521d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-5ed9e67d-8fa1-4ea6-a270-c23c21dd6450,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e8d4bd69-029a-4ae7-a056-18bd4bec3d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-455fa8ec-25ff-4339-bdfc-c2feeb0d52d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-cc932e58-5743-4405-bbf8-a1a543c51d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b6aa1127-320c-4242-b4b9-5b745f8483e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b771a33d-1cc3-4804-bcda-1bdd3ed6c3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345532209-172.17.0.20-1598564327447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-69e262e2-4566-4f0d-8e49-a3642db47876,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-78aed631-7b51-4433-996f-0f19894ebc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-02a3747a-bf6b-45f3-b7e8-7a676be3a8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-9c5361e0-d350-47a6-a6a0-54b794126367,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-83663413-1331-47ad-ac38-54bc6dd76af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-8a89d423-6215-4806-addb-b1f9a2166e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-1af4046e-c6f9-4ab3-96b3-7337d3bed0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-23baa745-92c6-4f7e-b937-27429c8448cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345532209-172.17.0.20-1598564327447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-69e262e2-4566-4f0d-8e49-a3642db47876,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-78aed631-7b51-4433-996f-0f19894ebc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-02a3747a-bf6b-45f3-b7e8-7a676be3a8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-9c5361e0-d350-47a6-a6a0-54b794126367,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-83663413-1331-47ad-ac38-54bc6dd76af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-8a89d423-6215-4806-addb-b1f9a2166e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-1af4046e-c6f9-4ab3-96b3-7337d3bed0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-23baa745-92c6-4f7e-b937-27429c8448cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404206922-172.17.0.20-1598565452433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-f2724afb-09e4-4353-99d7-e625d663bcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-49c0b58b-1023-465b-bd25-aa55c8d5a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-a10aa52b-0d8a-4074-bde6-da601010cede,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-acf777fa-6508-4bf6-924a-d9fa7a4c3117,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-28c87490-18c5-4812-85bf-627f46d56675,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-20305ace-5ba5-46c9-8d27-4db22f2a6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-af0b5d84-355a-4a69-a90e-de5a183bd1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-d8a7141c-7357-47b3-bc7b-539003687c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404206922-172.17.0.20-1598565452433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-f2724afb-09e4-4353-99d7-e625d663bcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-49c0b58b-1023-465b-bd25-aa55c8d5a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-a10aa52b-0d8a-4074-bde6-da601010cede,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-acf777fa-6508-4bf6-924a-d9fa7a4c3117,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-28c87490-18c5-4812-85bf-627f46d56675,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-20305ace-5ba5-46c9-8d27-4db22f2a6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-af0b5d84-355a-4a69-a90e-de5a183bd1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-d8a7141c-7357-47b3-bc7b-539003687c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908678558-172.17.0.20-1598565684022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-2e640c34-ffa0-4e77-b272-8e0d7cc8dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-ff0862a4-b763-4a8b-bfb3-3a92a7f43d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-c024d3fb-1a16-49d6-942a-c930e564d23b,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-b7d54891-1a07-4dc6-bf4e-5ae19e35dee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-c0eeb2ba-d076-487e-96e4-d6db6886b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-6475fa09-7845-4494-9a15-6b1573b4377a,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-eec25309-3ec1-40c5-8006-1105ae6916b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-58f4ad18-d711-4725-b388-786e7fe9e79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908678558-172.17.0.20-1598565684022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-2e640c34-ffa0-4e77-b272-8e0d7cc8dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-ff0862a4-b763-4a8b-bfb3-3a92a7f43d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-c024d3fb-1a16-49d6-942a-c930e564d23b,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-b7d54891-1a07-4dc6-bf4e-5ae19e35dee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-c0eeb2ba-d076-487e-96e4-d6db6886b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-6475fa09-7845-4494-9a15-6b1573b4377a,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-eec25309-3ec1-40c5-8006-1105ae6916b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-58f4ad18-d711-4725-b388-786e7fe9e79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574184807-172.17.0.20-1598565742603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37419,DS-8a37f13e-d851-458f-a49a-ba914b230e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-fab4690b-eedd-4e9a-a42d-96152b98f6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-1f907fbd-fefe-44da-a7c2-56af81f45586,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-15b7f023-f982-4e29-8a45-47a6f9b18d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-21f461ff-3633-4b20-b900-02882b864602,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-d0cf49f6-7c81-4872-b2f5-e9fee83735ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-4c1af79b-7c15-463e-9d23-2bc13d6f304b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-2c3b7e52-e60e-493a-99f7-46652f23cd80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574184807-172.17.0.20-1598565742603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37419,DS-8a37f13e-d851-458f-a49a-ba914b230e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-fab4690b-eedd-4e9a-a42d-96152b98f6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-1f907fbd-fefe-44da-a7c2-56af81f45586,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-15b7f023-f982-4e29-8a45-47a6f9b18d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-21f461ff-3633-4b20-b900-02882b864602,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-d0cf49f6-7c81-4872-b2f5-e9fee83735ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-4c1af79b-7c15-463e-9d23-2bc13d6f304b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-2c3b7e52-e60e-493a-99f7-46652f23cd80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057184493-172.17.0.20-1598565863129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-91c38cc3-6eae-4bf2-a026-14ed080c5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2bb03166-ba4a-44f3-9279-8653776fe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0f957ec5-e5bf-490b-bb0c-8750f4793e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-5f6512ac-a156-49f7-a78d-0bc9d090f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-0890ce2b-2d42-4d6e-92a2-e2ace360cb21,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-a6d467b3-553b-4167-81cf-5718f9771712,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-d7a1b085-e06f-4df3-8af1-a3bed7056a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-c1592ca3-3fff-47cf-8639-25a90fdf88cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057184493-172.17.0.20-1598565863129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-91c38cc3-6eae-4bf2-a026-14ed080c5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2bb03166-ba4a-44f3-9279-8653776fe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0f957ec5-e5bf-490b-bb0c-8750f4793e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-5f6512ac-a156-49f7-a78d-0bc9d090f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-0890ce2b-2d42-4d6e-92a2-e2ace360cb21,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-a6d467b3-553b-4167-81cf-5718f9771712,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-d7a1b085-e06f-4df3-8af1-a3bed7056a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-c1592ca3-3fff-47cf-8639-25a90fdf88cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4433
