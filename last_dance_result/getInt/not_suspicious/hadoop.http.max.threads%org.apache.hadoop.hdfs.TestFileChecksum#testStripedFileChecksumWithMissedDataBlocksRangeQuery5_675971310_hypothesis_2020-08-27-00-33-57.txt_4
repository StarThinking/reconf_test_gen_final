reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168410493-172.17.0.9-1598488799594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-94062bc0-6772-4a4b-8c5f-39627c8cdee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-7ba59e4f-3407-4c53-bcb0-797a87673153,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-3169969e-16c7-4c82-9d42-747dcdd9e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-db4878b5-de54-4900-8692-70a0ebe0b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-a4b4f6b5-47ab-4c4f-8aab-f8939890a17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-72d40c02-ec33-4d1e-9138-c14774df46ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-b964776d-8cef-4901-be65-4c4e01ad7773,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-de6fa69b-9da6-4899-a272-d6144cd0520b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168410493-172.17.0.9-1598488799594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-94062bc0-6772-4a4b-8c5f-39627c8cdee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-7ba59e4f-3407-4c53-bcb0-797a87673153,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-3169969e-16c7-4c82-9d42-747dcdd9e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-db4878b5-de54-4900-8692-70a0ebe0b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-a4b4f6b5-47ab-4c4f-8aab-f8939890a17e,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-72d40c02-ec33-4d1e-9138-c14774df46ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-b964776d-8cef-4901-be65-4c4e01ad7773,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-de6fa69b-9da6-4899-a272-d6144cd0520b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800242123-172.17.0.9-1598489133954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-a34b2add-fc3b-472a-86f9-4bacfab0f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-77f18873-e183-4cda-a65a-42e7bc26e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-4b303d45-cbd8-45ae-a705-0f33f3484687,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-e2351d39-a362-4598-81ce-1f0b53e7d919,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-2779f9d5-f0d6-4b6e-b359-c335b2ef4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-35e07845-2d38-4807-8b6e-7169e4ad6732,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-25b43f65-b87e-4938-927f-2fa448e06cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-8d62fb15-abab-4ef2-88f8-dfdf7e0a4e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800242123-172.17.0.9-1598489133954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-a34b2add-fc3b-472a-86f9-4bacfab0f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-77f18873-e183-4cda-a65a-42e7bc26e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-4b303d45-cbd8-45ae-a705-0f33f3484687,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-e2351d39-a362-4598-81ce-1f0b53e7d919,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-2779f9d5-f0d6-4b6e-b359-c335b2ef4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-35e07845-2d38-4807-8b6e-7169e4ad6732,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-25b43f65-b87e-4938-927f-2fa448e06cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-8d62fb15-abab-4ef2-88f8-dfdf7e0a4e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439999227-172.17.0.9-1598489312209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-8916adda-398a-4117-9229-bb770452b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-94800a4a-3d8b-463e-b586-9d9959a37caf,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-c580d7d5-84f0-4138-a2d4-4666981ca655,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-193d9591-668f-48a2-9868-013f3006e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e9d24177-10e4-49ac-bbec-51bbe325b170,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-503c8116-5f10-42f4-9596-c6708d3ed1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d08b0bb3-8d47-4af3-bb7c-a5484685d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-77a1620a-0b8c-41ca-8c1e-57ead3d471c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439999227-172.17.0.9-1598489312209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-8916adda-398a-4117-9229-bb770452b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-94800a4a-3d8b-463e-b586-9d9959a37caf,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-c580d7d5-84f0-4138-a2d4-4666981ca655,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-193d9591-668f-48a2-9868-013f3006e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e9d24177-10e4-49ac-bbec-51bbe325b170,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-503c8116-5f10-42f4-9596-c6708d3ed1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d08b0bb3-8d47-4af3-bb7c-a5484685d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-77a1620a-0b8c-41ca-8c1e-57ead3d471c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510547690-172.17.0.9-1598489823108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-45c9d07a-a644-4667-b7e5-7901197c987a,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e67d7e47-8e06-41ae-8e2d-cc0761badf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-c2f88214-553f-453e-adc5-af1244920dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-598fdf5a-2bed-426b-ba61-f7f03aa8176a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-47c223e9-0116-4d49-8092-86a3e85f0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-6450357a-3cf1-4619-936d-313a79a89bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-0fae3306-ac40-4fd8-9cfc-cc338635397e,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-46894957-a99a-4d6f-8bff-7e23a52ff7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510547690-172.17.0.9-1598489823108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-45c9d07a-a644-4667-b7e5-7901197c987a,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e67d7e47-8e06-41ae-8e2d-cc0761badf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-c2f88214-553f-453e-adc5-af1244920dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-598fdf5a-2bed-426b-ba61-f7f03aa8176a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-47c223e9-0116-4d49-8092-86a3e85f0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-6450357a-3cf1-4619-936d-313a79a89bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-0fae3306-ac40-4fd8-9cfc-cc338635397e,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-46894957-a99a-4d6f-8bff-7e23a52ff7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85849098-172.17.0.9-1598490402913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-582bc0df-941c-45a0-8cd5-d79f7d8852c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-1ca6728e-7a00-444e-9cd8-2b0fda78efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-54f39a4b-0bfd-472c-928b-eef1a496f075,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d83c976b-5081-4c31-ab84-551eddaa6eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-db500c3b-e574-43a0-a6ed-d76fbed065fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-6976ffe0-6dbe-4ebc-a16e-32148b203626,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-79b21a49-f484-4445-bdce-25d7b90b5d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-712f29bc-5361-4539-82de-30d5ac28b905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85849098-172.17.0.9-1598490402913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-582bc0df-941c-45a0-8cd5-d79f7d8852c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-1ca6728e-7a00-444e-9cd8-2b0fda78efd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-54f39a4b-0bfd-472c-928b-eef1a496f075,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-d83c976b-5081-4c31-ab84-551eddaa6eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-db500c3b-e574-43a0-a6ed-d76fbed065fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-6976ffe0-6dbe-4ebc-a16e-32148b203626,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-79b21a49-f484-4445-bdce-25d7b90b5d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-712f29bc-5361-4539-82de-30d5ac28b905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237801847-172.17.0.9-1598491258409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-10a21cfe-37c1-42b7-a565-e52f303d7f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-3814bbe5-d421-4ee8-9d8f-04d7d53e146e,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-8ab4a5cc-223c-406f-b9b7-7383bd816a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-375971dc-b0d6-438d-b0fe-e6dcfd930a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-974e0e9e-0c1e-4f7a-81d3-96e0038b8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-3e3f03d8-5542-41eb-96b3-0479762efaac,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-aeab7de4-18f2-476d-a994-c77615ffb631,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-1e1278b7-1207-4e7b-bfef-b9d5d97161d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237801847-172.17.0.9-1598491258409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-10a21cfe-37c1-42b7-a565-e52f303d7f83,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-3814bbe5-d421-4ee8-9d8f-04d7d53e146e,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-8ab4a5cc-223c-406f-b9b7-7383bd816a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-375971dc-b0d6-438d-b0fe-e6dcfd930a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-974e0e9e-0c1e-4f7a-81d3-96e0038b8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-3e3f03d8-5542-41eb-96b3-0479762efaac,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-aeab7de4-18f2-476d-a994-c77615ffb631,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-1e1278b7-1207-4e7b-bfef-b9d5d97161d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343754856-172.17.0.9-1598491528774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44010,DS-9a3b52ba-8d3b-4c1d-ad66-64707c07f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-bffb6495-e090-481d-8401-6e2b9e84b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-1fe12611-e6d7-4f02-a455-94e8b74a2ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-9c162fa2-211d-4837-ae0c-d759aba5c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-774f112a-e64b-4bd6-835d-1b114f32ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-b2469426-b725-44b2-aca1-a46d8b3d8414,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-a7f728ea-2f7e-4fac-be56-a4ce2581e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-edb55c5f-100a-4bb8-9f5a-5cff53b21012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343754856-172.17.0.9-1598491528774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44010,DS-9a3b52ba-8d3b-4c1d-ad66-64707c07f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-bffb6495-e090-481d-8401-6e2b9e84b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-1fe12611-e6d7-4f02-a455-94e8b74a2ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-9c162fa2-211d-4837-ae0c-d759aba5c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-774f112a-e64b-4bd6-835d-1b114f32ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-b2469426-b725-44b2-aca1-a46d8b3d8414,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-a7f728ea-2f7e-4fac-be56-a4ce2581e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-edb55c5f-100a-4bb8-9f5a-5cff53b21012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858112117-172.17.0.9-1598491944979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-5f20fc6a-468c-494f-ac78-303db5ccc045,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-5c1c4e82-f757-4c3f-bfdc-4f46606dff27,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e91538fa-bd2e-4499-a64a-1fd1f0876276,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-507fcd14-0479-4efc-8df2-cfeda3943b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-784f419a-d2b3-4117-b535-b5eab934e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-3612b8fc-b82c-4e89-ba9f-c44f58e3c277,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-80b4f720-5903-4533-8be1-618a52ea83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0b21d607-88b1-45ca-a200-90e35bf0ef61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858112117-172.17.0.9-1598491944979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-5f20fc6a-468c-494f-ac78-303db5ccc045,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-5c1c4e82-f757-4c3f-bfdc-4f46606dff27,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-e91538fa-bd2e-4499-a64a-1fd1f0876276,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-507fcd14-0479-4efc-8df2-cfeda3943b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-784f419a-d2b3-4117-b535-b5eab934e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-3612b8fc-b82c-4e89-ba9f-c44f58e3c277,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-80b4f720-5903-4533-8be1-618a52ea83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-0b21d607-88b1-45ca-a200-90e35bf0ef61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298740443-172.17.0.9-1598492721853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-59997ec2-57d1-4f86-8be4-175cb6419cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-1a6dbbe1-2234-461c-b8ec-5f15d4905f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-fd8ce9e2-4145-467d-a4b0-d76a2415ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-b776cd6c-6a03-43f4-9991-30b7e608208c,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-b11baa8d-290e-4ac6-8b3d-a51a0001215e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-16aa6b11-f8de-4fc5-8c1c-9148a07536f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-e0efb7d5-2fac-4b9e-9fa4-ebc69ed59031,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-2a1c9ea7-be6a-46d7-a31e-571952a8118e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298740443-172.17.0.9-1598492721853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-59997ec2-57d1-4f86-8be4-175cb6419cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-1a6dbbe1-2234-461c-b8ec-5f15d4905f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-fd8ce9e2-4145-467d-a4b0-d76a2415ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-b776cd6c-6a03-43f4-9991-30b7e608208c,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-b11baa8d-290e-4ac6-8b3d-a51a0001215e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-16aa6b11-f8de-4fc5-8c1c-9148a07536f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-e0efb7d5-2fac-4b9e-9fa4-ebc69ed59031,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-2a1c9ea7-be6a-46d7-a31e-571952a8118e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351217690-172.17.0.9-1598492939724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-cffcbd4e-7d80-428a-a918-48b844936747,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-f2edfa4c-8f33-4e1b-8408-355577109afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-6d9fe0f3-0673-4618-8998-5d2df7576aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-ca678364-6370-4d3a-9f87-11e0e42e2bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-16f936f5-ecc6-41b1-9261-f7d118625785,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b44f19ab-c77a-4496-b8c5-acb0c9ae3186,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-bf7845be-22b6-4729-bced-58587de97994,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-fc59077a-06c7-439c-bed3-ff22f2dce882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351217690-172.17.0.9-1598492939724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-cffcbd4e-7d80-428a-a918-48b844936747,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-f2edfa4c-8f33-4e1b-8408-355577109afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-6d9fe0f3-0673-4618-8998-5d2df7576aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-ca678364-6370-4d3a-9f87-11e0e42e2bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-16f936f5-ecc6-41b1-9261-f7d118625785,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b44f19ab-c77a-4496-b8c5-acb0c9ae3186,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-bf7845be-22b6-4729-bced-58587de97994,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-fc59077a-06c7-439c-bed3-ff22f2dce882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776479764-172.17.0.9-1598493110712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-5943775b-3adc-4232-845c-52b331e3b822,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-b195f4a4-1e59-465d-9cee-7921082e0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-95deb161-f60e-4624-acac-9b27f3f97e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-6c4641ff-c1f7-46b0-946d-71fb8b735e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-55c39ec4-c75b-4c0b-9d2c-12a52e122b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-67666030-5607-4cce-ac9e-661b2f0c3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-c96b69b8-d8b9-47bb-a5c8-39b2214b76df,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6dd63d55-9d15-4fea-8d72-575ed8718e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776479764-172.17.0.9-1598493110712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-5943775b-3adc-4232-845c-52b331e3b822,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-b195f4a4-1e59-465d-9cee-7921082e0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-95deb161-f60e-4624-acac-9b27f3f97e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-6c4641ff-c1f7-46b0-946d-71fb8b735e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-55c39ec4-c75b-4c0b-9d2c-12a52e122b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-67666030-5607-4cce-ac9e-661b2f0c3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-c96b69b8-d8b9-47bb-a5c8-39b2214b76df,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-6dd63d55-9d15-4fea-8d72-575ed8718e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517875232-172.17.0.9-1598493326925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-241eb3dc-a212-4a83-9b5f-95f68c403225,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b13ca46e-8e70-4819-8c36-14b75211bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-fd232f2f-4310-4a43-a40e-325126866f06,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-987e9411-72aa-481b-bdb7-36ea9f51d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-3a154fb6-baa6-41f5-9049-fd5fe6fcc3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-baff3ca7-44bc-4fdf-927e-24eca452825f,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-ee6d474d-2a91-4275-8c11-657047dc4097,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-3f9c034f-1b24-4d0e-aaf5-e16e49e4a4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517875232-172.17.0.9-1598493326925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-241eb3dc-a212-4a83-9b5f-95f68c403225,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b13ca46e-8e70-4819-8c36-14b75211bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-fd232f2f-4310-4a43-a40e-325126866f06,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-987e9411-72aa-481b-bdb7-36ea9f51d5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-3a154fb6-baa6-41f5-9049-fd5fe6fcc3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-baff3ca7-44bc-4fdf-927e-24eca452825f,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-ee6d474d-2a91-4275-8c11-657047dc4097,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-3f9c034f-1b24-4d0e-aaf5-e16e49e4a4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291512735-172.17.0.9-1598493736912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34904,DS-65dabb6a-bd93-4698-8634-e60ab8e470de,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4cde269f-a6f9-4256-8d05-a749f3e23c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-22bce21a-5bba-4f00-bc7d-2b52b88f51ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-29f06942-ad57-491b-bed4-fccd20614765,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-3ab5aa71-f55e-473a-875c-69af90f044bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-79ec76d9-746e-4969-b1d2-ab99dbe3b384,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-7f097765-90d2-4d31-848c-2a36d5f9ecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c0c7d543-6fe9-4ca1-87d9-40b79f721a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291512735-172.17.0.9-1598493736912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34904,DS-65dabb6a-bd93-4698-8634-e60ab8e470de,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4cde269f-a6f9-4256-8d05-a749f3e23c14,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-22bce21a-5bba-4f00-bc7d-2b52b88f51ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-29f06942-ad57-491b-bed4-fccd20614765,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-3ab5aa71-f55e-473a-875c-69af90f044bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-79ec76d9-746e-4969-b1d2-ab99dbe3b384,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-7f097765-90d2-4d31-848c-2a36d5f9ecb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c0c7d543-6fe9-4ca1-87d9-40b79f721a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5624
