reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930026393-172.17.0.19-1598628163563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-823a6adb-23dc-4b7a-8a21-843fa4815892,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-5a169b74-796d-4d84-bda0-38477c1cdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-32dfc9ff-065d-493c-bc09-575461816796,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-445b11e5-02a8-4551-9789-f6e1cbaf63bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-9708a49e-c50d-4f64-9598-ce44cbcd8840,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-072e08b2-3800-4cc7-8617-1334ec275d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4e2d5950-fb31-4eba-acf4-c1dc24e77292,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-da65156c-a040-4b87-8d28-2db1d84cd7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930026393-172.17.0.19-1598628163563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-823a6adb-23dc-4b7a-8a21-843fa4815892,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-5a169b74-796d-4d84-bda0-38477c1cdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-32dfc9ff-065d-493c-bc09-575461816796,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-445b11e5-02a8-4551-9789-f6e1cbaf63bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-9708a49e-c50d-4f64-9598-ce44cbcd8840,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-072e08b2-3800-4cc7-8617-1334ec275d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4e2d5950-fb31-4eba-acf4-c1dc24e77292,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-da65156c-a040-4b87-8d28-2db1d84cd7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538315896-172.17.0.19-1598628860305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-bbe0d893-af7e-4b58-b87c-0a14e75af944,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-3d42f83a-8431-4af0-99c3-f28a2d32c396,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-3aa13d74-5bc8-4ab3-a9f0-ca02fbdd296a,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-9d940784-73fa-47b9-ac55-0f8db483b4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-8fc62eee-2372-43e2-92a2-fd334e6b4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9c53e481-7363-4003-b7b0-f153c345a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-6e8903e5-3c96-4d3e-b603-f6eeea56d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-97cd0f44-129a-4406-b1e4-6c8f12539af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538315896-172.17.0.19-1598628860305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-bbe0d893-af7e-4b58-b87c-0a14e75af944,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-3d42f83a-8431-4af0-99c3-f28a2d32c396,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-3aa13d74-5bc8-4ab3-a9f0-ca02fbdd296a,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-9d940784-73fa-47b9-ac55-0f8db483b4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-8fc62eee-2372-43e2-92a2-fd334e6b4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-9c53e481-7363-4003-b7b0-f153c345a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-6e8903e5-3c96-4d3e-b603-f6eeea56d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-97cd0f44-129a-4406-b1e4-6c8f12539af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395989071-172.17.0.19-1598629055410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-c8895733-d00a-44a6-b232-8b22b7a6996e,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-5fbb4b9d-6f04-4054-bbab-87b28e792789,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1a645356-3d4e-4177-a2ce-fdb06ea8dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-4899f772-3a1a-4449-ad49-f99feafd8235,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-53faafd6-8015-477d-92a7-6d8a294ea97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-649bda23-6aec-436a-8873-31c5022d3d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-3859db6f-d6dd-4d20-b94a-badbe644c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-a3f96a2f-131c-4e52-a670-8b801b3ea75f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395989071-172.17.0.19-1598629055410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-c8895733-d00a-44a6-b232-8b22b7a6996e,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-5fbb4b9d-6f04-4054-bbab-87b28e792789,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1a645356-3d4e-4177-a2ce-fdb06ea8dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-4899f772-3a1a-4449-ad49-f99feafd8235,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-53faafd6-8015-477d-92a7-6d8a294ea97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-649bda23-6aec-436a-8873-31c5022d3d74,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-3859db6f-d6dd-4d20-b94a-badbe644c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-a3f96a2f-131c-4e52-a670-8b801b3ea75f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350766564-172.17.0.19-1598629220191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-fc6a2e4d-dc11-4f3a-88a5-130332cac468,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-62655032-701f-4a2a-89c0-adb3bdc735d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-ec72215a-beee-4d8f-a519-59b3a6a59c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-3182c1c7-387a-4d51-9bee-df82b685bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b2803ab6-b575-4aa2-a64f-710840d8ea32,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-e0a0255b-1b8c-4213-a91c-2bb715d9dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-67f8a808-9b46-45dc-8baf-2dcbd1964c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-fed02269-d0c4-42b5-9d6e-10f4c03d9bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350766564-172.17.0.19-1598629220191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-fc6a2e4d-dc11-4f3a-88a5-130332cac468,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-62655032-701f-4a2a-89c0-adb3bdc735d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-ec72215a-beee-4d8f-a519-59b3a6a59c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-3182c1c7-387a-4d51-9bee-df82b685bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b2803ab6-b575-4aa2-a64f-710840d8ea32,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-e0a0255b-1b8c-4213-a91c-2bb715d9dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-67f8a808-9b46-45dc-8baf-2dcbd1964c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-fed02269-d0c4-42b5-9d6e-10f4c03d9bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067146657-172.17.0.19-1598629289091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-18be877c-4d2b-4c14-b690-3d1750334913,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-44809ccf-f95b-4d9c-8c24-a837fced447c,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-034e1637-270d-4520-8ae2-c9e6f8b63cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-bbfaf045-bbc2-4f83-9147-e6477b9b1b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-ddf121b8-72ab-4462-9fd3-1252c6f597b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-b68b5407-fbc7-4500-8f0f-3b0fff358206,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e0019a4a-76d9-4742-b1f4-842b520800c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b9ac6291-3c40-4692-b230-3fd177cb4446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067146657-172.17.0.19-1598629289091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-18be877c-4d2b-4c14-b690-3d1750334913,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-44809ccf-f95b-4d9c-8c24-a837fced447c,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-034e1637-270d-4520-8ae2-c9e6f8b63cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-bbfaf045-bbc2-4f83-9147-e6477b9b1b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-ddf121b8-72ab-4462-9fd3-1252c6f597b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-b68b5407-fbc7-4500-8f0f-3b0fff358206,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-e0019a4a-76d9-4742-b1f4-842b520800c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b9ac6291-3c40-4692-b230-3fd177cb4446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514859901-172.17.0.19-1598629323531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38807,DS-26778326-7b67-45f1-8686-1380ba716968,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-a9777d3c-d166-4abb-88b2-106763646ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-9e803fcd-2162-43f9-be89-44fe4db06615,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-6c40b09d-8c91-4a83-87f0-5686f91b982e,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-2601a609-9172-41a9-868b-8c79e44ac90a,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-cd61181c-841a-48e6-8d1b-20da3aead9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-16c261b3-46a8-4aea-84db-6733c2a2cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-42385c61-1717-4bc1-800d-e67fc468c4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514859901-172.17.0.19-1598629323531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38807,DS-26778326-7b67-45f1-8686-1380ba716968,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-a9777d3c-d166-4abb-88b2-106763646ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-9e803fcd-2162-43f9-be89-44fe4db06615,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-6c40b09d-8c91-4a83-87f0-5686f91b982e,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-2601a609-9172-41a9-868b-8c79e44ac90a,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-cd61181c-841a-48e6-8d1b-20da3aead9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-16c261b3-46a8-4aea-84db-6733c2a2cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-42385c61-1717-4bc1-800d-e67fc468c4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133053535-172.17.0.19-1598629419575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-88323413-b71f-4585-bb8d-ed326ac08fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-89db2edb-d209-4b9f-8df4-51e63d8ef62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-527193d6-e978-4b91-9cce-534c8db3c721,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-2b3ab087-d932-4509-990a-2e41e1f2875d,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-759c78e8-f720-422b-b0b1-914f3950b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f022892c-6fd3-4043-9b0e-b540e70a83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-96e00c37-9036-49dd-9123-71330465436b,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-663c770b-efe7-4b4e-a2fc-d22a392d4092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133053535-172.17.0.19-1598629419575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-88323413-b71f-4585-bb8d-ed326ac08fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-89db2edb-d209-4b9f-8df4-51e63d8ef62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-527193d6-e978-4b91-9cce-534c8db3c721,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-2b3ab087-d932-4509-990a-2e41e1f2875d,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-759c78e8-f720-422b-b0b1-914f3950b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f022892c-6fd3-4043-9b0e-b540e70a83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-96e00c37-9036-49dd-9123-71330465436b,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-663c770b-efe7-4b4e-a2fc-d22a392d4092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226184304-172.17.0.19-1598629521823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-24b7206e-951c-4c16-9342-91ba661b18dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-ba70a961-7f83-4df3-b1f5-3fbd33658129,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-fb72990a-7d0c-42d8-94d9-579c52ee629b,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-ce345be4-482c-48c3-9058-3a7fa1e3af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-098e4370-ad4a-40e7-9622-f57186a9cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-47f74b1b-8af6-4d37-b989-6416a1856f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-5da76321-03c2-4c1b-a038-b469dd6d0866,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-efa050ea-1a7e-4d2f-b315-9f562ca4c4ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226184304-172.17.0.19-1598629521823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-24b7206e-951c-4c16-9342-91ba661b18dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-ba70a961-7f83-4df3-b1f5-3fbd33658129,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-fb72990a-7d0c-42d8-94d9-579c52ee629b,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-ce345be4-482c-48c3-9058-3a7fa1e3af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-098e4370-ad4a-40e7-9622-f57186a9cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-47f74b1b-8af6-4d37-b989-6416a1856f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-5da76321-03c2-4c1b-a038-b469dd6d0866,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-efa050ea-1a7e-4d2f-b315-9f562ca4c4ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966969261-172.17.0.19-1598630165532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39515,DS-4d172f17-cacb-4cb7-ab44-7da51dc79b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1b2583a8-8075-4918-9c42-1ce24491b695,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-d5e58b0a-f81c-4ab5-bb26-cacf5bf1a453,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-cee2a08c-62b1-46a5-8452-ad26db0ddb02,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-25446c63-7a71-474e-8dcc-93371c6cba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-e991ba9e-038b-42c9-88ad-fb9faac123d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-1c9cad8d-ee86-4f49-a831-ff8d33bf05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-cd8a6f84-ae86-43d4-8a1e-62ff276058cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966969261-172.17.0.19-1598630165532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39515,DS-4d172f17-cacb-4cb7-ab44-7da51dc79b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1b2583a8-8075-4918-9c42-1ce24491b695,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-d5e58b0a-f81c-4ab5-bb26-cacf5bf1a453,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-cee2a08c-62b1-46a5-8452-ad26db0ddb02,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-25446c63-7a71-474e-8dcc-93371c6cba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-e991ba9e-038b-42c9-88ad-fb9faac123d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-1c9cad8d-ee86-4f49-a831-ff8d33bf05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-cd8a6f84-ae86-43d4-8a1e-62ff276058cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980237404-172.17.0.19-1598630439646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33051,DS-e1119e56-26b5-42e5-b35e-4a92ded378fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-0ded4aa3-fa72-4960-9371-3ac6ea0fecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-74bb62b0-bb3a-44a3-a37f-c4658802cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-e2f9cc06-5adc-446b-905c-1fd2695b0760,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5d67283d-b16c-44db-8a8e-85313d769fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-5f90ae98-cbd7-457b-a20b-2c8b1e47e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-bf5d13d0-c0a0-46e9-8835-0b8126d32fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-c1da0da6-f3f2-4ce2-ba95-38edbb9aa9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980237404-172.17.0.19-1598630439646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33051,DS-e1119e56-26b5-42e5-b35e-4a92ded378fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-0ded4aa3-fa72-4960-9371-3ac6ea0fecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-74bb62b0-bb3a-44a3-a37f-c4658802cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-e2f9cc06-5adc-446b-905c-1fd2695b0760,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5d67283d-b16c-44db-8a8e-85313d769fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-5f90ae98-cbd7-457b-a20b-2c8b1e47e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-bf5d13d0-c0a0-46e9-8835-0b8126d32fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-c1da0da6-f3f2-4ce2-ba95-38edbb9aa9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035080933-172.17.0.19-1598630992419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-be897d48-6de8-444c-b764-c05d4b34766d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-1b46a939-d935-476b-89ab-220fd292fd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-9b8407b1-0238-4083-aa2e-c0712cce4871,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-41c1ba4f-a4dd-421d-b1d6-7758d7384686,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-dab53240-0b62-47d7-8c7c-c2da8d2ed9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-0895479a-bb3b-47b7-8148-976f96d1d572,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-ed941110-b257-4ec7-870a-e86da36f70c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-cfa7590d-5ab6-400b-99da-50b63aba52ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035080933-172.17.0.19-1598630992419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-be897d48-6de8-444c-b764-c05d4b34766d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-1b46a939-d935-476b-89ab-220fd292fd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-9b8407b1-0238-4083-aa2e-c0712cce4871,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-41c1ba4f-a4dd-421d-b1d6-7758d7384686,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-dab53240-0b62-47d7-8c7c-c2da8d2ed9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-0895479a-bb3b-47b7-8148-976f96d1d572,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-ed941110-b257-4ec7-870a-e86da36f70c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-cfa7590d-5ab6-400b-99da-50b63aba52ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284025154-172.17.0.19-1598631411934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-a3223cde-0ef6-4f3d-8396-7ea4c65af198,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-f08d19e3-5ce6-4fc7-95af-5ed1fd21b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-e1794510-6cba-4e99-b809-0a035656ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-11eaa079-ebcb-4437-bee7-89ab119e3f18,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-f37ac7d4-03db-4ce7-a2f1-66a549c58d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-a9652231-a1ae-47b4-8b08-04a4ed1605f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-4f5690aa-4291-43d8-8001-eea5a0a159ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-a80a8b58-b707-473a-9f0f-8e2ee52e780f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284025154-172.17.0.19-1598631411934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-a3223cde-0ef6-4f3d-8396-7ea4c65af198,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-f08d19e3-5ce6-4fc7-95af-5ed1fd21b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-e1794510-6cba-4e99-b809-0a035656ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-11eaa079-ebcb-4437-bee7-89ab119e3f18,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-f37ac7d4-03db-4ce7-a2f1-66a549c58d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-a9652231-a1ae-47b4-8b08-04a4ed1605f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-4f5690aa-4291-43d8-8001-eea5a0a159ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-a80a8b58-b707-473a-9f0f-8e2ee52e780f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451449411-172.17.0.19-1598631897445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-61924088-70a9-408f-a324-54a73010a9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-16546c5f-5bf9-41da-88a6-fb52d76781a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-302f6306-4509-4949-a2bc-37a9eede3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-cb6778d4-033b-4e65-99f0-be87f46a75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-cbccabb0-c2be-4de7-8520-ced790120752,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-97398a68-3853-4daf-90d7-942217143930,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d2690cd0-455f-4a5f-8651-e4a2b869c571,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-a7cd2fdf-8784-4850-b2f0-297bd2538d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451449411-172.17.0.19-1598631897445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-61924088-70a9-408f-a324-54a73010a9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-16546c5f-5bf9-41da-88a6-fb52d76781a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-302f6306-4509-4949-a2bc-37a9eede3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-cb6778d4-033b-4e65-99f0-be87f46a75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-cbccabb0-c2be-4de7-8520-ced790120752,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-97398a68-3853-4daf-90d7-942217143930,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d2690cd0-455f-4a5f-8651-e4a2b869c571,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-a7cd2fdf-8784-4850-b2f0-297bd2538d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860769838-172.17.0.19-1598631925051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-11759bd1-cc56-4749-83a7-6fc571c8524f,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c1d3e356-90ae-4e98-ab72-0f7b76cce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-577cd187-6ef3-4db7-b8da-a085d334dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-94e32a04-b5ce-49b6-be5f-f26114d55c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c22aa6ef-4f8c-4cc2-a759-6e2960ac1941,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c9f68704-370b-40ae-8463-b25210c3121c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-5c158c40-2f52-4fe8-aba5-2f5580e356fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-823f3007-5f15-46ad-97c3-f1c7c8b28045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860769838-172.17.0.19-1598631925051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-11759bd1-cc56-4749-83a7-6fc571c8524f,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c1d3e356-90ae-4e98-ab72-0f7b76cce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-577cd187-6ef3-4db7-b8da-a085d334dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-94e32a04-b5ce-49b6-be5f-f26114d55c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-c22aa6ef-4f8c-4cc2-a759-6e2960ac1941,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c9f68704-370b-40ae-8463-b25210c3121c,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-5c158c40-2f52-4fe8-aba5-2f5580e356fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-823f3007-5f15-46ad-97c3-f1c7c8b28045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733772796-172.17.0.19-1598632261394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-df848206-23c1-45ed-90b0-7ac644f66a73,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-ae89b03d-9327-41f8-a32e-49043ea9b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-d043a383-1a55-4cd4-9bc8-7d1179baedc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-63297a9b-dd28-4414-aa70-6296dabf355a,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-0a16e655-fb86-4e4e-ae5c-e275df68c748,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-1ce16e07-4e67-41f3-bd17-407dd936dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-d2f41a47-4ccc-42e4-95b7-e546bc6f5a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-32231b7b-77c7-45f7-8417-5f4bedf7f6e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733772796-172.17.0.19-1598632261394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-df848206-23c1-45ed-90b0-7ac644f66a73,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-ae89b03d-9327-41f8-a32e-49043ea9b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-d043a383-1a55-4cd4-9bc8-7d1179baedc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-63297a9b-dd28-4414-aa70-6296dabf355a,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-0a16e655-fb86-4e4e-ae5c-e275df68c748,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-1ce16e07-4e67-41f3-bd17-407dd936dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-d2f41a47-4ccc-42e4-95b7-e546bc6f5a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-32231b7b-77c7-45f7-8417-5f4bedf7f6e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084311806-172.17.0.19-1598632446735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-512e3788-186a-41c0-a362-e0d94c7d12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-050bef99-188b-404b-a07c-4d0cee7da59b,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-023ef1ec-080c-4d3d-84db-cd4882210ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-fc173e99-4f8f-431c-9521-e1ecbe9b5314,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-98438381-a6d8-409d-9363-37e88bd4cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-2ae25684-f306-4bf1-8929-06ef5aa00b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a8c40511-505a-459b-813f-1cd4e3f8a397,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-944cf9f8-3883-4018-a21d-ccf5bdb9e21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084311806-172.17.0.19-1598632446735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-512e3788-186a-41c0-a362-e0d94c7d12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-050bef99-188b-404b-a07c-4d0cee7da59b,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-023ef1ec-080c-4d3d-84db-cd4882210ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-fc173e99-4f8f-431c-9521-e1ecbe9b5314,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-98438381-a6d8-409d-9363-37e88bd4cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-2ae25684-f306-4bf1-8929-06ef5aa00b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-a8c40511-505a-459b-813f-1cd4e3f8a397,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-944cf9f8-3883-4018-a21d-ccf5bdb9e21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865525015-172.17.0.19-1598632519762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-928f3642-9621-4c56-8436-6ce69cad5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-b0b297ef-8845-4e34-8443-678ebd1f8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-de1ee334-34af-4322-bd56-7975b62fbccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-1d6cb458-039c-4ec5-8a36-3c4df6ccb8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-35096fff-15eb-4b2b-a980-945697092014,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-401bd778-0186-4c03-ae2a-39ff3f923ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-709b1cb0-46bf-4a6e-a019-5eb5e6fd95ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-db9039c1-7602-4285-84d0-7062b5133c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865525015-172.17.0.19-1598632519762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36280,DS-928f3642-9621-4c56-8436-6ce69cad5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-b0b297ef-8845-4e34-8443-678ebd1f8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-de1ee334-34af-4322-bd56-7975b62fbccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-1d6cb458-039c-4ec5-8a36-3c4df6ccb8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-35096fff-15eb-4b2b-a980-945697092014,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-401bd778-0186-4c03-ae2a-39ff3f923ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-709b1cb0-46bf-4a6e-a019-5eb5e6fd95ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-db9039c1-7602-4285-84d0-7062b5133c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839062131-172.17.0.19-1598632773533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-2f0301aa-627c-4fff-8290-7fccefed83c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-96cecac8-ed08-4dff-8fa0-ae82a4191096,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-f8416d73-f125-4a39-91af-0542473d1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-3a58c19e-a740-4119-a40f-f4810bf51118,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-040d7fcc-f924-4572-ade6-259010420e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-787de484-8025-440a-804a-b0b45fde3827,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-4e7968c3-ed48-4512-8834-191634b0ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-fa71e7b9-06bd-45f0-9711-6160603d67ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839062131-172.17.0.19-1598632773533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-2f0301aa-627c-4fff-8290-7fccefed83c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-96cecac8-ed08-4dff-8fa0-ae82a4191096,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-f8416d73-f125-4a39-91af-0542473d1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-3a58c19e-a740-4119-a40f-f4810bf51118,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-040d7fcc-f924-4572-ade6-259010420e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-787de484-8025-440a-804a-b0b45fde3827,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-4e7968c3-ed48-4512-8834-191634b0ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-fa71e7b9-06bd-45f0-9711-6160603d67ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 4988
