reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937595038-172.17.0.9-1598627580007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-cc1fdf2e-ecda-4e97-8f7f-3313c5376ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-511e6c71-8617-4fdf-be38-0305a09f2b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-ae5e5b93-4086-4949-93c0-de60e9371fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-502a62be-d41f-4d96-b6cf-96ab72c9e187,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-546c9e20-53ea-4699-9b77-03ed8662ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-051698f9-1119-4fe0-8340-2dcd17bade06,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-005b38fc-2823-4434-8e1b-45bd7487cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-a08e7dcc-83c4-4862-b076-25441f5f0ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937595038-172.17.0.9-1598627580007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-cc1fdf2e-ecda-4e97-8f7f-3313c5376ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-511e6c71-8617-4fdf-be38-0305a09f2b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-ae5e5b93-4086-4949-93c0-de60e9371fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-502a62be-d41f-4d96-b6cf-96ab72c9e187,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-546c9e20-53ea-4699-9b77-03ed8662ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-051698f9-1119-4fe0-8340-2dcd17bade06,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-005b38fc-2823-4434-8e1b-45bd7487cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-a08e7dcc-83c4-4862-b076-25441f5f0ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438970797-172.17.0.9-1598627805228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-ae1fc87f-64fd-4de1-9c9a-dbaa6a34909c,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-f784eb0f-1855-4fef-81f4-9863cdcd6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-a15af279-3fc0-4ef1-8f12-7f0e8b36d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-26322de5-2ddc-4c3d-8c43-2951de6c740d,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-6b291517-c77c-45a0-8d69-9f76127fd3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-144021b4-4ae7-44f6-8265-3fba8fe2374f,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-0f70b83b-aba7-4bf7-a0d6-2b495cc5627c,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b15d373d-860b-4df0-afe0-02997d05eba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438970797-172.17.0.9-1598627805228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-ae1fc87f-64fd-4de1-9c9a-dbaa6a34909c,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-f784eb0f-1855-4fef-81f4-9863cdcd6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-a15af279-3fc0-4ef1-8f12-7f0e8b36d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-26322de5-2ddc-4c3d-8c43-2951de6c740d,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-6b291517-c77c-45a0-8d69-9f76127fd3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-144021b4-4ae7-44f6-8265-3fba8fe2374f,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-0f70b83b-aba7-4bf7-a0d6-2b495cc5627c,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b15d373d-860b-4df0-afe0-02997d05eba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744304408-172.17.0.9-1598628100433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-95e07a35-d3b0-463a-a81b-1bcd6dd025ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-04f6d92d-76fe-405c-84cb-f721aa344b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-e3e6e148-de1d-4914-bce0-81cc8c5faa92,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-899db439-de3f-43d1-82a6-c25cf6d57193,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-317aa56c-0780-41ec-b42a-12158def256b,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-2ce9054c-2e5e-47f4-85e8-954fc737e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-fa8e5d15-6111-46ec-85ff-ec223d282c56,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-320887f0-1959-4381-aa7d-b66e2b63d224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744304408-172.17.0.9-1598628100433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-95e07a35-d3b0-463a-a81b-1bcd6dd025ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-04f6d92d-76fe-405c-84cb-f721aa344b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-e3e6e148-de1d-4914-bce0-81cc8c5faa92,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-899db439-de3f-43d1-82a6-c25cf6d57193,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-317aa56c-0780-41ec-b42a-12158def256b,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-2ce9054c-2e5e-47f4-85e8-954fc737e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-fa8e5d15-6111-46ec-85ff-ec223d282c56,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-320887f0-1959-4381-aa7d-b66e2b63d224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126854955-172.17.0.9-1598628635185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-d93bcdec-ad3a-4432-af07-0f817d63e005,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-62d54067-9004-407d-a4e9-043ad6b4bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-b81cb47a-4b0d-4599-a39d-486e139c4c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-3da2312e-3141-4902-960d-43938671103a,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e44ae80f-9702-4dea-8920-d638aab9d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-31174996-5121-4481-b186-661654cea855,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e138a65b-1ec4-477b-bdc7-52a1022af541,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-f099081e-9f72-483e-8b51-71ba95f66dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126854955-172.17.0.9-1598628635185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34266,DS-d93bcdec-ad3a-4432-af07-0f817d63e005,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-62d54067-9004-407d-a4e9-043ad6b4bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-b81cb47a-4b0d-4599-a39d-486e139c4c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-3da2312e-3141-4902-960d-43938671103a,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-e44ae80f-9702-4dea-8920-d638aab9d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-31174996-5121-4481-b186-661654cea855,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e138a65b-1ec4-477b-bdc7-52a1022af541,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-f099081e-9f72-483e-8b51-71ba95f66dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271330429-172.17.0.9-1598628717549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36672,DS-c356e183-547e-4456-8920-39c7bfe9c309,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-b9b00be0-83e3-4485-92ba-444fd09a101d,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-2bf1d112-271f-4703-9ffb-600e14ab1a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-ec7a4d2b-162f-4a28-89cd-8839f7e1e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-5aa0d9e1-9da5-4371-a8dc-1c1de8de35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3d471c58-c11e-42b6-970e-10b227b995ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-abb54b12-cd79-4e15-85ac-9fef1d8a0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-1d99347a-1a99-4c2d-9622-aa505fcf57f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271330429-172.17.0.9-1598628717549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36672,DS-c356e183-547e-4456-8920-39c7bfe9c309,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-b9b00be0-83e3-4485-92ba-444fd09a101d,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-2bf1d112-271f-4703-9ffb-600e14ab1a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-ec7a4d2b-162f-4a28-89cd-8839f7e1e8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-5aa0d9e1-9da5-4371-a8dc-1c1de8de35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3d471c58-c11e-42b6-970e-10b227b995ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-abb54b12-cd79-4e15-85ac-9fef1d8a0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-1d99347a-1a99-4c2d-9622-aa505fcf57f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266259962-172.17.0.9-1598628866339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-5ef1a8ae-12c4-4274-b81c-3b870a383d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-cf96af92-dfba-43bb-a73e-653a5a1dce42,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-6e2946c1-7798-417c-aeca-4d8d9332404e,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-48d953ba-42bb-4bde-99ba-87cfb1eaad88,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6682d2ad-74b8-4e9d-9c65-80ee569ecbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-0a3505b1-b9d5-4934-86e9-4bfc2a287c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-7c1e9591-17e3-4ab2-a54d-bdf15527f968,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-260c5820-072c-495d-898d-2dd38f3e28d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266259962-172.17.0.9-1598628866339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-5ef1a8ae-12c4-4274-b81c-3b870a383d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-cf96af92-dfba-43bb-a73e-653a5a1dce42,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-6e2946c1-7798-417c-aeca-4d8d9332404e,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-48d953ba-42bb-4bde-99ba-87cfb1eaad88,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-6682d2ad-74b8-4e9d-9c65-80ee569ecbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-0a3505b1-b9d5-4934-86e9-4bfc2a287c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-7c1e9591-17e3-4ab2-a54d-bdf15527f968,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-260c5820-072c-495d-898d-2dd38f3e28d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630244206-172.17.0.9-1598628906329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-10838718-2951-428e-87e6-064648952a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-1c47f30f-c565-4cf1-83ab-aa27c77c37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7dd1bbf0-bfed-4be5-80cd-8eba4322afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-0b958ff7-87e3-4f69-b6c0-e87bbad211e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2244fe00-6b3b-4a54-9700-aec7121c9c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-70b7d9a9-50cd-4a79-a97b-0fb36444c964,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-46db3290-1bef-48e0-9f17-2c226aa5f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-54c38eeb-426b-415d-a833-d757503c3a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630244206-172.17.0.9-1598628906329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-10838718-2951-428e-87e6-064648952a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-1c47f30f-c565-4cf1-83ab-aa27c77c37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7dd1bbf0-bfed-4be5-80cd-8eba4322afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-0b958ff7-87e3-4f69-b6c0-e87bbad211e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2244fe00-6b3b-4a54-9700-aec7121c9c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-70b7d9a9-50cd-4a79-a97b-0fb36444c964,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-46db3290-1bef-48e0-9f17-2c226aa5f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-54c38eeb-426b-415d-a833-d757503c3a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920725483-172.17.0.9-1598629630454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-a63f6eed-1ef3-4e8f-b594-275d7b81b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-a464990c-cab5-4e8d-bf40-1109409efc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-53563775-07aa-41d9-969d-e33a61fbdb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-8f28ccb2-779d-4d24-afab-72ceaa70af4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-a62992cd-82a1-494e-acd9-2833e20936e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-ea197181-7e50-45a1-a920-59df1109eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-ebce2533-604b-4777-beb3-0e9ce5fec026,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-56f7055f-823e-409b-85ad-25c96ef15583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920725483-172.17.0.9-1598629630454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-a63f6eed-1ef3-4e8f-b594-275d7b81b9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-a464990c-cab5-4e8d-bf40-1109409efc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-53563775-07aa-41d9-969d-e33a61fbdb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-8f28ccb2-779d-4d24-afab-72ceaa70af4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-a62992cd-82a1-494e-acd9-2833e20936e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-ea197181-7e50-45a1-a920-59df1109eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-ebce2533-604b-4777-beb3-0e9ce5fec026,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-56f7055f-823e-409b-85ad-25c96ef15583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352589395-172.17.0.9-1598629698280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45603,DS-4b2d7419-4e81-494f-be4e-833e46363e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-288df94e-0b8c-48f0-a25d-7ab909e4017f,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e91d44d6-9bf5-467d-9dfb-b76be4ad192c,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-55d6307c-1071-4799-b2ac-d584a98368d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-1ca34ee5-355e-4e2d-abee-cb29a3ddfbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-cee146f9-2958-4a27-b7b4-9df0b7690235,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-7a399b65-ecd3-424a-83a6-b54e2d059146,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7174cc89-6f2e-482c-b54f-df31ef6b2c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352589395-172.17.0.9-1598629698280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45603,DS-4b2d7419-4e81-494f-be4e-833e46363e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-288df94e-0b8c-48f0-a25d-7ab909e4017f,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e91d44d6-9bf5-467d-9dfb-b76be4ad192c,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-55d6307c-1071-4799-b2ac-d584a98368d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-1ca34ee5-355e-4e2d-abee-cb29a3ddfbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-cee146f9-2958-4a27-b7b4-9df0b7690235,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-7a399b65-ecd3-424a-83a6-b54e2d059146,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7174cc89-6f2e-482c-b54f-df31ef6b2c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453035041-172.17.0.9-1598629845408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-b9f73447-fb99-4bd8-8b70-4ac3ef262b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-6f62cda9-1d95-46d7-acf8-2c5b211b1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-2a42a073-4ff0-4565-b433-53120978cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-24d656a7-1018-4f44-b8a5-0f48d79a26d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-cf210741-8363-451c-978f-5093d1ff8321,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-6f8376e2-6ecd-453b-930e-2e13a7a185ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-83683a53-60e5-42a7-be5d-dab3efa07510,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-36c7323a-08b2-449c-9a3b-5574c9d20a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453035041-172.17.0.9-1598629845408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-b9f73447-fb99-4bd8-8b70-4ac3ef262b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-6f62cda9-1d95-46d7-acf8-2c5b211b1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-2a42a073-4ff0-4565-b433-53120978cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-24d656a7-1018-4f44-b8a5-0f48d79a26d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-cf210741-8363-451c-978f-5093d1ff8321,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-6f8376e2-6ecd-453b-930e-2e13a7a185ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-83683a53-60e5-42a7-be5d-dab3efa07510,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-36c7323a-08b2-449c-9a3b-5574c9d20a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12886183-172.17.0.9-1598630247959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-bda4eafe-0c1e-47ba-a836-92920b6c2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-9e84c62e-de74-4dad-9022-15a566013cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4eed54f7-77f2-4353-bc8b-1c21482a3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-586cce02-14bf-4d2d-bab1-c4860e9b9d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-25f808da-44b4-4250-b3db-be20f15f07ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-7e42dee9-1396-433e-8c87-54a0819b140f,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-212f69c1-2788-4502-9a9b-7c934b41eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-99e835a2-86bf-47a1-ad06-df289c0affeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12886183-172.17.0.9-1598630247959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-bda4eafe-0c1e-47ba-a836-92920b6c2b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-9e84c62e-de74-4dad-9022-15a566013cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4eed54f7-77f2-4353-bc8b-1c21482a3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-586cce02-14bf-4d2d-bab1-c4860e9b9d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-25f808da-44b4-4250-b3db-be20f15f07ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-7e42dee9-1396-433e-8c87-54a0819b140f,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-212f69c1-2788-4502-9a9b-7c934b41eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-99e835a2-86bf-47a1-ad06-df289c0affeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647308929-172.17.0.9-1598630324014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-9c91dbc6-62b2-48ce-95ae-b2eab0c49d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e2646614-60e9-4090-81e8-833fa032e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-ef39bff4-2c14-47e3-b8f4-3a9e91e89da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5cc4aa5e-a084-478d-a6d7-c27b36845ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-3cf783a0-27f0-4794-a0af-93053ca7a334,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-a797ef07-328e-4b9f-a8a1-e0218c625950,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-1690c025-2101-4b74-b9d4-d62b82990764,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-44590833-d123-4ccf-9b62-7147de4023d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647308929-172.17.0.9-1598630324014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-9c91dbc6-62b2-48ce-95ae-b2eab0c49d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e2646614-60e9-4090-81e8-833fa032e48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-ef39bff4-2c14-47e3-b8f4-3a9e91e89da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5cc4aa5e-a084-478d-a6d7-c27b36845ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-3cf783a0-27f0-4794-a0af-93053ca7a334,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-a797ef07-328e-4b9f-a8a1-e0218c625950,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-1690c025-2101-4b74-b9d4-d62b82990764,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-44590833-d123-4ccf-9b62-7147de4023d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255358590-172.17.0.9-1598630690747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-e4f9a5fb-342b-468e-b240-ed7141676ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-dfc2350e-8231-45b1-9436-cbd1eaf445cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-02fa940f-b378-49a1-9a56-fec5f93f27ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-da047bf4-1d7f-4de0-a05d-3b34eb57ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-14295b24-c7bd-4c3e-b9be-11bd9e0843ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-86bf0b85-5f7d-44c6-853f-035fc75ead0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-b3184925-fa53-48b5-a4d4-05231aaa229b,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-9eba70f0-9024-4db2-8aee-0981b96bbc69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255358590-172.17.0.9-1598630690747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-e4f9a5fb-342b-468e-b240-ed7141676ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-dfc2350e-8231-45b1-9436-cbd1eaf445cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-02fa940f-b378-49a1-9a56-fec5f93f27ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-da047bf4-1d7f-4de0-a05d-3b34eb57ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-14295b24-c7bd-4c3e-b9be-11bd9e0843ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-86bf0b85-5f7d-44c6-853f-035fc75ead0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-b3184925-fa53-48b5-a4d4-05231aaa229b,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-9eba70f0-9024-4db2-8aee-0981b96bbc69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526425581-172.17.0.9-1598630935318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-9eccb928-cb22-4719-8cc9-72acfb4b5dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1bfbb093-7f1d-4422-bfa1-8915356022e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-4faceb21-27d7-4a2e-a491-2710e22e8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-a7715b4a-96ab-4f4b-b56d-ce7da57a0ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-49d2e983-eddf-49ac-b2c7-15c44abd8597,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-919299cc-0ec0-45cf-b745-e28f5709e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-3df04c65-f664-4eba-b74f-8bb0bbbcb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-8d8df02b-50fa-4db9-9371-ace8714b4083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526425581-172.17.0.9-1598630935318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-9eccb928-cb22-4719-8cc9-72acfb4b5dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-1bfbb093-7f1d-4422-bfa1-8915356022e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-4faceb21-27d7-4a2e-a491-2710e22e8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-a7715b4a-96ab-4f4b-b56d-ce7da57a0ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-49d2e983-eddf-49ac-b2c7-15c44abd8597,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-919299cc-0ec0-45cf-b745-e28f5709e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-3df04c65-f664-4eba-b74f-8bb0bbbcb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-8d8df02b-50fa-4db9-9371-ace8714b4083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097130003-172.17.0.9-1598631038081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-3c4039b6-5d0e-491f-b003-660bba4f89ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-625d7a39-3ee9-4e00-8ac3-ef00433dd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-bc51c322-3060-4133-9d2b-17147fccc4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9cbeebbd-2869-431d-86f2-f8476ee960d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-2ec8335b-51b3-4e02-b777-125227312b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-500df886-db18-4f23-8328-102b8c9e30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-c46d8739-529b-47ed-b1fe-f7a18a6861df,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-8db90a89-0094-42ff-bc9f-264df6388751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097130003-172.17.0.9-1598631038081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-3c4039b6-5d0e-491f-b003-660bba4f89ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-625d7a39-3ee9-4e00-8ac3-ef00433dd3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-bc51c322-3060-4133-9d2b-17147fccc4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9cbeebbd-2869-431d-86f2-f8476ee960d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-2ec8335b-51b3-4e02-b777-125227312b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-500df886-db18-4f23-8328-102b8c9e30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-c46d8739-529b-47ed-b1fe-f7a18a6861df,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-8db90a89-0094-42ff-bc9f-264df6388751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624890326-172.17.0.9-1598631705039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-6a7877d8-471c-48d0-a50e-17c6d9f032b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-61d55f2c-489e-4ad7-b004-b46b35722769,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-27ffb698-0834-4d3f-9639-ca8133e2e961,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-25d09dbe-ab67-42d2-ad4b-04dd3f413cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-a0a88311-f15a-42fa-b99d-51788ccd4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-6a274dcd-42a8-491e-9212-1976238a89c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-7ceea6bc-062f-47d9-9875-0ca00624b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-af7f7978-4078-4bc6-8670-6e36aabba388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624890326-172.17.0.9-1598631705039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-6a7877d8-471c-48d0-a50e-17c6d9f032b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-61d55f2c-489e-4ad7-b004-b46b35722769,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-27ffb698-0834-4d3f-9639-ca8133e2e961,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-25d09dbe-ab67-42d2-ad4b-04dd3f413cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-a0a88311-f15a-42fa-b99d-51788ccd4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-6a274dcd-42a8-491e-9212-1976238a89c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-7ceea6bc-062f-47d9-9875-0ca00624b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-af7f7978-4078-4bc6-8670-6e36aabba388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928196496-172.17.0.9-1598632523971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41600,DS-9361a449-2954-4907-b7d4-172181d9c492,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-62fc68c9-de10-4955-af25-0af94c114194,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-5db8d7d7-cf45-4db3-a8bf-85021241da23,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-06261f69-dfd8-4686-8174-c5ec5718b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-bf04204e-6ad5-4964-8496-21f33599da44,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-dd5b2861-d784-4316-a3ba-1840160b46a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d203f871-189b-4070-8def-58fa2885e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-3c8b634c-a0bc-4a1b-a41f-79a57aba6a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928196496-172.17.0.9-1598632523971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41600,DS-9361a449-2954-4907-b7d4-172181d9c492,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-62fc68c9-de10-4955-af25-0af94c114194,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-5db8d7d7-cf45-4db3-a8bf-85021241da23,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-06261f69-dfd8-4686-8174-c5ec5718b01b,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-bf04204e-6ad5-4964-8496-21f33599da44,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-dd5b2861-d784-4316-a3ba-1840160b46a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d203f871-189b-4070-8def-58fa2885e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-3c8b634c-a0bc-4a1b-a41f-79a57aba6a25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.timeout
component: hdfs:DataNode
v1: 20000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572938313-172.17.0.9-1598632559081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-9b61ee23-2992-4542-b732-2ce0d09a4ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-a3d22832-802f-4d90-acff-2370c638212b,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-7ac617e8-326b-41d3-b000-3566ffae3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d96cf398-174a-43b6-91fc-170cb3be90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-c9b85866-fce3-431f-9349-7272696e5879,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-ab447e47-591b-46bb-89a3-8103d882199a,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5e93c172-35a8-4f96-8141-aa1b19486299,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-b08315c9-e926-494f-84c2-7762546e7aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572938313-172.17.0.9-1598632559081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-9b61ee23-2992-4542-b732-2ce0d09a4ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-a3d22832-802f-4d90-acff-2370c638212b,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-7ac617e8-326b-41d3-b000-3566ffae3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d96cf398-174a-43b6-91fc-170cb3be90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-c9b85866-fce3-431f-9349-7272696e5879,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-ab447e47-591b-46bb-89a3-8103d882199a,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5e93c172-35a8-4f96-8141-aa1b19486299,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-b08315c9-e926-494f-84c2-7762546e7aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5484
