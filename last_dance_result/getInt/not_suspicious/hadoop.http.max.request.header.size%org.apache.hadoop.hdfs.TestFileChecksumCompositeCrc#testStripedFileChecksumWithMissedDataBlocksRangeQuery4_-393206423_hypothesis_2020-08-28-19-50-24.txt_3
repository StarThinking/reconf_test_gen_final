reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001792374-172.17.0.7-1598644319609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-606849ff-36c6-44f7-bf90-d56da0eedca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-e529c444-0f20-40c2-a7d7-556a04b51758,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-c5a0347e-90ec-4c9a-b3fb-a3b969761573,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-c8b36609-71cb-4c92-b287-80c87552279e,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-f6f9741e-2269-4639-940b-a41f37a18b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-e2555c2b-d305-469c-bbe0-05fd1bcaa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-a0d72d90-57d9-4d58-b834-cf7b417bffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b3054b99-fce2-4885-8c65-fe46ac01b9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001792374-172.17.0.7-1598644319609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-606849ff-36c6-44f7-bf90-d56da0eedca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-e529c444-0f20-40c2-a7d7-556a04b51758,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-c5a0347e-90ec-4c9a-b3fb-a3b969761573,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-c8b36609-71cb-4c92-b287-80c87552279e,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-f6f9741e-2269-4639-940b-a41f37a18b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-e2555c2b-d305-469c-bbe0-05fd1bcaa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-a0d72d90-57d9-4d58-b834-cf7b417bffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b3054b99-fce2-4885-8c65-fe46ac01b9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20597836-172.17.0.7-1598644603126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-509e2434-8add-4931-929e-0351263b8789,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-15ce8cce-94a0-4808-9931-b692c80d30d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-cedded88-36ff-4c5a-9654-d57395acfea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2994ba72-00d2-4f7d-b581-362c5e5cb61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-04920a11-9a45-4321-a894-50f286e5e883,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-2d3bab7d-157b-4ddd-bd58-dc48355103a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-5fa85d5f-9ad8-492e-808f-0d765ea4904e,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-53f3a5ed-4336-4a21-89c3-44aee4d9ac8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20597836-172.17.0.7-1598644603126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-509e2434-8add-4931-929e-0351263b8789,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-15ce8cce-94a0-4808-9931-b692c80d30d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-cedded88-36ff-4c5a-9654-d57395acfea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2994ba72-00d2-4f7d-b581-362c5e5cb61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-04920a11-9a45-4321-a894-50f286e5e883,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-2d3bab7d-157b-4ddd-bd58-dc48355103a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-5fa85d5f-9ad8-492e-808f-0d765ea4904e,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-53f3a5ed-4336-4a21-89c3-44aee4d9ac8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117067296-172.17.0.7-1598644779317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-3b73af91-8445-4ba3-8906-5a32113149bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-40ad40ba-dc5a-402e-a4b3-199257278290,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-43af3d1b-223f-4176-9e92-08bca365a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-1f77ad7c-44d6-4cb1-9624-33aa3f1e920b,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2c62e200-813b-479e-9903-7edebaea9583,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-4460e1a8-76d2-4153-8a25-78fe7007894d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-cdbfc1dd-9846-4393-a79d-b68cde138ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-3b812e55-442c-4131-8d09-7b09f6e7746d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117067296-172.17.0.7-1598644779317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-3b73af91-8445-4ba3-8906-5a32113149bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-40ad40ba-dc5a-402e-a4b3-199257278290,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-43af3d1b-223f-4176-9e92-08bca365a15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-1f77ad7c-44d6-4cb1-9624-33aa3f1e920b,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2c62e200-813b-479e-9903-7edebaea9583,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-4460e1a8-76d2-4153-8a25-78fe7007894d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-cdbfc1dd-9846-4393-a79d-b68cde138ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-3b812e55-442c-4131-8d09-7b09f6e7746d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11901048-172.17.0.7-1598645505043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-e11d7c5a-4dfa-442e-b3fd-5cefdd5ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d02ba8e9-09dd-4656-a502-e1648e9dd937,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-79674e36-2a87-4fd6-b3d4-630e1137db34,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-05ae1774-3c8b-4611-aae5-2267f5d368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-dfd01b40-86bf-4e8f-ae94-e5b4d92c6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-e1a365a9-2f70-4321-8605-3b847bdc3430,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-e43c399f-100c-4b7a-992a-3163131bf1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-bf36a83e-71a4-4211-a473-3039d8a46d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11901048-172.17.0.7-1598645505043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-e11d7c5a-4dfa-442e-b3fd-5cefdd5ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-d02ba8e9-09dd-4656-a502-e1648e9dd937,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-79674e36-2a87-4fd6-b3d4-630e1137db34,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-05ae1774-3c8b-4611-aae5-2267f5d368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-dfd01b40-86bf-4e8f-ae94-e5b4d92c6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-e1a365a9-2f70-4321-8605-3b847bdc3430,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-e43c399f-100c-4b7a-992a-3163131bf1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-bf36a83e-71a4-4211-a473-3039d8a46d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916317254-172.17.0.7-1598645701816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-9d77b977-fae8-4429-a0b7-b5ea90b2b4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-92316a78-ecb8-4900-830d-8074e13855b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-65257899-2703-4308-adbc-6e43eac70901,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-ddae7dfe-5f5e-4c3b-a613-d48d2849c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-310c78d5-b819-44ad-ae7c-20e83f8d890e,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-bf0777d1-81b8-4cbf-8e45-487b2ac8f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-36c07e80-7054-4fed-bd86-bacb67abdb10,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-9f29f3b8-defb-46b0-aeae-3dc8f30f2ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916317254-172.17.0.7-1598645701816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-9d77b977-fae8-4429-a0b7-b5ea90b2b4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-92316a78-ecb8-4900-830d-8074e13855b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-65257899-2703-4308-adbc-6e43eac70901,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-ddae7dfe-5f5e-4c3b-a613-d48d2849c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-310c78d5-b819-44ad-ae7c-20e83f8d890e,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-bf0777d1-81b8-4cbf-8e45-487b2ac8f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-36c07e80-7054-4fed-bd86-bacb67abdb10,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-9f29f3b8-defb-46b0-aeae-3dc8f30f2ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665111861-172.17.0.7-1598646511460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-ce6ecf3b-31a4-455b-9ed7-f9a824f21421,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-2d391ca0-eabe-4a65-9035-a29562fcb2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-72902158-165c-41d6-b1c7-c04afeb68da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-4885dc26-6665-47b7-a567-ee0ba05f8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-f5fd9522-a869-49af-8466-bb43a53f169b,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-0764a87f-fa9f-4fec-a035-130a5409ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-676de7e9-59a6-4657-93a0-dd04952029d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ec2d66aa-8df3-4947-890c-e6994b3001f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665111861-172.17.0.7-1598646511460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-ce6ecf3b-31a4-455b-9ed7-f9a824f21421,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-2d391ca0-eabe-4a65-9035-a29562fcb2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-72902158-165c-41d6-b1c7-c04afeb68da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-4885dc26-6665-47b7-a567-ee0ba05f8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-f5fd9522-a869-49af-8466-bb43a53f169b,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-0764a87f-fa9f-4fec-a035-130a5409ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-676de7e9-59a6-4657-93a0-dd04952029d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ec2d66aa-8df3-4947-890c-e6994b3001f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700175613-172.17.0.7-1598646833704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-693bcf8b-d63f-4efd-8a96-1f7e472d0969,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-39d951f5-2ec7-4bc9-93a0-051377669731,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-85822af3-eaed-4709-9b3b-b17fa528240b,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-6545ab0b-a344-4141-9dbd-3901d8e78230,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-391db567-de4e-4fd4-b62b-97632351d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-dcc6411d-1488-48f8-ad3c-7c4ef921e190,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-f97c6f27-df03-40bd-af1f-00009864961a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-8be449d0-670f-4189-bcd0-321fb36cdc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700175613-172.17.0.7-1598646833704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40018,DS-693bcf8b-d63f-4efd-8a96-1f7e472d0969,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-39d951f5-2ec7-4bc9-93a0-051377669731,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-85822af3-eaed-4709-9b3b-b17fa528240b,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-6545ab0b-a344-4141-9dbd-3901d8e78230,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-391db567-de4e-4fd4-b62b-97632351d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-dcc6411d-1488-48f8-ad3c-7c4ef921e190,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-f97c6f27-df03-40bd-af1f-00009864961a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-8be449d0-670f-4189-bcd0-321fb36cdc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33137564-172.17.0.7-1598646870495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-496a1e48-4664-4a38-bc07-3bc0d8b05c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-be7de1f1-4968-441c-8d5a-9eb4851b9c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-1d5bf33a-783e-4cc7-b9b3-2d8563103f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-4936d531-1cb2-40f4-8a91-dc8365a503eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-912efa11-d2d6-4b13-a77d-05386d5f0df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-a3edd17d-be65-4b32-a4d5-fff248e1b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-f03f3e3c-e6e7-4498-8edd-49a7cc375d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a9fa7b9c-d229-471d-b530-a47686049724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33137564-172.17.0.7-1598646870495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-496a1e48-4664-4a38-bc07-3bc0d8b05c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-be7de1f1-4968-441c-8d5a-9eb4851b9c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-1d5bf33a-783e-4cc7-b9b3-2d8563103f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-4936d531-1cb2-40f4-8a91-dc8365a503eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-912efa11-d2d6-4b13-a77d-05386d5f0df2,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-a3edd17d-be65-4b32-a4d5-fff248e1b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-f03f3e3c-e6e7-4498-8edd-49a7cc375d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a9fa7b9c-d229-471d-b530-a47686049724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789097021-172.17.0.7-1598646962550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-1de0fb36-6c24-48a5-b5f6-e4f28d06a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-a65664a6-df22-4e0d-a3ce-019f77024a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-db0c8f6c-f935-49e4-b293-45443695f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-968894d6-a826-4fcb-97dc-e55fec2a3b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-38668764-5ccc-41cd-a919-c1aee7eefa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-aeb69304-15d1-461c-90ba-c30d9d684b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-685a7f09-5ca8-42ed-a501-049083a35431,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f712a3c0-813f-428c-9c6f-3b17d98828f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789097021-172.17.0.7-1598646962550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-1de0fb36-6c24-48a5-b5f6-e4f28d06a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-a65664a6-df22-4e0d-a3ce-019f77024a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-db0c8f6c-f935-49e4-b293-45443695f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-968894d6-a826-4fcb-97dc-e55fec2a3b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-38668764-5ccc-41cd-a919-c1aee7eefa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-aeb69304-15d1-461c-90ba-c30d9d684b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-685a7f09-5ca8-42ed-a501-049083a35431,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f712a3c0-813f-428c-9c6f-3b17d98828f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192905473-172.17.0.7-1598647027063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-6f621d1b-b84f-436a-9fbf-821d6d91d147,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-96b9ac79-f337-482e-b033-ded2647485ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-769c46f4-613c-4d13-ab6e-6afbf0f99cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-56d65ec3-b104-4ca9-99a3-06d689e3e511,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-63aee348-c3c6-4187-8090-f566a1498767,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-dcfd0e88-af8c-45ce-82a5-0b17b68106da,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-40ee7293-98c8-4373-a897-560aa3cc9845,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-687b7c5c-6e0c-4d97-8786-e23f0623c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192905473-172.17.0.7-1598647027063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-6f621d1b-b84f-436a-9fbf-821d6d91d147,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-96b9ac79-f337-482e-b033-ded2647485ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-769c46f4-613c-4d13-ab6e-6afbf0f99cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-56d65ec3-b104-4ca9-99a3-06d689e3e511,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-63aee348-c3c6-4187-8090-f566a1498767,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-dcfd0e88-af8c-45ce-82a5-0b17b68106da,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-40ee7293-98c8-4373-a897-560aa3cc9845,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-687b7c5c-6e0c-4d97-8786-e23f0623c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389469707-172.17.0.7-1598647130942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-58b61406-26e7-4d55-a77f-4dc51cd47ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-3e725092-5573-4d6a-8dc5-cabd6ae49513,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bc7208e9-2123-4183-8d9b-6038ca34c009,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6e56ded4-e53d-485c-aac1-f28942b2e555,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-b266a97d-a988-4e34-a199-b789255d86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-59f6c152-114a-4124-943b-05db684a14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-282e70d8-24cd-4171-bb5b-ab15d0b0f336,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-bcc9e808-dcfd-4161-8af7-0b5b8d45269c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389469707-172.17.0.7-1598647130942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-58b61406-26e7-4d55-a77f-4dc51cd47ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-3e725092-5573-4d6a-8dc5-cabd6ae49513,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bc7208e9-2123-4183-8d9b-6038ca34c009,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6e56ded4-e53d-485c-aac1-f28942b2e555,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-b266a97d-a988-4e34-a199-b789255d86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-59f6c152-114a-4124-943b-05db684a14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-282e70d8-24cd-4171-bb5b-ab15d0b0f336,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-bcc9e808-dcfd-4161-8af7-0b5b8d45269c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011875715-172.17.0.7-1598647918649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-07dcc91a-0231-4c7b-9c1a-8e5ee4738e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-476059e3-9e29-42fc-ae18-ebd0a15e55eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-1e1c43b1-2ed6-4bcd-9564-08395b14e0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-50bea616-7e3c-4091-90d1-d2fe8b7856f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6875f744-9699-4999-9603-751e8242a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-e53cc01d-6ccc-4d99-8094-0b79d63cfd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-580bf53a-7d33-41af-ac97-0600666d67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-10c1bdde-372b-4472-a3e4-14b5291fa7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011875715-172.17.0.7-1598647918649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-07dcc91a-0231-4c7b-9c1a-8e5ee4738e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-476059e3-9e29-42fc-ae18-ebd0a15e55eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-1e1c43b1-2ed6-4bcd-9564-08395b14e0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-50bea616-7e3c-4091-90d1-d2fe8b7856f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6875f744-9699-4999-9603-751e8242a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-e53cc01d-6ccc-4d99-8094-0b79d63cfd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-580bf53a-7d33-41af-ac97-0600666d67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-10c1bdde-372b-4472-a3e4-14b5291fa7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212092687-172.17.0.7-1598648085066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-cbb9b396-062b-447a-9223-e53e713d4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-0314a91a-01df-4970-a1a4-7cd0606536e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-67c20631-893c-4c59-ade1-406d54fbf697,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7e07f6d9-014d-4830-b620-86972b322ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-0402acb9-0a0d-4e15-896d-e79f48a60f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-552acda5-95f9-4c49-96b5-acab0e8e7f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-64e1795b-317f-48a7-952c-35f1a4d0e565,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-a952fdeb-c885-48b7-b5e6-5888e058254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212092687-172.17.0.7-1598648085066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-cbb9b396-062b-447a-9223-e53e713d4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-0314a91a-01df-4970-a1a4-7cd0606536e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-67c20631-893c-4c59-ade1-406d54fbf697,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7e07f6d9-014d-4830-b620-86972b322ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-0402acb9-0a0d-4e15-896d-e79f48a60f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-552acda5-95f9-4c49-96b5-acab0e8e7f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-64e1795b-317f-48a7-952c-35f1a4d0e565,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-a952fdeb-c885-48b7-b5e6-5888e058254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207535563-172.17.0.7-1598648283663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-8e6bd90d-16d8-476c-b8ca-e8200a92041f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7f236a66-0325-44ba-ba46-4b8a591005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-41d02f5e-a346-4252-926f-b939d8b4f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-8e09ca03-164c-4ea9-82c3-8fb43de7a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-bb72d26b-111c-463f-8640-fa0240e28c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b95e7ed9-ed43-4505-be57-055821462c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-05e6fb94-53ee-4875-9c43-a8114f338197,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-6e93cd7f-d7e6-4232-88de-0164f472c519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207535563-172.17.0.7-1598648283663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-8e6bd90d-16d8-476c-b8ca-e8200a92041f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7f236a66-0325-44ba-ba46-4b8a591005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-41d02f5e-a346-4252-926f-b939d8b4f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-8e09ca03-164c-4ea9-82c3-8fb43de7a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-bb72d26b-111c-463f-8640-fa0240e28c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b95e7ed9-ed43-4505-be57-055821462c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-05e6fb94-53ee-4875-9c43-a8114f338197,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-6e93cd7f-d7e6-4232-88de-0164f472c519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856594167-172.17.0.7-1598648373137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-99870b10-216d-45e7-a26b-f162df0d2c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-45fd8a33-2293-4716-90de-1f3b8c67aada,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-b620bfb1-6c94-4284-a1d9-347f154d21a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7124d33e-ea35-48f7-8091-74c974ba9276,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-64497bae-9976-4b96-9bbe-f0136c385934,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-3abee2a3-ae4d-4bee-a2f1-af64e616d568,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-9eefcfb0-fc67-45c0-a072-f202f1c3bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-3732cae8-b73e-4b79-99a5-800b033aa602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856594167-172.17.0.7-1598648373137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-99870b10-216d-45e7-a26b-f162df0d2c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-45fd8a33-2293-4716-90de-1f3b8c67aada,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-b620bfb1-6c94-4284-a1d9-347f154d21a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-7124d33e-ea35-48f7-8091-74c974ba9276,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-64497bae-9976-4b96-9bbe-f0136c385934,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-3abee2a3-ae4d-4bee-a2f1-af64e616d568,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-9eefcfb0-fc67-45c0-a072-f202f1c3bb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-3732cae8-b73e-4b79-99a5-800b033aa602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235121999-172.17.0.7-1598648587525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-0f40bc48-60a3-4e71-bbb0-3d0e796e1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-4a7d3f00-0447-481c-97cb-35b750747a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-9c37f47a-ebed-44c9-8b69-483ee338ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-e3b33ae7-6430-439f-b381-8e5e43fcbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-da498184-8e11-4d0e-bebc-be18a82bf5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-3a84328c-4883-4d0a-8bfc-33df84926917,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-0b9f8eca-1643-4074-aa87-aa44565b8514,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-db4c5521-8d0b-4a28-863c-a7a58942affa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235121999-172.17.0.7-1598648587525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-0f40bc48-60a3-4e71-bbb0-3d0e796e1d82,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-4a7d3f00-0447-481c-97cb-35b750747a20,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-9c37f47a-ebed-44c9-8b69-483ee338ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-e3b33ae7-6430-439f-b381-8e5e43fcbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-da498184-8e11-4d0e-bebc-be18a82bf5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-3a84328c-4883-4d0a-8bfc-33df84926917,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-0b9f8eca-1643-4074-aa87-aa44565b8514,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-db4c5521-8d0b-4a28-863c-a7a58942affa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425317294-172.17.0.7-1598648805671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-0762ba70-ec5e-4b48-b3f6-8d76916e3977,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-06eb52d5-078e-4b55-b081-81bdd9219436,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-1913eb0b-034d-43f5-9437-8391bd6e624c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-ec47fd30-7e62-42d2-a568-f6a37fc49fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-c314b3ba-cad1-414b-9cac-e4ff60bae2df,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-632b94fc-700c-4abe-86c1-61b2a9bb1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-2dde8ce4-6444-4401-96bf-2507d821d788,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-708e881e-2209-4e79-877f-007ada10bc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425317294-172.17.0.7-1598648805671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-0762ba70-ec5e-4b48-b3f6-8d76916e3977,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-06eb52d5-078e-4b55-b081-81bdd9219436,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-1913eb0b-034d-43f5-9437-8391bd6e624c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-ec47fd30-7e62-42d2-a568-f6a37fc49fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-c314b3ba-cad1-414b-9cac-e4ff60bae2df,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-632b94fc-700c-4abe-86c1-61b2a9bb1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-2dde8ce4-6444-4401-96bf-2507d821d788,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-708e881e-2209-4e79-877f-007ada10bc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840253406-172.17.0.7-1598648845046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-3b4a01a9-4799-43ff-bbba-096ff2aedfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-0d132e41-03d8-43bb-81a8-c7ef3dc05784,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-7144b87f-c287-4026-bd40-191aca4475c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-cbd9cc4d-2114-438b-828f-6a263c57887f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-0ca154f6-e69e-47fa-a2e4-bcb632750eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-fe85fd70-97ae-44bd-9e17-d6ef7cccc48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-5065c730-789a-44f1-a627-7fcfb5028d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-1f9f4834-8110-445d-9268-9aec993bfa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840253406-172.17.0.7-1598648845046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39746,DS-3b4a01a9-4799-43ff-bbba-096ff2aedfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-0d132e41-03d8-43bb-81a8-c7ef3dc05784,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-7144b87f-c287-4026-bd40-191aca4475c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-cbd9cc4d-2114-438b-828f-6a263c57887f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-0ca154f6-e69e-47fa-a2e4-bcb632750eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-fe85fd70-97ae-44bd-9e17-d6ef7cccc48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-5065c730-789a-44f1-a627-7fcfb5028d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-1f9f4834-8110-445d-9268-9aec993bfa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464534624-172.17.0.7-1598648945929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-55572d6d-f09f-43f6-a84a-ae01d125788f,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-2bd103ab-53c4-41c6-ad3f-003959902bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3ec2ed06-d1b0-4407-8789-bd2ce8409a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2bbc45ef-9e83-440d-854a-996ee316105d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-8bea9c86-ee0a-48e7-b102-0e7939f96817,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-f12f15f7-cd51-44be-a6fa-6a293124d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-128a0915-f929-4e90-a994-0b87de6cef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-2bb7b19d-d4c0-4910-bbef-6d7486eb608b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464534624-172.17.0.7-1598648945929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-55572d6d-f09f-43f6-a84a-ae01d125788f,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-2bd103ab-53c4-41c6-ad3f-003959902bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3ec2ed06-d1b0-4407-8789-bd2ce8409a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2bbc45ef-9e83-440d-854a-996ee316105d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-8bea9c86-ee0a-48e7-b102-0e7939f96817,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-f12f15f7-cd51-44be-a6fa-6a293124d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-128a0915-f929-4e90-a994-0b87de6cef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-2bb7b19d-d4c0-4910-bbef-6d7486eb608b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627934133-172.17.0.7-1598649311343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-8dd5d157-1480-4106-ae11-33edf9f8a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-bc785c08-826d-47f9-bd85-2805a0cf9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-aaf5e64c-8791-4284-ac6f-fb5ad5de38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-11ef1607-37dd-4f68-8f16-a57f18871fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-e4fbd1b4-9d79-4928-9fc1-15cf29d80790,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-8cbaac25-06e2-4336-9295-7312cc34baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-6fe08b94-f719-4017-b609-ab5fe6361dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-22e00cd4-cb3d-492c-bf54-e5e9797c35f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627934133-172.17.0.7-1598649311343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-8dd5d157-1480-4106-ae11-33edf9f8a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-bc785c08-826d-47f9-bd85-2805a0cf9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-aaf5e64c-8791-4284-ac6f-fb5ad5de38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-11ef1607-37dd-4f68-8f16-a57f18871fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-e4fbd1b4-9d79-4928-9fc1-15cf29d80790,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-8cbaac25-06e2-4336-9295-7312cc34baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-6fe08b94-f719-4017-b609-ab5fe6361dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-22e00cd4-cb3d-492c-bf54-e5e9797c35f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975133101-172.17.0.7-1598649423392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-565f7bd6-3734-4de9-a303-6ea5508e802c,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-ec58a7c5-e633-4c0c-af17-e41e6a9b22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-a779fa1e-2921-4e4c-845b-920c8f6ed8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-cbfc0009-837a-4cfb-a126-41d4ddb442fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-4432b838-4af6-48a2-b84c-cd1761d0d8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-3937c7b4-6dcb-42a7-89d0-d98138197bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-9a2ac2e2-13b2-4753-8ab1-d65568a9a9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-454e7c52-3a6f-488b-bcda-c8b057737e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975133101-172.17.0.7-1598649423392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-565f7bd6-3734-4de9-a303-6ea5508e802c,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-ec58a7c5-e633-4c0c-af17-e41e6a9b22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-a779fa1e-2921-4e4c-845b-920c8f6ed8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-cbfc0009-837a-4cfb-a126-41d4ddb442fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-4432b838-4af6-48a2-b84c-cd1761d0d8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-3937c7b4-6dcb-42a7-89d0-d98138197bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-9a2ac2e2-13b2-4753-8ab1-d65568a9a9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-454e7c52-3a6f-488b-bcda-c8b057737e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5303
