reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316608444-172.17.0.12-1598590377392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-9b4081ed-e95d-4371-b978-64c0e877f134,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-92f6240e-3e03-4524-93eb-7ee35da918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-e6ee0e0c-c58e-495d-8d49-39bdb3fad861,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4764a3cd-f713-4f0b-88b2-289bd484e8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-a587c6f7-e6f1-403a-8247-fbbedb2cb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-9deebfc2-ae3b-4de6-86a1-05cb7d745c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f2087486-4eb4-441d-a388-15dfced75e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-3c5545f2-9c21-4fb2-99ce-69960a0a6691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316608444-172.17.0.12-1598590377392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39976,DS-9b4081ed-e95d-4371-b978-64c0e877f134,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-92f6240e-3e03-4524-93eb-7ee35da918ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-e6ee0e0c-c58e-495d-8d49-39bdb3fad861,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4764a3cd-f713-4f0b-88b2-289bd484e8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-a587c6f7-e6f1-403a-8247-fbbedb2cb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-9deebfc2-ae3b-4de6-86a1-05cb7d745c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f2087486-4eb4-441d-a388-15dfced75e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-3c5545f2-9c21-4fb2-99ce-69960a0a6691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946701061-172.17.0.12-1598591027525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-1d0bc19c-d931-4bef-9c71-6736ed8a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-7624e7ee-8bca-466f-9a0c-82655d1a34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-545507f0-21df-443b-b483-00009ace0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-64d5df94-ff83-44e4-a9c4-6810c03d7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-746f7a92-5792-4e00-9eb1-14fa835f26e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-27441f80-f960-42d5-a16c-72516778b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-f9b41bcd-78d1-4eeb-8d4d-e845fc0f3976,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-81027d12-6917-4b18-aca5-10863798d380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946701061-172.17.0.12-1598591027525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-1d0bc19c-d931-4bef-9c71-6736ed8a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-7624e7ee-8bca-466f-9a0c-82655d1a34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-545507f0-21df-443b-b483-00009ace0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-64d5df94-ff83-44e4-a9c4-6810c03d7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-746f7a92-5792-4e00-9eb1-14fa835f26e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-27441f80-f960-42d5-a16c-72516778b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-f9b41bcd-78d1-4eeb-8d4d-e845fc0f3976,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-81027d12-6917-4b18-aca5-10863798d380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969827882-172.17.0.12-1598591140513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-720aa048-042f-490b-9ce5-3bb058f76c53,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-b24f9dcf-cb9d-437c-b349-de3e1f9b7915,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-506a8d7f-6499-487f-9f62-294546757b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-dd95dd6a-0a8a-4e91-bec9-9cb890fad5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-56a0ec9d-a21b-4eb6-9413-d07c3ef71bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-0429a93f-c528-4e05-bc56-bc19cdab4314,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-43486014-1f55-471b-b2e3-5c722ab690a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-2b10c969-9909-45fb-8b56-92eb8ab62fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969827882-172.17.0.12-1598591140513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-720aa048-042f-490b-9ce5-3bb058f76c53,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-b24f9dcf-cb9d-437c-b349-de3e1f9b7915,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-506a8d7f-6499-487f-9f62-294546757b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-dd95dd6a-0a8a-4e91-bec9-9cb890fad5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-56a0ec9d-a21b-4eb6-9413-d07c3ef71bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-0429a93f-c528-4e05-bc56-bc19cdab4314,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-43486014-1f55-471b-b2e3-5c722ab690a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-2b10c969-9909-45fb-8b56-92eb8ab62fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234497533-172.17.0.12-1598591451526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-6b85b427-2720-439c-a087-e9348886f231,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-9304f762-81ed-4571-ada2-5bff74643ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-ea99db27-ba2a-4a76-a19e-b2295f47c9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-ac1a713c-352b-42ff-b20b-9c66b1f1dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-836069bd-b7d0-4c0f-9f7d-4437ffd6911b,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-59720ce2-a94e-4edc-9d83-1ca19895a30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1ac1497e-b26a-4c1d-b90a-eb4637e83028,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-32ee31de-e46a-45b0-aabe-1d6e46a84a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234497533-172.17.0.12-1598591451526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-6b85b427-2720-439c-a087-e9348886f231,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-9304f762-81ed-4571-ada2-5bff74643ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-ea99db27-ba2a-4a76-a19e-b2295f47c9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-ac1a713c-352b-42ff-b20b-9c66b1f1dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-836069bd-b7d0-4c0f-9f7d-4437ffd6911b,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-59720ce2-a94e-4edc-9d83-1ca19895a30a,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1ac1497e-b26a-4c1d-b90a-eb4637e83028,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-32ee31de-e46a-45b0-aabe-1d6e46a84a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843241334-172.17.0.12-1598591674022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-015d3262-b358-4a31-85ae-d16c2691583a,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-1c7b44c5-8409-4fa2-856e-b2846c49bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-24a9af4e-a990-4b16-aa7c-9e81adb07fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-43ebc4f6-6cfd-4245-ade0-4106ddaecd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-b794e855-c72a-481c-80a5-5eb9a1fcb794,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-dc3d05a9-46b2-469f-a96c-a47c9375d050,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b4167901-14be-4ebc-b9f7-2cb7897fa70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-a6c9b75c-403a-4061-bcd5-fbf36c28d54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-843241334-172.17.0.12-1598591674022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-015d3262-b358-4a31-85ae-d16c2691583a,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-1c7b44c5-8409-4fa2-856e-b2846c49bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-24a9af4e-a990-4b16-aa7c-9e81adb07fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-43ebc4f6-6cfd-4245-ade0-4106ddaecd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-b794e855-c72a-481c-80a5-5eb9a1fcb794,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-dc3d05a9-46b2-469f-a96c-a47c9375d050,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b4167901-14be-4ebc-b9f7-2cb7897fa70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-a6c9b75c-403a-4061-bcd5-fbf36c28d54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018524816-172.17.0.12-1598591711176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-f7e0634a-8855-4450-85c7-a91e4685a194,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-b9eda4a4-a990-4952-83d0-dd8fdfd01010,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-236fde28-48c8-4e01-88b4-e7a3689d6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-eb3bde89-4924-4ca2-93fe-b3a0dd29cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-38ce0c1b-cc45-4534-9d43-fe00bcc2d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-81fa4364-9f6d-425a-9c44-b388f3630f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-506a40f5-090c-4f38-9999-b80e00944a92,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-adaa26f9-f259-4e51-8938-23025a24d593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018524816-172.17.0.12-1598591711176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33655,DS-f7e0634a-8855-4450-85c7-a91e4685a194,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-b9eda4a4-a990-4952-83d0-dd8fdfd01010,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-236fde28-48c8-4e01-88b4-e7a3689d6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-eb3bde89-4924-4ca2-93fe-b3a0dd29cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-38ce0c1b-cc45-4534-9d43-fe00bcc2d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-81fa4364-9f6d-425a-9c44-b388f3630f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-506a40f5-090c-4f38-9999-b80e00944a92,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-adaa26f9-f259-4e51-8938-23025a24d593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586534077-172.17.0.12-1598591794126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-2f326d6a-d864-467e-84b7-8e539c2cbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-961b8a51-f3d8-4cee-81d1-4d9153dff461,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-909faf15-8d7d-4b94-b2bd-7d5aa5336d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-e6a99d41-44ff-42d5-9d1b-105b46d791fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-e28ae519-abd4-4939-9d30-723126854969,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-29a0eb84-9cc4-4947-bc9b-8dc29e88459b,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-9a17ef28-f6cb-49cf-97f6-1ccdde4edde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-a96e5195-bbf1-4e91-8107-2005ae607c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586534077-172.17.0.12-1598591794126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-2f326d6a-d864-467e-84b7-8e539c2cbbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-961b8a51-f3d8-4cee-81d1-4d9153dff461,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-909faf15-8d7d-4b94-b2bd-7d5aa5336d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-e6a99d41-44ff-42d5-9d1b-105b46d791fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-e28ae519-abd4-4939-9d30-723126854969,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-29a0eb84-9cc4-4947-bc9b-8dc29e88459b,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-9a17ef28-f6cb-49cf-97f6-1ccdde4edde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-a96e5195-bbf1-4e91-8107-2005ae607c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806114499-172.17.0.12-1598591868166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-63a17b48-9516-4604-83f4-501b10ea67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-c4539847-f597-4e66-8a95-f45c7adc394d,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-69d25f0a-b0a1-4e96-be3b-a62749de60a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-2b612197-e3cf-4368-83c2-0a7426f9d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-19cf5ac5-76cd-4929-8755-c3005266b418,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ecb93c43-8a83-49eb-981a-a1350c9a2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-34fe81c7-9b89-4848-aaa3-f1ab4d1cae48,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c03d4afa-8adb-4ced-8ecc-31f2c6b125e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806114499-172.17.0.12-1598591868166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-63a17b48-9516-4604-83f4-501b10ea67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-c4539847-f597-4e66-8a95-f45c7adc394d,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-69d25f0a-b0a1-4e96-be3b-a62749de60a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-2b612197-e3cf-4368-83c2-0a7426f9d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-19cf5ac5-76cd-4929-8755-c3005266b418,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ecb93c43-8a83-49eb-981a-a1350c9a2a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-34fe81c7-9b89-4848-aaa3-f1ab4d1cae48,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c03d4afa-8adb-4ced-8ecc-31f2c6b125e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324485301-172.17.0.12-1598591946686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-bdc0f243-79fd-4394-8834-314f08898952,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-744fa029-2307-48d2-9d98-fc2010c2ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-d094a820-f1d7-413c-a957-d8ce9ae3f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-aef67e6f-84c0-47ba-ac40-72c3a4a0ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-2dde6501-3fb7-493a-aa11-cbf988def827,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-b5f831c0-2f0e-495d-bae8-98f5a9922c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c86c2fe0-3335-4b36-9b88-4ffb9e7aa246,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bb68a0d0-bc46-4bf1-9021-043b6157d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324485301-172.17.0.12-1598591946686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-bdc0f243-79fd-4394-8834-314f08898952,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-744fa029-2307-48d2-9d98-fc2010c2ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-d094a820-f1d7-413c-a957-d8ce9ae3f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-aef67e6f-84c0-47ba-ac40-72c3a4a0ee14,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-2dde6501-3fb7-493a-aa11-cbf988def827,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-b5f831c0-2f0e-495d-bae8-98f5a9922c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c86c2fe0-3335-4b36-9b88-4ffb9e7aa246,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bb68a0d0-bc46-4bf1-9021-043b6157d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893139144-172.17.0.12-1598592293641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-3d11723e-fee5-4dfd-83a0-2d13c7684818,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-4b6c50ed-b925-4108-93a0-6721908d3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-92e65140-bd99-4669-91f1-0c071af93f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-b8031772-d2d8-4f54-9f22-0905eb4059cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-907674ef-9d6b-451d-bd10-36dba36b5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-9f33e7f5-ca44-4ba5-9acd-a22fc77dfc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e04d9af8-0ffb-47db-9cf3-8c724bf25450,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-f3b45446-89fa-4912-8835-93a36fb93b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893139144-172.17.0.12-1598592293641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-3d11723e-fee5-4dfd-83a0-2d13c7684818,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-4b6c50ed-b925-4108-93a0-6721908d3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-92e65140-bd99-4669-91f1-0c071af93f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-b8031772-d2d8-4f54-9f22-0905eb4059cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-907674ef-9d6b-451d-bd10-36dba36b5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-9f33e7f5-ca44-4ba5-9acd-a22fc77dfc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e04d9af8-0ffb-47db-9cf3-8c724bf25450,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-f3b45446-89fa-4912-8835-93a36fb93b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309055666-172.17.0.12-1598592490244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-9ce9f11f-8382-403a-8a44-7f4b140fc968,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-0fcfe3c6-9a92-4f06-b71d-abd65926daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-8617a46b-cbf4-46f3-a493-a46c46e96a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-7281b4f2-b509-441f-9b67-f1cf512b6e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-0435e32b-197c-42b9-9617-323fd26ee41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-ae90064a-3be6-458d-9386-307c5c5d1303,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-441d1996-9f53-4359-950c-ca313fd9d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-913f395c-c398-4167-82fb-419424004be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309055666-172.17.0.12-1598592490244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-9ce9f11f-8382-403a-8a44-7f4b140fc968,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-0fcfe3c6-9a92-4f06-b71d-abd65926daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-8617a46b-cbf4-46f3-a493-a46c46e96a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-7281b4f2-b509-441f-9b67-f1cf512b6e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-0435e32b-197c-42b9-9617-323fd26ee41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-ae90064a-3be6-458d-9386-307c5c5d1303,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-441d1996-9f53-4359-950c-ca313fd9d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-913f395c-c398-4167-82fb-419424004be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810244355-172.17.0.12-1598592627678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-6f374c18-162f-4834-af6e-5fd56097cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-279e0ba9-fde4-4f0e-bb3f-c3fff47bfecd,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-08277383-2544-44c5-b0ce-7dd27fec244c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-ec4c435c-b188-41bd-8566-b793f70967cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-854caa90-c845-4b66-94c9-072cf0ce3482,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-a7c2963e-b5c8-4699-9530-418438108828,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-3a42d898-0a7b-4dae-8dfb-1886c14896d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e3ddfd36-48a6-4adf-95ab-838eeb4db8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810244355-172.17.0.12-1598592627678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-6f374c18-162f-4834-af6e-5fd56097cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-279e0ba9-fde4-4f0e-bb3f-c3fff47bfecd,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-08277383-2544-44c5-b0ce-7dd27fec244c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-ec4c435c-b188-41bd-8566-b793f70967cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-854caa90-c845-4b66-94c9-072cf0ce3482,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-a7c2963e-b5c8-4699-9530-418438108828,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-3a42d898-0a7b-4dae-8dfb-1886c14896d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e3ddfd36-48a6-4adf-95ab-838eeb4db8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842666092-172.17.0.12-1598592734914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-f7e610b8-9a99-43d5-be85-a12375e65e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-e08b7f9c-a126-41bb-914c-391e9dea38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5c93636b-8a05-44f4-b2c9-b08ae57a00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-66b2e699-b29b-442a-beac-22bf9f7b8a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-8c2c6b81-aa56-4a6f-b8f5-f30dc6b3f282,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-3f37ffcf-a8b2-4477-b768-520b43b175c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-2c40efd2-2821-4859-8701-54df899dd6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-9680f953-16a9-4761-a32f-eecd2bf9d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842666092-172.17.0.12-1598592734914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-f7e610b8-9a99-43d5-be85-a12375e65e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-e08b7f9c-a126-41bb-914c-391e9dea38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5c93636b-8a05-44f4-b2c9-b08ae57a00cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-66b2e699-b29b-442a-beac-22bf9f7b8a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-8c2c6b81-aa56-4a6f-b8f5-f30dc6b3f282,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-3f37ffcf-a8b2-4477-b768-520b43b175c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-2c40efd2-2821-4859-8701-54df899dd6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-9680f953-16a9-4761-a32f-eecd2bf9d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889672827-172.17.0.12-1598593091045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-9abb01c5-32e0-4076-af2a-fafb8a3c7662,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-8569be11-e9a5-489c-b3af-13b5c5a89244,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-bf15d75d-d7d6-48ff-be2e-175552926c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-b4fc2254-85c3-43ff-a24a-5a9cbf72d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d9d971da-ab80-400f-bf1f-1d434660a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-978de94c-54d5-4607-ba97-dadcb0ca05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-ef4a9745-ab7c-444b-8aa4-cff55583a034,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9a11b8e0-34bd-44fd-9319-c2419f6ecfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889672827-172.17.0.12-1598593091045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-9abb01c5-32e0-4076-af2a-fafb8a3c7662,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-8569be11-e9a5-489c-b3af-13b5c5a89244,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-bf15d75d-d7d6-48ff-be2e-175552926c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-b4fc2254-85c3-43ff-a24a-5a9cbf72d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d9d971da-ab80-400f-bf1f-1d434660a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-978de94c-54d5-4607-ba97-dadcb0ca05c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-ef4a9745-ab7c-444b-8aa4-cff55583a034,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9a11b8e0-34bd-44fd-9319-c2419f6ecfcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617492950-172.17.0.12-1598593273181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-0a6de466-c69b-4d6d-9133-c369d5947cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-db0305af-0ce7-44d4-ac8e-33da7bbb2560,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b938f1b2-8914-4dd6-a3be-46f459b759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-649480d4-7811-4906-ad7c-450e758ade48,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-fbace5ee-d476-4844-bd71-e52fe1a8f95e,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-ad71ff15-cb5f-46b4-bdaa-da719f8f2c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-1b7256d2-bf0a-45b1-a097-4b24f0356c03,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-2b1a908d-71c5-4a78-b542-532ade92ba01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617492950-172.17.0.12-1598593273181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46234,DS-0a6de466-c69b-4d6d-9133-c369d5947cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-db0305af-0ce7-44d4-ac8e-33da7bbb2560,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b938f1b2-8914-4dd6-a3be-46f459b759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-649480d4-7811-4906-ad7c-450e758ade48,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-fbace5ee-d476-4844-bd71-e52fe1a8f95e,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-ad71ff15-cb5f-46b4-bdaa-da719f8f2c68,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-1b7256d2-bf0a-45b1-a097-4b24f0356c03,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-2b1a908d-71c5-4a78-b542-532ade92ba01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933251883-172.17.0.12-1598593449845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-8cc9f688-25f6-4758-93d2-bd6e442aef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-79edb95c-8013-477e-9bc4-c4cc44012ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-8acf5846-421b-4f22-bfc0-638b958cb905,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-260d872e-8c80-4bb6-ba79-3567c08310f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3be38450-61c2-4c1d-a708-6fcd72ee76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-51164066-2c3e-4007-bb5a-478a40570733,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-889e00c9-fdb2-43e0-bef7-887b67f13b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-d4c3332a-e714-4083-9106-bb128c8dd88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933251883-172.17.0.12-1598593449845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-8cc9f688-25f6-4758-93d2-bd6e442aef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-79edb95c-8013-477e-9bc4-c4cc44012ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-8acf5846-421b-4f22-bfc0-638b958cb905,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-260d872e-8c80-4bb6-ba79-3567c08310f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3be38450-61c2-4c1d-a708-6fcd72ee76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-51164066-2c3e-4007-bb5a-478a40570733,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-889e00c9-fdb2-43e0-bef7-887b67f13b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-d4c3332a-e714-4083-9106-bb128c8dd88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041958891-172.17.0.12-1598594538470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-3fee53a6-a977-45d0-b77e-af6f0b790c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-b6f671d2-e848-465b-ad21-9cec4c370fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-6352ac8b-53a7-48a8-aada-a5541bdb3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8e7268ae-5b81-421d-a24b-d5f4b0633e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-13afac25-2458-49e8-82f1-aca5aa96223d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-0725ea99-b518-4633-8847-b99954ae4f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-92fdd933-210f-4256-87c3-70d7e5239e83,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-eb450045-86d1-4ef7-aaa2-0271fde96e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041958891-172.17.0.12-1598594538470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-3fee53a6-a977-45d0-b77e-af6f0b790c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-b6f671d2-e848-465b-ad21-9cec4c370fae,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-6352ac8b-53a7-48a8-aada-a5541bdb3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8e7268ae-5b81-421d-a24b-d5f4b0633e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-13afac25-2458-49e8-82f1-aca5aa96223d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-0725ea99-b518-4633-8847-b99954ae4f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-92fdd933-210f-4256-87c3-70d7e5239e83,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-eb450045-86d1-4ef7-aaa2-0271fde96e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51819997-172.17.0.12-1598595593209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-3e405468-54d9-4a78-8390-3eb8f6ae75d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-df1e592c-d1de-46cf-853b-a30642a0e370,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-7ebcc639-7fde-4cb3-95b1-2a77b3ad750e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4d091fc5-6f69-4f92-9ac2-28800a31829f,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a12ab734-e0e6-4306-b377-afac908ed488,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-1faeff54-5442-4f53-a32c-eb194862e555,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-570734f6-19a1-4be1-a0a9-9129946162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-867c77a8-bd9c-4464-b9bf-3490b9a574e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51819997-172.17.0.12-1598595593209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44066,DS-3e405468-54d9-4a78-8390-3eb8f6ae75d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-df1e592c-d1de-46cf-853b-a30642a0e370,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-7ebcc639-7fde-4cb3-95b1-2a77b3ad750e,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4d091fc5-6f69-4f92-9ac2-28800a31829f,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a12ab734-e0e6-4306-b377-afac908ed488,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-1faeff54-5442-4f53-a32c-eb194862e555,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-570734f6-19a1-4be1-a0a9-9129946162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-867c77a8-bd9c-4464-b9bf-3490b9a574e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926903618-172.17.0.12-1598595822248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-6792eaec-2081-433a-9653-9a65a2ee23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-44a7c639-0b28-4926-aca5-8e81dfa9c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-a428cc00-d920-4e88-98a0-7ba9871c0823,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-da375788-a30c-4c9c-8353-2bfe54966bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-72346525-c0f5-472b-b251-15a7151dbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-accd067e-a059-4c7c-82ff-ddd674b51f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-53f59f42-576e-40f8-ba3d-7cb33f931720,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-83426937-0756-4ba9-9793-5500fc6c1800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926903618-172.17.0.12-1598595822248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-6792eaec-2081-433a-9653-9a65a2ee23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-44a7c639-0b28-4926-aca5-8e81dfa9c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-a428cc00-d920-4e88-98a0-7ba9871c0823,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-da375788-a30c-4c9c-8353-2bfe54966bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-72346525-c0f5-472b-b251-15a7151dbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-accd067e-a059-4c7c-82ff-ddd674b51f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-53f59f42-576e-40f8-ba3d-7cb33f931720,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-83426937-0756-4ba9-9793-5500fc6c1800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5567
