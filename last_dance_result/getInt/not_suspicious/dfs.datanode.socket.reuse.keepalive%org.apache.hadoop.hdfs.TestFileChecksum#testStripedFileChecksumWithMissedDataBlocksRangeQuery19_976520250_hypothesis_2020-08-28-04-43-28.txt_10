reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239876520-172.17.0.17-1598590557191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-a757cc95-7fac-45f6-b503-5c7b2f317e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-0674468a-7e44-444e-be9c-5d9bdc958414,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-78e10fb0-92a9-497f-817c-008b1eeac7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-f3798bc4-d4b1-409a-b2fe-10d8b882e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-1c10c480-09df-41ad-856a-2bdeb76b6300,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-b9593f82-0562-4182-9ec9-8238415e840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-67ff26a3-f7e4-49a8-9e4c-fbf10130a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-1dbed3b6-a407-4730-8ccc-d989f0bdff0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239876520-172.17.0.17-1598590557191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-a757cc95-7fac-45f6-b503-5c7b2f317e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-0674468a-7e44-444e-be9c-5d9bdc958414,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-78e10fb0-92a9-497f-817c-008b1eeac7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-f3798bc4-d4b1-409a-b2fe-10d8b882e4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-1c10c480-09df-41ad-856a-2bdeb76b6300,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-b9593f82-0562-4182-9ec9-8238415e840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-67ff26a3-f7e4-49a8-9e4c-fbf10130a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-1dbed3b6-a407-4730-8ccc-d989f0bdff0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802014459-172.17.0.17-1598590601594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37490,DS-c315e0bf-d33e-4a2f-8b89-8e2fe20db503,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-15371638-330c-4b22-bea1-4f2b57511d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-d93449e7-3238-4aa1-80d0-03564489a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-92075517-dc4b-4a7c-9e8d-108404b32021,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-671a4c81-feb3-4989-b358-95761047e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-92540abb-43d7-4dd2-99c4-310173c0e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c58650ba-f335-4cff-be1b-3b03d3baab99,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-746c645b-1bb8-4344-aafc-9be4ab3299a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802014459-172.17.0.17-1598590601594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37490,DS-c315e0bf-d33e-4a2f-8b89-8e2fe20db503,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-15371638-330c-4b22-bea1-4f2b57511d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-d93449e7-3238-4aa1-80d0-03564489a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-92075517-dc4b-4a7c-9e8d-108404b32021,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-671a4c81-feb3-4989-b358-95761047e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-92540abb-43d7-4dd2-99c4-310173c0e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c58650ba-f335-4cff-be1b-3b03d3baab99,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-746c645b-1bb8-4344-aafc-9be4ab3299a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645656038-172.17.0.17-1598590639159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-63778de3-39a0-4b77-be9d-42aeaa527d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-ad6c345b-28af-4f1b-97c9-fdbca5f179ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3be4b229-ea73-472c-ad8d-42ba40096983,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-5bfa0fac-8bd3-435b-acae-d4d75dad5f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-6b7680e0-b70d-4f7b-8b5e-d7568cf82e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-5977c215-3edf-463a-830c-d66112c73e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-f84ee6f3-1ba9-4b24-bd57-cdc57588f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-3ed65160-51de-4848-b1d4-f2c81ecefd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645656038-172.17.0.17-1598590639159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-63778de3-39a0-4b77-be9d-42aeaa527d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-ad6c345b-28af-4f1b-97c9-fdbca5f179ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3be4b229-ea73-472c-ad8d-42ba40096983,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-5bfa0fac-8bd3-435b-acae-d4d75dad5f96,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-6b7680e0-b70d-4f7b-8b5e-d7568cf82e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-5977c215-3edf-463a-830c-d66112c73e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-f84ee6f3-1ba9-4b24-bd57-cdc57588f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-3ed65160-51de-4848-b1d4-f2c81ecefd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080574426-172.17.0.17-1598590743110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-a1248163-1138-4849-ac87-d94bb7ebd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-fa2ecb0d-f39e-4900-94a6-cbee52bf7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-8238ae0d-edf7-476c-bfcf-390e863c0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-5fd828c6-a96c-4bef-b3b5-0c20e449e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-ae49ca0d-b114-4640-acb8-3ad038ffd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-ffde3773-ca18-469b-9a01-48deb59483e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-5b14dd1b-58f9-42b0-99fc-26d5933011a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-d6eb43cc-d5f7-4f02-af6a-b3eef5aaaec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080574426-172.17.0.17-1598590743110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39209,DS-a1248163-1138-4849-ac87-d94bb7ebd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-fa2ecb0d-f39e-4900-94a6-cbee52bf7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-8238ae0d-edf7-476c-bfcf-390e863c0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-5fd828c6-a96c-4bef-b3b5-0c20e449e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-ae49ca0d-b114-4640-acb8-3ad038ffd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-ffde3773-ca18-469b-9a01-48deb59483e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-5b14dd1b-58f9-42b0-99fc-26d5933011a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-d6eb43cc-d5f7-4f02-af6a-b3eef5aaaec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830891412-172.17.0.17-1598591268583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-91d9187a-ef22-44e1-b621-3ee0d2f64fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-29cc9ef7-1bb4-48d0-96a1-9aac65bb813f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-8f07808c-6aba-4e4b-b4dc-dc45f81f4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-3b3ae1b2-b945-49d3-a356-229c4a10ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-e81f6b5b-18bd-4d2c-8ff9-1f57e44e9798,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-982716aa-2c90-4119-9a38-9ad52d44b556,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-63498442-dc09-401a-b353-3a1a97afc77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-077441cd-255f-4bd6-80d6-02ed91cdde15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830891412-172.17.0.17-1598591268583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-91d9187a-ef22-44e1-b621-3ee0d2f64fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-29cc9ef7-1bb4-48d0-96a1-9aac65bb813f,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-8f07808c-6aba-4e4b-b4dc-dc45f81f4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-3b3ae1b2-b945-49d3-a356-229c4a10ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-e81f6b5b-18bd-4d2c-8ff9-1f57e44e9798,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-982716aa-2c90-4119-9a38-9ad52d44b556,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-63498442-dc09-401a-b353-3a1a97afc77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-077441cd-255f-4bd6-80d6-02ed91cdde15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571412176-172.17.0.17-1598591431713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-4ca0c730-9833-4758-ba99-688f575c5d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-824c5972-dff1-4960-a5ee-167acf1bf3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-142f8b10-07d4-4c9b-855b-443c07868225,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-c451072e-0172-440e-b872-bb36c4ad1aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-2fd062f0-bbe6-4bf2-b564-80bce162b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-843c7f5e-c799-41b0-9e9f-58bbf7d08ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-bfd59fab-bd90-457d-84c5-cf605cb9658c,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-9f81b00d-c358-475e-9918-9edf68758215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571412176-172.17.0.17-1598591431713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-4ca0c730-9833-4758-ba99-688f575c5d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-824c5972-dff1-4960-a5ee-167acf1bf3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-142f8b10-07d4-4c9b-855b-443c07868225,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-c451072e-0172-440e-b872-bb36c4ad1aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-2fd062f0-bbe6-4bf2-b564-80bce162b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-843c7f5e-c799-41b0-9e9f-58bbf7d08ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-bfd59fab-bd90-457d-84c5-cf605cb9658c,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-9f81b00d-c358-475e-9918-9edf68758215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142451937-172.17.0.17-1598591670720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-15a4bd1f-54c6-4109-93eb-1446fbbcdfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-3edabf79-4756-41f8-bec3-251d6aec2c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-e1cd9ab9-6137-45a4-85b0-3fd3af716e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-47de092a-e866-4009-b953-05cb0065b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-242ac89f-1dec-4a02-9f30-c87d02af9490,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-d7f68e97-d6d3-476a-9db7-95db2107cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-f94b11e9-0f6b-4133-b0d1-fd8dcc8dba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-3107a955-98b7-4508-9043-eedcdff4da3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142451937-172.17.0.17-1598591670720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-15a4bd1f-54c6-4109-93eb-1446fbbcdfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-3edabf79-4756-41f8-bec3-251d6aec2c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-e1cd9ab9-6137-45a4-85b0-3fd3af716e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-47de092a-e866-4009-b953-05cb0065b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-242ac89f-1dec-4a02-9f30-c87d02af9490,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-d7f68e97-d6d3-476a-9db7-95db2107cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-f94b11e9-0f6b-4133-b0d1-fd8dcc8dba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-3107a955-98b7-4508-9043-eedcdff4da3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261367621-172.17.0.17-1598591864761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f2be8aa8-a38e-479d-a94f-5f27a488503e,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-c0888703-0bd9-4cf6-af22-165d9448f724,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-4996c966-c994-481d-bf6a-3e7ca45c3626,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-05a3fc0f-3115-4c81-8118-71961f322eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9725e1ce-6eba-450b-a1d5-286e6a86b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-a32d8a53-dcc5-472d-bf82-5ecc3c5b76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-969f199a-7da3-4794-98e5-1c5796b55a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-1beb062e-a4fb-4cc9-a345-8599fe4c94b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261367621-172.17.0.17-1598591864761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f2be8aa8-a38e-479d-a94f-5f27a488503e,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-c0888703-0bd9-4cf6-af22-165d9448f724,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-4996c966-c994-481d-bf6a-3e7ca45c3626,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-05a3fc0f-3115-4c81-8118-71961f322eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9725e1ce-6eba-450b-a1d5-286e6a86b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-a32d8a53-dcc5-472d-bf82-5ecc3c5b76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-969f199a-7da3-4794-98e5-1c5796b55a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-1beb062e-a4fb-4cc9-a345-8599fe4c94b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216699498-172.17.0.17-1598591961130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-2851e26a-fd14-4a60-9458-2df3c075d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6dc4f9ed-dfa8-4b17-86ea-864fbe156efa,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-53e73425-631d-44a9-b8ac-0290d0ea655f,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-d6cfd2fa-3de9-4605-8028-8f7a1d6873ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-9e2b45f1-35a0-4c6b-9209-65eecbf07e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-8392dafa-c09b-40b6-a362-bcb58540d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-c02176f1-38d7-49b6-96bf-665b1f2f6200,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d5a46730-04b3-4042-8b89-2ad7c8b3e74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216699498-172.17.0.17-1598591961130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-2851e26a-fd14-4a60-9458-2df3c075d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6dc4f9ed-dfa8-4b17-86ea-864fbe156efa,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-53e73425-631d-44a9-b8ac-0290d0ea655f,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-d6cfd2fa-3de9-4605-8028-8f7a1d6873ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-9e2b45f1-35a0-4c6b-9209-65eecbf07e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-8392dafa-c09b-40b6-a362-bcb58540d76b,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-c02176f1-38d7-49b6-96bf-665b1f2f6200,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d5a46730-04b3-4042-8b89-2ad7c8b3e74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66617316-172.17.0.17-1598592989587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-7759596e-1c6f-41d8-a023-7dd776943a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ae3ae6ff-4732-44b5-876f-d3e711da4213,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-07c43b61-8022-43d6-81df-b57d8132c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-5921cee1-51ac-4d8b-b8fa-08e765406bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-94c846dd-faa1-4115-9ad2-dfb27a4fe5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-6e9647b0-720e-449f-97ab-456c32ac187f,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-95769710-d925-48f2-b805-a61aa8d81425,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-7e1508f6-e3a5-421f-8964-f4e529e699cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66617316-172.17.0.17-1598592989587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-7759596e-1c6f-41d8-a023-7dd776943a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ae3ae6ff-4732-44b5-876f-d3e711da4213,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-07c43b61-8022-43d6-81df-b57d8132c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-5921cee1-51ac-4d8b-b8fa-08e765406bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-94c846dd-faa1-4115-9ad2-dfb27a4fe5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-6e9647b0-720e-449f-97ab-456c32ac187f,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-95769710-d925-48f2-b805-a61aa8d81425,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-7e1508f6-e3a5-421f-8964-f4e529e699cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539957625-172.17.0.17-1598593696745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-9dc58f4b-b192-4d2e-85da-9e181c20cbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4f4fac56-b1eb-434b-8b8c-6ab18ff431ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-5d8cf25b-39d4-4998-b7b9-f0e222100fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-fefd1862-1067-46f4-90ca-20b3935d1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-a4cf5781-6602-475c-87e4-9abccfdf4dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-3f3a0ca2-fcf8-422d-9fcf-58aa91c5fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-590e5ff1-5bb2-4e8e-8ba3-95a2498ee313,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-d0988fe3-279e-4e34-9d53-d4a08aba342f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539957625-172.17.0.17-1598593696745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44131,DS-9dc58f4b-b192-4d2e-85da-9e181c20cbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4f4fac56-b1eb-434b-8b8c-6ab18ff431ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-5d8cf25b-39d4-4998-b7b9-f0e222100fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-fefd1862-1067-46f4-90ca-20b3935d1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-a4cf5781-6602-475c-87e4-9abccfdf4dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-3f3a0ca2-fcf8-422d-9fcf-58aa91c5fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-590e5ff1-5bb2-4e8e-8ba3-95a2498ee313,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-d0988fe3-279e-4e34-9d53-d4a08aba342f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5398
