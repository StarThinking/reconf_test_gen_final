reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537849394-172.17.0.18-1598686623971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-e6d51a4c-71df-4151-a879-c197245c38e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-55db0efe-ba41-4e7a-a38e-cd9434d0c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-406f2808-2db6-4ba9-b723-ff89552e5a53,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-0f828040-baf6-4ef9-9e0a-fc68f44b637e,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-29c37462-2580-4e87-b410-309b52895160,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-15d3537a-82f0-49e5-a1f1-a5ad06fd5e94,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-80225b7e-2559-494c-b475-4b64ccf730e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-f2e2d6bd-7221-443e-9ac2-37f598541c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537849394-172.17.0.18-1598686623971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-e6d51a4c-71df-4151-a879-c197245c38e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-55db0efe-ba41-4e7a-a38e-cd9434d0c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-406f2808-2db6-4ba9-b723-ff89552e5a53,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-0f828040-baf6-4ef9-9e0a-fc68f44b637e,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-29c37462-2580-4e87-b410-309b52895160,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-15d3537a-82f0-49e5-a1f1-a5ad06fd5e94,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-80225b7e-2559-494c-b475-4b64ccf730e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-f2e2d6bd-7221-443e-9ac2-37f598541c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955543244-172.17.0.18-1598686661710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-476b8029-6aee-4d35-a145-14c7b5158bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-cb6fffef-e063-4ee4-9802-2389a8ab7186,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-9e19af55-5042-41d3-a198-d620c36a0619,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-6957d52a-f109-42a5-8523-53227d3f3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-76ee1b94-35d3-4a52-b365-aa4e6c59d303,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-34d80a94-6136-46a8-9e65-d7e880b240c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-bb47f41b-8d09-4045-84d4-f22bccbf0c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-d4b275cd-a909-45f8-9bc4-51455706f259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955543244-172.17.0.18-1598686661710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-476b8029-6aee-4d35-a145-14c7b5158bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-cb6fffef-e063-4ee4-9802-2389a8ab7186,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-9e19af55-5042-41d3-a198-d620c36a0619,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-6957d52a-f109-42a5-8523-53227d3f3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-76ee1b94-35d3-4a52-b365-aa4e6c59d303,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-34d80a94-6136-46a8-9e65-d7e880b240c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-bb47f41b-8d09-4045-84d4-f22bccbf0c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-d4b275cd-a909-45f8-9bc4-51455706f259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386331296-172.17.0.18-1598686959476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-de4d8f6f-a8d3-471a-a456-3b143b2f22e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-3fce502a-c8de-4bbc-8574-bec5f49b8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-93e73599-0d7e-4e63-9f2c-beb467852b27,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-2a799274-978c-458f-8e6b-400e61c03fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6e990ae3-a00c-402e-b30e-97f8b342593e,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-6a8bcc9d-028c-4a34-8825-92ffdd675a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-c5805cd7-40da-450c-b70f-6d4573b5ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-395238ec-d6e9-4e2c-bb3f-6a03dc2e5e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386331296-172.17.0.18-1598686959476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-de4d8f6f-a8d3-471a-a456-3b143b2f22e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-3fce502a-c8de-4bbc-8574-bec5f49b8ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-93e73599-0d7e-4e63-9f2c-beb467852b27,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-2a799274-978c-458f-8e6b-400e61c03fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6e990ae3-a00c-402e-b30e-97f8b342593e,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-6a8bcc9d-028c-4a34-8825-92ffdd675a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-c5805cd7-40da-450c-b70f-6d4573b5ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-395238ec-d6e9-4e2c-bb3f-6a03dc2e5e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673801583-172.17.0.18-1598687260862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-1314c08d-2004-4e20-a19a-f8b768317e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-aa145455-b110-440c-9928-18a213190f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-7dff8132-2a58-49cd-8755-1d526cf53bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-395c0c5c-b225-45e1-8832-fdbd20cb2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-88bdb893-ca55-4720-8d60-4bf7fd02443d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3b6ca624-200f-4cb4-b0dd-eb0336db7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-08caecc7-09e1-48c4-b476-21d1aaf77516,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-18846c2c-33c8-463f-9a5d-f21cf3f0095f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673801583-172.17.0.18-1598687260862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-1314c08d-2004-4e20-a19a-f8b768317e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-aa145455-b110-440c-9928-18a213190f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-7dff8132-2a58-49cd-8755-1d526cf53bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-395c0c5c-b225-45e1-8832-fdbd20cb2d19,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-88bdb893-ca55-4720-8d60-4bf7fd02443d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3b6ca624-200f-4cb4-b0dd-eb0336db7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-08caecc7-09e1-48c4-b476-21d1aaf77516,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-18846c2c-33c8-463f-9a5d-f21cf3f0095f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483459056-172.17.0.18-1598687556023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-87dcdccf-afcf-4b18-ba87-14f36b16dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-7d55851b-4dc3-4bad-9680-368d8b81a520,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-6034e406-6b09-41bb-8708-c134a722b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-22642f75-cad2-4a91-8511-66c54c6dba81,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-17cdb571-fed0-4d3e-a8ce-3a9c3675c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-93f09c68-c0d1-4ecb-af10-79aea9b0e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-9dbeb035-f842-4440-89b8-1a03da5a334e,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-e6657b8c-3e55-4b2d-9b4b-95aeac54e4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483459056-172.17.0.18-1598687556023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-87dcdccf-afcf-4b18-ba87-14f36b16dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-7d55851b-4dc3-4bad-9680-368d8b81a520,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-6034e406-6b09-41bb-8708-c134a722b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-22642f75-cad2-4a91-8511-66c54c6dba81,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-17cdb571-fed0-4d3e-a8ce-3a9c3675c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-93f09c68-c0d1-4ecb-af10-79aea9b0e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-9dbeb035-f842-4440-89b8-1a03da5a334e,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-e6657b8c-3e55-4b2d-9b4b-95aeac54e4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165143035-172.17.0.18-1598688005081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-bfd4ac8c-3026-4d73-80c3-7148d0050dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-4a35c68b-434a-46b0-a772-c5bfb4693459,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-965248e3-6ea8-4348-b2d3-1d9e78bf056c,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-a34ed7ac-a780-47ce-ad4f-0bbc06bed0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-83ecb85e-b96c-4971-be83-4cd336e826a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8640fa81-1087-4528-a886-bac23402a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-29bf255f-43d6-4666-b03f-3999eae1ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-4a3f7676-08dd-4614-8840-05e099cd0223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165143035-172.17.0.18-1598688005081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-bfd4ac8c-3026-4d73-80c3-7148d0050dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-4a35c68b-434a-46b0-a772-c5bfb4693459,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-965248e3-6ea8-4348-b2d3-1d9e78bf056c,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-a34ed7ac-a780-47ce-ad4f-0bbc06bed0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-83ecb85e-b96c-4971-be83-4cd336e826a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-8640fa81-1087-4528-a886-bac23402a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-29bf255f-43d6-4666-b03f-3999eae1ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-4a3f7676-08dd-4614-8840-05e099cd0223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858052196-172.17.0.18-1598688600687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-f350e00b-186a-440d-86c4-0297f18c6632,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-b9b8af44-0034-4405-9718-70218c18f092,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-42e990a4-3a9b-4825-b671-e1c722814b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-01e486c8-791c-4857-8be2-15c091ec57df,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-b1509db7-5fcb-48d2-a418-73b57fe6143b,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-12e392d9-926d-4546-83ea-ecd9732e56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-b45ae6a2-fc19-42b5-9ea1-e57d923bce14,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-6bc53971-b64e-4016-aa92-4a901d7b48da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858052196-172.17.0.18-1598688600687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-f350e00b-186a-440d-86c4-0297f18c6632,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-b9b8af44-0034-4405-9718-70218c18f092,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-42e990a4-3a9b-4825-b671-e1c722814b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-01e486c8-791c-4857-8be2-15c091ec57df,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-b1509db7-5fcb-48d2-a418-73b57fe6143b,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-12e392d9-926d-4546-83ea-ecd9732e56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-b45ae6a2-fc19-42b5-9ea1-e57d923bce14,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-6bc53971-b64e-4016-aa92-4a901d7b48da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668773734-172.17.0.18-1598688761472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-72600f68-79ef-485a-add5-f11edc1aa781,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-97b66bc5-1ecc-4590-9b1e-ef5a3ec6029d,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-071d439f-8bbf-4066-93db-669abbbe3535,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-b7a769e6-2b1f-4503-9a67-fd2a896a4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-9ec647af-651e-4862-92e5-9aa6c4baa8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-28c02a5c-4af1-4d6e-acc0-0fe2e70e5548,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d614b493-3238-4e65-89a1-4d20f885567b,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-9fc8dbe6-9ec4-4ea2-8d03-493a638dc8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668773734-172.17.0.18-1598688761472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-72600f68-79ef-485a-add5-f11edc1aa781,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-97b66bc5-1ecc-4590-9b1e-ef5a3ec6029d,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-071d439f-8bbf-4066-93db-669abbbe3535,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-b7a769e6-2b1f-4503-9a67-fd2a896a4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-9ec647af-651e-4862-92e5-9aa6c4baa8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-28c02a5c-4af1-4d6e-acc0-0fe2e70e5548,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d614b493-3238-4e65-89a1-4d20f885567b,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-9fc8dbe6-9ec4-4ea2-8d03-493a638dc8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137991850-172.17.0.18-1598689271954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-92957fef-4fe2-48b3-a2e5-88f54aaf0584,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-6f126021-8e93-498b-94e6-861ae0535bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-c06f110c-2e8d-49c2-ab9f-cf0165779a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2efbe782-4965-4646-8d68-2241e8a70475,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-a7a9dfd2-149a-4d83-b31b-6cddfd1bf145,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-b3d24064-33ed-40ed-b639-f0e4d677bc16,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d8634be3-cfa1-4dcb-8a7c-343fc2891683,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-29e2219f-ab4a-401c-8851-ebe2b5860979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137991850-172.17.0.18-1598689271954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-92957fef-4fe2-48b3-a2e5-88f54aaf0584,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-6f126021-8e93-498b-94e6-861ae0535bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-c06f110c-2e8d-49c2-ab9f-cf0165779a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2efbe782-4965-4646-8d68-2241e8a70475,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-a7a9dfd2-149a-4d83-b31b-6cddfd1bf145,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-b3d24064-33ed-40ed-b639-f0e4d677bc16,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-d8634be3-cfa1-4dcb-8a7c-343fc2891683,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-29e2219f-ab4a-401c-8851-ebe2b5860979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478166108-172.17.0.18-1598689311151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-b3f2f955-d5b2-4e28-a279-93411584d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-a43cb386-d688-409e-89f7-7fb3cf7f2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dcf23d43-a7eb-406e-887a-7c081c3fecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-cb4883c7-d6e3-40ab-8d52-310c8f8b7c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-d8d744d3-3db3-4728-ae24-1d5a21857a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-cb93d530-a2b6-4cf7-8c53-43247b47760b,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-2775032b-4987-442a-a5a3-3b5c8f4800fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5fed0072-7c56-4796-b351-75b7e702d668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478166108-172.17.0.18-1598689311151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-b3f2f955-d5b2-4e28-a279-93411584d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-a43cb386-d688-409e-89f7-7fb3cf7f2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-dcf23d43-a7eb-406e-887a-7c081c3fecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-cb4883c7-d6e3-40ab-8d52-310c8f8b7c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-d8d744d3-3db3-4728-ae24-1d5a21857a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-cb93d530-a2b6-4cf7-8c53-43247b47760b,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-2775032b-4987-442a-a5a3-3b5c8f4800fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-5fed0072-7c56-4796-b351-75b7e702d668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891304149-172.17.0.18-1598689396482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-5a7f981a-48b0-438b-b502-444ad699d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-c5911744-ee58-4875-8ee3-5967f1a54f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-3fe1e60e-e656-48f4-bf94-f1e8775d4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-75e57cde-1ee0-4a60-ab38-5f849db0448d,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8d367826-8b54-48b4-979e-f8c4fc4c9449,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2d141252-9719-445e-83a3-21772ac2c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-dac8b02c-eb71-4422-a0b8-649bc349dd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-1c67e06b-da1c-4811-8c24-ff2890903dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891304149-172.17.0.18-1598689396482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35252,DS-5a7f981a-48b0-438b-b502-444ad699d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-c5911744-ee58-4875-8ee3-5967f1a54f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-3fe1e60e-e656-48f4-bf94-f1e8775d4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-75e57cde-1ee0-4a60-ab38-5f849db0448d,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8d367826-8b54-48b4-979e-f8c4fc4c9449,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2d141252-9719-445e-83a3-21772ac2c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-dac8b02c-eb71-4422-a0b8-649bc349dd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-1c67e06b-da1c-4811-8c24-ff2890903dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860590704-172.17.0.18-1598689864432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-2a9fc873-43d0-4ac4-8dfd-a38797ea4886,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-29cf3ece-64a6-43d7-ac2e-435b642a1c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-6d37f3ce-bbc6-4640-a410-5600cf863111,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-2acbf196-431c-4411-aef9-dfa80d6700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-88bbfd01-c7d4-4cd2-9189-89c0cd85d943,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-3d2cb67d-1051-4e21-a560-4b474bc1f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3089f75-bd81-4b04-b56e-3294b58daaba,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-227f54ea-395b-4ecf-995c-a2694d03ab62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860590704-172.17.0.18-1598689864432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-2a9fc873-43d0-4ac4-8dfd-a38797ea4886,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-29cf3ece-64a6-43d7-ac2e-435b642a1c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-6d37f3ce-bbc6-4640-a410-5600cf863111,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-2acbf196-431c-4411-aef9-dfa80d6700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-88bbfd01-c7d4-4cd2-9189-89c0cd85d943,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-3d2cb67d-1051-4e21-a560-4b474bc1f49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3089f75-bd81-4b04-b56e-3294b58daaba,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-227f54ea-395b-4ecf-995c-a2694d03ab62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876138966-172.17.0.18-1598690147509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-d75a976c-e50c-4cb9-8fb2-0f82fef0fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-2c021f7b-a6b0-481f-9ca8-a39bb5bd263a,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-644cec17-0818-4cf9-ba9b-3fa5868b4b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-49ee1a1a-ea20-4559-9243-fc2c1c12c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-7b804403-f02a-4051-b5c4-e4e386f8a383,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-28354c19-4e29-402a-92c7-5f82628abbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9cff4489-6143-4fc6-9af6-c92bcb55b258,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-313c80a7-b63b-4f00-bda4-69082a8e4762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876138966-172.17.0.18-1598690147509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-d75a976c-e50c-4cb9-8fb2-0f82fef0fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-2c021f7b-a6b0-481f-9ca8-a39bb5bd263a,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-644cec17-0818-4cf9-ba9b-3fa5868b4b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-49ee1a1a-ea20-4559-9243-fc2c1c12c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-7b804403-f02a-4051-b5c4-e4e386f8a383,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-28354c19-4e29-402a-92c7-5f82628abbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9cff4489-6143-4fc6-9af6-c92bcb55b258,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-313c80a7-b63b-4f00-bda4-69082a8e4762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437702401-172.17.0.18-1598690266901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-c5b48254-d568-4728-8a66-d43cc650a978,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5a402375-4662-420f-9597-f0e2b802d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6d518feb-29cc-43a9-8120-8d31fe887cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-6b0a7805-5573-4c1d-a2ad-e20ffd0ff22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-81745ff8-87da-4cd7-87bc-3c6ced4b9122,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-7e27efbe-89e8-45ed-9532-2737230ab8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-11b8fb92-3d5c-427c-94b1-a76c6276c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-4bae3477-9e0c-413b-b9c1-77d860898016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437702401-172.17.0.18-1598690266901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44930,DS-c5b48254-d568-4728-8a66-d43cc650a978,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5a402375-4662-420f-9597-f0e2b802d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-6d518feb-29cc-43a9-8120-8d31fe887cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-6b0a7805-5573-4c1d-a2ad-e20ffd0ff22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-81745ff8-87da-4cd7-87bc-3c6ced4b9122,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-7e27efbe-89e8-45ed-9532-2737230ab8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-11b8fb92-3d5c-427c-94b1-a76c6276c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-4bae3477-9e0c-413b-b9c1-77d860898016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891843158-172.17.0.18-1598690994540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-4a7186e4-4d5b-48f8-b7bc-727091636c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-08589f3e-229a-4886-8784-04513cb7d382,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-09efda7f-44e2-4b2f-bc06-ba8ff577e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-b9eae34e-969e-4d7f-b04d-827c36d1122c,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-eb99e5c6-bc78-4792-860a-e97b1b243e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-1fa36321-7200-4fd4-b448-86a52de36d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-bfed7767-a0b9-4d6b-ac8b-26a0f400e819,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-7b3c1e9a-c1b3-4e04-beb0-89d125bf5ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891843158-172.17.0.18-1598690994540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-4a7186e4-4d5b-48f8-b7bc-727091636c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-08589f3e-229a-4886-8784-04513cb7d382,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-09efda7f-44e2-4b2f-bc06-ba8ff577e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-b9eae34e-969e-4d7f-b04d-827c36d1122c,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-eb99e5c6-bc78-4792-860a-e97b1b243e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-1fa36321-7200-4fd4-b448-86a52de36d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-bfed7767-a0b9-4d6b-ac8b-26a0f400e819,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-7b3c1e9a-c1b3-4e04-beb0-89d125bf5ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907665987-172.17.0.18-1598691174578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-a1f15172-6bf0-4a10-9dba-1f2ab1d505f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-43ef6aaf-9da5-4c35-ba0b-41f224c7737d,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-623f54ad-ab3b-44a3-ba61-600ea1bb7732,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-50bde600-a646-489f-a095-f44708a66c02,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-9f92e032-1b1c-45d1-be6c-be75bb3bee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-924dbee8-6f2d-4b7d-84cf-175e2eabcb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-b51f44a1-be8c-44f4-bde6-6976a68321ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-75a480cc-a989-47d9-8e8c-31137d263d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907665987-172.17.0.18-1598691174578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-a1f15172-6bf0-4a10-9dba-1f2ab1d505f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-43ef6aaf-9da5-4c35-ba0b-41f224c7737d,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-623f54ad-ab3b-44a3-ba61-600ea1bb7732,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-50bde600-a646-489f-a095-f44708a66c02,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-9f92e032-1b1c-45d1-be6c-be75bb3bee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-924dbee8-6f2d-4b7d-84cf-175e2eabcb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-b51f44a1-be8c-44f4-bde6-6976a68321ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-75a480cc-a989-47d9-8e8c-31137d263d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47373275-172.17.0.18-1598691254212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-00c6a0ee-d301-4ffd-aa51-0029136444ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-048a60f8-82db-453d-a56f-4197c26e8412,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-9c6463e0-e42f-4f51-bb0e-2be213df2640,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-27852955-e374-4137-aabc-a33971ab356d,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-c91b21fe-18ba-496b-8030-0d079e5d5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-3c21878c-5fc1-4913-a808-17610033b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-12fae242-c9c7-4a91-840b-53e1db56ee09,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-67426599-d062-4322-bb35-7335dad34ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47373275-172.17.0.18-1598691254212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-00c6a0ee-d301-4ffd-aa51-0029136444ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-048a60f8-82db-453d-a56f-4197c26e8412,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-9c6463e0-e42f-4f51-bb0e-2be213df2640,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-27852955-e374-4137-aabc-a33971ab356d,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-c91b21fe-18ba-496b-8030-0d079e5d5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-3c21878c-5fc1-4913-a808-17610033b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-12fae242-c9c7-4a91-840b-53e1db56ee09,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-67426599-d062-4322-bb35-7335dad34ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192427634-172.17.0.18-1598691290570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-25d23c00-43fb-44d8-bc1e-bf6bfc073b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-87e41587-a4a6-46d5-8646-625c01591901,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-e446b9e0-e255-41a7-ab48-73ed3e1e5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-eabfb9fa-b2b3-4764-ad36-c5287388d349,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-ae5adeed-83e0-425c-af71-c8e98d09d007,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-061a6b07-494b-492c-bd36-2e8ab405fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-de80f5d8-e54a-49d1-98c9-b68f0f18d86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d38f0ab3-0145-47c7-9590-ae3bdcdec3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192427634-172.17.0.18-1598691290570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-25d23c00-43fb-44d8-bc1e-bf6bfc073b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-87e41587-a4a6-46d5-8646-625c01591901,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-e446b9e0-e255-41a7-ab48-73ed3e1e5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-eabfb9fa-b2b3-4764-ad36-c5287388d349,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-ae5adeed-83e0-425c-af71-c8e98d09d007,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-061a6b07-494b-492c-bd36-2e8ab405fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-de80f5d8-e54a-49d1-98c9-b68f0f18d86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-d38f0ab3-0145-47c7-9590-ae3bdcdec3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722265380-172.17.0.18-1598691478185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45076,DS-32d26e18-df75-45ad-8c7e-725c95551158,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-598773a9-48c6-486b-83a1-98c0d4438ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-80aa9124-f76b-4209-9592-dee3c989fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-465f7c8f-18e6-4290-aac2-bbaf83faf51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9cd4480e-234c-4889-9831-8e56b7384c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-67d72630-5a86-4a5c-bd33-3477b03f1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-488ff71d-db08-4415-96fc-0601f81d35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-20cfe830-8905-4063-9a35-61311b632f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722265380-172.17.0.18-1598691478185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45076,DS-32d26e18-df75-45ad-8c7e-725c95551158,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-598773a9-48c6-486b-83a1-98c0d4438ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-80aa9124-f76b-4209-9592-dee3c989fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-465f7c8f-18e6-4290-aac2-bbaf83faf51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9cd4480e-234c-4889-9831-8e56b7384c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-67d72630-5a86-4a5c-bd33-3477b03f1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-488ff71d-db08-4415-96fc-0601f81d35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-20cfe830-8905-4063-9a35-61311b632f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451097035-172.17.0.18-1598691692565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-0f2026db-a18b-47b1-bb1e-d521b01f2b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-5d1cb63e-d4ad-4057-8ff2-840ddd09fb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-007b1128-3d8d-478a-8d1f-4610bfcafb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5110d8a9-4194-4f2e-bb91-dc7b4285de9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-caef7151-fd02-48a2-8e07-b75042ea179c,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-60d9b716-d586-4ff6-a455-01d395c6abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-ee980a26-2836-4461-87f0-a25456211525,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-784dae2c-add4-49a5-a34e-5547d7f80a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451097035-172.17.0.18-1598691692565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-0f2026db-a18b-47b1-bb1e-d521b01f2b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-5d1cb63e-d4ad-4057-8ff2-840ddd09fb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-007b1128-3d8d-478a-8d1f-4610bfcafb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5110d8a9-4194-4f2e-bb91-dc7b4285de9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-caef7151-fd02-48a2-8e07-b75042ea179c,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-60d9b716-d586-4ff6-a455-01d395c6abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-ee980a26-2836-4461-87f0-a25456211525,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-784dae2c-add4-49a5-a34e-5547d7f80a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861225600-172.17.0.18-1598691728779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-36f707d2-e2b6-45c4-8096-0a8fbb3ff629,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-f4a33bb7-b94c-45a8-9afd-fb175ddbc1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-ae036f36-28e2-418e-92b0-f0909e51bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-a7e57a07-134c-4b76-b172-b3b28f0ae1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-34f5ac74-27d2-4970-ba97-ac4777ffeb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-035f8e58-b4b3-4255-b070-26aae7c4ee52,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-2110baf0-98c0-4f19-9228-bb3a6e88b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-6fc2c4bd-75f3-457e-abf3-2c529ac3aca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861225600-172.17.0.18-1598691728779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-36f707d2-e2b6-45c4-8096-0a8fbb3ff629,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-f4a33bb7-b94c-45a8-9afd-fb175ddbc1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-ae036f36-28e2-418e-92b0-f0909e51bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-a7e57a07-134c-4b76-b172-b3b28f0ae1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-34f5ac74-27d2-4970-ba97-ac4777ffeb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-035f8e58-b4b3-4255-b070-26aae7c4ee52,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-2110baf0-98c0-4f19-9228-bb3a6e88b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-6fc2c4bd-75f3-457e-abf3-2c529ac3aca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407352520-172.17.0.18-1598691774477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-22c94ba6-f94b-4f5b-8ead-1661c759f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-189c62b0-120b-4644-8bc1-fa75e9f048e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-24f98a02-73ce-4d26-bc1d-e26a01c246f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-cd5f3511-9595-4e88-bae6-3d07231d4033,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b5988589-80a3-4200-a352-7399a0d78a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-022585f6-8245-407f-ac06-b0edab60076a,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-009e2846-e7be-419d-a106-c2b10e41b621,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-b9b4ed1e-f9d1-43a8-9d3b-83d4cc14928a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407352520-172.17.0.18-1598691774477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38749,DS-22c94ba6-f94b-4f5b-8ead-1661c759f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-189c62b0-120b-4644-8bc1-fa75e9f048e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-24f98a02-73ce-4d26-bc1d-e26a01c246f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-cd5f3511-9595-4e88-bae6-3d07231d4033,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b5988589-80a3-4200-a352-7399a0d78a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-022585f6-8245-407f-ac06-b0edab60076a,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-009e2846-e7be-419d-a106-c2b10e41b621,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-b9b4ed1e-f9d1-43a8-9d3b-83d4cc14928a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5445
