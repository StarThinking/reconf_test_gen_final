reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790629794-172.17.0.7-1598651673019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-d8a3780f-704d-4ce1-be56-45af55bd40af,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-93326ecd-7592-4836-9b58-4b17fbe855cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-4a5f1fda-f409-4534-92e8-e6c0fca971c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-2b47fb56-6d9c-43dc-b0a3-7f718a19ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3f2765a4-6a88-45b1-af04-f1c81745c895,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-f85492e5-1864-4247-ac2c-14a4a0720033,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-201cb929-cf57-4f17-a224-90f5898aca24,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8770a214-7ce9-4fb0-ba88-00b264835460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790629794-172.17.0.7-1598651673019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-d8a3780f-704d-4ce1-be56-45af55bd40af,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-93326ecd-7592-4836-9b58-4b17fbe855cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-4a5f1fda-f409-4534-92e8-e6c0fca971c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-2b47fb56-6d9c-43dc-b0a3-7f718a19ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3f2765a4-6a88-45b1-af04-f1c81745c895,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-f85492e5-1864-4247-ac2c-14a4a0720033,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-201cb929-cf57-4f17-a224-90f5898aca24,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-8770a214-7ce9-4fb0-ba88-00b264835460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634788827-172.17.0.7-1598652557960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-9cba5769-7389-4701-abbe-8d6a55dfa787,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-915f8ae1-f203-4f43-943a-e8f18f7cd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-2a38d2cf-6457-4768-80f7-504b9fc70894,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-7cde7f17-12d6-4a64-bd2b-5620b8b67ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-a3838151-9b6d-4c1a-bbd1-2e4632a4c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-fde44a9f-4120-44c5-bb5d-a1791b25104b,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3672be29-9f89-41aa-b8ce-8ae35f995b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-8cdf240f-64da-4b8f-b234-e547126b866e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634788827-172.17.0.7-1598652557960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-9cba5769-7389-4701-abbe-8d6a55dfa787,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-915f8ae1-f203-4f43-943a-e8f18f7cd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-2a38d2cf-6457-4768-80f7-504b9fc70894,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-7cde7f17-12d6-4a64-bd2b-5620b8b67ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-a3838151-9b6d-4c1a-bbd1-2e4632a4c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-fde44a9f-4120-44c5-bb5d-a1791b25104b,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3672be29-9f89-41aa-b8ce-8ae35f995b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-8cdf240f-64da-4b8f-b234-e547126b866e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594021297-172.17.0.7-1598652775937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-7fd2054a-e78e-4f3c-9b59-dd042ef63783,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f8b2cb76-7785-424e-88ca-7b0e108ee570,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-2bd795b9-bb08-45ad-8694-368ce333cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-1f5aa0cc-1888-4de9-95c2-1cc7e35a7439,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-3d174da1-ec83-461f-b936-a133bd29e429,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-e3741089-d309-4759-8187-226fa14bbcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-08e017c4-a0df-4620-bb2e-7975c81898f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-8d7c1389-58b1-478b-a57c-7dd41d2b9047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594021297-172.17.0.7-1598652775937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-7fd2054a-e78e-4f3c-9b59-dd042ef63783,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f8b2cb76-7785-424e-88ca-7b0e108ee570,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-2bd795b9-bb08-45ad-8694-368ce333cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-1f5aa0cc-1888-4de9-95c2-1cc7e35a7439,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-3d174da1-ec83-461f-b936-a133bd29e429,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-e3741089-d309-4759-8187-226fa14bbcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-08e017c4-a0df-4620-bb2e-7975c81898f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-8d7c1389-58b1-478b-a57c-7dd41d2b9047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592191677-172.17.0.7-1598653215158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-3f1bf4be-56a5-4c4f-a937-c10c49fa0fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-3333f2c2-bdb3-4e83-856a-6af778c00843,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-f504e7fc-6b9b-4710-ba34-5c49f09792bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-e5555031-1571-47c8-bbc5-2ed50b2b2595,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-58967649-b016-4f78-a660-396057920a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-1a1b8117-0bfe-468d-964a-7c24789acdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-b6f9335c-2374-4c5c-9c83-1a59117e445a,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-3be3afa0-0ff4-48c4-8214-6e360c681240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592191677-172.17.0.7-1598653215158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-3f1bf4be-56a5-4c4f-a937-c10c49fa0fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-3333f2c2-bdb3-4e83-856a-6af778c00843,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-f504e7fc-6b9b-4710-ba34-5c49f09792bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-e5555031-1571-47c8-bbc5-2ed50b2b2595,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-58967649-b016-4f78-a660-396057920a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-1a1b8117-0bfe-468d-964a-7c24789acdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-b6f9335c-2374-4c5c-9c83-1a59117e445a,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-3be3afa0-0ff4-48c4-8214-6e360c681240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963583223-172.17.0.7-1598653459905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42420,DS-55438069-aaa4-4a3f-9dd9-d333cb14ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-89401792-ffcb-4651-8dc7-0c55d956ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-772b4302-9e73-4690-9194-9a98f1225feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-42927acf-ee08-43c8-bb3d-78a29aef26af,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6a206e2c-5e6b-4dfa-8cbf-f65ed90c5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-08382481-f7ef-4b9b-aee4-d4a21e1f39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-54d9aee5-e64e-4269-80a8-93e69a262804,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-5205b132-08bb-4cb2-b44b-afb98ff9ecbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963583223-172.17.0.7-1598653459905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42420,DS-55438069-aaa4-4a3f-9dd9-d333cb14ba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-89401792-ffcb-4651-8dc7-0c55d956ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-772b4302-9e73-4690-9194-9a98f1225feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-42927acf-ee08-43c8-bb3d-78a29aef26af,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6a206e2c-5e6b-4dfa-8cbf-f65ed90c5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-08382481-f7ef-4b9b-aee4-d4a21e1f39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-54d9aee5-e64e-4269-80a8-93e69a262804,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-5205b132-08bb-4cb2-b44b-afb98ff9ecbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348050026-172.17.0.7-1598653673964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40883,DS-be03c547-a49f-4f5e-acb0-0ec5dd549f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-6dc405cc-3168-48a3-aa83-903472d0dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-0b55a372-a86a-4cfd-889e-82fff02bc6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0fb5105b-ce66-4b55-a028-24e1535b6f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-f9c86c6e-aa90-4493-958a-af33c84b3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-97ef9bb5-a2e7-48d6-8591-69032f1a15af,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-c193a4d7-1487-4fe1-9a56-65d06a0139f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-dcbd1db0-2b57-477e-86ca-590452d2c661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348050026-172.17.0.7-1598653673964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40883,DS-be03c547-a49f-4f5e-acb0-0ec5dd549f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-6dc405cc-3168-48a3-aa83-903472d0dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-0b55a372-a86a-4cfd-889e-82fff02bc6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0fb5105b-ce66-4b55-a028-24e1535b6f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-f9c86c6e-aa90-4493-958a-af33c84b3edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-97ef9bb5-a2e7-48d6-8591-69032f1a15af,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-c193a4d7-1487-4fe1-9a56-65d06a0139f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-dcbd1db0-2b57-477e-86ca-590452d2c661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705894360-172.17.0.7-1598653768798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-f844d673-a146-4b7a-bf68-827d85642b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1b6e606b-e2e9-429f-89a9-9f18eb5feed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-dc46efa9-ab3e-4a75-82a5-237646f6171b,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-ceb6faab-72c8-4de6-9efe-4ad0b635fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-1590e40f-0e5d-4dc8-8f9b-451c2f028a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c430bdb3-f6e9-4cfb-b94d-d460769927f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a702835f-fcbb-4157-a335-3db6bfbbc8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e31f96aa-e02f-435e-a15f-c0747f678a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705894360-172.17.0.7-1598653768798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-f844d673-a146-4b7a-bf68-827d85642b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1b6e606b-e2e9-429f-89a9-9f18eb5feed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-dc46efa9-ab3e-4a75-82a5-237646f6171b,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-ceb6faab-72c8-4de6-9efe-4ad0b635fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-1590e40f-0e5d-4dc8-8f9b-451c2f028a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-c430bdb3-f6e9-4cfb-b94d-d460769927f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-a702835f-fcbb-4157-a335-3db6bfbbc8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-e31f96aa-e02f-435e-a15f-c0747f678a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072628471-172.17.0.7-1598654180313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43089,DS-ea2ce9a4-2b78-40ce-99b7-1ce22a2d1260,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-40255e38-b902-4166-8a72-e21e68a2b484,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-8ad254b6-9841-4c89-b5f1-b29ca29aa6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3bff95c5-3a5d-488e-89aa-d0895159e781,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-8d1b8e24-5e9a-4e60-849c-59352282ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-e8e023c3-ce53-4a69-8a60-5297f1d086b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-323ff604-8563-47b3-a204-40a4c8fc2142,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-4a045310-6172-4e1e-9e69-43e84b9c5e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072628471-172.17.0.7-1598654180313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43089,DS-ea2ce9a4-2b78-40ce-99b7-1ce22a2d1260,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-40255e38-b902-4166-8a72-e21e68a2b484,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-8ad254b6-9841-4c89-b5f1-b29ca29aa6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3bff95c5-3a5d-488e-89aa-d0895159e781,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-8d1b8e24-5e9a-4e60-849c-59352282ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-e8e023c3-ce53-4a69-8a60-5297f1d086b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-323ff604-8563-47b3-a204-40a4c8fc2142,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-4a045310-6172-4e1e-9e69-43e84b9c5e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58805833-172.17.0.7-1598654251575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-75a68d8c-84a3-4dcf-9a11-683d19f69ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-c62b9f62-a962-46b7-9927-ba45b1438580,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-a8df3509-faef-46fa-875a-81f6fe2249d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-fd8f4c02-2257-4637-8f0e-e3a8b3d5b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bcd61f44-f050-45da-a4d0-a208aab1690f,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-1e391c60-02f4-4219-bf78-c9db111213a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-b6ad73b1-ed36-40ff-8ee3-f89fba346f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-f44de130-3c1d-4eee-8352-1f5187dc5b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58805833-172.17.0.7-1598654251575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-75a68d8c-84a3-4dcf-9a11-683d19f69ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-c62b9f62-a962-46b7-9927-ba45b1438580,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-a8df3509-faef-46fa-875a-81f6fe2249d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-fd8f4c02-2257-4637-8f0e-e3a8b3d5b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bcd61f44-f050-45da-a4d0-a208aab1690f,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-1e391c60-02f4-4219-bf78-c9db111213a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-b6ad73b1-ed36-40ff-8ee3-f89fba346f71,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-f44de130-3c1d-4eee-8352-1f5187dc5b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934770914-172.17.0.7-1598654532757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-cb63544c-0312-4e25-a141-da96c6310023,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-40621c99-6ca7-46c2-bb24-968e3a3909f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-89c348e3-e1c8-441e-9a41-f39a24c6f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-5885007e-2a17-456e-9c4c-41d8c543640a,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-2592d15d-d947-4abf-aac9-fefcad899d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6ba54082-adf6-4bbc-a1d5-99d155c06339,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-e80c5eb6-a937-457d-85e2-c18ba4dfb47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-a337f380-3dc1-4c92-9954-1691272726f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934770914-172.17.0.7-1598654532757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-cb63544c-0312-4e25-a141-da96c6310023,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-40621c99-6ca7-46c2-bb24-968e3a3909f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-89c348e3-e1c8-441e-9a41-f39a24c6f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-5885007e-2a17-456e-9c4c-41d8c543640a,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-2592d15d-d947-4abf-aac9-fefcad899d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6ba54082-adf6-4bbc-a1d5-99d155c06339,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-e80c5eb6-a937-457d-85e2-c18ba4dfb47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-a337f380-3dc1-4c92-9954-1691272726f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897558154-172.17.0.7-1598654674070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-91036eb7-89eb-44fc-9c70-171ec9141907,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-3f2bd5f0-d267-4b85-93e7-77719c194b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-b000da07-ed60-428b-bc34-b25ce01b5a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a2fb6aa9-bcde-46fd-967d-ce3b07738460,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-8b6491c9-cec7-4fca-b3c1-d0e4f499f1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-bd8bd468-b64b-4846-941a-bf203ba2304f,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-78691c1a-8fa6-47cd-9c05-252c1e36f277,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-500dff36-fd1a-4d87-b329-767d912fd7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897558154-172.17.0.7-1598654674070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-91036eb7-89eb-44fc-9c70-171ec9141907,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-3f2bd5f0-d267-4b85-93e7-77719c194b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-b000da07-ed60-428b-bc34-b25ce01b5a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a2fb6aa9-bcde-46fd-967d-ce3b07738460,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-8b6491c9-cec7-4fca-b3c1-d0e4f499f1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-bd8bd468-b64b-4846-941a-bf203ba2304f,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-78691c1a-8fa6-47cd-9c05-252c1e36f277,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-500dff36-fd1a-4d87-b329-767d912fd7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351350375-172.17.0.7-1598655111296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-db08d6ba-aa14-4267-bc8b-03421e3c18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-0f62404c-8162-4ee3-8437-c7cdcef9c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-463ef4ea-82df-43f5-bea0-5a4d7791d5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-fafd2f51-a501-425c-84d5-1ff67b3dc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-2b34718f-075e-46e7-8376-b65f487cf020,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6a8869b9-8d02-4c92-bac0-4c054148bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-7e6d2923-16df-4581-ba41-a06c42800723,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-aebd3669-e9a8-4e6b-9588-e025dc2a3c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351350375-172.17.0.7-1598655111296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-db08d6ba-aa14-4267-bc8b-03421e3c18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-0f62404c-8162-4ee3-8437-c7cdcef9c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-463ef4ea-82df-43f5-bea0-5a4d7791d5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-fafd2f51-a501-425c-84d5-1ff67b3dc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-2b34718f-075e-46e7-8376-b65f487cf020,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6a8869b9-8d02-4c92-bac0-4c054148bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-7e6d2923-16df-4581-ba41-a06c42800723,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-aebd3669-e9a8-4e6b-9588-e025dc2a3c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718697139-172.17.0.7-1598655301490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-f0b6ddc7-a62b-4cf7-b09a-e15e19aa9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6472be6b-386c-485c-b6d5-c9053b6b0f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-69fbfa93-88e6-4ed6-a8e6-ae03f1cb4486,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6efa3549-53fd-440b-b646-e53c8079f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-6d87ab29-e1cd-45e8-a1c1-434521919906,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6133d769-95ea-4a58-87bd-37b522b9f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fd7177a3-9071-4c7f-a75f-0a4e17d70528,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d4ebb452-5371-4ea6-a634-4c1d04a01462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718697139-172.17.0.7-1598655301490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-f0b6ddc7-a62b-4cf7-b09a-e15e19aa9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-6472be6b-386c-485c-b6d5-c9053b6b0f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-69fbfa93-88e6-4ed6-a8e6-ae03f1cb4486,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6efa3549-53fd-440b-b646-e53c8079f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-6d87ab29-e1cd-45e8-a1c1-434521919906,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6133d769-95ea-4a58-87bd-37b522b9f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fd7177a3-9071-4c7f-a75f-0a4e17d70528,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d4ebb452-5371-4ea6-a634-4c1d04a01462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111262439-172.17.0.7-1598655338202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-71d2813c-4820-4e70-b724-db9c1a52a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-088a00a2-1b83-42bc-aa8b-0fc99351c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b35603de-7d6e-4524-904d-e5eb90fa6329,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-80165897-7514-47c5-8cdf-6087772494b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-bc1d7fd8-57be-48ad-a556-aa2d65044902,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-9737e005-c885-416a-b183-2d9cd205f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-1aa90e6a-805b-4399-b558-73c6850161a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-e94341a8-fb2a-4126-add9-8ff43fea04c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111262439-172.17.0.7-1598655338202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-71d2813c-4820-4e70-b724-db9c1a52a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-088a00a2-1b83-42bc-aa8b-0fc99351c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b35603de-7d6e-4524-904d-e5eb90fa6329,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-80165897-7514-47c5-8cdf-6087772494b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-bc1d7fd8-57be-48ad-a556-aa2d65044902,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-9737e005-c885-416a-b183-2d9cd205f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-1aa90e6a-805b-4399-b558-73c6850161a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-e94341a8-fb2a-4126-add9-8ff43fea04c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054289643-172.17.0.7-1598656478196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-367fa165-6d06-4044-ab4c-c19d93a10b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-efe625e4-dfae-421c-b4d2-0cb11317cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-6098100e-373f-45d2-8396-eeccbe787877,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-3c840e4e-5006-4d6b-87ae-e163972e4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-4c7f2575-ec8d-4bf8-baf3-799766313e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-77bc6e43-30fb-4012-8dfb-48595c4a8e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-99505e19-20d4-4868-9015-60fd0c33d0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-64446480-4396-4294-ba3b-0fa2c6f89def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054289643-172.17.0.7-1598656478196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39066,DS-367fa165-6d06-4044-ab4c-c19d93a10b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-efe625e4-dfae-421c-b4d2-0cb11317cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-6098100e-373f-45d2-8396-eeccbe787877,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-3c840e4e-5006-4d6b-87ae-e163972e4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-4c7f2575-ec8d-4bf8-baf3-799766313e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-77bc6e43-30fb-4012-8dfb-48595c4a8e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-99505e19-20d4-4868-9015-60fd0c33d0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-64446480-4396-4294-ba3b-0fa2c6f89def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297142007-172.17.0.7-1598656510239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-18e0ef9b-55df-4640-a077-347baf111006,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-3df35673-bcea-428c-942e-24d7c8cd536b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7d7d2088-d1ab-47be-a90e-726994650316,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-c670d3be-0720-490a-8975-05712cb2dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-26824456-93e6-49d5-bbde-4388f32da210,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-068f5f52-a205-4fda-9c1a-d2cb091304a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-2c28a709-11db-4cd2-950f-5783b28942e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-2c90f919-53cd-4a87-bb92-5f3cdd9c202d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297142007-172.17.0.7-1598656510239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-18e0ef9b-55df-4640-a077-347baf111006,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-3df35673-bcea-428c-942e-24d7c8cd536b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7d7d2088-d1ab-47be-a90e-726994650316,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-c670d3be-0720-490a-8975-05712cb2dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-26824456-93e6-49d5-bbde-4388f32da210,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-068f5f52-a205-4fda-9c1a-d2cb091304a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-2c28a709-11db-4cd2-950f-5783b28942e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-2c90f919-53cd-4a87-bb92-5f3cdd9c202d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5151
