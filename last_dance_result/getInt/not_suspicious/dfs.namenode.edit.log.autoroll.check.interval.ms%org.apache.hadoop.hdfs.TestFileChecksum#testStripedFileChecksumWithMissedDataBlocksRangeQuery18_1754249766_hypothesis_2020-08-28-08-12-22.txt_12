reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184634809-172.17.0.16-1598602516284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-d183ee56-e052-4367-8faa-79cdebbe1526,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-cc30e4fa-c448-437e-a076-dd7967db125f,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c1624202-c272-492f-8411-a5284023b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-1732b363-fbf2-4bb6-894a-0f986b7c54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-6caa5994-7782-41ca-82bb-36a7d8e3dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-7317fada-1ee5-4d84-a7d8-a30b34f372e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-bdb66911-b66f-4a2b-b3d4-2cf45e31a320,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-887e89de-f850-4c20-a5a2-ca08454a4942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184634809-172.17.0.16-1598602516284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-d183ee56-e052-4367-8faa-79cdebbe1526,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-cc30e4fa-c448-437e-a076-dd7967db125f,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-c1624202-c272-492f-8411-a5284023b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-1732b363-fbf2-4bb6-894a-0f986b7c54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-6caa5994-7782-41ca-82bb-36a7d8e3dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-7317fada-1ee5-4d84-a7d8-a30b34f372e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-bdb66911-b66f-4a2b-b3d4-2cf45e31a320,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-887e89de-f850-4c20-a5a2-ca08454a4942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919888828-172.17.0.16-1598602850940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-bb0f6ef0-3c53-4243-be68-926623c2a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-1da534ce-0445-4822-838b-84e58e30baee,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-a0b660a3-98a3-4196-a407-3e953861674c,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-f2a545c5-f865-49f9-ba91-615accd70774,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-40cf135c-6ca5-44eb-bbd7-08abee9df65b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-f7a704f6-9ea2-4b8f-bafd-b0a38cfdb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-bfea541d-1d24-4023-bd6e-7cf8f2758db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-508877e3-c2cb-4fc2-9a45-2dfe648de009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919888828-172.17.0.16-1598602850940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-bb0f6ef0-3c53-4243-be68-926623c2a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-1da534ce-0445-4822-838b-84e58e30baee,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-a0b660a3-98a3-4196-a407-3e953861674c,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-f2a545c5-f865-49f9-ba91-615accd70774,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-40cf135c-6ca5-44eb-bbd7-08abee9df65b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-f7a704f6-9ea2-4b8f-bafd-b0a38cfdb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-bfea541d-1d24-4023-bd6e-7cf8f2758db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-508877e3-c2cb-4fc2-9a45-2dfe648de009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531283825-172.17.0.16-1598604191973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38550,DS-3799d414-e6f3-473b-bda2-98b724a14326,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-f9b24252-cb6a-4edf-bb7d-1d2f95cd171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-a4e8e504-1fc3-4ab8-83bf-1673029a5531,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-2b1f5b22-3b68-4c81-8eeb-3daeaa42fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-09642c38-c7fc-4e4c-bbda-5c9008f75e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-d8c66f40-06cc-4127-938e-01bdbfbfc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-45f3f10e-24af-4952-8728-43ee7e706a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-0794d13f-f1d5-4542-9272-0e25502d2a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531283825-172.17.0.16-1598604191973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38550,DS-3799d414-e6f3-473b-bda2-98b724a14326,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-f9b24252-cb6a-4edf-bb7d-1d2f95cd171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-a4e8e504-1fc3-4ab8-83bf-1673029a5531,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-2b1f5b22-3b68-4c81-8eeb-3daeaa42fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-09642c38-c7fc-4e4c-bbda-5c9008f75e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-d8c66f40-06cc-4127-938e-01bdbfbfc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-45f3f10e-24af-4952-8728-43ee7e706a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-0794d13f-f1d5-4542-9272-0e25502d2a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008773265-172.17.0.16-1598604483536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-b5e614ba-ca00-4ab4-ac0d-5ebd8e8d1fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-c347ce5b-e9e3-4bd7-9c67-023b4e94b367,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-342ba911-9adf-414f-a1ae-0ef7db3ce820,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-c75868a2-8591-4318-923a-b50ae5939564,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-e0c6cf5e-0a84-4bf9-90c3-4fe545139190,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-64b6137c-22fc-4f61-a23b-02fe23bb9659,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-5e7ed5d5-b40c-4fc3-a998-2aa2c5abe703,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-2d071fdf-1b9f-4daa-9eec-b27a6e638e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008773265-172.17.0.16-1598604483536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-b5e614ba-ca00-4ab4-ac0d-5ebd8e8d1fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-c347ce5b-e9e3-4bd7-9c67-023b4e94b367,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-342ba911-9adf-414f-a1ae-0ef7db3ce820,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-c75868a2-8591-4318-923a-b50ae5939564,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-e0c6cf5e-0a84-4bf9-90c3-4fe545139190,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-64b6137c-22fc-4f61-a23b-02fe23bb9659,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-5e7ed5d5-b40c-4fc3-a998-2aa2c5abe703,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-2d071fdf-1b9f-4daa-9eec-b27a6e638e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284443196-172.17.0.16-1598604925564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-b43c7a1b-5488-4032-8e65-bd3b54bc0b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-8475dd50-d1fd-4bb1-b9bb-e499b16ca904,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-4ee68cb4-6119-46b8-91dc-bb1bd18b0a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-9b7410f7-1c9a-42c5-a903-15671148f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-18809d3e-7900-4911-b6a0-676d5bb616da,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-8af98b89-2826-44ab-b79a-9c7691e1943c,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-5ed2195a-a359-452f-9fc3-4a4957053cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-c87abdaf-89f5-4af2-810e-938851a49d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284443196-172.17.0.16-1598604925564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-b43c7a1b-5488-4032-8e65-bd3b54bc0b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-8475dd50-d1fd-4bb1-b9bb-e499b16ca904,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-4ee68cb4-6119-46b8-91dc-bb1bd18b0a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-9b7410f7-1c9a-42c5-a903-15671148f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-18809d3e-7900-4911-b6a0-676d5bb616da,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-8af98b89-2826-44ab-b79a-9c7691e1943c,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-5ed2195a-a359-452f-9fc3-4a4957053cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-c87abdaf-89f5-4af2-810e-938851a49d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332067941-172.17.0.16-1598605521408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-4af963d1-6e82-40ae-bb7d-aac3ab259927,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-bec6618c-b41a-4cd6-8f05-bfb1bc54e524,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-050ab3e6-13a9-480d-8a15-f4bb6846dd94,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-8fef31b2-ac31-48d5-87b7-3471aa8e45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-92fe628b-e992-46bc-8ee5-0eca5a3e6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-b32dcc06-2cfc-4d9c-aefd-9cbcfaa943c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-0dafa881-6729-4efe-b84f-48f691ac340a,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-0231e6d9-1d3c-466d-936b-46263499a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332067941-172.17.0.16-1598605521408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-4af963d1-6e82-40ae-bb7d-aac3ab259927,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-bec6618c-b41a-4cd6-8f05-bfb1bc54e524,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-050ab3e6-13a9-480d-8a15-f4bb6846dd94,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-8fef31b2-ac31-48d5-87b7-3471aa8e45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-92fe628b-e992-46bc-8ee5-0eca5a3e6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-b32dcc06-2cfc-4d9c-aefd-9cbcfaa943c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-0dafa881-6729-4efe-b84f-48f691ac340a,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-0231e6d9-1d3c-466d-936b-46263499a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687176214-172.17.0.16-1598605553690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-d5d6470f-e6ed-4241-aeab-1eb70cb2d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ff98123d-5900-4a43-a866-244240bc993b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4230453a-4524-4c58-8c7a-f5b9ea080b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-085f2d27-90f9-4811-bf63-c1b734b64a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2bf7acae-65d4-408c-b010-752dd1567283,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-0690ac4c-8763-4e25-8657-ac2723401f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-cd125594-f5a2-4b8a-bd54-277ba55ef9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-bfa45b1a-6443-4396-a149-9f931cc32155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687176214-172.17.0.16-1598605553690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-d5d6470f-e6ed-4241-aeab-1eb70cb2d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ff98123d-5900-4a43-a866-244240bc993b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-4230453a-4524-4c58-8c7a-f5b9ea080b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-085f2d27-90f9-4811-bf63-c1b734b64a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-2bf7acae-65d4-408c-b010-752dd1567283,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-0690ac4c-8763-4e25-8657-ac2723401f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-cd125594-f5a2-4b8a-bd54-277ba55ef9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-bfa45b1a-6443-4396-a149-9f931cc32155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012462613-172.17.0.16-1598605591267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-10ab7913-7184-4737-88a9-42b03ac42f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-fcb2cfbb-5c41-46f7-af3c-aacb988f6ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1f0991cd-44fe-40c1-b7a3-2f6a1d0fe4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-d6e2c22a-4bd4-4291-a116-3946bcf18f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-7cb2c915-28ee-420e-9584-4b0daf54584c,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-a8330c81-f910-496e-b441-8aa1da03a181,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6f6c9dd5-af25-492c-8a50-cb47b9883aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-274e3768-17a1-41c4-8e5d-a11f15ba930f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012462613-172.17.0.16-1598605591267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-10ab7913-7184-4737-88a9-42b03ac42f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-fcb2cfbb-5c41-46f7-af3c-aacb988f6ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1f0991cd-44fe-40c1-b7a3-2f6a1d0fe4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-d6e2c22a-4bd4-4291-a116-3946bcf18f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-7cb2c915-28ee-420e-9584-4b0daf54584c,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-a8330c81-f910-496e-b441-8aa1da03a181,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6f6c9dd5-af25-492c-8a50-cb47b9883aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-274e3768-17a1-41c4-8e5d-a11f15ba930f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340664324-172.17.0.16-1598606021243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-26da8fe3-4151-47f3-b371-cbfdde3539c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-1eb35e3d-69f3-4000-89c5-162d586c0585,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-db3d29a3-a368-41c9-91ea-50a56f572395,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-f0b0689b-80a9-46bb-8c65-ab8d4b21ee97,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-48e5e532-21eb-4cdf-8068-02f9a9b5fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7117257c-c94f-4b62-a175-bae2c77e60aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-96d9462b-dc59-41b8-bf1c-9c93626c9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-8e8d25fe-38ce-4123-8603-71909e424fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-340664324-172.17.0.16-1598606021243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-26da8fe3-4151-47f3-b371-cbfdde3539c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-1eb35e3d-69f3-4000-89c5-162d586c0585,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-db3d29a3-a368-41c9-91ea-50a56f572395,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-f0b0689b-80a9-46bb-8c65-ab8d4b21ee97,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-48e5e532-21eb-4cdf-8068-02f9a9b5fd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7117257c-c94f-4b62-a175-bae2c77e60aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-96d9462b-dc59-41b8-bf1c-9c93626c9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-8e8d25fe-38ce-4123-8603-71909e424fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582080486-172.17.0.16-1598606265884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46098,DS-df0c79b2-dc58-498f-a102-ba48799fdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-9878d328-fd57-4075-8881-d19de69d4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-b37d0ed3-82a9-4595-9228-7ad15f694066,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-620560f0-64db-49d0-86e7-c111c4aa68fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-fe709a51-ce43-47ce-b5d7-07aa5d56f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-3c6f81ab-382a-4976-b07e-ca155dd20311,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c9f9a282-8491-4c93-8d3c-b797489d05da,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eae26a51-cbb6-434c-a5cb-9e7ad4c8cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582080486-172.17.0.16-1598606265884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46098,DS-df0c79b2-dc58-498f-a102-ba48799fdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-9878d328-fd57-4075-8881-d19de69d4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-b37d0ed3-82a9-4595-9228-7ad15f694066,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-620560f0-64db-49d0-86e7-c111c4aa68fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-fe709a51-ce43-47ce-b5d7-07aa5d56f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-3c6f81ab-382a-4976-b07e-ca155dd20311,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c9f9a282-8491-4c93-8d3c-b797489d05da,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-eae26a51-cbb6-434c-a5cb-9e7ad4c8cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943191224-172.17.0.16-1598606345371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-6aede5b0-3d5a-41c8-ac1d-a802325b1ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-c2f9bfec-28a2-4026-a9af-b04a9d171658,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-28e671ba-c9a2-4bb0-ae34-24034d293ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-380154b1-b075-44da-a83a-06f4007afc16,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-250b48b6-f520-45e3-b6dd-b7ea6019e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-f4178538-5f84-460d-b497-cb7c0e4450d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c4b87adf-6426-42c4-bbc1-fe0fca688e77,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-d454b9c5-2ee5-436b-b4fa-8c5477dc1574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943191224-172.17.0.16-1598606345371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-6aede5b0-3d5a-41c8-ac1d-a802325b1ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-c2f9bfec-28a2-4026-a9af-b04a9d171658,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-28e671ba-c9a2-4bb0-ae34-24034d293ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-380154b1-b075-44da-a83a-06f4007afc16,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-250b48b6-f520-45e3-b6dd-b7ea6019e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-f4178538-5f84-460d-b497-cb7c0e4450d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c4b87adf-6426-42c4-bbc1-fe0fca688e77,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-d454b9c5-2ee5-436b-b4fa-8c5477dc1574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012957606-172.17.0.16-1598606452834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45018,DS-6f1da505-aed3-4f02-9d04-9fdf8ede4671,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-a8922ade-739d-4d1d-a0a7-d9d7c84735ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-41679b07-1067-4dfd-a0d0-e0fa315d077f,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-e43963da-04c0-4b2a-bdb5-62c9f6f2ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-1ad5f23e-0f72-4770-b666-51ee0c12dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-35974da7-a5da-4ae9-805e-edd04c1a3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c1a41ca1-9f9e-4ef5-9168-2473a7cfdfae,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4ddae6da-3628-44cb-877b-6076d53d9688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012957606-172.17.0.16-1598606452834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45018,DS-6f1da505-aed3-4f02-9d04-9fdf8ede4671,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-a8922ade-739d-4d1d-a0a7-d9d7c84735ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-41679b07-1067-4dfd-a0d0-e0fa315d077f,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-e43963da-04c0-4b2a-bdb5-62c9f6f2ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-1ad5f23e-0f72-4770-b666-51ee0c12dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-35974da7-a5da-4ae9-805e-edd04c1a3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c1a41ca1-9f9e-4ef5-9168-2473a7cfdfae,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-4ddae6da-3628-44cb-877b-6076d53d9688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860366851-172.17.0.16-1598606696061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-9a4ca3c5-0929-47e6-9587-cad2d15b7738,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-fb9d6c2b-2de9-4fc7-8564-dd580171cb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e56cca1f-912e-4aa3-b021-41ca731529f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-0fd4e5b6-28af-4583-a32e-2274f0ab8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-113865d4-c431-48fb-a991-d6e10d015864,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f44b5313-0c45-4aef-93ed-92e517ea9476,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8b05ef13-f361-4e89-bc49-3138ada5a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-bc8e55fd-94c1-499c-b69c-17470bc611ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860366851-172.17.0.16-1598606696061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-9a4ca3c5-0929-47e6-9587-cad2d15b7738,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-fb9d6c2b-2de9-4fc7-8564-dd580171cb80,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-e56cca1f-912e-4aa3-b021-41ca731529f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-0fd4e5b6-28af-4583-a32e-2274f0ab8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-113865d4-c431-48fb-a991-d6e10d015864,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f44b5313-0c45-4aef-93ed-92e517ea9476,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8b05ef13-f361-4e89-bc49-3138ada5a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-bc8e55fd-94c1-499c-b69c-17470bc611ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420319756-172.17.0.16-1598606768016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-aaebfc84-97bc-412d-99d9-701c62f5f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-ec105c57-5f1b-4d46-b466-b0d63a5686fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-6eb2fbb0-1013-4ab3-bf7e-d2c13159707a,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-d3b532e9-f3ae-4b34-b341-1fa01c4ec068,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-7a704d82-c26d-4bc5-897a-72e02dcaf3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1e649f8a-6636-49d1-9921-b280fa1e2879,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-b41b098a-28a5-4cf4-ab72-a38effee4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-aaa20db3-489f-4807-83fa-063a3e73de01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420319756-172.17.0.16-1598606768016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-aaebfc84-97bc-412d-99d9-701c62f5f4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-ec105c57-5f1b-4d46-b466-b0d63a5686fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-6eb2fbb0-1013-4ab3-bf7e-d2c13159707a,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-d3b532e9-f3ae-4b34-b341-1fa01c4ec068,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-7a704d82-c26d-4bc5-897a-72e02dcaf3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1e649f8a-6636-49d1-9921-b280fa1e2879,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-b41b098a-28a5-4cf4-ab72-a38effee4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-aaa20db3-489f-4807-83fa-063a3e73de01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822881857-172.17.0.16-1598606873567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-36a30dd1-e156-4911-9d51-951edde68e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-06ef255f-8648-4e81-b88a-1835d9002667,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-bfa471b1-232d-47ac-8d52-04fd7da39471,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-20160cac-4b87-4a36-a2f5-2bd5ba47b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-6170ef9b-2bf1-4e8b-9b88-cf3c7db43612,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-78b07821-0399-48bd-98ec-538f775d2ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-344716b8-7391-4b00-9d99-340fc483a630,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-90fccb3c-f0c5-404e-8eb1-c51418d798b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822881857-172.17.0.16-1598606873567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-36a30dd1-e156-4911-9d51-951edde68e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-06ef255f-8648-4e81-b88a-1835d9002667,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-bfa471b1-232d-47ac-8d52-04fd7da39471,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-20160cac-4b87-4a36-a2f5-2bd5ba47b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-6170ef9b-2bf1-4e8b-9b88-cf3c7db43612,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-78b07821-0399-48bd-98ec-538f775d2ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-344716b8-7391-4b00-9d99-340fc483a630,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-90fccb3c-f0c5-404e-8eb1-c51418d798b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872781520-172.17.0.16-1598607161927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-99d91896-222f-4cd5-af6a-364165f95d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-1bd4f3df-85db-485e-b284-f5b6565f7110,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-6a948401-79f3-4fcf-8004-5aa389045e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-2c21fca2-a9de-4039-9fe4-348846fb526d,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e054a73e-c915-4810-b4f5-68fae2ffc9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8d225ef7-c11a-4a96-8846-15ad184dd146,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-20a5a830-198f-48b8-91c4-5f186fd2776a,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-e0fd55da-157a-4246-9b1a-55287010fc5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872781520-172.17.0.16-1598607161927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-99d91896-222f-4cd5-af6a-364165f95d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-1bd4f3df-85db-485e-b284-f5b6565f7110,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-6a948401-79f3-4fcf-8004-5aa389045e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-2c21fca2-a9de-4039-9fe4-348846fb526d,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-e054a73e-c915-4810-b4f5-68fae2ffc9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-8d225ef7-c11a-4a96-8846-15ad184dd146,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-20a5a830-198f-48b8-91c4-5f186fd2776a,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-e0fd55da-157a-4246-9b1a-55287010fc5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5062
