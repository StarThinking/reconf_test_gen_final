reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245494986-172.17.0.8-1598608725463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-05489996-4421-4047-b313-582fb844ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-c47b05dd-394c-4f73-bbfa-ffd9f8d3c805,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f2823abe-1a0c-4b83-89d8-cfc533732c42,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-2b49c2ef-09c5-4891-b5d6-4ea7ef4f4756,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d78fca8a-332b-4969-93bd-7248bdbaf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-7491c044-9f4a-4b1e-9a17-b6ae529e28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-fd12a075-e79a-4b1c-b488-92d746f92e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-827b444e-09f1-4704-88d3-652b10c13855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245494986-172.17.0.8-1598608725463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-05489996-4421-4047-b313-582fb844ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-c47b05dd-394c-4f73-bbfa-ffd9f8d3c805,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-f2823abe-1a0c-4b83-89d8-cfc533732c42,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-2b49c2ef-09c5-4891-b5d6-4ea7ef4f4756,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d78fca8a-332b-4969-93bd-7248bdbaf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-7491c044-9f4a-4b1e-9a17-b6ae529e28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-fd12a075-e79a-4b1c-b488-92d746f92e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-827b444e-09f1-4704-88d3-652b10c13855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206369955-172.17.0.8-1598608900759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-30098278-47a2-4db8-a636-586020e20c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-aa44dede-d76e-43cc-aaff-71cde41166f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-64add19d-d6e4-45dc-a8d8-4254e457c075,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-4dbd6fa4-64b3-4b4a-a6d7-bee9fa82269b,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-1d1dce29-9a60-49aa-939d-e0132f324a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-46ac3967-1f4f-48a0-bf33-d6b862c1224d,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-a4469cc8-3348-4b11-bc01-857ca4c910df,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-48ba7c50-4a07-4d25-8dae-e7ad7a0f64d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206369955-172.17.0.8-1598608900759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46840,DS-30098278-47a2-4db8-a636-586020e20c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-aa44dede-d76e-43cc-aaff-71cde41166f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-64add19d-d6e4-45dc-a8d8-4254e457c075,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-4dbd6fa4-64b3-4b4a-a6d7-bee9fa82269b,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-1d1dce29-9a60-49aa-939d-e0132f324a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-46ac3967-1f4f-48a0-bf33-d6b862c1224d,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-a4469cc8-3348-4b11-bc01-857ca4c910df,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-48ba7c50-4a07-4d25-8dae-e7ad7a0f64d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484045944-172.17.0.8-1598609091130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-7b6032fa-7fda-4515-b1c1-f658ee3eda6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-70047db4-51c6-40af-90fb-2069a40ec4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-6d2db852-4968-4785-9849-0aa234f0ad9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-ba2b21a1-5ab9-436b-bda7-5b81a72b09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-2ee083a9-1770-4c19-ae3f-cc2fd1d7f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-242cafa5-83ff-4b52-9100-f54faa9e208f,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-343d64cf-a6d2-4763-8c60-985126f07a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-2ce26b48-0004-4c7d-b9d7-869d04602b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484045944-172.17.0.8-1598609091130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-7b6032fa-7fda-4515-b1c1-f658ee3eda6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-70047db4-51c6-40af-90fb-2069a40ec4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-6d2db852-4968-4785-9849-0aa234f0ad9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-ba2b21a1-5ab9-436b-bda7-5b81a72b09c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-2ee083a9-1770-4c19-ae3f-cc2fd1d7f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-242cafa5-83ff-4b52-9100-f54faa9e208f,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-343d64cf-a6d2-4763-8c60-985126f07a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-2ce26b48-0004-4c7d-b9d7-869d04602b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891091889-172.17.0.8-1598609124428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-de8275d1-e1bf-4aa9-a6b3-c1859d63559d,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-b4a4e955-fcb7-4127-9eee-9a3866719daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-7874609a-2462-40e5-8650-9acebed090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-a3f5e1d4-9dee-45ab-aa66-e3200a116a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-7ea1e345-781b-4c85-8d3a-3e3d87dc59e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c5785d2f-2d66-4335-abc9-2bb0953bc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-fb57a8f2-bf2f-4e19-9983-a71b92372b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-a932fa28-a606-4af5-bc2c-bdea09ea57e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891091889-172.17.0.8-1598609124428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-de8275d1-e1bf-4aa9-a6b3-c1859d63559d,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-b4a4e955-fcb7-4127-9eee-9a3866719daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-7874609a-2462-40e5-8650-9acebed090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-a3f5e1d4-9dee-45ab-aa66-e3200a116a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-7ea1e345-781b-4c85-8d3a-3e3d87dc59e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c5785d2f-2d66-4335-abc9-2bb0953bc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-fb57a8f2-bf2f-4e19-9983-a71b92372b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-a932fa28-a606-4af5-bc2c-bdea09ea57e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909076165-172.17.0.8-1598609193170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-5c578d2a-0c23-443a-8e6a-68c9eb6f8947,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-f34b7eee-ab10-4897-b503-f29074e7aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-43c9a0f3-6f52-4fd6-a73b-d0bbff64f647,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-797f74a9-2c57-4e60-8ab2-fe61485c2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-7793bf89-6824-4cd9-8589-1080e1c026fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3b98bd15-21ad-4326-a028-6a70a4cd110d,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-84ffb150-2b93-44e8-9862-cbaf3b40bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-08f0681b-8b87-4620-8fec-4244144ecb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909076165-172.17.0.8-1598609193170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-5c578d2a-0c23-443a-8e6a-68c9eb6f8947,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-f34b7eee-ab10-4897-b503-f29074e7aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-43c9a0f3-6f52-4fd6-a73b-d0bbff64f647,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-797f74a9-2c57-4e60-8ab2-fe61485c2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-7793bf89-6824-4cd9-8589-1080e1c026fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3b98bd15-21ad-4326-a028-6a70a4cd110d,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-84ffb150-2b93-44e8-9862-cbaf3b40bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-08f0681b-8b87-4620-8fec-4244144ecb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387420018-172.17.0.8-1598609364279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-77804d4b-f8a2-4723-92a3-f25c186ce5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-532d123a-a44c-4e65-99c5-eb88785efd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-595c1377-1fb3-4881-9f06-51dc30a46a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-59e2032b-1b49-4481-9ed0-140e7460c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-21bd4013-c63f-4a01-837e-7ac781d5034d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-d08dad43-ee9b-4795-a376-ab28f4f572b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-c79c100b-fe89-4a33-be2b-9e34949e9174,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-8f38b51f-737a-4327-9537-37389be7687e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387420018-172.17.0.8-1598609364279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-77804d4b-f8a2-4723-92a3-f25c186ce5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-532d123a-a44c-4e65-99c5-eb88785efd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-595c1377-1fb3-4881-9f06-51dc30a46a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-59e2032b-1b49-4481-9ed0-140e7460c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-21bd4013-c63f-4a01-837e-7ac781d5034d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-d08dad43-ee9b-4795-a376-ab28f4f572b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-c79c100b-fe89-4a33-be2b-9e34949e9174,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-8f38b51f-737a-4327-9537-37389be7687e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351423717-172.17.0.8-1598609715628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-bd9877a7-2d89-4140-91af-7afe02268a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-4980a0b9-009c-4776-8379-3f85d78cc96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-547a7263-525c-482b-a366-7313d9ae87c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-9f2d7b91-714e-4403-a45c-d996478987a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-54af2f60-35f2-46fc-b435-5ae8ba174e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-228159a3-bf65-4963-b0ee-8e48d6805533,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-2b694279-fcb1-41d1-937a-96f39b2541c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-62c088c3-8934-4897-a6ce-8eb5efbf2922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351423717-172.17.0.8-1598609715628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-bd9877a7-2d89-4140-91af-7afe02268a01,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-4980a0b9-009c-4776-8379-3f85d78cc96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-547a7263-525c-482b-a366-7313d9ae87c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-9f2d7b91-714e-4403-a45c-d996478987a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-54af2f60-35f2-46fc-b435-5ae8ba174e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-228159a3-bf65-4963-b0ee-8e48d6805533,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-2b694279-fcb1-41d1-937a-96f39b2541c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-62c088c3-8934-4897-a6ce-8eb5efbf2922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197566258-172.17.0.8-1598609787606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-3df78474-0669-491d-ae9d-f00acac73b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-a152d4fb-c286-437f-8552-37fdb6e33411,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-4b5965be-2554-402a-a465-75cc8666bc63,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-e071d19b-c90c-40cc-b16d-7961ab8ea228,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-74bbb180-83a0-4441-81c9-607739a02ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-218527c5-ff1b-41ec-ae1e-d39b9b9b675d,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e6892f90-5250-471a-9634-f05dfc17f084,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-1a32f339-696c-4748-acac-7f21939bc238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197566258-172.17.0.8-1598609787606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-3df78474-0669-491d-ae9d-f00acac73b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-a152d4fb-c286-437f-8552-37fdb6e33411,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-4b5965be-2554-402a-a465-75cc8666bc63,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-e071d19b-c90c-40cc-b16d-7961ab8ea228,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-74bbb180-83a0-4441-81c9-607739a02ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-218527c5-ff1b-41ec-ae1e-d39b9b9b675d,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e6892f90-5250-471a-9634-f05dfc17f084,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-1a32f339-696c-4748-acac-7f21939bc238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246366390-172.17.0.8-1598610111061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-7cab2d4f-f663-48db-9fb9-d50f028b31eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-434b5fa6-1002-43ad-961a-94f2030fad42,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-1f342f49-2d63-45f2-a354-df2492dcf296,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-7f85322a-1b08-4ec7-a88b-456fcca294d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-058d6265-c915-4f90-9c5e-ad6d44dfa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-600e032d-e0ec-4dd8-9c18-e099b29dec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-c0fbe2ed-4f3c-4df7-bf86-e838e62d17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-828ce2ac-ee38-409b-8cf5-18f36d7dd603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246366390-172.17.0.8-1598610111061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-7cab2d4f-f663-48db-9fb9-d50f028b31eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-434b5fa6-1002-43ad-961a-94f2030fad42,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-1f342f49-2d63-45f2-a354-df2492dcf296,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-7f85322a-1b08-4ec7-a88b-456fcca294d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-058d6265-c915-4f90-9c5e-ad6d44dfa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-600e032d-e0ec-4dd8-9c18-e099b29dec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-c0fbe2ed-4f3c-4df7-bf86-e838e62d17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-828ce2ac-ee38-409b-8cf5-18f36d7dd603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654593549-172.17.0.8-1598610333156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-862aeaea-1ba8-4917-80d4-eeba9e56af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6166ac11-fd49-467e-ab31-aae8d3cb20fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-8fece276-2beb-4497-9c2d-bbb637b174ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-b755e417-c75d-494b-b12d-9658fa8e1466,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-be28ca8d-f5a1-460c-b325-d4bf8e2d1647,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-84efa40a-878b-464a-bde1-953ffce00ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-9c4eeb64-5b4c-4597-8a5c-bdc889f37577,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-57563f1f-fcfe-441f-9755-c7fc13e208ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654593549-172.17.0.8-1598610333156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-862aeaea-1ba8-4917-80d4-eeba9e56af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6166ac11-fd49-467e-ab31-aae8d3cb20fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-8fece276-2beb-4497-9c2d-bbb637b174ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-b755e417-c75d-494b-b12d-9658fa8e1466,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-be28ca8d-f5a1-460c-b325-d4bf8e2d1647,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-84efa40a-878b-464a-bde1-953ffce00ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-9c4eeb64-5b4c-4597-8a5c-bdc889f37577,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-57563f1f-fcfe-441f-9755-c7fc13e208ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213012812-172.17.0.8-1598610626296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-8fe550af-110a-4ee9-8f29-d3b43be3f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-358447d3-03d1-4b3b-b2ce-24d36688fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5347ebf1-51e7-4a53-b20b-fe49b11542f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cb130800-c1e5-426e-858a-427ee77e103f,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-fe92d205-1a12-494e-8682-5d9031238cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-74c079a6-4707-4120-9b18-5093922c45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-7de85318-838a-423e-b9bc-325991ffa93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-be58d644-f776-4e1f-8dd9-e8058bf5da69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213012812-172.17.0.8-1598610626296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44174,DS-8fe550af-110a-4ee9-8f29-d3b43be3f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-358447d3-03d1-4b3b-b2ce-24d36688fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5347ebf1-51e7-4a53-b20b-fe49b11542f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cb130800-c1e5-426e-858a-427ee77e103f,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-fe92d205-1a12-494e-8682-5d9031238cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-74c079a6-4707-4120-9b18-5093922c45a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-7de85318-838a-423e-b9bc-325991ffa93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-be58d644-f776-4e1f-8dd9-e8058bf5da69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72280662-172.17.0.8-1598610664213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-093c5f19-e19c-447d-92b8-2e6d33c89918,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-719a1f3f-cd57-4ee7-aebf-1e28c287a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-96109382-ea1e-4c63-9bb9-29f0919c0777,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-939935c3-1c74-4af5-b673-ceb5aca12006,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-82d31199-9994-4740-bce5-4c2c59c4462d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-859d8f91-1f39-405b-8403-c9f7c47df504,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-75cf25b0-fd0f-463e-af33-9b457c61c394,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-eec88153-5eb0-4833-b2b7-fbe8445aaf82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72280662-172.17.0.8-1598610664213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-093c5f19-e19c-447d-92b8-2e6d33c89918,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-719a1f3f-cd57-4ee7-aebf-1e28c287a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-96109382-ea1e-4c63-9bb9-29f0919c0777,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-939935c3-1c74-4af5-b673-ceb5aca12006,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-82d31199-9994-4740-bce5-4c2c59c4462d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-859d8f91-1f39-405b-8403-c9f7c47df504,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-75cf25b0-fd0f-463e-af33-9b457c61c394,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-eec88153-5eb0-4833-b2b7-fbe8445aaf82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554966460-172.17.0.8-1598610727068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-798b88ec-3956-4df5-aec3-2c436031f4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-28a0fc51-e006-42d7-91bb-05c73aeaced9,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-eb964c2c-3cea-4672-9a3b-4012f5346d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-d5eada81-17c4-4841-aa6e-0ae34595ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-e8c5d6eb-adb5-4102-bfb9-d11ebc2b4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-d231f2e9-e7f2-40f2-b54e-67f883066907,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-2115d294-d73e-41bb-8327-72b794c6b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-a7040d18-7309-4665-a747-36af33b424b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554966460-172.17.0.8-1598610727068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-798b88ec-3956-4df5-aec3-2c436031f4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-28a0fc51-e006-42d7-91bb-05c73aeaced9,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-eb964c2c-3cea-4672-9a3b-4012f5346d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-d5eada81-17c4-4841-aa6e-0ae34595ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-e8c5d6eb-adb5-4102-bfb9-d11ebc2b4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-d231f2e9-e7f2-40f2-b54e-67f883066907,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-2115d294-d73e-41bb-8327-72b794c6b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-a7040d18-7309-4665-a747-36af33b424b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568072675-172.17.0.8-1598611530796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-82eb6c4d-69c6-408c-91d3-fae887f09745,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e2e0a4c4-3c84-4465-a7ca-ca840c625763,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-3d1c41c5-962c-4d62-8c04-484380a1029e,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-c40b4529-b7ac-43d3-9822-111314624d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-a9133e63-54f1-4941-bbdd-2411d7706fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-57b3ee18-1f8b-4168-b8d3-557386f74d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-1733ca3c-60e7-4a0c-93b6-b355dd076d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-0103365c-3f85-4c7b-a141-a3dc2009bacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568072675-172.17.0.8-1598611530796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-82eb6c4d-69c6-408c-91d3-fae887f09745,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e2e0a4c4-3c84-4465-a7ca-ca840c625763,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-3d1c41c5-962c-4d62-8c04-484380a1029e,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-c40b4529-b7ac-43d3-9822-111314624d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-a9133e63-54f1-4941-bbdd-2411d7706fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-57b3ee18-1f8b-4168-b8d3-557386f74d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-1733ca3c-60e7-4a0c-93b6-b355dd076d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-0103365c-3f85-4c7b-a141-a3dc2009bacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094509744-172.17.0.8-1598612195601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-0ca0237f-f1f4-4f91-b162-4f4995d9f301,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-776e9c24-fd35-4696-8885-223b6b9b000b,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-8336ce81-4899-45a1-9070-574e142a0551,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-daba1b70-9e71-46c6-9e03-914d87fa559a,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-702f7544-120f-4c56-a5fc-d4e3cbd4cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-647a9ea7-423b-456a-af5d-cee0ec85dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-6a75c884-841d-4892-8028-3249168a65ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-27ff9f55-8fc3-4c9d-82a0-b0947781b97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094509744-172.17.0.8-1598612195601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-0ca0237f-f1f4-4f91-b162-4f4995d9f301,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-776e9c24-fd35-4696-8885-223b6b9b000b,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-8336ce81-4899-45a1-9070-574e142a0551,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-daba1b70-9e71-46c6-9e03-914d87fa559a,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-702f7544-120f-4c56-a5fc-d4e3cbd4cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-647a9ea7-423b-456a-af5d-cee0ec85dc68,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-6a75c884-841d-4892-8028-3249168a65ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-27ff9f55-8fc3-4c9d-82a0-b0947781b97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054761599-172.17.0.8-1598612304348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-f8d31f7c-ad8f-4816-b88e-ca5193f37c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-f9f96f19-8229-458e-b2a5-60738dd62524,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-46559c9e-78e1-45da-bcf8-96ba340a29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-f7346c54-ab0c-4b85-9579-a71909ee7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-dc8cc732-2dc0-41fe-bddf-f5068999e577,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-a5700496-0275-48f2-8f4d-57b125066140,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-22bc7c2d-2154-42e9-a57e-fd9659f8a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-c56e4d06-decc-45b1-82f9-3d58ec68410a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054761599-172.17.0.8-1598612304348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-f8d31f7c-ad8f-4816-b88e-ca5193f37c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-f9f96f19-8229-458e-b2a5-60738dd62524,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-46559c9e-78e1-45da-bcf8-96ba340a29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-f7346c54-ab0c-4b85-9579-a71909ee7b80,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-dc8cc732-2dc0-41fe-bddf-f5068999e577,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-a5700496-0275-48f2-8f4d-57b125066140,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-22bc7c2d-2154-42e9-a57e-fd9659f8a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-c56e4d06-decc-45b1-82f9-3d58ec68410a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826159435-172.17.0.8-1598612659478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-ffb69fcb-be27-4cd8-9fcc-3fb680fef5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-9ddafa33-2b71-4a76-99d2-07ee0c784b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-22c36826-84f4-41fc-84b3-5606dd6ae50b,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-2f9b4572-dcfe-441c-ba68-1c0bbd4e24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-451ec000-54c9-4edf-bf83-52c8cee6ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-fa1342bb-3c1d-4b80-b839-bab151bce909,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a80c26a3-a28c-4d8e-b8cd-e7cdde709976,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-e7cc6a28-0cf3-430f-94e3-f3794aadbc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826159435-172.17.0.8-1598612659478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-ffb69fcb-be27-4cd8-9fcc-3fb680fef5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-9ddafa33-2b71-4a76-99d2-07ee0c784b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-22c36826-84f4-41fc-84b3-5606dd6ae50b,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-2f9b4572-dcfe-441c-ba68-1c0bbd4e24d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-451ec000-54c9-4edf-bf83-52c8cee6ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-fa1342bb-3c1d-4b80-b839-bab151bce909,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-a80c26a3-a28c-4d8e-b8cd-e7cdde709976,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-e7cc6a28-0cf3-430f-94e3-f3794aadbc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952710131-172.17.0.8-1598613303628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-b9c20f92-5137-4b50-96ec-9c46017e8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-10593321-5f10-44d3-9bc9-9af3474c8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d96e2778-042e-444e-9601-42b554cb4936,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-de2924de-1464-40eb-bc86-141e60b35d12,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-2626adf3-56bd-4c6f-a11e-2d1425a7f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-2aa312a1-bcc8-47bb-a668-b53367a5bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-40909d16-fc75-49da-9e66-dcc92fde3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-e8b8db7e-50f4-4a8b-9235-fdc5f7a8debd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952710131-172.17.0.8-1598613303628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-b9c20f92-5137-4b50-96ec-9c46017e8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-10593321-5f10-44d3-9bc9-9af3474c8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-d96e2778-042e-444e-9601-42b554cb4936,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-de2924de-1464-40eb-bc86-141e60b35d12,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-2626adf3-56bd-4c6f-a11e-2d1425a7f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-2aa312a1-bcc8-47bb-a668-b53367a5bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-40909d16-fc75-49da-9e66-dcc92fde3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-e8b8db7e-50f4-4a8b-9235-fdc5f7a8debd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155238020-172.17.0.8-1598613563315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-e6c31e87-2adc-421f-ac04-50e372dd9de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-ca023770-60b1-4224-9fe8-8af195995616,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-2e93d947-3e0e-41e9-8b70-48f2c846df39,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3dfce228-ad9a-4c41-81e5-fb3382e37ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-6e23a821-5f44-4f59-a7ff-bd7a9e161e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b419e0a1-fc33-46b6-aa7e-33631a72badd,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b54cb41c-5efa-4dd5-9e10-d1cce7b00cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-a38080e3-1b51-4b58-b979-946c310d3ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155238020-172.17.0.8-1598613563315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-e6c31e87-2adc-421f-ac04-50e372dd9de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-ca023770-60b1-4224-9fe8-8af195995616,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-2e93d947-3e0e-41e9-8b70-48f2c846df39,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3dfce228-ad9a-4c41-81e5-fb3382e37ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-6e23a821-5f44-4f59-a7ff-bd7a9e161e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b419e0a1-fc33-46b6-aa7e-33631a72badd,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b54cb41c-5efa-4dd5-9e10-d1cce7b00cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-a38080e3-1b51-4b58-b979-946c310d3ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830505566-172.17.0.8-1598613706394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-ad52cf74-5306-49db-8b59-1718b176a397,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-4f33f5d4-ff47-41a4-940f-97462eeb7961,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-d52eb9a8-d054-45f5-8a6a-cf858e38f438,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-82d6f6e3-b8ab-49af-a46a-ab08dec26b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-feafe020-1b12-421e-819a-723dd42bd696,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-641d83b1-9b21-4325-a2bc-1471e93db2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-02bf763c-e584-4494-b320-99f069138b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-60730359-b6ab-46b6-945f-412c45fc9f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830505566-172.17.0.8-1598613706394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-ad52cf74-5306-49db-8b59-1718b176a397,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-4f33f5d4-ff47-41a4-940f-97462eeb7961,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-d52eb9a8-d054-45f5-8a6a-cf858e38f438,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-82d6f6e3-b8ab-49af-a46a-ab08dec26b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-feafe020-1b12-421e-819a-723dd42bd696,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-641d83b1-9b21-4325-a2bc-1471e93db2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-02bf763c-e584-4494-b320-99f069138b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-60730359-b6ab-46b6-945f-412c45fc9f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410930353-172.17.0.8-1598613825476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-dc280249-6c91-4a34-86f6-8de4154dd405,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-f687aba7-9eaa-48ed-be29-527f641206b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-85692c0e-f87c-4507-b88b-02af19335743,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-839457c9-ee4a-4cba-98ed-702c5387e072,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-cbd4e48d-1f83-41d2-8f46-e53bc701417d,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-9e17bb3c-81f7-4a11-8299-08fffd550be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-3b990fa5-1c4a-46f5-826f-fcf89e18d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ae5cd092-0e37-4f6a-88d2-3063778beaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410930353-172.17.0.8-1598613825476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-dc280249-6c91-4a34-86f6-8de4154dd405,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-f687aba7-9eaa-48ed-be29-527f641206b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-85692c0e-f87c-4507-b88b-02af19335743,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-839457c9-ee4a-4cba-98ed-702c5387e072,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-cbd4e48d-1f83-41d2-8f46-e53bc701417d,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-9e17bb3c-81f7-4a11-8299-08fffd550be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-3b990fa5-1c4a-46f5-826f-fcf89e18d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ae5cd092-0e37-4f6a-88d2-3063778beaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5249
