reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071400582-172.17.0.13-1598495267430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-e77cf287-6d8c-4cca-affc-f4864a1a71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0eb689c2-f329-4fbb-b92d-c157267748f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-d7b61c60-120f-4a26-88c3-a0cccda417b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-68ffb82f-cbc7-4de0-ae1f-9fcb3022a791,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d6f85b4d-3aed-46de-9b26-c8512ec04e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-8e58963c-cf50-4732-91e5-09576cbf0988,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-b92ebc6c-6034-4fd4-865b-7e4e12bc85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-27c83f19-3831-4dc3-b73a-c7e63d99070a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071400582-172.17.0.13-1598495267430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-e77cf287-6d8c-4cca-affc-f4864a1a71bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0eb689c2-f329-4fbb-b92d-c157267748f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-d7b61c60-120f-4a26-88c3-a0cccda417b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-68ffb82f-cbc7-4de0-ae1f-9fcb3022a791,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-d6f85b4d-3aed-46de-9b26-c8512ec04e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-8e58963c-cf50-4732-91e5-09576cbf0988,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-b92ebc6c-6034-4fd4-865b-7e4e12bc85a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-27c83f19-3831-4dc3-b73a-c7e63d99070a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279122236-172.17.0.13-1598495903081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-5674d5df-6772-45a3-8bfc-92ff36bcbb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-0f927f36-87b9-438f-a088-58df076c4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-49eeba4d-21f5-403a-8e0d-bcca1496cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-759737fe-b3ab-42d3-9c0e-5bc07bd4330f,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-57832fcf-f324-4f04-a953-495c931e0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-44065c11-cba7-4bd6-b08d-f78276d1bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-f95cf611-ddac-47eb-a942-903be33b6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-b7428207-2bfe-4541-9762-745d4ba63d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279122236-172.17.0.13-1598495903081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-5674d5df-6772-45a3-8bfc-92ff36bcbb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-0f927f36-87b9-438f-a088-58df076c4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-49eeba4d-21f5-403a-8e0d-bcca1496cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-759737fe-b3ab-42d3-9c0e-5bc07bd4330f,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-57832fcf-f324-4f04-a953-495c931e0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-44065c11-cba7-4bd6-b08d-f78276d1bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-f95cf611-ddac-47eb-a942-903be33b6aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-b7428207-2bfe-4541-9762-745d4ba63d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615327991-172.17.0.13-1598497054985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-ee28ec8e-316c-490b-b4b7-1a44f1ca3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-d3d0d59c-c371-4414-9a12-26b7cc66eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-1b2573a6-77cd-49a5-8ab1-5e3ac99db1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-059fa9d3-0ddc-406c-86aa-caeb52d26e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-c463fc33-2e30-4c45-b596-4b90d775c11a,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-f68a2b4e-f479-4cc2-b88a-a733873b778e,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-62073c6b-c26c-4ba7-9d85-0347a24faf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-6030de77-bf3b-4c4c-940a-1572b46313ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615327991-172.17.0.13-1598497054985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-ee28ec8e-316c-490b-b4b7-1a44f1ca3d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-d3d0d59c-c371-4414-9a12-26b7cc66eb06,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-1b2573a6-77cd-49a5-8ab1-5e3ac99db1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-059fa9d3-0ddc-406c-86aa-caeb52d26e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-c463fc33-2e30-4c45-b596-4b90d775c11a,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-f68a2b4e-f479-4cc2-b88a-a733873b778e,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-62073c6b-c26c-4ba7-9d85-0347a24faf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-6030de77-bf3b-4c4c-940a-1572b46313ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405972987-172.17.0.13-1598497695975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-6073fc79-81bb-46c8-a3b7-6be85331e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e669fc15-ca19-4f95-a5e4-30b62db2f198,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-edc45b91-e292-42df-8a88-7a604585e5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-c6c8cee3-8736-4019-98a2-999bc35b6335,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-fb901547-3ade-4c40-af26-3da2e71c32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3a8ac86f-793c-46de-b718-b836ea2a4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-c4e44525-04a9-4fc4-bd54-88cea1d5d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-eafeed30-67ca-431d-a575-654bc097ae58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405972987-172.17.0.13-1598497695975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-6073fc79-81bb-46c8-a3b7-6be85331e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-e669fc15-ca19-4f95-a5e4-30b62db2f198,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-edc45b91-e292-42df-8a88-7a604585e5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-c6c8cee3-8736-4019-98a2-999bc35b6335,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-fb901547-3ade-4c40-af26-3da2e71c32fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3a8ac86f-793c-46de-b718-b836ea2a4aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-c4e44525-04a9-4fc4-bd54-88cea1d5d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-eafeed30-67ca-431d-a575-654bc097ae58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308853463-172.17.0.13-1598497732682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-7dec1c60-310b-4ddd-bbba-78ec1253dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0cc6c9f2-3bd4-475b-9b55-6ee671be8040,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-5b8a3c18-9c71-4e55-a10f-409f7555dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-41168c75-782d-42b0-962d-a4ec6023ad47,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-504c65bf-ce8a-4f7e-badc-9c1b1492fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-31ee2015-b133-4e1a-812f-f276cca9b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-9d773f1f-308b-43a9-a289-c76fce8077e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-48ea4609-aa18-4aac-abd3-f66d466483eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308853463-172.17.0.13-1598497732682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-7dec1c60-310b-4ddd-bbba-78ec1253dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-0cc6c9f2-3bd4-475b-9b55-6ee671be8040,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-5b8a3c18-9c71-4e55-a10f-409f7555dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-41168c75-782d-42b0-962d-a4ec6023ad47,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-504c65bf-ce8a-4f7e-badc-9c1b1492fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-31ee2015-b133-4e1a-812f-f276cca9b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-9d773f1f-308b-43a9-a289-c76fce8077e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-48ea4609-aa18-4aac-abd3-f66d466483eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285837005-172.17.0.13-1598497810715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-53fc4471-21a8-4975-877e-13289450d083,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6e2b3873-bcf2-46ac-b746-f70facc96237,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-4e3fff47-4b38-4a4a-bbc4-45a42d63b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-1273921d-c63e-4054-aae7-5916765c5761,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-d9fcd3a2-a181-4385-b9c4-84d573a947cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-88f54621-7b39-4cf2-afc5-30d9e91fbbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-d720f90d-0d0e-425e-8899-2cb8a8bb3eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-419367f6-79d0-4e6d-a15a-1750ffbe72f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285837005-172.17.0.13-1598497810715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-53fc4471-21a8-4975-877e-13289450d083,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6e2b3873-bcf2-46ac-b746-f70facc96237,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-4e3fff47-4b38-4a4a-bbc4-45a42d63b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-1273921d-c63e-4054-aae7-5916765c5761,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-d9fcd3a2-a181-4385-b9c4-84d573a947cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-88f54621-7b39-4cf2-afc5-30d9e91fbbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-d720f90d-0d0e-425e-8899-2cb8a8bb3eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-419367f6-79d0-4e6d-a15a-1750ffbe72f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841265806-172.17.0.13-1598497956224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-6f420307-5e00-4083-8636-35941c664b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-a8c6af05-45ec-434f-b27a-f3eb271fe9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-e70cb054-ee14-4a83-94f1-519ea34d6871,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-03ac4687-7b23-431f-942a-5bb38cce0164,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-556879f8-c695-4a20-8abf-9eb6c53206b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-ee1e13de-df13-467c-953e-6c73ab1edd84,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-40319868-8603-4c3f-b3f7-af8e58f1f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-4ae156e8-0e1b-436f-b9de-bcc6a85ecf05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841265806-172.17.0.13-1598497956224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-6f420307-5e00-4083-8636-35941c664b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-a8c6af05-45ec-434f-b27a-f3eb271fe9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-e70cb054-ee14-4a83-94f1-519ea34d6871,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-03ac4687-7b23-431f-942a-5bb38cce0164,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-556879f8-c695-4a20-8abf-9eb6c53206b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-ee1e13de-df13-467c-953e-6c73ab1edd84,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-40319868-8603-4c3f-b3f7-af8e58f1f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-4ae156e8-0e1b-436f-b9de-bcc6a85ecf05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843118723-172.17.0.13-1598498619106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-8f3a2c72-0ba4-4331-bc27-cc5053533f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-68c0aceb-13b7-40ef-8659-303bef437ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-bf0aef9c-8c86-4072-8a96-387f42d4ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-143558ce-9ff1-4949-9297-0810b0e06bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-936b69d8-972d-4867-9dab-0274f965bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-b1a830a2-edb4-43b4-ac05-f93ae736d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-b222865a-bd04-4d58-84c7-1f4294bc6bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-0c197a1b-2cd7-46bb-b227-b5f4ffbf71a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843118723-172.17.0.13-1598498619106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-8f3a2c72-0ba4-4331-bc27-cc5053533f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-68c0aceb-13b7-40ef-8659-303bef437ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-bf0aef9c-8c86-4072-8a96-387f42d4ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-143558ce-9ff1-4949-9297-0810b0e06bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-936b69d8-972d-4867-9dab-0274f965bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-b1a830a2-edb4-43b4-ac05-f93ae736d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-b222865a-bd04-4d58-84c7-1f4294bc6bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-0c197a1b-2cd7-46bb-b227-b5f4ffbf71a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505080887-172.17.0.13-1598498867188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-599c1e77-1106-4e15-ac26-5945b6f0884a,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-09e95108-11e3-4a6c-8baa-c0fe662f4845,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-b5914266-b237-4928-9a8d-63e6d01e9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-0960a410-7e34-4d60-a51e-62230cbb2c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-7b472a61-6cb4-41de-826a-869f85edd00b,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-34346027-c5f8-45f7-9fcc-1e4fff7e6588,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-52af990f-96cb-40cc-b065-7e4bd3d2d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-9b03fd3c-8fb1-4eab-81e1-cba3bc537ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505080887-172.17.0.13-1598498867188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-599c1e77-1106-4e15-ac26-5945b6f0884a,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-09e95108-11e3-4a6c-8baa-c0fe662f4845,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-b5914266-b237-4928-9a8d-63e6d01e9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-0960a410-7e34-4d60-a51e-62230cbb2c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-7b472a61-6cb4-41de-826a-869f85edd00b,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-34346027-c5f8-45f7-9fcc-1e4fff7e6588,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-52af990f-96cb-40cc-b065-7e4bd3d2d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-9b03fd3c-8fb1-4eab-81e1-cba3bc537ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258223203-172.17.0.13-1598498901670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-9ffb514b-31bb-49d3-9c86-afe941a0ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b9c2b158-3807-47b1-b780-5b5f7f47e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-be604889-fb3b-4889-9193-6d7cec677be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-ea0eb72d-57b6-44d8-b9cc-c54f73f1e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-6358c5fd-8de7-42ab-9537-b4148d48b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-04e17e24-b367-4a35-a110-3d7ad2328850,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-9b220801-b2c5-43ff-8b27-8bdbbaeb8e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-eedc2e5a-7966-4591-aa28-64c2551b7f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258223203-172.17.0.13-1598498901670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-9ffb514b-31bb-49d3-9c86-afe941a0ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b9c2b158-3807-47b1-b780-5b5f7f47e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-be604889-fb3b-4889-9193-6d7cec677be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-ea0eb72d-57b6-44d8-b9cc-c54f73f1e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-6358c5fd-8de7-42ab-9537-b4148d48b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-04e17e24-b367-4a35-a110-3d7ad2328850,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-9b220801-b2c5-43ff-8b27-8bdbbaeb8e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-eedc2e5a-7966-4591-aa28-64c2551b7f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553426275-172.17.0.13-1598498972914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-d27be472-dcb9-424b-93cb-aac908bd496c,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9d5a60ae-180b-4e33-879e-76980ce3b886,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-2d01ce52-a47b-42c3-8468-4e812cd21f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-812c38c1-9945-4465-bab9-8234d9276934,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-f4d8915e-4979-4457-b729-86effd009541,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2e07b987-9dcd-410a-be94-a10ca92427f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-24b6a712-6195-430b-9ba4-210750400d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-95281868-55a2-419a-b6b5-55197f93a993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553426275-172.17.0.13-1598498972914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-d27be472-dcb9-424b-93cb-aac908bd496c,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9d5a60ae-180b-4e33-879e-76980ce3b886,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-2d01ce52-a47b-42c3-8468-4e812cd21f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-812c38c1-9945-4465-bab9-8234d9276934,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-f4d8915e-4979-4457-b729-86effd009541,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2e07b987-9dcd-410a-be94-a10ca92427f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-24b6a712-6195-430b-9ba4-210750400d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-95281868-55a2-419a-b6b5-55197f93a993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963505505-172.17.0.13-1598499004946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41280,DS-8de734a0-9a69-43f8-94d3-dcc1bdc31278,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9d2ee912-2df0-4cd7-8ef4-86b6e218742a,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-5b329a39-508d-4b10-b702-c2cd47610d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-8b8f1ca7-7a72-4c78-ae5c-590f9fb4b1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-8d1cb181-d223-470a-99f5-0d697d88b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-4c84c9c0-8143-474e-8041-64fb39cfc44a,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-14eabf61-3110-4985-9ff5-c2b577d4a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-4baa3a91-6192-40aa-83eb-2b4ea57f445c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963505505-172.17.0.13-1598499004946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41280,DS-8de734a0-9a69-43f8-94d3-dcc1bdc31278,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9d2ee912-2df0-4cd7-8ef4-86b6e218742a,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-5b329a39-508d-4b10-b702-c2cd47610d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-8b8f1ca7-7a72-4c78-ae5c-590f9fb4b1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-8d1cb181-d223-470a-99f5-0d697d88b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-4c84c9c0-8143-474e-8041-64fb39cfc44a,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-14eabf61-3110-4985-9ff5-c2b577d4a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-4baa3a91-6192-40aa-83eb-2b4ea57f445c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572804101-172.17.0.13-1598499037401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36515,DS-a8b9e279-4b12-4441-8be0-26ff80d69e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-d6660a45-c51e-4f75-b75c-48f1f77516cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-87d95da8-0c84-47b9-9a9f-c39c210d5fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e32695ca-1dfe-41b0-91d3-5df51519d162,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-4b35eb82-bb40-4236-8b14-61556e918ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-eb9fd833-de76-4e65-b4e4-7643ac37ae83,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-87f19c97-d295-4827-a1da-6ef2c6ad87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-b465a5d5-531a-416e-963c-8189adb042e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572804101-172.17.0.13-1598499037401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36515,DS-a8b9e279-4b12-4441-8be0-26ff80d69e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-d6660a45-c51e-4f75-b75c-48f1f77516cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-87d95da8-0c84-47b9-9a9f-c39c210d5fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e32695ca-1dfe-41b0-91d3-5df51519d162,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-4b35eb82-bb40-4236-8b14-61556e918ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-eb9fd833-de76-4e65-b4e4-7643ac37ae83,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-87f19c97-d295-4827-a1da-6ef2c6ad87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-b465a5d5-531a-416e-963c-8189adb042e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449972132-172.17.0.13-1598499076383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-79dc088c-754c-43c3-be23-597eb5531676,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-0b87e482-5a4d-4a09-a075-5595e564293b,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-2f961f98-2772-4ed7-b2c0-6119c0829e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c6623085-4de8-4265-a389-749d9598e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-75751412-9ca4-46c3-b602-a391d97edc56,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-a28a1705-8a63-4cdf-8341-8228541b7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-18dd3463-85ac-4742-9af2-1b304cddcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-37f06afa-330f-4f32-8d5a-1d85359be084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449972132-172.17.0.13-1598499076383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-79dc088c-754c-43c3-be23-597eb5531676,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-0b87e482-5a4d-4a09-a075-5595e564293b,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-2f961f98-2772-4ed7-b2c0-6119c0829e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-c6623085-4de8-4265-a389-749d9598e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-75751412-9ca4-46c3-b602-a391d97edc56,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-a28a1705-8a63-4cdf-8341-8228541b7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-18dd3463-85ac-4742-9af2-1b304cddcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-37f06afa-330f-4f32-8d5a-1d85359be084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320831819-172.17.0.13-1598499361886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-773fa865-1fd1-459d-8099-d5124e48a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-89c242e0-1552-4857-9e3f-9369d8af0b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-9e4e8958-416b-4430-9d53-14c24bedaa85,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-6dee58db-ad53-49ed-8e45-30bfebd18e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-0e70e546-533c-4e89-a292-d66198e875eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-b76682a3-627c-4917-91df-06584cc3c092,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-aba5d332-6a87-49c7-a081-9586d6912285,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-5877dd05-563c-484c-94f9-56d7f98febaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320831819-172.17.0.13-1598499361886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-773fa865-1fd1-459d-8099-d5124e48a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-89c242e0-1552-4857-9e3f-9369d8af0b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-9e4e8958-416b-4430-9d53-14c24bedaa85,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-6dee58db-ad53-49ed-8e45-30bfebd18e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-0e70e546-533c-4e89-a292-d66198e875eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-b76682a3-627c-4917-91df-06584cc3c092,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-aba5d332-6a87-49c7-a081-9586d6912285,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-5877dd05-563c-484c-94f9-56d7f98febaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-component-length
component: hdfs:NameNode
v1: 511
v2: 255
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703427263-172.17.0.13-1598499916614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-36d6307f-a17c-400b-8753-9a3a15c8ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-a2058e8f-f9bf-4fb0-9797-5ff2751379bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-709d3ddb-899f-4181-9276-b22cfdeba8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-59cfacd5-eb74-4578-9602-8ba71ccf7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-f38df850-4533-4ae3-8e80-b0819b526817,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-8e8d06b8-97bf-4b64-89d2-e648939f26f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-f2828129-bdb4-4c2d-99ae-a9ca5084af70,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-645f4e57-dd25-4e8c-b36d-5b72ff4b841e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703427263-172.17.0.13-1598499916614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-36d6307f-a17c-400b-8753-9a3a15c8ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-a2058e8f-f9bf-4fb0-9797-5ff2751379bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-709d3ddb-899f-4181-9276-b22cfdeba8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-59cfacd5-eb74-4578-9602-8ba71ccf7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-f38df850-4533-4ae3-8e80-b0819b526817,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-8e8d06b8-97bf-4b64-89d2-e648939f26f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-f2828129-bdb4-4c2d-99ae-a9ca5084af70,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-645f4e57-dd25-4e8c-b36d-5b72ff4b841e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5363
