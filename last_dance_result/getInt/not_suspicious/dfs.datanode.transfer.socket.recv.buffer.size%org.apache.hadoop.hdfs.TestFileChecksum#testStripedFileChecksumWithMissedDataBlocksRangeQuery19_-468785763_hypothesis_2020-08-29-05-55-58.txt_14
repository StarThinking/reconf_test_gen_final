reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335720065-172.17.0.19-1598680604158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-55a34b7d-400e-4477-a4f6-b7cdf5007471,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-774bdeb4-7b9e-40f8-b48d-1f8e2aa17c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-6e078c9f-72f1-4438-8a45-bdb32b24bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-29ea6f87-b358-4f7a-a3a4-4c1bffe8eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-7dd9d874-1fa6-4eba-b593-a7fc8dab7222,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-14483dcd-b191-4d45-ba9c-3ae2b02c23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-eb76b2f7-3537-4cd4-afc5-2d9d04472fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-158667a2-fbf0-4a6d-8b3c-1c07b178a95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335720065-172.17.0.19-1598680604158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-55a34b7d-400e-4477-a4f6-b7cdf5007471,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-774bdeb4-7b9e-40f8-b48d-1f8e2aa17c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-6e078c9f-72f1-4438-8a45-bdb32b24bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-29ea6f87-b358-4f7a-a3a4-4c1bffe8eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-7dd9d874-1fa6-4eba-b593-a7fc8dab7222,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-14483dcd-b191-4d45-ba9c-3ae2b02c23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-eb76b2f7-3537-4cd4-afc5-2d9d04472fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-158667a2-fbf0-4a6d-8b3c-1c07b178a95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751129409-172.17.0.19-1598680729014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-a7eb80f1-cd42-4bc2-a331-164a1e551de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-c9e18948-bf29-4c91-bc86-6457d0d6a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-4423927d-17af-4c3f-b24d-640e0b348e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-431d53f6-15ef-418f-af54-9777ab992754,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1c35c1ed-c4e6-4d59-9df5-229978cc3c25,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-51ab1486-f4da-45f4-8844-35aacdaf32c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-861126bb-2514-497e-a37d-92d511278c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-67b33c48-46d3-4e01-82aa-1d9c5baa1985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751129409-172.17.0.19-1598680729014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-a7eb80f1-cd42-4bc2-a331-164a1e551de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-c9e18948-bf29-4c91-bc86-6457d0d6a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-4423927d-17af-4c3f-b24d-640e0b348e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-431d53f6-15ef-418f-af54-9777ab992754,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1c35c1ed-c4e6-4d59-9df5-229978cc3c25,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-51ab1486-f4da-45f4-8844-35aacdaf32c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-861126bb-2514-497e-a37d-92d511278c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-67b33c48-46d3-4e01-82aa-1d9c5baa1985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022755435-172.17.0.19-1598680795749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-32abb2da-5979-444a-83f9-c98dd57831c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-896e25b4-ca0a-415d-a9df-61fa77e3363d,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-8460e88d-bca1-4cd6-a419-ac7678b60e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-9a7abdc8-4fcf-4ceb-bb1c-692c00ad8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-04946a0d-e5e4-4260-ac46-1b1ffd8d32b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-ff8e1de5-d22e-4b14-8ec9-f8c5f8a6b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b272b8f3-6e73-457a-89db-12e07b05716d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-2b02e5ba-7040-4de0-af04-f7834404245b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022755435-172.17.0.19-1598680795749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-32abb2da-5979-444a-83f9-c98dd57831c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-896e25b4-ca0a-415d-a9df-61fa77e3363d,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-8460e88d-bca1-4cd6-a419-ac7678b60e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-9a7abdc8-4fcf-4ceb-bb1c-692c00ad8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-04946a0d-e5e4-4260-ac46-1b1ffd8d32b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-ff8e1de5-d22e-4b14-8ec9-f8c5f8a6b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b272b8f3-6e73-457a-89db-12e07b05716d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-2b02e5ba-7040-4de0-af04-f7834404245b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785010618-172.17.0.19-1598681395673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-13b5d4e4-d876-41c5-bbe6-88b04a2fd9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9ba1fc16-43e5-4951-bc11-f5fdbf5d886d,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-1317a1dd-c8ad-4108-b93b-f34238524547,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-a0773728-f50c-4c78-80c2-8e6ee3fedb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-ab8c16a6-8386-4d67-b50d-537bd71647ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8d73155a-2918-4fa1-9dec-7d7914e1fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-71f9ccf9-550f-4f26-b508-2e23c32fb3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-2a0b38fc-9353-4c9a-9f57-f3950099e849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785010618-172.17.0.19-1598681395673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-13b5d4e4-d876-41c5-bbe6-88b04a2fd9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9ba1fc16-43e5-4951-bc11-f5fdbf5d886d,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-1317a1dd-c8ad-4108-b93b-f34238524547,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-a0773728-f50c-4c78-80c2-8e6ee3fedb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-ab8c16a6-8386-4d67-b50d-537bd71647ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8d73155a-2918-4fa1-9dec-7d7914e1fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-71f9ccf9-550f-4f26-b508-2e23c32fb3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-2a0b38fc-9353-4c9a-9f57-f3950099e849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995558788-172.17.0.19-1598681747111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-b3bafdc6-871e-4c54-ac79-0f31c5b14bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-dedea393-ea7a-43f0-8cf7-3c3810a09582,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-d0a17521-1830-4b7f-bdd0-b817f83d1311,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-57d93a18-96c7-46d0-942b-b5206ca8f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-77564c4f-8469-42f0-af34-041b7595aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-977a4747-d462-497e-8a29-3dc555c3fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-b7a11468-a1ad-4f82-84c3-8117b5a0860c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-730b8f9e-52df-4331-b698-458625f17db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995558788-172.17.0.19-1598681747111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-b3bafdc6-871e-4c54-ac79-0f31c5b14bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-dedea393-ea7a-43f0-8cf7-3c3810a09582,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-d0a17521-1830-4b7f-bdd0-b817f83d1311,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-57d93a18-96c7-46d0-942b-b5206ca8f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-77564c4f-8469-42f0-af34-041b7595aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-977a4747-d462-497e-8a29-3dc555c3fd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-b7a11468-a1ad-4f82-84c3-8117b5a0860c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-730b8f9e-52df-4331-b698-458625f17db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053291756-172.17.0.19-1598682109070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-2d7c31aa-39e4-4c1f-8880-efaf03993d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-44f22f9e-b68e-4ca0-b8f5-1a516f2477a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-70976be8-1159-4aea-af0d-f9c35ed7d79d,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-52f5ba0a-ec01-4310-b71a-079c9f25981d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-246a79ee-8eb7-4d73-88da-e4b2a556a4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a51d29b4-d9da-4495-93d3-da81b432b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-41dfb2ee-a3e8-4821-a721-775eb6d36a40,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-5f43ba8a-fa53-43bd-a398-87c66473d7fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053291756-172.17.0.19-1598682109070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-2d7c31aa-39e4-4c1f-8880-efaf03993d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-44f22f9e-b68e-4ca0-b8f5-1a516f2477a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-70976be8-1159-4aea-af0d-f9c35ed7d79d,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-52f5ba0a-ec01-4310-b71a-079c9f25981d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-246a79ee-8eb7-4d73-88da-e4b2a556a4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a51d29b4-d9da-4495-93d3-da81b432b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-41dfb2ee-a3e8-4821-a721-775eb6d36a40,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-5f43ba8a-fa53-43bd-a398-87c66473d7fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097577859-172.17.0.19-1598682270558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-345e04be-873d-424d-abcc-b9d6556c639a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-22551b70-a915-4e88-9b16-50d46eafed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-48d02f2f-6311-4b13-b5ad-09bcdb11bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-99ab7560-d1d4-4f8a-a649-70af2f9b646b,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-04e4df79-de18-4ad3-971a-c3aeb084cdba,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d798c420-3f6b-4c6a-b6da-0a2a59776d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-217b6eb8-1201-4a64-a882-7ac7b37d3180,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-d8322b51-34c0-4cf3-9d6f-ec4f2bc322d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097577859-172.17.0.19-1598682270558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-345e04be-873d-424d-abcc-b9d6556c639a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-22551b70-a915-4e88-9b16-50d46eafed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-48d02f2f-6311-4b13-b5ad-09bcdb11bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-99ab7560-d1d4-4f8a-a649-70af2f9b646b,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-04e4df79-de18-4ad3-971a-c3aeb084cdba,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d798c420-3f6b-4c6a-b6da-0a2a59776d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-217b6eb8-1201-4a64-a882-7ac7b37d3180,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-d8322b51-34c0-4cf3-9d6f-ec4f2bc322d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176862420-172.17.0.19-1598682449482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-54cc55e1-aa5b-4c61-899c-a28186828097,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-7d6dc92e-ad7c-4191-a817-bb43c36c119d,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-5976f6c3-d68a-43b0-a6ea-1b6b180cc283,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-c9431e85-2f7a-4b0b-a33f-310aba16ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-0aaf430d-9743-4325-8ab0-b2bab2611635,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-9bbbba6e-fb46-47cd-97a6-6c42b7a75275,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-3bcdde91-41ea-416b-8ce5-ef50f959fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-03269e22-c89f-4b33-9853-9fd8d87a1f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176862420-172.17.0.19-1598682449482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-54cc55e1-aa5b-4c61-899c-a28186828097,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-7d6dc92e-ad7c-4191-a817-bb43c36c119d,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-5976f6c3-d68a-43b0-a6ea-1b6b180cc283,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-c9431e85-2f7a-4b0b-a33f-310aba16ec4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-0aaf430d-9743-4325-8ab0-b2bab2611635,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-9bbbba6e-fb46-47cd-97a6-6c42b7a75275,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-3bcdde91-41ea-416b-8ce5-ef50f959fbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-03269e22-c89f-4b33-9853-9fd8d87a1f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512840863-172.17.0.19-1598682551087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-7f5e4665-28ce-4e1f-b93b-4fafb2607bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-1e4cce5f-9b85-411b-941c-7a39a70604c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-93f94e25-cb70-4c00-886d-6854682f356d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-ec413ce0-b915-42b3-8f1c-741ddb293f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-fa7f0ada-a7dc-47d9-bdb9-5c36763489c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-0b86738e-8e30-4016-9bdb-ecbdf360049d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-95ce1f2f-385d-47b3-a892-fe161b363c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-e7bf60a0-63c1-4aa1-adc8-690e181f7e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512840863-172.17.0.19-1598682551087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-7f5e4665-28ce-4e1f-b93b-4fafb2607bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-1e4cce5f-9b85-411b-941c-7a39a70604c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-93f94e25-cb70-4c00-886d-6854682f356d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-ec413ce0-b915-42b3-8f1c-741ddb293f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-fa7f0ada-a7dc-47d9-bdb9-5c36763489c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-0b86738e-8e30-4016-9bdb-ecbdf360049d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-95ce1f2f-385d-47b3-a892-fe161b363c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-e7bf60a0-63c1-4aa1-adc8-690e181f7e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999595166-172.17.0.19-1598682683945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-47a8241b-cea0-43cd-bb5c-bf0510be7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-e6316187-d147-4400-997f-ead22878c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-e1362e90-0cc1-4fd3-beb1-9bd771fbeac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-3374bb58-ee25-4d33-9466-95fb70434073,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-54eb2fae-3202-4c5a-bce4-00e71c817760,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-6cef7742-39f4-4b38-a0b6-93d572ec9259,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-52a59df0-66e8-4b7c-961f-ad7aabe44e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-62e4f83a-c1ed-4607-bcaa-a4187c502d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999595166-172.17.0.19-1598682683945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-47a8241b-cea0-43cd-bb5c-bf0510be7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-e6316187-d147-4400-997f-ead22878c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-e1362e90-0cc1-4fd3-beb1-9bd771fbeac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-3374bb58-ee25-4d33-9466-95fb70434073,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-54eb2fae-3202-4c5a-bce4-00e71c817760,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-6cef7742-39f4-4b38-a0b6-93d572ec9259,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-52a59df0-66e8-4b7c-961f-ad7aabe44e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-62e4f83a-c1ed-4607-bcaa-a4187c502d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492851256-172.17.0.19-1598682922494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-c6bbccb8-9bd0-4214-ae96-3d9e46b31f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-abd615f5-4227-4067-9aa0-1021aa37e998,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-a6b89249-3b34-41d5-b4b5-05e2ea140af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-cc0ed08b-7d3f-4e6a-a062-90934c85c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-e5278e2d-0ad1-4a45-8350-0e8656270394,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-00c00b61-ad6d-4a67-8a51-885265ec1101,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-1ab52fd5-f798-449c-8d4a-aa43c54d508d,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3ea6f2e3-ff8f-4eaa-9f8a-dccd3d769688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492851256-172.17.0.19-1598682922494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-c6bbccb8-9bd0-4214-ae96-3d9e46b31f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-abd615f5-4227-4067-9aa0-1021aa37e998,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-a6b89249-3b34-41d5-b4b5-05e2ea140af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-cc0ed08b-7d3f-4e6a-a062-90934c85c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-e5278e2d-0ad1-4a45-8350-0e8656270394,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-00c00b61-ad6d-4a67-8a51-885265ec1101,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-1ab52fd5-f798-449c-8d4a-aa43c54d508d,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3ea6f2e3-ff8f-4eaa-9f8a-dccd3d769688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748337826-172.17.0.19-1598683158223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-db5dfbc6-68ad-4d11-b6ab-72e9698772cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-b8b09234-b8fc-4a9f-ba25-eb99b33c59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a4a3f6fe-0216-40ce-800e-64025937fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-05268e1f-5956-49e6-9ce8-bc80fbacdfad,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-4b5913ba-bf3f-4398-aa73-81e6fec2926a,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-14830aa8-1617-46dc-b1c1-3cb974a90ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-692d6ec3-933b-4489-b205-bb4e2059e408,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-24d17902-a1f1-4245-9210-5903effbbacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748337826-172.17.0.19-1598683158223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-db5dfbc6-68ad-4d11-b6ab-72e9698772cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-b8b09234-b8fc-4a9f-ba25-eb99b33c59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a4a3f6fe-0216-40ce-800e-64025937fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-05268e1f-5956-49e6-9ce8-bc80fbacdfad,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-4b5913ba-bf3f-4398-aa73-81e6fec2926a,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-14830aa8-1617-46dc-b1c1-3cb974a90ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-692d6ec3-933b-4489-b205-bb4e2059e408,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-24d17902-a1f1-4245-9210-5903effbbacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018254327-172.17.0.19-1598683763829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-30fcf396-969e-42b2-9ad3-bfb41d56126e,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-87eb080c-b15c-4107-9f0b-a1807d842eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-f721da94-cba3-4d39-ae49-9bbd50f1a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-cec300cf-24c5-4b98-88e5-3aa61ee8cc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-aeba4d68-4ee2-4ea1-b08a-b63a069f8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-0cb9e3ff-e401-406c-9d2e-f7cfd367b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-d5e6fa23-e353-44c5-b4db-3d98ed0e7b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-dca081ff-b9bc-4279-bae0-d9374bd204f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018254327-172.17.0.19-1598683763829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-30fcf396-969e-42b2-9ad3-bfb41d56126e,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-87eb080c-b15c-4107-9f0b-a1807d842eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-f721da94-cba3-4d39-ae49-9bbd50f1a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-cec300cf-24c5-4b98-88e5-3aa61ee8cc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-aeba4d68-4ee2-4ea1-b08a-b63a069f8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-0cb9e3ff-e401-406c-9d2e-f7cfd367b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-d5e6fa23-e353-44c5-b4db-3d98ed0e7b09,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-dca081ff-b9bc-4279-bae0-d9374bd204f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707861170-172.17.0.19-1598683984984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-520b3dba-7ca1-45f7-ae0e-28f26d4b633c,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2248e0b1-57a0-433e-9bd0-082fb0691068,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-7110e864-4375-48b5-9264-4e0090b142fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-e310f346-d7f4-4f88-86d4-59c8bba1bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-2d3be245-ea04-4dfe-8958-63da064e95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-aa9557f7-bbc4-48f7-abff-a17fc1ea5e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-e9c1e2a1-94e4-45e1-b42a-53592694901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-629d43ce-6256-4618-8e0a-934929f40a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707861170-172.17.0.19-1598683984984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-520b3dba-7ca1-45f7-ae0e-28f26d4b633c,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2248e0b1-57a0-433e-9bd0-082fb0691068,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-7110e864-4375-48b5-9264-4e0090b142fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-e310f346-d7f4-4f88-86d4-59c8bba1bac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-2d3be245-ea04-4dfe-8958-63da064e95d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-aa9557f7-bbc4-48f7-abff-a17fc1ea5e54,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-e9c1e2a1-94e4-45e1-b42a-53592694901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-629d43ce-6256-4618-8e0a-934929f40a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853866163-172.17.0.19-1598684316469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-051b9803-ec08-4cbc-8cb1-6508a008f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-357fcf45-018c-46e8-9db5-658bbc3e3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-9111c18c-0f5f-4fe4-95a1-619ee1e3ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fc9acdb8-6d3a-4735-bfc5-41e7ab277b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-7c3a096c-8420-4d67-8d5d-7bb8df45b4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-1e580766-5569-4cdc-bf06-0f3a07379f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-21ab29ec-8db5-4a4a-9622-debea6a8cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-4d11382d-27e9-4f12-b6ef-510e5144fe00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853866163-172.17.0.19-1598684316469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39577,DS-051b9803-ec08-4cbc-8cb1-6508a008f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-357fcf45-018c-46e8-9db5-658bbc3e3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-9111c18c-0f5f-4fe4-95a1-619ee1e3ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fc9acdb8-6d3a-4735-bfc5-41e7ab277b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-7c3a096c-8420-4d67-8d5d-7bb8df45b4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-1e580766-5569-4cdc-bf06-0f3a07379f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-21ab29ec-8db5-4a4a-9622-debea6a8cea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-4d11382d-27e9-4f12-b6ef-510e5144fe00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763388340-172.17.0.19-1598684863346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41346,DS-c3a38ab5-cc81-480b-a0f4-e80edd5af3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-a5e91649-6c58-4f7a-b209-1e77c0d48a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-8410114a-3dc8-467a-9738-44e801b7ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-cc0e2adb-134f-4c5a-ac60-fd821ee93bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-46efec6a-6228-4bbc-964d-34228c3d993f,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-302350c0-d0f2-428f-81e4-c0a02bf182dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-8cd282d8-97c8-4b0c-972f-b5c780d41d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-fb911732-eb46-4aee-8fa3-afc38f5add64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763388340-172.17.0.19-1598684863346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41346,DS-c3a38ab5-cc81-480b-a0f4-e80edd5af3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-a5e91649-6c58-4f7a-b209-1e77c0d48a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-8410114a-3dc8-467a-9738-44e801b7ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-cc0e2adb-134f-4c5a-ac60-fd821ee93bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-46efec6a-6228-4bbc-964d-34228c3d993f,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-302350c0-d0f2-428f-81e4-c0a02bf182dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-8cd282d8-97c8-4b0c-972f-b5c780d41d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-fb911732-eb46-4aee-8fa3-afc38f5add64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123939180-172.17.0.19-1598684891598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-16ebd72c-a6bc-4cf1-a2a0-d1b00045ed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0ce67e2a-9c68-4e70-9cb9-63fc01d246ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-c768c5bf-1f6b-4827-82f7-9ee0ac087685,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-1aa8d711-d5e0-410a-9689-8595f97c8f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1983e6f8-c47a-40a9-ad9d-c0c9e2f085e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-950f9949-366f-40cb-b3eb-7ee806a52af8,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-244d2991-981d-467c-8853-8fb5e8a1ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-7a820e4d-22a3-4539-8cb9-9893de73ba99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123939180-172.17.0.19-1598684891598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41755,DS-16ebd72c-a6bc-4cf1-a2a0-d1b00045ed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0ce67e2a-9c68-4e70-9cb9-63fc01d246ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-c768c5bf-1f6b-4827-82f7-9ee0ac087685,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-1aa8d711-d5e0-410a-9689-8595f97c8f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1983e6f8-c47a-40a9-ad9d-c0c9e2f085e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-950f9949-366f-40cb-b3eb-7ee806a52af8,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-244d2991-981d-467c-8853-8fb5e8a1ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-7a820e4d-22a3-4539-8cb9-9893de73ba99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081504549-172.17.0.19-1598685003487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-a159d830-e930-4c02-a215-bca3685ac594,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-dee935d0-fab4-4ba3-b685-1eac5c0d326a,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-38b447f7-814e-495c-9da8-32485a90896b,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-75d12348-eb90-45b6-be86-35b770d648d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-d45f9a38-8c1c-40a8-a705-93b38b75dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-5b44bbbb-bdd9-46ee-b4eb-bedf1ffe0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-f3555f25-0db3-464d-8a51-251056d96759,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-4d13794f-abf4-4891-9694-84a513bdbe9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081504549-172.17.0.19-1598685003487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-a159d830-e930-4c02-a215-bca3685ac594,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-dee935d0-fab4-4ba3-b685-1eac5c0d326a,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-38b447f7-814e-495c-9da8-32485a90896b,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-75d12348-eb90-45b6-be86-35b770d648d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-d45f9a38-8c1c-40a8-a705-93b38b75dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-5b44bbbb-bdd9-46ee-b4eb-bedf1ffe0edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-f3555f25-0db3-464d-8a51-251056d96759,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-4d13794f-abf4-4891-9694-84a513bdbe9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5055
