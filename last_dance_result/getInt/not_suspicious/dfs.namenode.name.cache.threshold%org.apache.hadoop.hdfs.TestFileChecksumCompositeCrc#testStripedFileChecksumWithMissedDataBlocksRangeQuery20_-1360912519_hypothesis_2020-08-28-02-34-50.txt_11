reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777894826-172.17.0.13-1598582446038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33261,DS-a25e536a-8def-4f70-9edd-f7b760ff4253,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-856b94e3-b6c1-4d41-abef-d14b2b41ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-cd7af436-472c-4a25-abc2-20e744f8dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-25a77452-0f65-4748-a9c8-416bc98ba196,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-0e52d7ca-782b-4dd2-bdd6-815cda2ef6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3cdca475-db10-4582-a721-5e48a9cbce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f47303cc-6cac-4a71-9769-83e3fb0e242c,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-65828925-5fb2-4522-8e02-7ed243d6aec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777894826-172.17.0.13-1598582446038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33261,DS-a25e536a-8def-4f70-9edd-f7b760ff4253,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-856b94e3-b6c1-4d41-abef-d14b2b41ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-cd7af436-472c-4a25-abc2-20e744f8dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-25a77452-0f65-4748-a9c8-416bc98ba196,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-0e52d7ca-782b-4dd2-bdd6-815cda2ef6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3cdca475-db10-4582-a721-5e48a9cbce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f47303cc-6cac-4a71-9769-83e3fb0e242c,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-65828925-5fb2-4522-8e02-7ed243d6aec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825115942-172.17.0.13-1598583046667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-80ad150a-e55d-48ed-a991-5c5d74715b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e8fc0560-dc0a-4fdd-819c-3c4c0a4c1174,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-72b12528-0c56-4d26-b51a-487eefeeef96,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a79d0124-59c1-4fe0-874e-28e25b1971c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a4283345-73e7-40c7-80f0-a238a5012d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-41fca85a-6e1a-4351-b0a3-52a6aaf95425,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-e2ba2bce-d308-47d0-9ec4-4e50522b1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-78f778ca-1ad7-43da-94a1-b0a78b619d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825115942-172.17.0.13-1598583046667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40538,DS-80ad150a-e55d-48ed-a991-5c5d74715b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-e8fc0560-dc0a-4fdd-819c-3c4c0a4c1174,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-72b12528-0c56-4d26-b51a-487eefeeef96,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a79d0124-59c1-4fe0-874e-28e25b1971c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a4283345-73e7-40c7-80f0-a238a5012d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-41fca85a-6e1a-4351-b0a3-52a6aaf95425,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-e2ba2bce-d308-47d0-9ec4-4e50522b1a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-78f778ca-1ad7-43da-94a1-b0a78b619d36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52312498-172.17.0.13-1598583076378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-3d640af3-0fdf-4cef-a014-9a071461a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-062ca3a3-483d-49b0-8fc2-36d28132301a,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-1a0ca9b5-a432-4b7f-9d6c-e57e3d31569e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-ceb601be-d69c-4110-a808-207098dbdba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-18d8b04e-f7bd-490c-abb8-7d7a4cf1eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b0c55224-c4a1-4df6-b35f-f812b040ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-accdae98-107b-4af8-90b1-d7d7623cff35,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-a9de54b3-ff57-4e3b-8578-c83469d6e029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52312498-172.17.0.13-1598583076378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-3d640af3-0fdf-4cef-a014-9a071461a04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-062ca3a3-483d-49b0-8fc2-36d28132301a,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-1a0ca9b5-a432-4b7f-9d6c-e57e3d31569e,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-ceb601be-d69c-4110-a808-207098dbdba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-18d8b04e-f7bd-490c-abb8-7d7a4cf1eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-b0c55224-c4a1-4df6-b35f-f812b040ae34,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-accdae98-107b-4af8-90b1-d7d7623cff35,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-a9de54b3-ff57-4e3b-8578-c83469d6e029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831160338-172.17.0.13-1598583115091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-6b5064c9-6676-40a2-8b60-a2766d3a41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-39dc2aa9-c951-4d15-8279-582df02a759c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-fb7a2b0f-fec8-4d9a-96ba-073c3b5bf5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-af6de331-1a12-4228-954a-be583d8ca602,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-b80c7f3f-21ad-445a-b656-001c3eab4b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-1e279b26-282c-4f2e-bbad-8f62e62a11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-b66149b1-2399-4cec-8ac0-feb96327eb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-d6ebf450-b723-4ea8-9645-655a2c124cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831160338-172.17.0.13-1598583115091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-6b5064c9-6676-40a2-8b60-a2766d3a41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-39dc2aa9-c951-4d15-8279-582df02a759c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-fb7a2b0f-fec8-4d9a-96ba-073c3b5bf5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-af6de331-1a12-4228-954a-be583d8ca602,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-b80c7f3f-21ad-445a-b656-001c3eab4b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-1e279b26-282c-4f2e-bbad-8f62e62a11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-b66149b1-2399-4cec-8ac0-feb96327eb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-d6ebf450-b723-4ea8-9645-655a2c124cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031502966-172.17.0.13-1598583169429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-33600a99-b303-46cb-942c-f2dcd0289ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-a66b01d2-2e00-46a3-94bd-a531dba3e553,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-445be7f1-6fb5-4659-bfb4-88446b8741fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-edad2cac-bd09-4adb-a9ee-523fbadeded6,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-fe38cfce-02d5-4aa0-ae8b-272a595a3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-7241a45d-bc38-4fcd-96f7-923e407f0f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-abccf726-9e29-4f79-bdf7-ca502acb7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-f795d19a-01f2-4ea6-9290-5a2e01a679e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031502966-172.17.0.13-1598583169429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-33600a99-b303-46cb-942c-f2dcd0289ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-a66b01d2-2e00-46a3-94bd-a531dba3e553,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-445be7f1-6fb5-4659-bfb4-88446b8741fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-edad2cac-bd09-4adb-a9ee-523fbadeded6,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-fe38cfce-02d5-4aa0-ae8b-272a595a3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-7241a45d-bc38-4fcd-96f7-923e407f0f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-abccf726-9e29-4f79-bdf7-ca502acb7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-f795d19a-01f2-4ea6-9290-5a2e01a679e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33672482-172.17.0.13-1598583403666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-d51d6f69-8a5c-4f26-9661-308c9e40f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-44abf9cf-d71a-49d3-8ace-72df18dab273,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-ae246a1e-55c2-495e-842c-2a688db105b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-07984871-1fd8-413d-beb2-ee52fd994a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-afa2f56f-b8e9-4db3-923f-cf51d94543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-cd36421a-ef00-4039-87df-ea64b7d861ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0f0fc078-3448-473e-89a2-9e6651a89fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-25e67646-f0f0-43f6-bb0e-c8d954923edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33672482-172.17.0.13-1598583403666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-d51d6f69-8a5c-4f26-9661-308c9e40f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-44abf9cf-d71a-49d3-8ace-72df18dab273,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-ae246a1e-55c2-495e-842c-2a688db105b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-07984871-1fd8-413d-beb2-ee52fd994a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-afa2f56f-b8e9-4db3-923f-cf51d94543bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-cd36421a-ef00-4039-87df-ea64b7d861ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0f0fc078-3448-473e-89a2-9e6651a89fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-25e67646-f0f0-43f6-bb0e-c8d954923edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256595179-172.17.0.13-1598584335864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-90f90b33-af57-46a3-ba62-938eae70a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-35557422-e5cb-4fb4-884b-58495f4d70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c3cdcf68-185f-4b77-b545-5817aa95ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-2d71263b-9eeb-4f92-971b-0ba78c356457,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-37bb4904-6487-4fcb-8081-ef1267982f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-a6a4ba33-de5d-4d69-9739-4a51d4f0d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-956a641e-dffd-458b-a6cf-278c770c6c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-17e09d09-72ec-4ea9-af8b-e362093d13d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256595179-172.17.0.13-1598584335864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-90f90b33-af57-46a3-ba62-938eae70a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-35557422-e5cb-4fb4-884b-58495f4d70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c3cdcf68-185f-4b77-b545-5817aa95ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-2d71263b-9eeb-4f92-971b-0ba78c356457,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-37bb4904-6487-4fcb-8081-ef1267982f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-a6a4ba33-de5d-4d69-9739-4a51d4f0d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-956a641e-dffd-458b-a6cf-278c770c6c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-17e09d09-72ec-4ea9-af8b-e362093d13d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913006930-172.17.0.13-1598584695009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-523ae502-9380-467f-a3e7-314425f58e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ec96914f-5975-47a7-8b78-92694830c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-82ea2945-3268-4dea-a0c7-cf0d47b124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-790821e2-6d00-464a-86a5-3764219172f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-7eacc3bc-6422-4446-b60d-9e9dfa538fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-b10ecd43-a20d-495e-a6a9-10e7c602d9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e94c5858-e2fe-4c9c-8dde-9a57c7eeacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-8c50dc98-672b-4290-b0e5-4f9099a9f95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913006930-172.17.0.13-1598584695009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-523ae502-9380-467f-a3e7-314425f58e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ec96914f-5975-47a7-8b78-92694830c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-82ea2945-3268-4dea-a0c7-cf0d47b124f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-790821e2-6d00-464a-86a5-3764219172f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-7eacc3bc-6422-4446-b60d-9e9dfa538fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-b10ecd43-a20d-495e-a6a9-10e7c602d9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e94c5858-e2fe-4c9c-8dde-9a57c7eeacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-8c50dc98-672b-4290-b0e5-4f9099a9f95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907778266-172.17.0.13-1598585268379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44744,DS-24fc4f79-6415-48cf-83b7-fce88ddd15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-ead47fae-e9f5-4d2f-ab61-00b5caca7b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-44bbd663-0519-4343-86a4-282b9b9b4986,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-40678f67-7eb1-4cb4-9f3d-eec4e7b4d782,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-cf9f228a-78a7-4f2a-895f-719f46119ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-0cb2f56c-a208-4b32-ad13-56a958310743,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-b982209a-63b3-4fc7-9dfc-b260f6a3629b,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-c5f203fd-efca-4f42-9a69-e8fb978dd65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907778266-172.17.0.13-1598585268379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44744,DS-24fc4f79-6415-48cf-83b7-fce88ddd15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-ead47fae-e9f5-4d2f-ab61-00b5caca7b25,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-44bbd663-0519-4343-86a4-282b9b9b4986,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-40678f67-7eb1-4cb4-9f3d-eec4e7b4d782,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-cf9f228a-78a7-4f2a-895f-719f46119ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-0cb2f56c-a208-4b32-ad13-56a958310743,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-b982209a-63b3-4fc7-9dfc-b260f6a3629b,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-c5f203fd-efca-4f42-9a69-e8fb978dd65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555547500-172.17.0.13-1598586027745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-b2947c46-de7f-4666-af2d-cfdb7fda6aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-4a8002e0-7427-47a6-9806-3d63fbd5556e,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-f9584f56-086e-45fd-98bd-76fdee3c28ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-89ce4e99-7868-4e88-b932-ddaac62ff7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cc4607b3-897f-42b4-a29f-11160f71b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-fd418f87-0f16-4629-883d-27829033c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-81e0e90b-a0a1-4226-a271-342f1b39f320,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-53075260-62d4-4563-ac2a-b23965c98225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555547500-172.17.0.13-1598586027745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-b2947c46-de7f-4666-af2d-cfdb7fda6aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-4a8002e0-7427-47a6-9806-3d63fbd5556e,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-f9584f56-086e-45fd-98bd-76fdee3c28ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-89ce4e99-7868-4e88-b932-ddaac62ff7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cc4607b3-897f-42b4-a29f-11160f71b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-fd418f87-0f16-4629-883d-27829033c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-81e0e90b-a0a1-4226-a271-342f1b39f320,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-53075260-62d4-4563-ac2a-b23965c98225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975918542-172.17.0.13-1598586352106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-f90fc460-6f3e-40d2-9dd9-1ef24c83b005,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0094bb1a-73ca-442a-8f06-e3e7e0bfba40,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-1acb899e-3ec1-4028-8dd6-cd5d4995ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f57e8a3c-4e47-4ff3-a84d-b868c5beb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-439cb0dd-8ce5-40c2-a12e-d73b588adee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-10bd60c3-e841-42ad-b2fc-70a7317e20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-87fc3f22-3f42-4a29-b377-9af679581a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-4f8d5ed3-0662-423f-a393-766f36796184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975918542-172.17.0.13-1598586352106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-f90fc460-6f3e-40d2-9dd9-1ef24c83b005,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0094bb1a-73ca-442a-8f06-e3e7e0bfba40,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-1acb899e-3ec1-4028-8dd6-cd5d4995ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f57e8a3c-4e47-4ff3-a84d-b868c5beb6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-439cb0dd-8ce5-40c2-a12e-d73b588adee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-10bd60c3-e841-42ad-b2fc-70a7317e20ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-87fc3f22-3f42-4a29-b377-9af679581a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-4f8d5ed3-0662-423f-a393-766f36796184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752401599-172.17.0.13-1598586423832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-dd73f25a-88ef-4087-8872-5c02620724bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-af057cb8-8b2a-45c5-8f34-be85a7b6c983,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-cd52dcc1-0b41-4f17-bb6a-b7afc8d6cdac,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-d895bee7-cecc-4e4a-83b3-a115dbe549ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9a447f72-99bf-478b-b3fd-757124d1fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-83e4de1a-f948-4f78-84f1-82cf575a8bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-c8eeac38-6165-44ee-99f7-0962b945d744,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-090cbed1-e079-4b0f-a353-64367354edf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752401599-172.17.0.13-1598586423832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-dd73f25a-88ef-4087-8872-5c02620724bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-af057cb8-8b2a-45c5-8f34-be85a7b6c983,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-cd52dcc1-0b41-4f17-bb6a-b7afc8d6cdac,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-d895bee7-cecc-4e4a-83b3-a115dbe549ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9a447f72-99bf-478b-b3fd-757124d1fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-83e4de1a-f948-4f78-84f1-82cf575a8bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-c8eeac38-6165-44ee-99f7-0962b945d744,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-090cbed1-e079-4b0f-a353-64367354edf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490141664-172.17.0.13-1598586493639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-a44d6197-b78c-4020-a9ee-e87bd922114b,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-eee5dc75-f69a-4685-b70f-93ec860da1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-b3924863-1476-4fa4-995d-86d8c515e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-e3f8d5a6-e43b-4720-8fc2-da4d6c1f4395,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8a56e373-2ab6-4ac7-9fac-118414d9d122,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-203752d1-c8bc-46b5-a8d8-016d9def7878,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-d2817c17-db5a-458a-92a4-b6221519f317,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-25b04abd-9ee2-4c5d-9732-257bd7d37a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490141664-172.17.0.13-1598586493639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-a44d6197-b78c-4020-a9ee-e87bd922114b,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-eee5dc75-f69a-4685-b70f-93ec860da1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-b3924863-1476-4fa4-995d-86d8c515e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-e3f8d5a6-e43b-4720-8fc2-da4d6c1f4395,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8a56e373-2ab6-4ac7-9fac-118414d9d122,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-203752d1-c8bc-46b5-a8d8-016d9def7878,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-d2817c17-db5a-458a-92a4-b6221519f317,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-25b04abd-9ee2-4c5d-9732-257bd7d37a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887069106-172.17.0.13-1598586530872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-4f6e0ac1-9eb5-4a30-adb4-7b5aabe31d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-2e8ea550-81e7-42a0-aa26-e71f3f2e4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-e8c6e7a3-1a32-4989-bf6e-bc30a5ceec38,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-54f94e8d-b1f1-4618-97d2-5c9148b836af,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-bc607eca-79a6-49f4-8462-144d7a4bd16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-0c01985a-514a-4962-926e-4a77222fb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-b41d210b-7233-4b03-9464-ec01404ee873,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-473cbfeb-3358-41d7-9bfb-583cddde5a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887069106-172.17.0.13-1598586530872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-4f6e0ac1-9eb5-4a30-adb4-7b5aabe31d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-2e8ea550-81e7-42a0-aa26-e71f3f2e4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-e8c6e7a3-1a32-4989-bf6e-bc30a5ceec38,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-54f94e8d-b1f1-4618-97d2-5c9148b836af,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-bc607eca-79a6-49f4-8462-144d7a4bd16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-0c01985a-514a-4962-926e-4a77222fb7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-b41d210b-7233-4b03-9464-ec01404ee873,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-473cbfeb-3358-41d7-9bfb-583cddde5a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504071300-172.17.0.13-1598586602790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-1647f7e9-10c6-4fae-baec-c47e7eea8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-a9d6ed7f-d368-4b53-8868-4a813245898f,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-bb59c1e6-47af-4c04-a2c1-1a3b9535abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-83c99588-e714-40ef-ac8f-2276b51047ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-d223ace5-ff22-444c-9b45-e707a07a70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-e0bd8535-b57a-4533-a59e-70f3b7b4d9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-3a0c39c9-fc6e-4414-aa35-5cff49dc2d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-3faca47a-105d-4c27-bbd5-e1752e06dc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504071300-172.17.0.13-1598586602790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-1647f7e9-10c6-4fae-baec-c47e7eea8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-a9d6ed7f-d368-4b53-8868-4a813245898f,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-bb59c1e6-47af-4c04-a2c1-1a3b9535abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-83c99588-e714-40ef-ac8f-2276b51047ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-d223ace5-ff22-444c-9b45-e707a07a70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-e0bd8535-b57a-4533-a59e-70f3b7b4d9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-3a0c39c9-fc6e-4414-aa35-5cff49dc2d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-3faca47a-105d-4c27-bbd5-e1752e06dc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.cache.threshold
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626892006-172.17.0.13-1598586888388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-9d01c67b-74d2-46b0-a293-8e5e0cce58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-9394dbfe-bf34-42cf-87b7-a8972141ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-e7788c08-2aa4-4ffb-af25-f88294278fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-03b5475b-ff56-471b-8497-ce7f4a187005,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-e8ccd77d-2a69-4357-a770-80b20e141376,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-8f0f7b37-5f95-417a-bbb7-8620d1eebbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-3a3ac42c-92a8-4658-b770-ccc68a73aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-fd63ca0f-8c07-4967-858a-383e2ffe13f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626892006-172.17.0.13-1598586888388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-9d01c67b-74d2-46b0-a293-8e5e0cce58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-9394dbfe-bf34-42cf-87b7-a8972141ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-e7788c08-2aa4-4ffb-af25-f88294278fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-03b5475b-ff56-471b-8497-ce7f4a187005,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-e8ccd77d-2a69-4357-a770-80b20e141376,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-8f0f7b37-5f95-417a-bbb7-8620d1eebbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-3a3ac42c-92a8-4658-b770-ccc68a73aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-fd63ca0f-8c07-4967-858a-383e2ffe13f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5326
