reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402912630-172.17.0.12-1598543431361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-8c683ea4-e22d-4c2e-a05b-65295b4ffdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-cd3b3080-dc17-4e55-af9a-f62aacda5296,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-59cc0d51-3742-4199-8de7-c40d8c3a7858,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ff7d9775-3ed7-484d-b81e-dccf33964fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7fc339e8-6f90-4d98-a456-d5a59c2278f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-0b5a42b8-5995-47f8-b41c-58172d7b49c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e2a7b847-44aa-4441-9984-a42a9a8d86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-09499b41-cc99-4715-807c-4a52ffb55aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402912630-172.17.0.12-1598543431361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-8c683ea4-e22d-4c2e-a05b-65295b4ffdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-cd3b3080-dc17-4e55-af9a-f62aacda5296,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-59cc0d51-3742-4199-8de7-c40d8c3a7858,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-ff7d9775-3ed7-484d-b81e-dccf33964fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7fc339e8-6f90-4d98-a456-d5a59c2278f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-0b5a42b8-5995-47f8-b41c-58172d7b49c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e2a7b847-44aa-4441-9984-a42a9a8d86d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-09499b41-cc99-4715-807c-4a52ffb55aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096543210-172.17.0.12-1598543467794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-825532bc-d087-403c-88d2-f1e349a7654a,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-fc811717-aa44-4fe2-b9b3-ed06fce9fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-26df7f6a-99c2-42e5-a687-278bb53a1500,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-a50b74fa-4269-4a15-a634-e856ed62e959,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-3f1d0951-9b8d-41d9-a791-5fbe97eaae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-e060daf8-b12c-42e9-9a6e-f95743539d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-15ceb227-37ff-402c-94c2-ae7b63e46206,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-dfcab173-ed07-4eee-934c-f4d6e2642f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096543210-172.17.0.12-1598543467794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-825532bc-d087-403c-88d2-f1e349a7654a,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-fc811717-aa44-4fe2-b9b3-ed06fce9fc62,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-26df7f6a-99c2-42e5-a687-278bb53a1500,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-a50b74fa-4269-4a15-a634-e856ed62e959,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-3f1d0951-9b8d-41d9-a791-5fbe97eaae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-e060daf8-b12c-42e9-9a6e-f95743539d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-15ceb227-37ff-402c-94c2-ae7b63e46206,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-dfcab173-ed07-4eee-934c-f4d6e2642f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149313924-172.17.0.12-1598544309865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-a9a3e70d-a07e-4bdd-81dc-dd4e5147ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-2470a5b7-c6ef-496d-ad68-4fce50c3ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-df4aad1d-5f2f-4de0-87f3-2f589e4dc4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1c3d3103-7f99-40ee-9c57-021448ef8539,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-0c9bde58-1e37-474e-a489-0a8b6bb25fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-f21f3bfd-7c3f-462f-8460-877ed44f941f,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-bb6da07b-afa8-499b-9425-5f7797b6a62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-70e3dffa-d957-417a-9a02-cb11fc8926eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149313924-172.17.0.12-1598544309865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-a9a3e70d-a07e-4bdd-81dc-dd4e5147ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-2470a5b7-c6ef-496d-ad68-4fce50c3ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-df4aad1d-5f2f-4de0-87f3-2f589e4dc4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1c3d3103-7f99-40ee-9c57-021448ef8539,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-0c9bde58-1e37-474e-a489-0a8b6bb25fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-f21f3bfd-7c3f-462f-8460-877ed44f941f,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-bb6da07b-afa8-499b-9425-5f7797b6a62f,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-70e3dffa-d957-417a-9a02-cb11fc8926eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588204327-172.17.0.12-1598544721419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-61f08a1e-172c-4281-bbed-9150a886c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-51785876-2284-453c-84ff-596e6e19937c,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-7a90dc83-498b-4526-9b70-bee922c41203,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-2186a3bc-26f5-49df-88ab-52fa6ab39005,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-4dc8fc23-bb63-4a46-bfd1-cb7288527be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-9cb87743-442d-4686-9cfb-9700c62401b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-4e76e5b7-9baf-4c25-a968-351ffab21c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fd6d1e4f-c462-4054-a439-1bc6892285b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588204327-172.17.0.12-1598544721419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-61f08a1e-172c-4281-bbed-9150a886c4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-51785876-2284-453c-84ff-596e6e19937c,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-7a90dc83-498b-4526-9b70-bee922c41203,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-2186a3bc-26f5-49df-88ab-52fa6ab39005,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-4dc8fc23-bb63-4a46-bfd1-cb7288527be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-9cb87743-442d-4686-9cfb-9700c62401b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-4e76e5b7-9baf-4c25-a968-351ffab21c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fd6d1e4f-c462-4054-a439-1bc6892285b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102743067-172.17.0.12-1598544757451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-8c7303e7-b8b5-4259-8a63-0f087c5c7da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-3fdbd9be-6ee0-4f48-bd17-e3ad19cd5a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ea62f0ba-379f-4c45-adc8-54fa0749da86,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-938bbb99-5770-47b3-ab92-91df0ebbd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-81cd0ee0-dd97-4fd2-ad8a-d9fef871bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-f7993d0b-805a-40bd-ad98-3cd2ad2829d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-22a87d08-4f41-4fa0-8f98-1abc43bfd8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-d246981b-94cc-4481-9bf8-9da7862a500d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102743067-172.17.0.12-1598544757451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-8c7303e7-b8b5-4259-8a63-0f087c5c7da1,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-3fdbd9be-6ee0-4f48-bd17-e3ad19cd5a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ea62f0ba-379f-4c45-adc8-54fa0749da86,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-938bbb99-5770-47b3-ab92-91df0ebbd23e,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-81cd0ee0-dd97-4fd2-ad8a-d9fef871bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-f7993d0b-805a-40bd-ad98-3cd2ad2829d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-22a87d08-4f41-4fa0-8f98-1abc43bfd8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-d246981b-94cc-4481-9bf8-9da7862a500d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604333450-172.17.0.12-1598544898719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-6ac42f08-512c-419c-a7d4-884d75dc7444,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-cc76e69c-b48e-4b77-af47-7035f0484589,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-0a6d0d37-c547-4260-8a4f-56289255e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-9c2a73ea-7398-4f7b-91c9-98dc3d694887,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-3ede991f-c08b-43c6-b372-07b8b3cb0a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-21bc6494-4f0f-4c6a-b052-edbff1030881,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-8e06c446-fc9c-4470-8253-492c6bd2d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-676eec72-08c0-436f-a3a9-cc75e0c2c78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604333450-172.17.0.12-1598544898719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-6ac42f08-512c-419c-a7d4-884d75dc7444,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-cc76e69c-b48e-4b77-af47-7035f0484589,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-0a6d0d37-c547-4260-8a4f-56289255e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-9c2a73ea-7398-4f7b-91c9-98dc3d694887,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-3ede991f-c08b-43c6-b372-07b8b3cb0a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-21bc6494-4f0f-4c6a-b052-edbff1030881,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-8e06c446-fc9c-4470-8253-492c6bd2d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-676eec72-08c0-436f-a3a9-cc75e0c2c78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929499137-172.17.0.12-1598544969190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-ad37417c-5a97-45e6-99d9-6c341c6f8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-2009cfb4-42b5-4752-950e-d1e6d130434c,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-b61fce12-6341-463e-b752-4cdbaf64479b,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-a05aac8c-d79f-41bf-a785-95c3e8108c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-def2f5e5-f378-4cff-aa48-ddceeded1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-7d75f99d-9484-4e08-be11-2d882a83be07,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0a673bb3-a8b3-41b0-b5b0-85636c695382,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-3a47e17a-1ac8-46c2-9813-ba6dc0053640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929499137-172.17.0.12-1598544969190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-ad37417c-5a97-45e6-99d9-6c341c6f8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-2009cfb4-42b5-4752-950e-d1e6d130434c,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-b61fce12-6341-463e-b752-4cdbaf64479b,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-a05aac8c-d79f-41bf-a785-95c3e8108c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-def2f5e5-f378-4cff-aa48-ddceeded1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-7d75f99d-9484-4e08-be11-2d882a83be07,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0a673bb3-a8b3-41b0-b5b0-85636c695382,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-3a47e17a-1ac8-46c2-9813-ba6dc0053640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705779631-172.17.0.12-1598545518244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-3a75962e-7c33-425d-9a07-bd907a9588f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-7c815b03-8d07-4221-979c-51706d1bea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-32a127b2-0e0a-4c1a-9fc3-cafea0350e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-40cf167e-1956-42b5-8bac-29d3887dd452,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-965c12f4-8f53-4957-9da1-c17b58a05bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-776f333a-eabd-429b-914b-ca5953d9ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-cdf44281-aa06-4b9b-ab5a-397492e037b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-140ea0df-5604-40c7-9232-0d5326e15899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705779631-172.17.0.12-1598545518244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-3a75962e-7c33-425d-9a07-bd907a9588f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-7c815b03-8d07-4221-979c-51706d1bea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-32a127b2-0e0a-4c1a-9fc3-cafea0350e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-40cf167e-1956-42b5-8bac-29d3887dd452,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-965c12f4-8f53-4957-9da1-c17b58a05bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-776f333a-eabd-429b-914b-ca5953d9ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-cdf44281-aa06-4b9b-ab5a-397492e037b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-140ea0df-5604-40c7-9232-0d5326e15899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141442261-172.17.0.12-1598546105293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-013a05a1-7de5-479b-9fdf-981303826c57,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-0a305cc0-7658-457b-8f8a-fbc3a69d6b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-e63ae02c-ea3e-47ba-bf7d-fc0e22f55970,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-abd43d75-bbab-47d4-91f8-d63ecafb06df,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-01732066-55a4-4fcf-a287-c32bd3d24ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c80c7536-d55f-4145-9878-a93fcdf63634,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-8d8e17ca-ddc5-4db3-8ced-3ac6f720dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-53c2135d-ab4d-4a72-a4e8-293c693edf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141442261-172.17.0.12-1598546105293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-013a05a1-7de5-479b-9fdf-981303826c57,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-0a305cc0-7658-457b-8f8a-fbc3a69d6b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-e63ae02c-ea3e-47ba-bf7d-fc0e22f55970,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-abd43d75-bbab-47d4-91f8-d63ecafb06df,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-01732066-55a4-4fcf-a287-c32bd3d24ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c80c7536-d55f-4145-9878-a93fcdf63634,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-8d8e17ca-ddc5-4db3-8ced-3ac6f720dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-53c2135d-ab4d-4a72-a4e8-293c693edf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486880616-172.17.0.12-1598546213059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-c7809ab8-b625-4b86-ac6e-928149b80e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-4d832e3e-60d1-49de-938f-9de32fa86be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b2b5376e-1b2a-4ab7-a2c3-757a54c15c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-9ca7293f-341b-4f3b-aefc-42a75ff00fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-c06faf70-eacf-453f-b421-2bd845ee9670,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b8309fdb-9061-4b24-aa97-bc72b6085ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-4144e9a6-dac4-425a-a31b-863aeba1ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-23d19856-ab0f-4453-afa8-8ace3a12b3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486880616-172.17.0.12-1598546213059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-c7809ab8-b625-4b86-ac6e-928149b80e10,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-4d832e3e-60d1-49de-938f-9de32fa86be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b2b5376e-1b2a-4ab7-a2c3-757a54c15c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-9ca7293f-341b-4f3b-aefc-42a75ff00fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-c06faf70-eacf-453f-b421-2bd845ee9670,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b8309fdb-9061-4b24-aa97-bc72b6085ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-4144e9a6-dac4-425a-a31b-863aeba1ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-23d19856-ab0f-4453-afa8-8ace3a12b3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222646949-172.17.0.12-1598546566674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-18d50600-425c-40a7-b310-44e01f811669,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-a006bb4a-e4e7-4635-ab8a-31afe41bad17,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-f3ef42f0-14af-4d13-a124-3c12ab46cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7a4b169e-4a1c-4183-b140-c2795e431c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-fc685218-0cdc-41d4-b26a-0becd6d67332,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-465f2cd7-8504-4ad3-b95e-36300290de30,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-de411da9-b94d-42f8-9325-3842dcce8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-ddcc8d0c-37e8-4a94-b1d3-54fe61e9daa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222646949-172.17.0.12-1598546566674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44464,DS-18d50600-425c-40a7-b310-44e01f811669,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-a006bb4a-e4e7-4635-ab8a-31afe41bad17,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-f3ef42f0-14af-4d13-a124-3c12ab46cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7a4b169e-4a1c-4183-b140-c2795e431c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-fc685218-0cdc-41d4-b26a-0becd6d67332,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-465f2cd7-8504-4ad3-b95e-36300290de30,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-de411da9-b94d-42f8-9325-3842dcce8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-ddcc8d0c-37e8-4a94-b1d3-54fe61e9daa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375202598-172.17.0.12-1598546716226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-7d2cd1be-6dc2-46b3-b79c-a241a8dc4617,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-15e9b708-1430-43d4-a100-2e13f153d889,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-27ac9f0e-63c2-45d3-9d94-09f5d93da278,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-ac72e597-0c0b-447e-9960-2308a0a743a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-e518dbf2-9207-4b15-92dc-d4767b34c8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-6d3f47c4-74e3-4d31-9de8-925c537f9880,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-126fa546-ecdd-4f7a-ba6e-5143eb423e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-80709795-1d2b-4ae3-aad9-fa6c8d75c885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375202598-172.17.0.12-1598546716226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-7d2cd1be-6dc2-46b3-b79c-a241a8dc4617,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-15e9b708-1430-43d4-a100-2e13f153d889,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-27ac9f0e-63c2-45d3-9d94-09f5d93da278,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-ac72e597-0c0b-447e-9960-2308a0a743a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-e518dbf2-9207-4b15-92dc-d4767b34c8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-6d3f47c4-74e3-4d31-9de8-925c537f9880,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-126fa546-ecdd-4f7a-ba6e-5143eb423e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-80709795-1d2b-4ae3-aad9-fa6c8d75c885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273811014-172.17.0.12-1598547498634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-d07f7b08-ab80-4e13-bb3b-c84d504c8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-54b4b76e-197f-402a-9dcf-60e113ed4970,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-5862ae8e-ffea-44cd-a661-0c7ddc8297ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-8e53a9fa-09b3-42ab-b1aa-f19aa15540e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-05e58b74-d57d-4d95-8134-9d7a3a1b4279,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-f085df14-2b91-4e6e-ac75-cbb63bffad57,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-321da634-2582-4569-a3af-bc71aaf30d84,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a77c2ac6-cad0-4c51-986c-50b7912a934d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273811014-172.17.0.12-1598547498634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-d07f7b08-ab80-4e13-bb3b-c84d504c8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-54b4b76e-197f-402a-9dcf-60e113ed4970,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-5862ae8e-ffea-44cd-a661-0c7ddc8297ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-8e53a9fa-09b3-42ab-b1aa-f19aa15540e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-05e58b74-d57d-4d95-8134-9d7a3a1b4279,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-f085df14-2b91-4e6e-ac75-cbb63bffad57,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-321da634-2582-4569-a3af-bc71aaf30d84,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a77c2ac6-cad0-4c51-986c-50b7912a934d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778957668-172.17.0.12-1598547721780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-2f4a3a08-b24e-4b5b-b75f-d5268c759b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-9ef6d6c2-1645-46ac-9949-1b3bc64b95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-03701f2b-10b9-486c-90b1-50cd3e28fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-420791a8-19e4-40c3-b4d2-cb83ee146040,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-0733aa84-ba50-4487-9aa9-271f793aaced,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-3a590ed4-789b-463b-beab-f84ffe043daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-1c8f3470-d523-4ba6-8355-159bbd8deb89,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-50186964-8e7b-4212-b2c6-c000caf0f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778957668-172.17.0.12-1598547721780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-2f4a3a08-b24e-4b5b-b75f-d5268c759b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-9ef6d6c2-1645-46ac-9949-1b3bc64b95a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-03701f2b-10b9-486c-90b1-50cd3e28fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-420791a8-19e4-40c3-b4d2-cb83ee146040,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-0733aa84-ba50-4487-9aa9-271f793aaced,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-3a590ed4-789b-463b-beab-f84ffe043daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-1c8f3470-d523-4ba6-8355-159bbd8deb89,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-50186964-8e7b-4212-b2c6-c000caf0f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104924661-172.17.0.12-1598547766074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44767,DS-43fd54ee-494b-41fe-96cb-23bfe5cab918,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-e6439b65-13e2-4d30-829d-60d231527f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-5fc4c8e8-83ef-4db5-b23e-40ab8264c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-9e20c0cf-43bb-4ee5-a53d-8e873c614527,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-194f87f9-9f26-4607-92c8-ef0966fd1f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bd6f8876-a4b0-408a-9c26-e5efd0c81b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7dbe00a6-e7aa-4a02-9027-1e9d8f697e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-53eec3f5-9dde-446b-814e-19854f2068d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104924661-172.17.0.12-1598547766074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44767,DS-43fd54ee-494b-41fe-96cb-23bfe5cab918,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-e6439b65-13e2-4d30-829d-60d231527f75,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-5fc4c8e8-83ef-4db5-b23e-40ab8264c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-9e20c0cf-43bb-4ee5-a53d-8e873c614527,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-194f87f9-9f26-4607-92c8-ef0966fd1f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bd6f8876-a4b0-408a-9c26-e5efd0c81b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7dbe00a6-e7aa-4a02-9027-1e9d8f697e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-53eec3f5-9dde-446b-814e-19854f2068d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386741628-172.17.0.12-1598547801255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34889,DS-f79d8186-e7c1-4fdd-a8c1-e8abc1948a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-938040df-bbec-4a52-892d-91da5865cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-798d6ffe-5f3b-4539-8e1b-7185839f9312,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-3017fd38-7c3f-4ab5-9330-c75c9d25c713,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-aeac7615-9619-4588-a0b7-a9b264726c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-9e2a4fd1-5a5f-43b9-b220-aecfaecb557e,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-865e8d46-4ae2-4247-8c48-23ad4ca3b106,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-6adfd5a9-4cdc-4852-bf04-1b2177903a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386741628-172.17.0.12-1598547801255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34889,DS-f79d8186-e7c1-4fdd-a8c1-e8abc1948a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-938040df-bbec-4a52-892d-91da5865cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-798d6ffe-5f3b-4539-8e1b-7185839f9312,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-3017fd38-7c3f-4ab5-9330-c75c9d25c713,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-aeac7615-9619-4588-a0b7-a9b264726c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-9e2a4fd1-5a5f-43b9-b220-aecfaecb557e,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-865e8d46-4ae2-4247-8c48-23ad4ca3b106,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-6adfd5a9-4cdc-4852-bf04-1b2177903a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350538831-172.17.0.12-1598548841239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-e9e912b5-196a-4003-ab2c-4724c119fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-1c116f04-d00d-4724-bc19-d422eb827678,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-cfa75a0a-16f7-4963-b30e-0850cc318ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-859ae706-a5c9-4ebc-a97c-926513674378,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-71c33584-9297-4642-98b5-cd7389ff9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-cdceae35-b555-43f0-98de-032003707f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-78e82618-cd05-43e6-9b53-280033714729,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-2029c3ef-c5c5-4352-805b-60700355c9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350538831-172.17.0.12-1598548841239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-e9e912b5-196a-4003-ab2c-4724c119fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-1c116f04-d00d-4724-bc19-d422eb827678,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-cfa75a0a-16f7-4963-b30e-0850cc318ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-859ae706-a5c9-4ebc-a97c-926513674378,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-71c33584-9297-4642-98b5-cd7389ff9b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-cdceae35-b555-43f0-98de-032003707f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-78e82618-cd05-43e6-9b53-280033714729,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-2029c3ef-c5c5-4352-805b-60700355c9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5475
