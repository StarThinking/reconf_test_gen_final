reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907846207-172.17.0.6-1598522814286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38424,DS-78be0cc7-7bab-4d3e-aa95-264a6cba7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-80deb04f-c174-40e4-af3a-a22aa4a0574b,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-25ea868b-7dc7-4048-a64e-bbd118c7611c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-6f82bc7c-b6a3-429f-a776-469d83bc4716,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-8dca54e6-c52f-48c1-b768-975fbe1521ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-e4bd42cc-1569-4321-a807-668baf492e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-bded113b-38c7-4d9d-ab8c-e52bd7332fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-fdb14cfd-128a-47b6-8d2a-897f17a3afcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907846207-172.17.0.6-1598522814286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38424,DS-78be0cc7-7bab-4d3e-aa95-264a6cba7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-80deb04f-c174-40e4-af3a-a22aa4a0574b,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-25ea868b-7dc7-4048-a64e-bbd118c7611c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-6f82bc7c-b6a3-429f-a776-469d83bc4716,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-8dca54e6-c52f-48c1-b768-975fbe1521ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-e4bd42cc-1569-4321-a807-668baf492e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-bded113b-38c7-4d9d-ab8c-e52bd7332fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-fdb14cfd-128a-47b6-8d2a-897f17a3afcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088321646-172.17.0.6-1598523460554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-aa662ced-e628-49cf-8de9-e14189035b24,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-11a20c93-9d41-4b7b-a9a0-f2212f09718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-d1d27d82-1b94-4ad2-abce-61083f854b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-c2cc24a0-b6ee-480e-81b1-ad881183c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-99e0b911-d9fd-4469-8e4c-e5dfb939628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-d70e4aa8-30d1-41c1-a1cd-80cd448f6311,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-a9124006-5764-49c6-9d2f-1b6188b649b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-1d329b4c-29bf-4b0e-b945-e3d605abf51b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088321646-172.17.0.6-1598523460554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-aa662ced-e628-49cf-8de9-e14189035b24,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-11a20c93-9d41-4b7b-a9a0-f2212f09718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-d1d27d82-1b94-4ad2-abce-61083f854b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-c2cc24a0-b6ee-480e-81b1-ad881183c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-99e0b911-d9fd-4469-8e4c-e5dfb939628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-d70e4aa8-30d1-41c1-a1cd-80cd448f6311,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-a9124006-5764-49c6-9d2f-1b6188b649b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-1d329b4c-29bf-4b0e-b945-e3d605abf51b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940689525-172.17.0.6-1598523698002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-794a3b3e-5736-4d06-ba67-37925991dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-7484ec4f-1d1d-4728-b350-e7fa2096b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-04c48892-640d-4f25-9e4c-1bb2721fcdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-405e84de-e9f5-4a42-9b91-c25f4e67825a,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-5672af6f-dfc2-4398-bd8a-a0d9b1a40acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-08c3f879-e74e-4a8e-a212-4561b6b00069,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-77a11988-9cc1-4be6-bdb0-d0d75e34eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-dcf8306b-82bc-46f8-8e8b-2c12e4f91ac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940689525-172.17.0.6-1598523698002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-794a3b3e-5736-4d06-ba67-37925991dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-7484ec4f-1d1d-4728-b350-e7fa2096b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-04c48892-640d-4f25-9e4c-1bb2721fcdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-405e84de-e9f5-4a42-9b91-c25f4e67825a,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-5672af6f-dfc2-4398-bd8a-a0d9b1a40acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-08c3f879-e74e-4a8e-a212-4561b6b00069,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-77a11988-9cc1-4be6-bdb0-d0d75e34eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-dcf8306b-82bc-46f8-8e8b-2c12e4f91ac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178298829-172.17.0.6-1598523890861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-1256e4b9-f12f-47a0-9442-c45515fbea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-6f9038d9-5c94-4a1b-8122-4810583523b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d199db6d-deb0-4b1c-850b-ceaf9c924cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-01b2227e-3153-442b-9c8e-501219af7192,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-8cb9e734-7788-4b5d-850d-a7d4b57ed081,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-15ea7d02-5b58-4464-8570-98f0c6ffa0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fece3609-fbd5-469a-add8-3535710ff7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-54ed4316-86d4-4531-9767-792b1ef6da78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178298829-172.17.0.6-1598523890861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-1256e4b9-f12f-47a0-9442-c45515fbea6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-6f9038d9-5c94-4a1b-8122-4810583523b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-d199db6d-deb0-4b1c-850b-ceaf9c924cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-01b2227e-3153-442b-9c8e-501219af7192,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-8cb9e734-7788-4b5d-850d-a7d4b57ed081,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-15ea7d02-5b58-4464-8570-98f0c6ffa0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fece3609-fbd5-469a-add8-3535710ff7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-54ed4316-86d4-4531-9767-792b1ef6da78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211981630-172.17.0.6-1598524160305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-794659d9-eebf-4517-afaf-c8fa815230fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-ca45d797-144f-472c-aad8-a928f500f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-20b39961-d6de-4f1a-8f94-eab3ac607507,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4ceae628-ebed-40c0-bd9a-81c59eb84ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-b6018e73-7335-4a5c-9ca3-63552837f503,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-b603bc3b-3e5e-45a7-8045-d2c4e6c0e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-08ca7776-51db-48a0-8c99-e87897951066,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-e96519a2-eef3-4b8c-9cea-79db03d62823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211981630-172.17.0.6-1598524160305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38402,DS-794659d9-eebf-4517-afaf-c8fa815230fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-ca45d797-144f-472c-aad8-a928f500f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-20b39961-d6de-4f1a-8f94-eab3ac607507,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-4ceae628-ebed-40c0-bd9a-81c59eb84ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-b6018e73-7335-4a5c-9ca3-63552837f503,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-b603bc3b-3e5e-45a7-8045-d2c4e6c0e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-08ca7776-51db-48a0-8c99-e87897951066,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-e96519a2-eef3-4b8c-9cea-79db03d62823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276399732-172.17.0.6-1598524193103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-8afb8f4f-a6db-4112-8b4c-5840024543b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-1c13b14d-7aba-4730-8cb5-c053fd24396f,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-6faf5d0b-0136-467b-8660-958f10b99867,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-c8f003df-e0d0-4cd3-97eb-d17590f1a307,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-aea22784-425d-4942-99e2-fc86d20d3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-89c7c59f-ea8b-4ab1-87e6-1db9cd7dd06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-78d42260-c585-4b0d-acd9-f468db4355ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-fb347384-259f-49c0-a28a-941aa8612a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276399732-172.17.0.6-1598524193103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-8afb8f4f-a6db-4112-8b4c-5840024543b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-1c13b14d-7aba-4730-8cb5-c053fd24396f,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-6faf5d0b-0136-467b-8660-958f10b99867,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-c8f003df-e0d0-4cd3-97eb-d17590f1a307,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-aea22784-425d-4942-99e2-fc86d20d3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-89c7c59f-ea8b-4ab1-87e6-1db9cd7dd06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-78d42260-c585-4b0d-acd9-f468db4355ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-fb347384-259f-49c0-a28a-941aa8612a61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117385971-172.17.0.6-1598524623353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-b0f2e0b4-f7a6-4e55-97a6-d9a01c2bc693,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-518fa687-6183-4205-bd00-77c5e7bdf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-4489d1a7-7309-4f4c-afc9-7a84abcdbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-95d7dc54-e4a6-4028-a8e5-a21499be63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ea9caac8-ed45-43d3-8d98-96f9116b63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-d626fbf2-89b4-4d4f-9cd0-0b9bb68dce72,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d71549a3-520c-49c1-bd8f-1735ddec53cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-b12c6db3-bda9-48e2-8613-3efd26c25d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117385971-172.17.0.6-1598524623353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-b0f2e0b4-f7a6-4e55-97a6-d9a01c2bc693,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-518fa687-6183-4205-bd00-77c5e7bdf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-4489d1a7-7309-4f4c-afc9-7a84abcdbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-95d7dc54-e4a6-4028-a8e5-a21499be63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ea9caac8-ed45-43d3-8d98-96f9116b63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-d626fbf2-89b4-4d4f-9cd0-0b9bb68dce72,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-d71549a3-520c-49c1-bd8f-1735ddec53cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-b12c6db3-bda9-48e2-8613-3efd26c25d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602200690-172.17.0.6-1598524698484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-835be4c8-e5da-4216-9ea6-4e1c588a6a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-569c5eca-b396-4441-817b-be718ecfe7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-96c13030-9ce8-40e7-8148-2a9c3cedea50,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-422984d7-d42c-41f9-8f1e-ba641fb882a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-e870fb64-96dc-4138-9212-46929d5ebecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-77d5e20c-ba8b-49fb-b1e0-1cbe65f947ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-bb626afb-494e-4271-9041-493016ef27c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-2cb585f8-2f8b-4aad-bb4a-750f370b3f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602200690-172.17.0.6-1598524698484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-835be4c8-e5da-4216-9ea6-4e1c588a6a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-569c5eca-b396-4441-817b-be718ecfe7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-96c13030-9ce8-40e7-8148-2a9c3cedea50,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-422984d7-d42c-41f9-8f1e-ba641fb882a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-e870fb64-96dc-4138-9212-46929d5ebecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-77d5e20c-ba8b-49fb-b1e0-1cbe65f947ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-bb626afb-494e-4271-9041-493016ef27c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-2cb585f8-2f8b-4aad-bb4a-750f370b3f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711290361-172.17.0.6-1598524778832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-79582d81-ed1d-4788-9fd7-776219cfbdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-9aaa3c5a-e9c5-47e1-82d9-9f91c03bb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-9304c4d3-e43f-47ab-ab77-ad82c1354a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-c37ead23-3738-4d66-8c7d-60bced67b616,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-a81f9903-d95a-46da-8d87-f531304873cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-2d8fac76-870e-4e73-833d-14b0aca9b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-18ae156e-873e-41d8-9840-5c430389f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d1fd1650-f3af-4929-bc3f-211b8f42453f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711290361-172.17.0.6-1598524778832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39391,DS-79582d81-ed1d-4788-9fd7-776219cfbdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-9aaa3c5a-e9c5-47e1-82d9-9f91c03bb9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-9304c4d3-e43f-47ab-ab77-ad82c1354a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-c37ead23-3738-4d66-8c7d-60bced67b616,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-a81f9903-d95a-46da-8d87-f531304873cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-2d8fac76-870e-4e73-833d-14b0aca9b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-18ae156e-873e-41d8-9840-5c430389f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d1fd1650-f3af-4929-bc3f-211b8f42453f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394078781-172.17.0.6-1598526258079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-75c67600-74ad-4094-8dc6-3fa93b31e982,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-1c58ea0e-ebfe-4018-841f-b7bd1cf60865,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ad9a4645-7557-4945-9c7d-0397dd4f26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-0d19a0fc-6fcf-4266-bb9c-773865e48a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-ab816fab-5795-4b0c-b82f-93354557e003,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-37d802ea-c383-44e7-a57f-2c350456bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-f1ebd4d2-b52d-4ea5-9137-10f3c67db606,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-585f43ef-3060-4a67-8dbc-6b1810d1d16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394078781-172.17.0.6-1598526258079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-75c67600-74ad-4094-8dc6-3fa93b31e982,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-1c58ea0e-ebfe-4018-841f-b7bd1cf60865,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-ad9a4645-7557-4945-9c7d-0397dd4f26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-0d19a0fc-6fcf-4266-bb9c-773865e48a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-ab816fab-5795-4b0c-b82f-93354557e003,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-37d802ea-c383-44e7-a57f-2c350456bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-f1ebd4d2-b52d-4ea5-9137-10f3c67db606,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-585f43ef-3060-4a67-8dbc-6b1810d1d16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515075542-172.17.0.6-1598526369504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-47160111-e4fa-4c32-8344-46327f5984b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-0b9c1abb-7955-46d7-be22-0011a6ec5647,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ac044132-b9ea-404d-99ed-110069418e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-e06832eb-fb38-4cb3-ae82-a5dd703d641e,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-7a4c2d5b-4a02-406a-9a91-d37b001f4b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-bfbf4a9a-86c6-4ee3-96c2-81a8292a51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-4f7964c9-afb7-4ae4-95fe-da21f2610d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-9832d6a6-c8da-4530-b9e1-4ebdcabba0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515075542-172.17.0.6-1598526369504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-47160111-e4fa-4c32-8344-46327f5984b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-0b9c1abb-7955-46d7-be22-0011a6ec5647,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-ac044132-b9ea-404d-99ed-110069418e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-e06832eb-fb38-4cb3-ae82-a5dd703d641e,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-7a4c2d5b-4a02-406a-9a91-d37b001f4b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-bfbf4a9a-86c6-4ee3-96c2-81a8292a51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-4f7964c9-afb7-4ae4-95fe-da21f2610d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-9832d6a6-c8da-4530-b9e1-4ebdcabba0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764111740-172.17.0.6-1598527177950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-dfe75316-aefb-43da-b5f6-e8cb34c87831,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-69b68e3e-e20b-4e87-b591-eecc039a6a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-a539ed2e-532e-4dff-bb92-64e70ca6a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-dc286eae-7cfe-437d-839b-771cc4bd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-a176c1a2-d5dc-4111-a6e3-06d5dfd0f952,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-8d96ec62-df57-456f-91c6-1a007ef9714a,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-31393b19-abec-426b-ae5d-b47cb57ff783,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-c50744e8-80a6-4997-a839-d966b8563951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764111740-172.17.0.6-1598527177950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-dfe75316-aefb-43da-b5f6-e8cb34c87831,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-69b68e3e-e20b-4e87-b591-eecc039a6a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-a539ed2e-532e-4dff-bb92-64e70ca6a68a,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-dc286eae-7cfe-437d-839b-771cc4bd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-a176c1a2-d5dc-4111-a6e3-06d5dfd0f952,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-8d96ec62-df57-456f-91c6-1a007ef9714a,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-31393b19-abec-426b-ae5d-b47cb57ff783,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-c50744e8-80a6-4997-a839-d966b8563951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130839362-172.17.0.6-1598527573140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-f5a3ae20-df37-49bf-b493-1430d2aa8607,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-291cf2a3-c0b8-4652-814d-dd2082514d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-42063793-d6f0-43f5-a474-33ae02a28d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-a3ec10a2-ec30-4770-a926-f709b1c926ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-6d845c57-4c26-42a6-81fd-8ab663582bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-00348912-c24f-4310-ae03-f1412089511e,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-67202592-08b4-4080-82d3-9951d07e98ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-56e5a149-36fe-4368-87f8-8e6b478640e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130839362-172.17.0.6-1598527573140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-f5a3ae20-df37-49bf-b493-1430d2aa8607,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-291cf2a3-c0b8-4652-814d-dd2082514d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-42063793-d6f0-43f5-a474-33ae02a28d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-a3ec10a2-ec30-4770-a926-f709b1c926ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-6d845c57-4c26-42a6-81fd-8ab663582bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-00348912-c24f-4310-ae03-f1412089511e,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-67202592-08b4-4080-82d3-9951d07e98ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-56e5a149-36fe-4368-87f8-8e6b478640e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124066287-172.17.0.6-1598527620308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-fcbf821a-935a-4d9b-807c-e3e7f7502748,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-de75a591-f838-42b5-8cb6-80396fc40611,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-2bff7cd6-085a-4e09-b58a-9612675d3044,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-b6b6eba2-d6b6-47f6-af78-41a928559354,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-c3a2e6cf-0d91-46b3-ba32-a885d6d05a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-7e4ca900-8ecf-454c-a5ec-55427da8f905,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-1de7966e-bc99-4613-b455-893c413e86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-731114aa-e874-4994-b910-4215670237a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124066287-172.17.0.6-1598527620308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-fcbf821a-935a-4d9b-807c-e3e7f7502748,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-de75a591-f838-42b5-8cb6-80396fc40611,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-2bff7cd6-085a-4e09-b58a-9612675d3044,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-b6b6eba2-d6b6-47f6-af78-41a928559354,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-c3a2e6cf-0d91-46b3-ba32-a885d6d05a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-7e4ca900-8ecf-454c-a5ec-55427da8f905,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-1de7966e-bc99-4613-b455-893c413e86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-731114aa-e874-4994-b910-4215670237a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378957715-172.17.0.6-1598527956328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-215452de-4e63-4cdf-8a8e-25e4c7d68300,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-798e557f-fb62-4a65-b0c0-bd6d1e9661fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-b7064b65-be16-416b-b30c-dd8138b13b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-adb41e36-cedb-4750-bfbc-91a3279af55c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-f4a68672-4dd9-4b64-9598-2a01ff77157a,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-308ef233-b54a-44c6-8ab9-6b9fa234d456,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-060795d3-1c87-4a42-900c-8d35faceba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-ad165649-0818-46f5-9756-3198ac1b0e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378957715-172.17.0.6-1598527956328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-215452de-4e63-4cdf-8a8e-25e4c7d68300,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-798e557f-fb62-4a65-b0c0-bd6d1e9661fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-b7064b65-be16-416b-b30c-dd8138b13b31,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-adb41e36-cedb-4750-bfbc-91a3279af55c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-f4a68672-4dd9-4b64-9598-2a01ff77157a,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-308ef233-b54a-44c6-8ab9-6b9fa234d456,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-060795d3-1c87-4a42-900c-8d35faceba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-ad165649-0818-46f5-9756-3198ac1b0e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5601
