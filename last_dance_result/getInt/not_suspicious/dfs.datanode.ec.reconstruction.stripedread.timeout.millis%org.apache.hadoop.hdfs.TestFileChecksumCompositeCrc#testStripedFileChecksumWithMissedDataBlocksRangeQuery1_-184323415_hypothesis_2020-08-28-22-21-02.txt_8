reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658410600-172.17.0.18-1598653419586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-8666b5dd-1706-45cf-97fe-bdbc80ea85f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-bcb234cb-eff9-4983-9de9-23cbcfe7ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-1f53dbfd-0f95-40e4-922a-74f5194e3594,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-b10d405e-6338-4897-a935-00433554e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-04210b23-d224-4ede-bb02-9e9c70f249da,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-beb3310c-408b-4b0a-9124-c8df054af57c,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-835e6927-7821-4c98-9a00-a53686af99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-73504905-cbe0-46bc-b796-d4fa09e7eb26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658410600-172.17.0.18-1598653419586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-8666b5dd-1706-45cf-97fe-bdbc80ea85f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-bcb234cb-eff9-4983-9de9-23cbcfe7ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-1f53dbfd-0f95-40e4-922a-74f5194e3594,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-b10d405e-6338-4897-a935-00433554e1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-04210b23-d224-4ede-bb02-9e9c70f249da,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-beb3310c-408b-4b0a-9124-c8df054af57c,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-835e6927-7821-4c98-9a00-a53686af99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-73504905-cbe0-46bc-b796-d4fa09e7eb26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897491032-172.17.0.18-1598653453214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-b6049970-c157-4b33-8072-fb054b6d63b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-97c07b99-6d74-4f6b-afef-4ad54154401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-9529efe8-7aea-4ff0-a48d-b56dc28bd8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6b811f42-32ea-4dbf-ba7a-23da8a36b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-384ae324-91a6-4a85-b735-51c069796a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-4f6a32c9-6d2b-4c21-af63-eb1eb8b70009,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-5fadfedc-10e7-4fb2-becd-b6e006a5121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7fdfbda0-db01-455b-8a8c-a17d4cfc83a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897491032-172.17.0.18-1598653453214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-b6049970-c157-4b33-8072-fb054b6d63b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-97c07b99-6d74-4f6b-afef-4ad54154401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-9529efe8-7aea-4ff0-a48d-b56dc28bd8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6b811f42-32ea-4dbf-ba7a-23da8a36b8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-384ae324-91a6-4a85-b735-51c069796a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-4f6a32c9-6d2b-4c21-af63-eb1eb8b70009,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-5fadfedc-10e7-4fb2-becd-b6e006a5121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7fdfbda0-db01-455b-8a8c-a17d4cfc83a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245444929-172.17.0.18-1598653743960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-1ad8be42-3f84-44c8-a725-178de3cf2773,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-1e3c7715-20d6-4fcc-8199-c057677c03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-4a21a05f-c00f-4d1a-ae51-bdc58c9bf734,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-bd0b3387-b693-49bc-97c3-fb6c8a1b10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-0c063ef2-504a-4532-8bd7-508db2e9707d,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-bce81028-8d7d-41da-86f8-69d9c40b9fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-4579e993-6d1f-4352-8da6-a06e3d8b35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-e129f033-ba03-4115-885b-d083b2507288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245444929-172.17.0.18-1598653743960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-1ad8be42-3f84-44c8-a725-178de3cf2773,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-1e3c7715-20d6-4fcc-8199-c057677c03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-4a21a05f-c00f-4d1a-ae51-bdc58c9bf734,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-bd0b3387-b693-49bc-97c3-fb6c8a1b10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-0c063ef2-504a-4532-8bd7-508db2e9707d,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-bce81028-8d7d-41da-86f8-69d9c40b9fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-4579e993-6d1f-4352-8da6-a06e3d8b35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-e129f033-ba03-4115-885b-d083b2507288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516072710-172.17.0.18-1598653992401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-b141b42b-d278-4961-a650-796d2d659730,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-ba4accca-8033-498a-ad11-9376fa59442c,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-b291d2fa-9fee-4976-807d-a53c02b1223d,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-6a9a6468-8b0f-4595-b385-b5d4915705ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-f2df5beb-b89c-46ce-bb7c-051f1defe98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-2a5142cd-00bf-4ed1-811c-9bd4ca6968bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-8f1ae013-46d9-4a82-b224-a313c1c54085,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-840a4ab9-48da-42e6-b51d-0be19d7b6d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516072710-172.17.0.18-1598653992401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41209,DS-b141b42b-d278-4961-a650-796d2d659730,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-ba4accca-8033-498a-ad11-9376fa59442c,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-b291d2fa-9fee-4976-807d-a53c02b1223d,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-6a9a6468-8b0f-4595-b385-b5d4915705ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-f2df5beb-b89c-46ce-bb7c-051f1defe98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-2a5142cd-00bf-4ed1-811c-9bd4ca6968bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-8f1ae013-46d9-4a82-b224-a313c1c54085,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-840a4ab9-48da-42e6-b51d-0be19d7b6d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935067835-172.17.0.18-1598654100177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-4ab8bb85-abe3-432b-bcb6-5762054f6536,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-d02e205a-531a-4f6d-aea7-4f3cdc5ae73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-3ddd1e7c-8ab7-42fe-997f-bbaa8652cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-f30ccaa5-8ac0-43d8-9e40-d0e4daa7ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-97ffdced-40f4-4a76-9d13-e3afd27858d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-9683e33e-4a9c-48eb-b9ff-16c91ca2fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-6c3a1b94-67fc-4431-813e-5268f95cf82b,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-e1ed121b-a87f-4cc0-8ff3-4ba221dd30ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935067835-172.17.0.18-1598654100177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-4ab8bb85-abe3-432b-bcb6-5762054f6536,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-d02e205a-531a-4f6d-aea7-4f3cdc5ae73e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-3ddd1e7c-8ab7-42fe-997f-bbaa8652cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-f30ccaa5-8ac0-43d8-9e40-d0e4daa7ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-97ffdced-40f4-4a76-9d13-e3afd27858d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-9683e33e-4a9c-48eb-b9ff-16c91ca2fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-6c3a1b94-67fc-4431-813e-5268f95cf82b,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-e1ed121b-a87f-4cc0-8ff3-4ba221dd30ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558374927-172.17.0.18-1598654485464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36114,DS-c64b655b-f519-40f6-9cd9-b6733d30778b,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-27ba9a76-42bf-4b61-94af-f02458c42f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-5008a671-d936-4e5c-b9c4-5f7f59219ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-f8680a4a-702d-4679-a85e-e25f566e1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-d4e9a86a-ab7f-4703-af44-fee3e42b333b,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-b414c786-ae66-4d06-9b14-3d0cb6948bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-0bde96ce-1230-4c9d-adad-3339cc6372d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-74b6555a-90fb-45f8-a0bb-d2813ffc13c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558374927-172.17.0.18-1598654485464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36114,DS-c64b655b-f519-40f6-9cd9-b6733d30778b,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-27ba9a76-42bf-4b61-94af-f02458c42f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-5008a671-d936-4e5c-b9c4-5f7f59219ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-f8680a4a-702d-4679-a85e-e25f566e1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-d4e9a86a-ab7f-4703-af44-fee3e42b333b,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-b414c786-ae66-4d06-9b14-3d0cb6948bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-0bde96ce-1230-4c9d-adad-3339cc6372d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-74b6555a-90fb-45f8-a0bb-d2813ffc13c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765191376-172.17.0.18-1598654589684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36001,DS-aaa9c715-271e-4edb-ba42-82992f3be16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-566a26df-9575-4aa8-882e-3aba2a0e709d,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-df3abc4d-c07b-4ee6-b0aa-8f5c99a78a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-8a443285-5ec6-4f30-b17b-9ce0b8a6883f,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-20443cdb-03dc-446a-9771-c258444065ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-b6f11d94-4c25-4335-bec6-92ce89d7b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9b4224c2-940b-4a32-b39a-8b36c4f99798,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-292be6df-fe5e-4908-b0a8-81daa5977870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765191376-172.17.0.18-1598654589684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36001,DS-aaa9c715-271e-4edb-ba42-82992f3be16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-566a26df-9575-4aa8-882e-3aba2a0e709d,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-df3abc4d-c07b-4ee6-b0aa-8f5c99a78a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-8a443285-5ec6-4f30-b17b-9ce0b8a6883f,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-20443cdb-03dc-446a-9771-c258444065ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-b6f11d94-4c25-4335-bec6-92ce89d7b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-9b4224c2-940b-4a32-b39a-8b36c4f99798,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-292be6df-fe5e-4908-b0a8-81daa5977870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892813738-172.17.0.18-1598654877978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-cfedec51-b3d4-4e83-84ae-0019e32f708d,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-7f930f1b-548d-4607-83ef-964b68924371,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0718b9dd-35e1-4aca-981e-4ee70aad1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-8526b255-9021-4542-9154-75b60aebaf72,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-1c978ee0-098f-43c4-a757-fc585d516947,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f3510edd-65ef-48bd-9000-ee9a1df76422,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-0c538b1c-e30b-46a8-82fd-777cb6fe3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-59ba681d-bcd7-4fbb-9781-253c33e00649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892813738-172.17.0.18-1598654877978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-cfedec51-b3d4-4e83-84ae-0019e32f708d,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-7f930f1b-548d-4607-83ef-964b68924371,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0718b9dd-35e1-4aca-981e-4ee70aad1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-8526b255-9021-4542-9154-75b60aebaf72,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-1c978ee0-098f-43c4-a757-fc585d516947,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f3510edd-65ef-48bd-9000-ee9a1df76422,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-0c538b1c-e30b-46a8-82fd-777cb6fe3b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-59ba681d-bcd7-4fbb-9781-253c33e00649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585581045-172.17.0.18-1598655013315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-39b6aa57-5510-4261-b557-89ce05902a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-cfd0a9c7-8ae4-4ff6-b710-5effc34fe1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-4d0bd457-f284-4890-bc04-0d560034a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-3a20ed9b-5f08-47bb-bb0e-6558810da733,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-a0ebb968-c87f-4332-ae38-5dc3a2e0a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-96359985-e0e9-433c-b55f-4bd3622fce48,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c385586c-8c36-45c7-a79f-23bbd9dddd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ba53209c-0c91-47ca-a4d5-a21983078e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585581045-172.17.0.18-1598655013315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-39b6aa57-5510-4261-b557-89ce05902a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-cfd0a9c7-8ae4-4ff6-b710-5effc34fe1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-4d0bd457-f284-4890-bc04-0d560034a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-3a20ed9b-5f08-47bb-bb0e-6558810da733,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-a0ebb968-c87f-4332-ae38-5dc3a2e0a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-96359985-e0e9-433c-b55f-4bd3622fce48,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c385586c-8c36-45c7-a79f-23bbd9dddd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-ba53209c-0c91-47ca-a4d5-a21983078e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648510499-172.17.0.18-1598655088267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-7588ff28-0fb1-4862-8908-08237836a988,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e65f24fa-2416-438d-8641-408d5d8a339c,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-3a2da001-486e-40dd-8340-341653d35511,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-f26de9e5-5d2d-4f7e-8d56-774c1c59a540,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-771839bc-5322-48a1-854e-eb27bc9d0eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-9e56f329-2d65-46fe-80eb-6f522aa318b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-74520ac4-0c2b-4aac-bcfd-251e46e842aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f9329a5d-0980-4293-834d-190fc50a082c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648510499-172.17.0.18-1598655088267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-7588ff28-0fb1-4862-8908-08237836a988,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e65f24fa-2416-438d-8641-408d5d8a339c,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-3a2da001-486e-40dd-8340-341653d35511,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-f26de9e5-5d2d-4f7e-8d56-774c1c59a540,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-771839bc-5322-48a1-854e-eb27bc9d0eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-9e56f329-2d65-46fe-80eb-6f522aa318b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-74520ac4-0c2b-4aac-bcfd-251e46e842aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-f9329a5d-0980-4293-834d-190fc50a082c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789664302-172.17.0.18-1598655821793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-5363bb51-3806-4a29-9239-3b10e161f515,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-facc37a5-7f6d-4582-8af7-86ddcc50349a,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-5959d277-5bc0-4d4d-b14a-5e68a7fb0365,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-cd00dd5a-251a-48aa-9705-c9cadbb4baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-296b1a66-bdaf-4575-b26c-38526b485076,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-76866c28-5ed4-4f0e-bf36-399f76c0f927,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-4341d50e-dc0e-4c01-ad81-1b723a94803e,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-2c276d29-a5b7-4cbd-aaca-f7f4545e1b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789664302-172.17.0.18-1598655821793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-5363bb51-3806-4a29-9239-3b10e161f515,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-facc37a5-7f6d-4582-8af7-86ddcc50349a,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-5959d277-5bc0-4d4d-b14a-5e68a7fb0365,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-cd00dd5a-251a-48aa-9705-c9cadbb4baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-296b1a66-bdaf-4575-b26c-38526b485076,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-76866c28-5ed4-4f0e-bf36-399f76c0f927,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-4341d50e-dc0e-4c01-ad81-1b723a94803e,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-2c276d29-a5b7-4cbd-aaca-f7f4545e1b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219526635-172.17.0.18-1598655964006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-d8f03eca-f8f0-4f1e-8947-608c382fe543,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-97d59aa3-ba4f-4f5e-ae2f-3d9981b5ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-77e1075d-ee43-4034-8fab-3900477edbba,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-2cfa4a98-81bb-4a1b-9c1e-f5a46b4c620b,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-eb4a07fc-3460-435e-a1c1-9773738648ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-22016ae5-d0de-4a30-aef2-bcdc35c6621b,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-90c2a3c7-dbd4-4446-81d5-f420075447b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-42f5f379-2f54-41ca-96dd-8b5425200101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219526635-172.17.0.18-1598655964006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-d8f03eca-f8f0-4f1e-8947-608c382fe543,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-97d59aa3-ba4f-4f5e-ae2f-3d9981b5ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-77e1075d-ee43-4034-8fab-3900477edbba,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-2cfa4a98-81bb-4a1b-9c1e-f5a46b4c620b,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-eb4a07fc-3460-435e-a1c1-9773738648ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-22016ae5-d0de-4a30-aef2-bcdc35c6621b,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-90c2a3c7-dbd4-4446-81d5-f420075447b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-42f5f379-2f54-41ca-96dd-8b5425200101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515223972-172.17.0.18-1598656598556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-a163e2df-06a4-47ee-9321-52e161dbfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c8f1e7ff-fba1-414f-a557-b9bcfb53338a,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-46a2521b-735e-4bdd-8ece-a9bce4af06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-f24a0fcd-96d6-4914-83b7-cbf9d1027579,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-5f7456d5-832a-4bcc-bd49-979d52be18a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-4293f3f0-816e-48db-a7a4-25042b5047dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-d91fd249-9543-499e-97f3-b7f07a1678d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-42a3332e-41ac-49a4-aab3-e92aeb7bb33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515223972-172.17.0.18-1598656598556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-a163e2df-06a4-47ee-9321-52e161dbfb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c8f1e7ff-fba1-414f-a557-b9bcfb53338a,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-46a2521b-735e-4bdd-8ece-a9bce4af06c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-f24a0fcd-96d6-4914-83b7-cbf9d1027579,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-5f7456d5-832a-4bcc-bd49-979d52be18a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-4293f3f0-816e-48db-a7a4-25042b5047dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-d91fd249-9543-499e-97f3-b7f07a1678d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-42a3332e-41ac-49a4-aab3-e92aeb7bb33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394022008-172.17.0.18-1598656636980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-62666f7f-d758-41d3-92fd-450454eddd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-3c956ce0-dee9-4448-93dc-988690fe90c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-90744904-c678-445b-9d6a-402066ae890e,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-5539d6c0-83c0-4589-86fa-2b363213560b,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-1894e9cd-00a8-4cb3-8cff-ea68b3d77d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-33daea56-1994-4f98-96e8-0a37f9767672,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-1ca67f45-63df-455d-a8a4-81481ad58181,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a18c6245-d347-4ed4-8edc-a13b99d957be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394022008-172.17.0.18-1598656636980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-62666f7f-d758-41d3-92fd-450454eddd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-3c956ce0-dee9-4448-93dc-988690fe90c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-90744904-c678-445b-9d6a-402066ae890e,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-5539d6c0-83c0-4589-86fa-2b363213560b,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-1894e9cd-00a8-4cb3-8cff-ea68b3d77d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-33daea56-1994-4f98-96e8-0a37f9767672,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-1ca67f45-63df-455d-a8a4-81481ad58181,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a18c6245-d347-4ed4-8edc-a13b99d957be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855295212-172.17.0.18-1598656794816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-bcacda58-e2aa-4995-8ccb-3774837a8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-596b1d68-cf6f-4b14-9c91-d3074f0770a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-46e6f753-9f1b-4305-b6bb-39b6f4e7b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-19244412-21c9-4869-9f0f-bfc284b278e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-67c2a604-6670-4b6e-906c-4d4e711849f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-2c916779-8d06-4963-a2d7-56b85ebd1059,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-dc16c663-1ef9-43c6-8432-a34a71f9c333,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-fbe4205d-a9b7-404a-9c6b-d630c1db29c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855295212-172.17.0.18-1598656794816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43200,DS-bcacda58-e2aa-4995-8ccb-3774837a8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-596b1d68-cf6f-4b14-9c91-d3074f0770a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-46e6f753-9f1b-4305-b6bb-39b6f4e7b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-19244412-21c9-4869-9f0f-bfc284b278e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-67c2a604-6670-4b6e-906c-4d4e711849f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-2c916779-8d06-4963-a2d7-56b85ebd1059,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-dc16c663-1ef9-43c6-8432-a34a71f9c333,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-fbe4205d-a9b7-404a-9c6b-d630c1db29c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892493478-172.17.0.18-1598656858444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-44984ca9-cd99-4e06-b526-4e484427b815,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-340b494c-be0f-47bf-a389-68342273fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-317dd87d-5759-4d7d-8e7f-6acff2bc969e,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-470ece7b-5c56-47a4-bb76-b4caa94706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-27e848ea-e26a-4824-99c1-f740cfd467c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-7b3b6902-56dc-41a4-871d-6bc46fdf90fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-bd986798-3f3c-4658-b724-a8c47efc82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-cb207243-65a3-409e-aeb2-0f571d4f620d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892493478-172.17.0.18-1598656858444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-44984ca9-cd99-4e06-b526-4e484427b815,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-340b494c-be0f-47bf-a389-68342273fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-317dd87d-5759-4d7d-8e7f-6acff2bc969e,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-470ece7b-5c56-47a4-bb76-b4caa94706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-27e848ea-e26a-4824-99c1-f740cfd467c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-7b3b6902-56dc-41a4-871d-6bc46fdf90fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-bd986798-3f3c-4658-b724-a8c47efc82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-cb207243-65a3-409e-aeb2-0f571d4f620d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930842654-172.17.0.18-1598657928091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-b9619183-928a-4bd9-bb32-fd05776a6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-cbf0e421-7fb6-4ffb-b78d-1e31770ea458,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-263afe86-6edf-44c3-9e38-05cd5ea9de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8d5388b8-c8f3-4a2e-83be-e3e7ff4a28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-9e504323-f4e4-4a44-a2bd-40622ea0c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-35548619-4788-4ff1-a603-006ce4ad3b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-64e0b5c3-1ad4-4ca3-854e-94db9d7a36af,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-2ac9d648-930d-4db4-a746-40a839a7574c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930842654-172.17.0.18-1598657928091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-b9619183-928a-4bd9-bb32-fd05776a6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-cbf0e421-7fb6-4ffb-b78d-1e31770ea458,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-263afe86-6edf-44c3-9e38-05cd5ea9de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8d5388b8-c8f3-4a2e-83be-e3e7ff4a28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-9e504323-f4e4-4a44-a2bd-40622ea0c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-35548619-4788-4ff1-a603-006ce4ad3b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-64e0b5c3-1ad4-4ca3-854e-94db9d7a36af,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-2ac9d648-930d-4db4-a746-40a839a7574c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.timeout.millis
component: hdfs:DataNode
v1: 5000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458814197-172.17.0.18-1598658297363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-12167b9e-e569-448a-870e-02d4f8eb8820,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-93a1f7c2-79a7-423a-9234-4ae1a1e9c044,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-e3807a7f-a484-4c04-a3a0-39070eacf3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-e931c253-00de-4a76-b777-643d628a88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-051a2b19-121b-48ad-8f3f-3587589cc4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-895e8d94-a73b-4aec-ae74-becb06a4c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d5ec5be1-d5ae-4eca-b310-b14222a2094e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-03d0dbb1-baba-47a7-9bbf-502a0f9d5f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458814197-172.17.0.18-1598658297363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46127,DS-12167b9e-e569-448a-870e-02d4f8eb8820,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-93a1f7c2-79a7-423a-9234-4ae1a1e9c044,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-e3807a7f-a484-4c04-a3a0-39070eacf3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-e931c253-00de-4a76-b777-643d628a88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-051a2b19-121b-48ad-8f3f-3587589cc4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-895e8d94-a73b-4aec-ae74-becb06a4c30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-d5ec5be1-d5ae-4eca-b310-b14222a2094e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-03d0dbb1-baba-47a7-9bbf-502a0f9d5f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5087
