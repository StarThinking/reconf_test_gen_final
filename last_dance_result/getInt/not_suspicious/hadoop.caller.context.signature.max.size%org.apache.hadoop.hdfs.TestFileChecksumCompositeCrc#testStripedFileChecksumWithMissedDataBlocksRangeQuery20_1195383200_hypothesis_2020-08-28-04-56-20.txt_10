reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406392705-172.17.0.6-1598590895204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-c82194f1-011e-443c-842b-7a73507531c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-3843c94d-9cb6-4456-86c0-db4f61b8974d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-7a2dba8a-1a54-4b93-8320-6a7a5caa87b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-fcbaab61-3be6-41b1-8708-46042dcffc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-36d4f16c-4d8b-4e6b-a4d5-1b0b7b8350f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-7ef15526-e707-4591-8457-4ef9403364dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-93b2ba91-87e6-452b-9fa5-9d58d71f5c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-a12b5db9-1225-46cf-95b1-0b9425905474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406392705-172.17.0.6-1598590895204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-c82194f1-011e-443c-842b-7a73507531c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-3843c94d-9cb6-4456-86c0-db4f61b8974d,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-7a2dba8a-1a54-4b93-8320-6a7a5caa87b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-fcbaab61-3be6-41b1-8708-46042dcffc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-36d4f16c-4d8b-4e6b-a4d5-1b0b7b8350f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-7ef15526-e707-4591-8457-4ef9403364dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-93b2ba91-87e6-452b-9fa5-9d58d71f5c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-a12b5db9-1225-46cf-95b1-0b9425905474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413867118-172.17.0.6-1598591036596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-38527cf3-acb6-4822-b1e7-bfc97853d348,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-34888f64-d953-4890-b5a9-b6db1a7a88f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-aeef39d0-c077-43c6-bdf4-7afbfca5f664,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-b7c6e4bb-17da-4057-86a0-d93c5c38727a,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-b5c113f9-c255-4d82-bb80-9f6164daef31,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-8db70b3d-13da-4f08-8d53-5459913087fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-6b8c1b49-059f-4205-a824-835e54b89456,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-0e4aeab9-66b3-48af-a510-d1f8ec3dad93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413867118-172.17.0.6-1598591036596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-38527cf3-acb6-4822-b1e7-bfc97853d348,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-34888f64-d953-4890-b5a9-b6db1a7a88f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-aeef39d0-c077-43c6-bdf4-7afbfca5f664,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-b7c6e4bb-17da-4057-86a0-d93c5c38727a,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-b5c113f9-c255-4d82-bb80-9f6164daef31,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-8db70b3d-13da-4f08-8d53-5459913087fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-6b8c1b49-059f-4205-a824-835e54b89456,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-0e4aeab9-66b3-48af-a510-d1f8ec3dad93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125640356-172.17.0.6-1598591069585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-b4f0411a-5da6-4d91-9919-eb49aae885f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-a7f3e714-5559-4a2d-a630-f791a471906c,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0076d1e3-863e-41ac-8464-41b03b413710,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-eb6eb865-ac28-4f09-bf14-f40b579077c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-69b4c3f8-2bc3-4867-bc18-3480288aa333,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-e76ff2b9-6f2f-42fb-a46a-d9000a736d67,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-a71391ba-5aaa-40c8-8d0a-c3a9e551d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-11bbcfc5-f50c-4f47-84f4-7669801a319c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125640356-172.17.0.6-1598591069585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-b4f0411a-5da6-4d91-9919-eb49aae885f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-a7f3e714-5559-4a2d-a630-f791a471906c,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0076d1e3-863e-41ac-8464-41b03b413710,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-eb6eb865-ac28-4f09-bf14-f40b579077c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-69b4c3f8-2bc3-4867-bc18-3480288aa333,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-e76ff2b9-6f2f-42fb-a46a-d9000a736d67,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-a71391ba-5aaa-40c8-8d0a-c3a9e551d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-11bbcfc5-f50c-4f47-84f4-7669801a319c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400301940-172.17.0.6-1598591556172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-a5f361fb-96c4-4e2f-badc-5f838361f131,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-9e40295b-a042-4405-bb35-6f3fc57e17be,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-9cfdbf41-2f19-4f8b-82d2-a566588cdea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-d4324f67-8a42-4a7f-bf49-bc045609c481,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-49d901b6-3719-40e9-b2b1-a3a7e2f1167f,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-8ff278c3-ff44-4f89-8f44-c5f561e69d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-cd17b7c8-9e52-40e9-8526-fcb824d26144,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-17c5b618-8545-4aca-a7ab-65e9030aed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400301940-172.17.0.6-1598591556172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-a5f361fb-96c4-4e2f-badc-5f838361f131,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-9e40295b-a042-4405-bb35-6f3fc57e17be,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-9cfdbf41-2f19-4f8b-82d2-a566588cdea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-d4324f67-8a42-4a7f-bf49-bc045609c481,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-49d901b6-3719-40e9-b2b1-a3a7e2f1167f,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-8ff278c3-ff44-4f89-8f44-c5f561e69d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-cd17b7c8-9e52-40e9-8526-fcb824d26144,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-17c5b618-8545-4aca-a7ab-65e9030aed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899602689-172.17.0.6-1598592023430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-b39cea2d-2a8f-43bd-ab22-3d57910734a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-4a879653-25ff-4062-af7b-186be9e90c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-6f743dd1-ad17-4b10-a05d-14acfcbd8603,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-c9fbbbcb-b1ef-4df3-9199-094d4ff201d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e2d2b623-51cf-4341-b1b8-d84bdb6ac558,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-8e5cc640-b7df-4691-a2c1-7b1cc5f63273,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-8ff1a4f8-70cc-4bc9-8f33-6f41b8d4df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-7cb98a44-b8a1-4590-a420-d7426f074d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899602689-172.17.0.6-1598592023430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-b39cea2d-2a8f-43bd-ab22-3d57910734a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-4a879653-25ff-4062-af7b-186be9e90c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-6f743dd1-ad17-4b10-a05d-14acfcbd8603,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-c9fbbbcb-b1ef-4df3-9199-094d4ff201d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e2d2b623-51cf-4341-b1b8-d84bdb6ac558,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-8e5cc640-b7df-4691-a2c1-7b1cc5f63273,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-8ff1a4f8-70cc-4bc9-8f33-6f41b8d4df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-7cb98a44-b8a1-4590-a420-d7426f074d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439028255-172.17.0.6-1598592423457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-574fef9a-8f38-4c80-bead-a76f125fec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-03ff77b0-f984-407e-9d6a-cbe9afbffdac,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4a8a0e61-33a7-4843-a79f-af462483d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-50efb2c8-be6f-4a55-834d-8d6ade54acfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-f1f7d163-fbe2-4240-a14c-ccaa7ed01a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6c3d9f4a-9f68-4072-8521-62ec338ed8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-dceb4fc0-2aa5-46f5-b31e-f1a887b15b42,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-92590a8a-4996-44b1-a65b-f218097bd022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439028255-172.17.0.6-1598592423457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-574fef9a-8f38-4c80-bead-a76f125fec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-03ff77b0-f984-407e-9d6a-cbe9afbffdac,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-4a8a0e61-33a7-4843-a79f-af462483d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-50efb2c8-be6f-4a55-834d-8d6ade54acfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-f1f7d163-fbe2-4240-a14c-ccaa7ed01a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6c3d9f4a-9f68-4072-8521-62ec338ed8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-dceb4fc0-2aa5-46f5-b31e-f1a887b15b42,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-92590a8a-4996-44b1-a65b-f218097bd022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453675136-172.17.0.6-1598592900580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-aeb0435d-bb07-43d2-94fa-8664d32fe156,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-f5e88621-c9f3-4de4-8116-277fc50195a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-69d95c0d-faeb-41c7-b340-a9a88e11d798,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-400b8005-4ae0-4402-9908-ff23e4bd6722,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-e1236515-b73b-47c7-86e8-88d45bccc592,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-13640cbf-6a9e-4e12-b472-f6f9953baaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-7b5c685e-77ee-4966-9fda-87b43829a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-eb311a13-5f55-489b-97a7-387f8fad6a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453675136-172.17.0.6-1598592900580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-aeb0435d-bb07-43d2-94fa-8664d32fe156,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-f5e88621-c9f3-4de4-8116-277fc50195a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-69d95c0d-faeb-41c7-b340-a9a88e11d798,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-400b8005-4ae0-4402-9908-ff23e4bd6722,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-e1236515-b73b-47c7-86e8-88d45bccc592,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-13640cbf-6a9e-4e12-b472-f6f9953baaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-7b5c685e-77ee-4966-9fda-87b43829a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-eb311a13-5f55-489b-97a7-387f8fad6a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232460051-172.17.0.6-1598593132618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-b7f82645-5ccb-46b6-b85a-f536ff43da67,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-51f487f7-3f7c-4535-b156-fa13588646ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-fb695d35-4de6-45d9-8812-df6faec2a996,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-33c17864-d3c4-4a66-9292-30b555dbd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-5d8d2279-aaa8-42aa-b136-54a86b337908,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-f43e6ec9-09b1-489a-bb04-1f02b63a99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-3cbd6748-9e9a-47d2-a6c1-7c5f35d3d055,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-1403985b-cffa-49f3-93ff-ac2fa7f41093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232460051-172.17.0.6-1598593132618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-b7f82645-5ccb-46b6-b85a-f536ff43da67,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-51f487f7-3f7c-4535-b156-fa13588646ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-fb695d35-4de6-45d9-8812-df6faec2a996,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-33c17864-d3c4-4a66-9292-30b555dbd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-5d8d2279-aaa8-42aa-b136-54a86b337908,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-f43e6ec9-09b1-489a-bb04-1f02b63a99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-3cbd6748-9e9a-47d2-a6c1-7c5f35d3d055,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-1403985b-cffa-49f3-93ff-ac2fa7f41093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998916930-172.17.0.6-1598593204645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-ebb84aba-babc-4308-b124-c84217fd9943,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1d43f149-10b3-4792-a800-f80b7324e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-a6bec3b7-85b5-4f87-9362-cf557ee598ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-a5385813-424a-4f93-993f-28f0c3c7e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-a43785b8-2b61-4f34-a6c6-ccafb695c25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-a14a6afd-dd50-461b-bea4-d18f94f46470,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-49881f18-9cd2-4c97-a0bd-7ddfc6685b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-44b6fe4e-a76d-4120-8675-ab79f59f1260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998916930-172.17.0.6-1598593204645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-ebb84aba-babc-4308-b124-c84217fd9943,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1d43f149-10b3-4792-a800-f80b7324e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-a6bec3b7-85b5-4f87-9362-cf557ee598ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-a5385813-424a-4f93-993f-28f0c3c7e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-a43785b8-2b61-4f34-a6c6-ccafb695c25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-a14a6afd-dd50-461b-bea4-d18f94f46470,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-49881f18-9cd2-4c97-a0bd-7ddfc6685b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-44b6fe4e-a76d-4120-8675-ab79f59f1260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250170625-172.17.0.6-1598593590872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-c14876a3-0c3b-4f7d-a263-abc157424c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-43d4a925-9e84-46f7-a003-6d796a11d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f3411c30-2cb6-4cf1-8c5e-8777b6e1b354,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d1bd686d-127d-47b4-bf14-167f959479b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-0edbe568-89ab-4314-81fe-b6c5ea9fa041,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7a075647-f1c6-4a70-9d9a-495400f6c349,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c4999b7b-ad8d-4285-b7e0-f0a2689bc945,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-99178af5-efae-4d72-8829-a943ac9b4cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250170625-172.17.0.6-1598593590872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39838,DS-c14876a3-0c3b-4f7d-a263-abc157424c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-43d4a925-9e84-46f7-a003-6d796a11d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f3411c30-2cb6-4cf1-8c5e-8777b6e1b354,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d1bd686d-127d-47b4-bf14-167f959479b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-0edbe568-89ab-4314-81fe-b6c5ea9fa041,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7a075647-f1c6-4a70-9d9a-495400f6c349,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c4999b7b-ad8d-4285-b7e0-f0a2689bc945,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-99178af5-efae-4d72-8829-a943ac9b4cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956883988-172.17.0.6-1598594334980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-01e338ca-49b5-4be0-99ce-d8305aa38e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-b9d55d95-92f0-4adb-89bb-b6c24f4845bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-282e527b-7ba7-4cb3-8589-f22e7900a005,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-48914627-6f16-4c9c-8ec2-6853ceca70d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-7aed2769-0985-4b9f-a478-ea82a9c6265a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-f12ef03e-fffe-43da-9cfd-b00c0d520e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-68b4b196-9033-4c71-b28d-e3413f94d509,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-bd6b4855-0fb1-4560-9f8a-ae8b7da0355b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956883988-172.17.0.6-1598594334980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-01e338ca-49b5-4be0-99ce-d8305aa38e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-b9d55d95-92f0-4adb-89bb-b6c24f4845bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-282e527b-7ba7-4cb3-8589-f22e7900a005,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-48914627-6f16-4c9c-8ec2-6853ceca70d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-7aed2769-0985-4b9f-a478-ea82a9c6265a,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-f12ef03e-fffe-43da-9cfd-b00c0d520e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-68b4b196-9033-4c71-b28d-e3413f94d509,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-bd6b4855-0fb1-4560-9f8a-ae8b7da0355b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744088654-172.17.0.6-1598594533991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-4cc2e506-a9a5-463d-ad68-11ee993121b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-c18bad93-ebf2-4bf8-ae6a-6b7a2f7c0aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-e494ddfb-a592-4883-a67f-ccae592ff888,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0998cb20-2ca7-4d2b-92ed-97139c88c977,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-9eb5090a-01b1-43ed-aae6-5cf11509f890,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-86bb55ad-e3c8-4adc-bf24-3f6d37117289,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-33a43051-29fb-49f5-98f9-fc09912f3454,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-6e84704f-af2d-4724-8dd0-370c8d66d855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744088654-172.17.0.6-1598594533991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-4cc2e506-a9a5-463d-ad68-11ee993121b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-c18bad93-ebf2-4bf8-ae6a-6b7a2f7c0aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-e494ddfb-a592-4883-a67f-ccae592ff888,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0998cb20-2ca7-4d2b-92ed-97139c88c977,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-9eb5090a-01b1-43ed-aae6-5cf11509f890,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-86bb55ad-e3c8-4adc-bf24-3f6d37117289,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-33a43051-29fb-49f5-98f9-fc09912f3454,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-6e84704f-af2d-4724-8dd0-370c8d66d855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859377273-172.17.0.6-1598594705586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-191ba19a-2eb4-4176-b73e-bf1d041bb65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-c4488822-971e-439a-858e-01cc5e6ee3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-b30ea7b0-1d72-4908-8052-8b3f9129fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-cb12daa1-4e2a-43ea-bb13-a648d0b4c064,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-5fa5ae71-43e0-40d7-93a6-648c9b6dad97,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-1405a08c-988f-4d41-8d54-4d54db41214d,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-e5034ced-f663-4512-be90-9d81e4d37db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-545b7b8b-ec10-416c-ad55-604a48e00b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859377273-172.17.0.6-1598594705586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-191ba19a-2eb4-4176-b73e-bf1d041bb65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-c4488822-971e-439a-858e-01cc5e6ee3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-b30ea7b0-1d72-4908-8052-8b3f9129fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-cb12daa1-4e2a-43ea-bb13-a648d0b4c064,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-5fa5ae71-43e0-40d7-93a6-648c9b6dad97,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-1405a08c-988f-4d41-8d54-4d54db41214d,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-e5034ced-f663-4512-be90-9d81e4d37db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-545b7b8b-ec10-416c-ad55-604a48e00b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547085630-172.17.0.6-1598595055873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-cb720d23-642f-4a4a-a9a6-6e57761d516c,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-824dfbfb-0657-45fb-b805-2895a9888fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d2ac9ecb-4413-43c3-ac4a-e9118edefede,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-47466df7-cb71-4954-95dd-2c80dd63e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-26b9f26d-45b9-4263-9103-770a4579eb31,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-57b1a9bf-789a-45de-9a00-f3d47c304f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-0ca88467-85e1-4201-93b4-2144dbbfd942,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-ae65960e-79cb-40ee-ae84-111d4f1e37e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547085630-172.17.0.6-1598595055873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-cb720d23-642f-4a4a-a9a6-6e57761d516c,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-824dfbfb-0657-45fb-b805-2895a9888fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d2ac9ecb-4413-43c3-ac4a-e9118edefede,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-47466df7-cb71-4954-95dd-2c80dd63e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-26b9f26d-45b9-4263-9103-770a4579eb31,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-57b1a9bf-789a-45de-9a00-f3d47c304f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-0ca88467-85e1-4201-93b4-2144dbbfd942,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-ae65960e-79cb-40ee-ae84-111d4f1e37e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818063622-172.17.0.6-1598595131380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-7ddac264-df06-4369-9b00-b95979b6683d,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-36a28412-7eff-4e25-b716-b980b183c791,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-f4cd234c-3bfb-4841-9e65-078a5e372f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-c32ba7d2-12b4-4d84-8493-c02a49ccec98,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-f6fdd01c-0751-4d7a-a43e-dc5d3d446a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-cd74fba2-589d-44de-882e-ba65ad0219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-401b9157-dcd9-4ede-8ac1-b555a44393b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-628243a3-f294-4df0-bc27-8e86a50d6ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818063622-172.17.0.6-1598595131380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-7ddac264-df06-4369-9b00-b95979b6683d,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-36a28412-7eff-4e25-b716-b980b183c791,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-f4cd234c-3bfb-4841-9e65-078a5e372f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-c32ba7d2-12b4-4d84-8493-c02a49ccec98,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-f6fdd01c-0751-4d7a-a43e-dc5d3d446a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-cd74fba2-589d-44de-882e-ba65ad0219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-401b9157-dcd9-4ede-8ac1-b555a44393b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-628243a3-f294-4df0-bc27-8e86a50d6ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272713998-172.17.0.6-1598595169248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-d3ad204e-c618-44b3-bb66-b459915bac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-8640c205-44f3-4443-8c14-0a19db73c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-1f9c790b-62bc-4e35-bb0d-e429143999ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-2c53aed1-8f93-454f-921e-80907ebead72,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e15c32f8-7468-4794-a982-a508c56feece,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-9aad992c-7cf6-4019-9d96-c9c6073a7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-a9c6ce91-671e-44c7-95e6-600a19050081,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-59bc7ca5-7540-47f3-abd8-b30cd4408476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272713998-172.17.0.6-1598595169248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-d3ad204e-c618-44b3-bb66-b459915bac9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-8640c205-44f3-4443-8c14-0a19db73c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-1f9c790b-62bc-4e35-bb0d-e429143999ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-2c53aed1-8f93-454f-921e-80907ebead72,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-e15c32f8-7468-4794-a982-a508c56feece,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-9aad992c-7cf6-4019-9d96-c9c6073a7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-a9c6ce91-671e-44c7-95e6-600a19050081,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-59bc7ca5-7540-47f3-abd8-b30cd4408476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 50
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185847258-172.17.0.6-1598595578470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-0bcf60b7-4861-4ca0-95c5-1ea58d701e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-29cca4e5-e753-40f7-a3d9-897b0acd794b,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-aa92fc38-4bd9-4965-b2d0-347eb0af8763,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-0a0170f4-e7ac-4796-a3b3-c13feb7da3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-905204a9-7b12-47e8-8897-a4c3d27335de,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-2872e055-4522-49ed-a577-d3890be10ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c294697e-cfe4-4fc8-9a68-494a05d23b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-9b1c537a-621b-4ae7-8345-8a589a299186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185847258-172.17.0.6-1598595578470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-0bcf60b7-4861-4ca0-95c5-1ea58d701e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-29cca4e5-e753-40f7-a3d9-897b0acd794b,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-aa92fc38-4bd9-4965-b2d0-347eb0af8763,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-0a0170f4-e7ac-4796-a3b3-c13feb7da3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-905204a9-7b12-47e8-8897-a4c3d27335de,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-2872e055-4522-49ed-a577-d3890be10ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-c294697e-cfe4-4fc8-9a68-494a05d23b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-9b1c537a-621b-4ae7-8345-8a589a299186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5161
