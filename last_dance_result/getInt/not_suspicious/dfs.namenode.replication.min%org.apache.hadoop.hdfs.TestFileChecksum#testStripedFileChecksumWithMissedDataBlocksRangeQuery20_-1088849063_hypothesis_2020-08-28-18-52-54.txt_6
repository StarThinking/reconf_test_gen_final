reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043893032-172.17.0.18-1598640785758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-9950355d-08ef-4197-a9fa-78af5c31018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-539d7400-295a-4deb-a66a-e25963617ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-2155b18f-c539-419b-add0-b636c083a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-bc388259-5764-49d6-b3e3-2861a22a5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3d115552-24e3-47f7-bc0e-4074cc698123,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-acfa68a5-98c2-481f-af05-f9e4badb0913,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85e7b9f2-27ff-4cf1-8791-800259df0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-330480e8-6475-4176-8125-7744887514d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043893032-172.17.0.18-1598640785758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-9950355d-08ef-4197-a9fa-78af5c31018d,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-539d7400-295a-4deb-a66a-e25963617ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-2155b18f-c539-419b-add0-b636c083a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-bc388259-5764-49d6-b3e3-2861a22a5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3d115552-24e3-47f7-bc0e-4074cc698123,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-acfa68a5-98c2-481f-af05-f9e4badb0913,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85e7b9f2-27ff-4cf1-8791-800259df0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-330480e8-6475-4176-8125-7744887514d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959532595-172.17.0.18-1598641317586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-ddbc8655-7a69-4642-96c1-dde3df004adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-2965088c-197a-4233-875c-924172b3ae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-9fa88185-3f2f-4eda-9459-f49b811580e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-2f4d0edd-bd0c-4d8f-8a07-8c0141ecf75c,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a7b81ff6-fda2-43bc-842e-45e0879f83a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-78bc24de-623d-4dbb-9f3d-5321d553f463,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-beb18aa7-9c58-4db0-84d7-d84597a578ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-58738fa2-0fd8-4819-99cc-5348f4d2da93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959532595-172.17.0.18-1598641317586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43041,DS-ddbc8655-7a69-4642-96c1-dde3df004adc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-2965088c-197a-4233-875c-924172b3ae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-9fa88185-3f2f-4eda-9459-f49b811580e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-2f4d0edd-bd0c-4d8f-8a07-8c0141ecf75c,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a7b81ff6-fda2-43bc-842e-45e0879f83a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-78bc24de-623d-4dbb-9f3d-5321d553f463,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-beb18aa7-9c58-4db0-84d7-d84597a578ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-58738fa2-0fd8-4819-99cc-5348f4d2da93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937354214-172.17.0.18-1598641550157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-e03f3da1-109c-46da-b8fd-7b846ad610b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-41bca591-9284-49cb-96f3-c69d4d793202,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-e687e1bd-8675-4ae1-9dc9-528190a8b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-875af836-8868-41be-9e7a-cd60e15d9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-305f8eb3-f09f-4b96-ab9d-3a47ef514a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-4e5851bc-15a2-42e6-8377-292528960976,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-e07bf8d3-e4a8-4c13-a571-8e02225e1695,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6f040144-ab60-43a5-8bc9-a24bd09a3965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937354214-172.17.0.18-1598641550157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-e03f3da1-109c-46da-b8fd-7b846ad610b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-41bca591-9284-49cb-96f3-c69d4d793202,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-e687e1bd-8675-4ae1-9dc9-528190a8b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-875af836-8868-41be-9e7a-cd60e15d9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-305f8eb3-f09f-4b96-ab9d-3a47ef514a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-4e5851bc-15a2-42e6-8377-292528960976,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-e07bf8d3-e4a8-4c13-a571-8e02225e1695,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-6f040144-ab60-43a5-8bc9-a24bd09a3965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164167946-172.17.0.18-1598641772302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-a71f812d-11e3-4532-9bcb-77f4b3893081,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-c0c0f976-889f-48fe-8abd-8f5172e2d326,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-17da476d-9943-4232-9538-06f6f7f33638,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-5f3a0ba6-7494-42fd-addf-dedef25d146c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-caf5a0bd-ca5b-4d84-91fe-ace625a142fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-7b447805-962f-4fc4-bd26-83e6ce841394,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-e923eb83-5b34-48cf-b52e-df97c570832d,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a4f0ac12-39f7-4d80-be23-82a30659ebbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164167946-172.17.0.18-1598641772302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-a71f812d-11e3-4532-9bcb-77f4b3893081,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-c0c0f976-889f-48fe-8abd-8f5172e2d326,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-17da476d-9943-4232-9538-06f6f7f33638,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-5f3a0ba6-7494-42fd-addf-dedef25d146c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-caf5a0bd-ca5b-4d84-91fe-ace625a142fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-7b447805-962f-4fc4-bd26-83e6ce841394,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-e923eb83-5b34-48cf-b52e-df97c570832d,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a4f0ac12-39f7-4d80-be23-82a30659ebbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203649162-172.17.0.18-1598641813648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-30910446-ae05-47cb-89a7-e2edccb2b275,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-dd2a148f-f42d-48f7-b62e-80cefecedfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-61f5fe7d-2857-4521-86c0-8c5bef035f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-ed11a079-38dd-4319-9606-957abdc250d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-3755ac63-abfb-4545-9275-b2249eeb437a,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-be0b3dba-e3cd-4a46-9e2c-b8ec9b93bbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-cf53ae9b-d20c-4ff7-aab5-0b2cd8826f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-fcf6bbf0-9dac-483f-ad11-dfc8e38f590a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203649162-172.17.0.18-1598641813648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-30910446-ae05-47cb-89a7-e2edccb2b275,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-dd2a148f-f42d-48f7-b62e-80cefecedfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-61f5fe7d-2857-4521-86c0-8c5bef035f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-ed11a079-38dd-4319-9606-957abdc250d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-3755ac63-abfb-4545-9275-b2249eeb437a,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-be0b3dba-e3cd-4a46-9e2c-b8ec9b93bbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-cf53ae9b-d20c-4ff7-aab5-0b2cd8826f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-fcf6bbf0-9dac-483f-ad11-dfc8e38f590a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713710270-172.17.0.18-1598641880731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-6cbb8746-6e36-4219-8d83-3a0b3375d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-e2bb05ae-ab00-41a3-b20f-7ada2659ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-928c7f6f-7824-47f7-9ef8-4ed23ef0dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-c928baab-56cd-46d9-b148-4b1d14fc2f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-295e1587-2a88-4ce8-91a8-64a7abca71a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-2d442d0b-8638-433e-83c5-609d9b98e530,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-af6978e4-2ddf-42d1-9c39-6e6f1cf0e135,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-2ac9e550-7d18-4dfe-b5f0-d7a66be083e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713710270-172.17.0.18-1598641880731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-6cbb8746-6e36-4219-8d83-3a0b3375d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-e2bb05ae-ab00-41a3-b20f-7ada2659ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-928c7f6f-7824-47f7-9ef8-4ed23ef0dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-c928baab-56cd-46d9-b148-4b1d14fc2f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-295e1587-2a88-4ce8-91a8-64a7abca71a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-2d442d0b-8638-433e-83c5-609d9b98e530,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-af6978e4-2ddf-42d1-9c39-6e6f1cf0e135,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-2ac9e550-7d18-4dfe-b5f0-d7a66be083e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144854390-172.17.0.18-1598642251983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-c8c7ce82-fdd1-42e1-8b91-dc76f959423a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-67279dc7-ae38-49f7-ae74-4b4bbeb43fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-843266b9-d11c-4374-b525-021f8c270155,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-f9c29f3c-2393-4c2d-b95f-53b9c0781cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-6b6419a7-f9f1-4886-a27e-f3bef93f4457,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-3c241830-043f-4faf-ada0-62879107b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b32f61bb-ff11-4d9e-b681-dd6c00dc9ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-8cbcac74-aa27-4136-8b2e-cac5acf4c24a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144854390-172.17.0.18-1598642251983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-c8c7ce82-fdd1-42e1-8b91-dc76f959423a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-67279dc7-ae38-49f7-ae74-4b4bbeb43fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-843266b9-d11c-4374-b525-021f8c270155,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-f9c29f3c-2393-4c2d-b95f-53b9c0781cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-6b6419a7-f9f1-4886-a27e-f3bef93f4457,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-3c241830-043f-4faf-ada0-62879107b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b32f61bb-ff11-4d9e-b681-dd6c00dc9ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-8cbcac74-aa27-4136-8b2e-cac5acf4c24a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192950031-172.17.0.18-1598642316377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-4cbefe29-e81e-450c-b34b-dd9e031f2b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-e695306d-a06b-42e0-b546-4c7ff2a4b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-81c88f3d-8261-4e50-b0f6-3e0b1acccbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-e6a9793e-2b4f-4e46-b8aa-479ad8c1ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-ba552cc8-51cc-4b3d-b44e-4de302bd3add,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-4c9ddfda-4439-4a51-9358-de0d7a7bf5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-637382e9-94dc-4415-a87f-b5f537c53414,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-afed2ce3-b3e6-4579-a627-01fa0ab4ff35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192950031-172.17.0.18-1598642316377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-4cbefe29-e81e-450c-b34b-dd9e031f2b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-e695306d-a06b-42e0-b546-4c7ff2a4b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-81c88f3d-8261-4e50-b0f6-3e0b1acccbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-e6a9793e-2b4f-4e46-b8aa-479ad8c1ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-ba552cc8-51cc-4b3d-b44e-4de302bd3add,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-4c9ddfda-4439-4a51-9358-de0d7a7bf5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-637382e9-94dc-4415-a87f-b5f537c53414,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-afed2ce3-b3e6-4579-a627-01fa0ab4ff35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139667661-172.17.0.18-1598642374692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-7fdc4177-bd62-4230-b5cd-57fac54f72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-4c7e0f7c-29de-41bc-8ee4-0578744563fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-fa1aed17-45db-466d-a8d6-b271dc041116,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6bf9ba13-7cbb-449b-8339-e30e2c01fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-567a18fd-bddf-4e78-9928-5e0a17340483,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-3cfcd1b2-23c3-4d70-bcc9-af571a0b1174,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-bc919fdb-50e4-45ba-8dcc-c0865042e292,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-59a1bc13-9700-4be6-bcf2-c1ffa421f4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139667661-172.17.0.18-1598642374692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-7fdc4177-bd62-4230-b5cd-57fac54f72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-4c7e0f7c-29de-41bc-8ee4-0578744563fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-fa1aed17-45db-466d-a8d6-b271dc041116,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6bf9ba13-7cbb-449b-8339-e30e2c01fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-567a18fd-bddf-4e78-9928-5e0a17340483,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-3cfcd1b2-23c3-4d70-bcc9-af571a0b1174,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-bc919fdb-50e4-45ba-8dcc-c0865042e292,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-59a1bc13-9700-4be6-bcf2-c1ffa421f4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136417773-172.17.0.18-1598642466209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-c61438cf-f0a2-49b8-a6d8-e71f90107dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-31ac63b3-e7b4-4948-9236-634207f8805a,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-41f6d528-aea1-4a41-baea-448b18a5275e,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-fba6c877-5729-434e-9174-4f84c65a0c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-3a3b8bdf-6317-4e9c-a2cd-e9472dac2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-027fbc42-8920-4d38-99ed-e10a3692dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-e21d35a4-5825-450a-847e-5ef4fc50ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-3eb2c936-1d02-4b72-9e38-655ad9d5a465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136417773-172.17.0.18-1598642466209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-c61438cf-f0a2-49b8-a6d8-e71f90107dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-31ac63b3-e7b4-4948-9236-634207f8805a,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-41f6d528-aea1-4a41-baea-448b18a5275e,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-fba6c877-5729-434e-9174-4f84c65a0c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-3a3b8bdf-6317-4e9c-a2cd-e9472dac2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-027fbc42-8920-4d38-99ed-e10a3692dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-e21d35a4-5825-450a-847e-5ef4fc50ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-3eb2c936-1d02-4b72-9e38-655ad9d5a465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498404332-172.17.0.18-1598642661297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-b0cd91aa-9ac9-431a-acaf-146e3c5034ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-9e71a4d2-18ea-4351-90c2-31877c33b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-8f645489-f097-4bac-be8c-bd44ffa43f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-8aa34433-9bcf-4075-bde2-94b2525be732,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-f1345f5c-58dc-47e0-8bbc-c3a7e8b51490,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-3225ba13-9541-4dbf-bbbf-2c030ff0c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-c3375043-0ba4-45e6-8c60-76a2eac4ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f192a96f-698b-414a-b121-73e44a859c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498404332-172.17.0.18-1598642661297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-b0cd91aa-9ac9-431a-acaf-146e3c5034ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-9e71a4d2-18ea-4351-90c2-31877c33b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-8f645489-f097-4bac-be8c-bd44ffa43f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-8aa34433-9bcf-4075-bde2-94b2525be732,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-f1345f5c-58dc-47e0-8bbc-c3a7e8b51490,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-3225ba13-9541-4dbf-bbbf-2c030ff0c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-c3375043-0ba4-45e6-8c60-76a2eac4ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f192a96f-698b-414a-b121-73e44a859c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883346716-172.17.0.18-1598642724182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-0d2715fb-d3b7-47c0-bf73-37e6362eaa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7bf65a48-b19b-466f-bba5-f0a99385f418,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-4b3609d7-3c93-42bc-a74c-6ad2f613a106,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-49c72d10-52c5-4e5e-90d8-37ebb30d4664,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-96ddc93e-8b5c-4c50-877f-e73a3dcc24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-3860741b-22b2-49f1-a38c-6bc09ce92333,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-ce510100-91f0-4aed-a3a6-d62ec30d4660,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-036fddd4-f04c-4034-84c7-d651507c6d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883346716-172.17.0.18-1598642724182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42856,DS-0d2715fb-d3b7-47c0-bf73-37e6362eaa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7bf65a48-b19b-466f-bba5-f0a99385f418,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-4b3609d7-3c93-42bc-a74c-6ad2f613a106,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-49c72d10-52c5-4e5e-90d8-37ebb30d4664,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-96ddc93e-8b5c-4c50-877f-e73a3dcc24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-3860741b-22b2-49f1-a38c-6bc09ce92333,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-ce510100-91f0-4aed-a3a6-d62ec30d4660,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-036fddd4-f04c-4034-84c7-d651507c6d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199691857-172.17.0.18-1598643045544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-d23207e0-5a2e-48b0-a22b-9c53433bb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-c6c5c97c-46fa-47ad-9ba8-a5651699eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-2a86135c-f031-4b22-8f93-fe34961ce931,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-20099466-df7e-41f1-8874-c544b1aa1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-3e58dff7-c945-4edc-9cf3-e19a3d418612,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-626f5812-8093-41ed-ae5d-7cb8ea976aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9c1aa474-a95e-43f3-a2e4-f3e5266c6486,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-0e3060f0-ed33-42dd-9d61-f52bf9870803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199691857-172.17.0.18-1598643045544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-d23207e0-5a2e-48b0-a22b-9c53433bb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-c6c5c97c-46fa-47ad-9ba8-a5651699eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-2a86135c-f031-4b22-8f93-fe34961ce931,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-20099466-df7e-41f1-8874-c544b1aa1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-3e58dff7-c945-4edc-9cf3-e19a3d418612,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-626f5812-8093-41ed-ae5d-7cb8ea976aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-9c1aa474-a95e-43f3-a2e4-f3e5266c6486,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-0e3060f0-ed33-42dd-9d61-f52bf9870803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480125535-172.17.0.18-1598643209328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-a62dba57-b008-4b63-b542-8214e25d62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d3353ca1-6085-4658-bee0-94bc1a813e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-0e27a1bb-59d6-4cb7-a5c4-f63f40fd7242,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-65eb0c2a-0c36-4e9d-aa21-d64e5b433ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-5053bf95-7d38-4c36-ab20-9b98199dc324,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-97020809-e351-45e8-9062-0a05187fe81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-bd7252e2-a8f5-458a-a946-eb087a5bc222,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-37c52262-21c8-4361-9e25-423002660f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480125535-172.17.0.18-1598643209328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-a62dba57-b008-4b63-b542-8214e25d62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d3353ca1-6085-4658-bee0-94bc1a813e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-0e27a1bb-59d6-4cb7-a5c4-f63f40fd7242,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-65eb0c2a-0c36-4e9d-aa21-d64e5b433ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-5053bf95-7d38-4c36-ab20-9b98199dc324,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-97020809-e351-45e8-9062-0a05187fe81b,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-bd7252e2-a8f5-458a-a946-eb087a5bc222,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-37c52262-21c8-4361-9e25-423002660f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514879016-172.17.0.18-1598643375841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-cb1d84fb-1a87-4b56-a062-42232a93bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-3bbb22d5-23a9-4235-93c0-4c804e12fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-2e286927-232c-436b-89fd-16f53c695a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-181385e6-1aa0-4f98-a18d-b214d06c4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-e41118d4-54c3-49cb-92c1-e6d857d72c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-de349610-0348-46e9-9405-f1b2ea3faf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-6f51f23d-c809-4981-9d99-f52a1ecacbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-c5b4cc77-714d-4b64-9c0a-4ab364e8a962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514879016-172.17.0.18-1598643375841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-cb1d84fb-1a87-4b56-a062-42232a93bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-3bbb22d5-23a9-4235-93c0-4c804e12fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-2e286927-232c-436b-89fd-16f53c695a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-181385e6-1aa0-4f98-a18d-b214d06c4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-e41118d4-54c3-49cb-92c1-e6d857d72c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-de349610-0348-46e9-9405-f1b2ea3faf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-6f51f23d-c809-4981-9d99-f52a1ecacbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-c5b4cc77-714d-4b64-9c0a-4ab364e8a962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314135764-172.17.0.18-1598643464590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-f85a3ccb-431e-48dd-9363-790d1f0447f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-58725cdf-921f-4239-bd37-22ce0ac2bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-6857e904-0aa8-49ba-8a20-8cad3f8e307d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-571d9c1b-9aee-44d5-a799-f03c6205891d,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-d81a1a40-5f60-4239-ab6d-71a783d6d14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-678c3b04-1057-4ac1-8361-5811793136e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-018ef686-36bb-46f8-b1cd-56f2efead852,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-d5e99203-e4b4-4bf7-98d7-700104d15f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314135764-172.17.0.18-1598643464590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-f85a3ccb-431e-48dd-9363-790d1f0447f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-58725cdf-921f-4239-bd37-22ce0ac2bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-6857e904-0aa8-49ba-8a20-8cad3f8e307d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-571d9c1b-9aee-44d5-a799-f03c6205891d,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-d81a1a40-5f60-4239-ab6d-71a783d6d14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-678c3b04-1057-4ac1-8361-5811793136e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-018ef686-36bb-46f8-b1cd-56f2efead852,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-d5e99203-e4b4-4bf7-98d7-700104d15f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379059453-172.17.0.18-1598643862394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-6b98d3a6-cdfe-4386-aa95-0958ca76089b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-7ae7c87f-1e25-4e50-a6d8-3de766e6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-3a5ce051-90c3-4c5b-9a73-20d75c500fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-a2ced53f-8502-49f5-994c-9abbc6507ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-e0d1398e-7426-4c8a-a238-d581e4f557ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-31fce87f-4f12-4744-9bc8-e578e409677d,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d8308378-b41f-43ad-8c01-009d25e8f77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-d62451cb-26f8-4fb1-b79a-125cc8fb6365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379059453-172.17.0.18-1598643862394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-6b98d3a6-cdfe-4386-aa95-0958ca76089b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-7ae7c87f-1e25-4e50-a6d8-3de766e6813d,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-3a5ce051-90c3-4c5b-9a73-20d75c500fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-a2ced53f-8502-49f5-994c-9abbc6507ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-e0d1398e-7426-4c8a-a238-d581e4f557ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-31fce87f-4f12-4744-9bc8-e578e409677d,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d8308378-b41f-43ad-8c01-009d25e8f77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-d62451cb-26f8-4fb1-b79a-125cc8fb6365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245194872-172.17.0.18-1598644209996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-52d60358-732e-449a-8822-42999e72bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-50f04edc-536d-4770-a502-7002fecfd7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-5f72e85a-0793-4af0-8645-1660cfda72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-bc72ca32-dbd0-4d31-bf75-cd2141ef6816,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-d50129e9-13e9-4bc6-a45b-fdcfacf72e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d05abfa3-e0aa-423f-983c-6e0cf0172f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-0680edda-f0d6-4191-bec4-dbfccc093a86,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-4dcc79c9-a9d5-4308-89e1-83769c9f2781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245194872-172.17.0.18-1598644209996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-52d60358-732e-449a-8822-42999e72bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-50f04edc-536d-4770-a502-7002fecfd7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-5f72e85a-0793-4af0-8645-1660cfda72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-bc72ca32-dbd0-4d31-bf75-cd2141ef6816,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-d50129e9-13e9-4bc6-a45b-fdcfacf72e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d05abfa3-e0aa-423f-983c-6e0cf0172f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-0680edda-f0d6-4191-bec4-dbfccc093a86,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-4dcc79c9-a9d5-4308-89e1-83769c9f2781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132571771-172.17.0.18-1598644274652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-63fed28a-c78c-433c-a653-e598b51a2f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-4a28a750-3fa5-4943-b862-d7174997ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-0cce15ad-319c-4fc0-a30f-8502d0b22ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-58760b78-b9fd-469b-94b8-e62fc1e969fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-a4ee0eb1-2597-4092-a669-b354aadba537,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-6d45d3f5-3748-41dd-abe8-248f82e43b73,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-648a19cd-8620-4127-9f9d-1e8143f51211,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-153a7924-864a-4294-bc2d-95677078097f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132571771-172.17.0.18-1598644274652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-63fed28a-c78c-433c-a653-e598b51a2f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-4a28a750-3fa5-4943-b862-d7174997ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-0cce15ad-319c-4fc0-a30f-8502d0b22ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-58760b78-b9fd-469b-94b8-e62fc1e969fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-a4ee0eb1-2597-4092-a669-b354aadba537,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-6d45d3f5-3748-41dd-abe8-248f82e43b73,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-648a19cd-8620-4127-9f9d-1e8143f51211,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-153a7924-864a-4294-bc2d-95677078097f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019215321-172.17.0.18-1598645161309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-eb9c05f9-73cf-4278-9810-a8db967533c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-9ac1868e-6f87-46c4-8cef-fc074bcee36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-04624fd5-8847-459a-8bf0-b641d04809eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-27f210df-fe5e-4345-af64-3146252e0b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-57e5f062-74b5-4df7-b0c7-157afc4329a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-2b14e085-b88e-447f-9c02-bb95880c3499,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-4b126ba2-cf98-43e4-87ec-32af54880fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-9d657d6e-d005-429d-8f61-681618d91f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019215321-172.17.0.18-1598645161309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-eb9c05f9-73cf-4278-9810-a8db967533c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-9ac1868e-6f87-46c4-8cef-fc074bcee36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-04624fd5-8847-459a-8bf0-b641d04809eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-27f210df-fe5e-4345-af64-3146252e0b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-57e5f062-74b5-4df7-b0c7-157afc4329a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-2b14e085-b88e-447f-9c02-bb95880c3499,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-4b126ba2-cf98-43e4-87ec-32af54880fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-9d657d6e-d005-429d-8f61-681618d91f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4988
