reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291616736-172.17.0.10-1598659500039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-308a04c2-cb39-42ed-897b-e3cff23a7684,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-4ee11218-6e33-4670-9223-81e77b57fe55,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-94a99a89-e0ff-4444-b2f6-5feb737b7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-5cfcfc69-965a-4a8a-91fd-de15fb16a184,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-a9bb8d18-113f-469b-a418-a82687dfa89e,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-45acd0cb-638b-4594-88e9-e306f7132714,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-50bb3a6f-935b-4b0b-8c3a-352ae2928e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-0bbda53a-9d78-4601-a0dd-78b0ec1096a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291616736-172.17.0.10-1598659500039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-308a04c2-cb39-42ed-897b-e3cff23a7684,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-4ee11218-6e33-4670-9223-81e77b57fe55,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-94a99a89-e0ff-4444-b2f6-5feb737b7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-5cfcfc69-965a-4a8a-91fd-de15fb16a184,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-a9bb8d18-113f-469b-a418-a82687dfa89e,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-45acd0cb-638b-4594-88e9-e306f7132714,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-50bb3a6f-935b-4b0b-8c3a-352ae2928e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-0bbda53a-9d78-4601-a0dd-78b0ec1096a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116083833-172.17.0.10-1598659576749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-e870c761-1d43-4eb1-a559-740d479f2995,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-77d7ea15-8906-4b68-8fc3-2bca2b5bb17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-8f4c7be8-281f-4798-9220-c33581d32834,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-1c40422a-af90-4309-abf2-7e825b57edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-f8ad5105-a7ba-47e3-ac03-0a02ce0b5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-ff677088-849f-4b78-806e-05a3f41212d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-44786c49-2f89-4497-8757-edeec628d464,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-ef5439cd-2f78-48df-bd24-cb760906f4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116083833-172.17.0.10-1598659576749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-e870c761-1d43-4eb1-a559-740d479f2995,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-77d7ea15-8906-4b68-8fc3-2bca2b5bb17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-8f4c7be8-281f-4798-9220-c33581d32834,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-1c40422a-af90-4309-abf2-7e825b57edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-f8ad5105-a7ba-47e3-ac03-0a02ce0b5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-ff677088-849f-4b78-806e-05a3f41212d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-44786c49-2f89-4497-8757-edeec628d464,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-ef5439cd-2f78-48df-bd24-cb760906f4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272755436-172.17.0.10-1598660296443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-51ab4b91-3fec-4ac0-a34c-8e905bc0cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-7d7ad9e6-a43f-47cb-a717-522e4ef969a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-0c95f6b9-f142-41fb-acb5-c20f1e547433,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-38e9209c-e66c-41ba-8a6d-6d905c19d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-b1eccc55-d352-4910-b8c0-cf907ea01ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-a7be71d1-4774-4dbd-90a6-a5bb1bf06b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-bcad2996-4ca0-47a3-851a-7f75118b2970,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-c3647f57-f855-4c8f-bdfd-9e47e17ea83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272755436-172.17.0.10-1598660296443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-51ab4b91-3fec-4ac0-a34c-8e905bc0cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-7d7ad9e6-a43f-47cb-a717-522e4ef969a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-0c95f6b9-f142-41fb-acb5-c20f1e547433,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-38e9209c-e66c-41ba-8a6d-6d905c19d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-b1eccc55-d352-4910-b8c0-cf907ea01ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-a7be71d1-4774-4dbd-90a6-a5bb1bf06b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-bcad2996-4ca0-47a3-851a-7f75118b2970,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-c3647f57-f855-4c8f-bdfd-9e47e17ea83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509966766-172.17.0.10-1598660427430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-06102f28-bf90-4b77-acb7-02ff4d1a483b,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-72f20b6c-8833-408e-95fa-f8162fbfb541,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-229358e6-6439-4b14-b8c0-8cee272db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-51a17057-31eb-4c14-ac2c-3eae1e1d0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6624a327-be45-4356-a203-601189673f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-05f6ca9a-1d36-4845-a980-c0de48dd01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-36bdafea-95a2-4fbf-aac7-8c24a0a58e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-ac86e871-b25b-4ab1-a53c-763f9ec7d82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509966766-172.17.0.10-1598660427430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-06102f28-bf90-4b77-acb7-02ff4d1a483b,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-72f20b6c-8833-408e-95fa-f8162fbfb541,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-229358e6-6439-4b14-b8c0-8cee272db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-51a17057-31eb-4c14-ac2c-3eae1e1d0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6624a327-be45-4356-a203-601189673f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-05f6ca9a-1d36-4845-a980-c0de48dd01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-36bdafea-95a2-4fbf-aac7-8c24a0a58e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-ac86e871-b25b-4ab1-a53c-763f9ec7d82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817916275-172.17.0.10-1598660494792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-b8570ec9-5e52-48cd-8c3c-71464085bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-d2ed58a8-3247-465e-91bb-9f6b4ea9149c,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-aba670ca-329f-425c-9479-9930f3653cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-0d9f1ffc-0919-4ae8-ac3f-68c854ad7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-fb8b43dd-b4b2-49e1-9c7b-88d903040168,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-7c96d8eb-118f-4bf7-8343-690bdddeae06,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-44ac263c-96be-48db-ac18-b97222b41bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-ad5a9d12-4031-454b-ae78-4b7e8bb51380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817916275-172.17.0.10-1598660494792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-b8570ec9-5e52-48cd-8c3c-71464085bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-d2ed58a8-3247-465e-91bb-9f6b4ea9149c,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-aba670ca-329f-425c-9479-9930f3653cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-0d9f1ffc-0919-4ae8-ac3f-68c854ad7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-fb8b43dd-b4b2-49e1-9c7b-88d903040168,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-7c96d8eb-118f-4bf7-8343-690bdddeae06,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-44ac263c-96be-48db-ac18-b97222b41bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-ad5a9d12-4031-454b-ae78-4b7e8bb51380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886456037-172.17.0.10-1598660860596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-c8583d95-06de-4d41-9c3e-f2a9bfb17899,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3a96282e-a6df-4140-816c-2a4b97dda81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-eced61cb-8250-46a4-a88a-1cd9e0bbd75d,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-4d85151b-0410-4fbe-8cad-48e1809226a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-713c7d10-a993-4920-a458-e835a0d31bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-46613156-7fb6-476e-ab60-fe5a1d095f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-2d5c0324-ddf7-4851-8fb7-3e5ac6f0609b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-be2b9c1a-5acb-4b5b-800f-d6695028fb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886456037-172.17.0.10-1598660860596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-c8583d95-06de-4d41-9c3e-f2a9bfb17899,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3a96282e-a6df-4140-816c-2a4b97dda81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-eced61cb-8250-46a4-a88a-1cd9e0bbd75d,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-4d85151b-0410-4fbe-8cad-48e1809226a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-713c7d10-a993-4920-a458-e835a0d31bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-46613156-7fb6-476e-ab60-fe5a1d095f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-2d5c0324-ddf7-4851-8fb7-3e5ac6f0609b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-be2b9c1a-5acb-4b5b-800f-d6695028fb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732992695-172.17.0.10-1598661445027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-d244a39b-ba74-4162-ad4d-382c8d1ab880,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-2d40f18b-2f82-4a21-aa3c-7f913f64fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-a268f390-4c7b-450e-88e8-4ce67e1549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-10109460-c0f4-4db6-96c9-95c0eac1e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-2320e252-f7ca-4444-a47b-e8822ebac67b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ee6a137c-3f4b-4426-a523-75eafcbb4755,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-c4d6ea94-8127-40bd-8079-7bef484945da,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-20a8afcd-7274-48a0-8bb9-d9512ff3c7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732992695-172.17.0.10-1598661445027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-d244a39b-ba74-4162-ad4d-382c8d1ab880,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-2d40f18b-2f82-4a21-aa3c-7f913f64fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-a268f390-4c7b-450e-88e8-4ce67e1549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-10109460-c0f4-4db6-96c9-95c0eac1e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-2320e252-f7ca-4444-a47b-e8822ebac67b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ee6a137c-3f4b-4426-a523-75eafcbb4755,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-c4d6ea94-8127-40bd-8079-7bef484945da,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-20a8afcd-7274-48a0-8bb9-d9512ff3c7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927788160-172.17.0.10-1598662053201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-dda342aa-ab08-4b19-a989-46ab9a2938ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c1bbdbff-8133-4448-9084-f5aded3a0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-eb699c9e-7387-4b8e-a47c-41a5a5c976bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-5ba93a37-1b77-4598-8388-8d74bce2f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-40038617-d543-48da-b179-fa0e315b7788,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-da3c6a21-ae5a-4c14-902f-ad7e1623c460,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-7b2beb81-28b8-40e6-8308-e89bd20c9fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-f46e532e-0e7d-4d7f-ac03-d83349e75d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927788160-172.17.0.10-1598662053201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-dda342aa-ab08-4b19-a989-46ab9a2938ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c1bbdbff-8133-4448-9084-f5aded3a0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-eb699c9e-7387-4b8e-a47c-41a5a5c976bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-5ba93a37-1b77-4598-8388-8d74bce2f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-40038617-d543-48da-b179-fa0e315b7788,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-da3c6a21-ae5a-4c14-902f-ad7e1623c460,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-7b2beb81-28b8-40e6-8308-e89bd20c9fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-f46e532e-0e7d-4d7f-ac03-d83349e75d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225285843-172.17.0.10-1598662133588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-02a1b27e-a652-4882-b3d4-1ff35a9dcd29,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-205f79f6-a870-426e-8c42-292417c9d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-71502e13-f6c9-4bc2-b328-4eb3059a0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-5b8ab0df-2392-42fa-99b6-c357e349e9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-730cf47e-def8-442a-9cee-fc983c052615,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-232f9ff1-6498-4211-b78a-ff78e9549869,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-e181a2a6-a5dc-4590-a82d-54089683c285,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8cbdfc61-cabe-40fe-95ad-ffc31e71b35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225285843-172.17.0.10-1598662133588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-02a1b27e-a652-4882-b3d4-1ff35a9dcd29,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-205f79f6-a870-426e-8c42-292417c9d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-71502e13-f6c9-4bc2-b328-4eb3059a0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-5b8ab0df-2392-42fa-99b6-c357e349e9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-730cf47e-def8-442a-9cee-fc983c052615,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-232f9ff1-6498-4211-b78a-ff78e9549869,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-e181a2a6-a5dc-4590-a82d-54089683c285,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8cbdfc61-cabe-40fe-95ad-ffc31e71b35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861857083-172.17.0.10-1598663221248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-0ba61cdf-cd66-421a-95c1-688311a0121b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0a361e83-9b30-467d-ba9b-dc36a8f584b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-6c8dfab2-8ba9-45c5-88e6-99a538246213,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-600d26b2-af78-4b9f-b468-b6d4e57809f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-579c3f9c-c9b7-439e-8c23-8a1ce314f871,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-793feb24-2cdc-4841-a181-f28e85f5c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-1831dbf0-caa1-4533-9098-17e0ba4f50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c36fdb63-89f2-488c-a7c2-a00b7d7656be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861857083-172.17.0.10-1598663221248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-0ba61cdf-cd66-421a-95c1-688311a0121b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0a361e83-9b30-467d-ba9b-dc36a8f584b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-6c8dfab2-8ba9-45c5-88e6-99a538246213,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-600d26b2-af78-4b9f-b468-b6d4e57809f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-579c3f9c-c9b7-439e-8c23-8a1ce314f871,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-793feb24-2cdc-4841-a181-f28e85f5c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-1831dbf0-caa1-4533-9098-17e0ba4f50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c36fdb63-89f2-488c-a7c2-a00b7d7656be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181734859-172.17.0.10-1598663783718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-0030d8e0-adc1-4f72-8fdc-5418774ee0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-b1678d91-8dae-4df5-b75d-6a5be7e45be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-2a81c918-2e50-4244-b754-e3ae1085d7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-5cf31efe-c3cb-469a-af3f-a95cafa3ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-a906e276-9101-4413-b8a8-2fa1d78851ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-9b302d88-790d-49bb-9aee-663d9d88a549,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-1356b6ab-9e8e-4cc4-a7a7-09537abda9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-1505db82-7d66-4a71-916f-e771bd50e860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181734859-172.17.0.10-1598663783718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-0030d8e0-adc1-4f72-8fdc-5418774ee0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-b1678d91-8dae-4df5-b75d-6a5be7e45be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-2a81c918-2e50-4244-b754-e3ae1085d7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-5cf31efe-c3cb-469a-af3f-a95cafa3ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-a906e276-9101-4413-b8a8-2fa1d78851ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-9b302d88-790d-49bb-9aee-663d9d88a549,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-1356b6ab-9e8e-4cc4-a7a7-09537abda9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-1505db82-7d66-4a71-916f-e771bd50e860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589140606-172.17.0.10-1598664243676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-c7f3e8cd-e920-4b39-96e2-d560d793f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-d4145af3-7dc6-4df0-9031-a09ebadd75d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-05b7df1f-9c79-45e8-9663-45fcfe594e53,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-06816a22-9c32-49f6-8f32-f37663b7ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-6e1578e1-3642-4ba5-828a-576e191b6630,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ac3f298e-9a03-4400-b77b-d12ae31b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-930e5373-0d1d-4ab8-92c3-6a6a8cbe46a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7ef5038b-6488-43ae-9b5f-462b06a13480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589140606-172.17.0.10-1598664243676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-c7f3e8cd-e920-4b39-96e2-d560d793f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-d4145af3-7dc6-4df0-9031-a09ebadd75d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-05b7df1f-9c79-45e8-9663-45fcfe594e53,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-06816a22-9c32-49f6-8f32-f37663b7ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-6e1578e1-3642-4ba5-828a-576e191b6630,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-ac3f298e-9a03-4400-b77b-d12ae31b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-930e5373-0d1d-4ab8-92c3-6a6a8cbe46a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7ef5038b-6488-43ae-9b5f-462b06a13480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98948232-172.17.0.10-1598664661186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-6ad878dc-e6d9-4193-8beb-bd5697d8062d,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-6a0d4f39-6f5e-4b10-bbf4-13fae0783be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-242aa9f9-fe4a-483d-84ff-62c42e2d8745,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-833cc597-7e79-4d23-9010-403debf88388,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-39525c27-3854-4c57-8e53-45eabb3acbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-d706095c-0971-45b8-b9f1-3b86f60d780c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c8477b0f-1fa8-4e7f-868c-a59dd16eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-2b0d655f-5cc0-4564-b9ba-9cea427dbd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98948232-172.17.0.10-1598664661186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-6ad878dc-e6d9-4193-8beb-bd5697d8062d,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-6a0d4f39-6f5e-4b10-bbf4-13fae0783be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-242aa9f9-fe4a-483d-84ff-62c42e2d8745,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-833cc597-7e79-4d23-9010-403debf88388,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-39525c27-3854-4c57-8e53-45eabb3acbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-d706095c-0971-45b8-b9f1-3b86f60d780c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c8477b0f-1fa8-4e7f-868c-a59dd16eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-2b0d655f-5cc0-4564-b9ba-9cea427dbd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5560
