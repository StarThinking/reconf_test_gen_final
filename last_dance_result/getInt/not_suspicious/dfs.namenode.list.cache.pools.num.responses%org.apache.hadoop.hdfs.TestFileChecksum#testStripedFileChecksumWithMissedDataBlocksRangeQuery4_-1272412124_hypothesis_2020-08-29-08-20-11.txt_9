reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843880190-172.17.0.20-1598689226552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-1a14568b-2134-43a6-a528-6c07a72b2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-9c43f0a4-d3f7-46cb-a792-cbeb0303949b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-883d81b8-ec51-455b-b2a9-7e0a451e9bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-aad3834a-f9ba-481f-a6ad-990f6612f864,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d597844d-45d9-444f-a47f-45eac2eb774f,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-45cc3b03-c4ac-4469-96ed-a9e609d1a96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-c5623bc8-8954-4770-9386-6c90479b043d,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-785d17dc-8982-4d6d-b7ba-236b73aebc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843880190-172.17.0.20-1598689226552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-1a14568b-2134-43a6-a528-6c07a72b2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-9c43f0a4-d3f7-46cb-a792-cbeb0303949b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-883d81b8-ec51-455b-b2a9-7e0a451e9bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-aad3834a-f9ba-481f-a6ad-990f6612f864,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d597844d-45d9-444f-a47f-45eac2eb774f,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-45cc3b03-c4ac-4469-96ed-a9e609d1a96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-c5623bc8-8954-4770-9386-6c90479b043d,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-785d17dc-8982-4d6d-b7ba-236b73aebc6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354663522-172.17.0.20-1598689767970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-b86c3a02-8db0-4c8a-8a27-32d020050113,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-75b6dea7-5e46-4e9b-a01e-83d720599779,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-b9a4056c-597c-4377-a857-c8e0fabd84a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-a3b6c156-1e27-4f4c-a959-7bec8b34f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a97e5a8d-2ea2-4288-8f3b-82c682f2aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-76b70176-2ab8-4e3d-8a0f-b4b433084949,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-b6ba2081-6a70-416f-9b6a-d015aab684d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-fc9f6113-8a9e-4a22-b498-5242e134b71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354663522-172.17.0.20-1598689767970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42056,DS-b86c3a02-8db0-4c8a-8a27-32d020050113,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-75b6dea7-5e46-4e9b-a01e-83d720599779,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-b9a4056c-597c-4377-a857-c8e0fabd84a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-a3b6c156-1e27-4f4c-a959-7bec8b34f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a97e5a8d-2ea2-4288-8f3b-82c682f2aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-76b70176-2ab8-4e3d-8a0f-b4b433084949,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-b6ba2081-6a70-416f-9b6a-d015aab684d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-fc9f6113-8a9e-4a22-b498-5242e134b71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203792956-172.17.0.20-1598690004536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-fa41f8d3-60de-4804-876a-4bd2a8047e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-dba49dbe-27c6-4d3c-a075-af4ecc185d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-78535dec-ca96-4e73-8c7b-d7fe73e9edca,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-7d3f82fe-b90e-42cc-8b3e-ac8dfe9d873e,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-cc2f1edd-c394-45c0-8d82-0c6f0e95e545,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-00591e9b-1b8c-40fe-a775-7264f51462d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-ae8b4c38-29df-4b6c-b171-8639e7891676,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4db3d670-5747-4bc0-b470-e5856ba2db60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203792956-172.17.0.20-1598690004536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-fa41f8d3-60de-4804-876a-4bd2a8047e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-dba49dbe-27c6-4d3c-a075-af4ecc185d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-78535dec-ca96-4e73-8c7b-d7fe73e9edca,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-7d3f82fe-b90e-42cc-8b3e-ac8dfe9d873e,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-cc2f1edd-c394-45c0-8d82-0c6f0e95e545,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-00591e9b-1b8c-40fe-a775-7264f51462d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-ae8b4c38-29df-4b6c-b171-8639e7891676,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4db3d670-5747-4bc0-b470-e5856ba2db60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611934166-172.17.0.20-1598690400339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-d00b104c-1ba4-4e03-804e-76793abdf4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-d49bc468-21f9-4591-91f8-52589d748c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-4299e13a-358c-4485-b24a-a4660369d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-096d128a-1c6d-44b7-bde6-5ce9c660d770,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0cdbbe7f-044e-4606-83e7-0e37b93c37a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-95ba844d-cab1-4e43-b397-ea0b7385436a,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-9ca54844-1e2f-43f2-b7b4-3e29046cae80,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-61241493-433e-436e-82ea-a9ed798ca1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611934166-172.17.0.20-1598690400339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-d00b104c-1ba4-4e03-804e-76793abdf4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-d49bc468-21f9-4591-91f8-52589d748c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-4299e13a-358c-4485-b24a-a4660369d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-096d128a-1c6d-44b7-bde6-5ce9c660d770,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0cdbbe7f-044e-4606-83e7-0e37b93c37a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-95ba844d-cab1-4e43-b397-ea0b7385436a,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-9ca54844-1e2f-43f2-b7b4-3e29046cae80,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-61241493-433e-436e-82ea-a9ed798ca1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393944148-172.17.0.20-1598690890068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-90b164af-cdfb-4eb1-9b11-d709d5daab32,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-a5d6fb18-ea71-41e5-be7b-3fa9303cb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-865a4a6c-948e-477b-8776-007c67bfe069,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-95eaae32-efe4-4a3b-b613-2651c164b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-d3b024f7-b150-4fef-a80c-32b467ee0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-badb0c4b-f4b1-469d-ba9b-d37a87b634ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b78e8188-c50f-4b0a-9b1e-f5fd076cce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-b4042318-f200-4fbb-bd6d-b1e056b07aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393944148-172.17.0.20-1598690890068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-90b164af-cdfb-4eb1-9b11-d709d5daab32,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-a5d6fb18-ea71-41e5-be7b-3fa9303cb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-865a4a6c-948e-477b-8776-007c67bfe069,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-95eaae32-efe4-4a3b-b613-2651c164b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-d3b024f7-b150-4fef-a80c-32b467ee0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-badb0c4b-f4b1-469d-ba9b-d37a87b634ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b78e8188-c50f-4b0a-9b1e-f5fd076cce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-b4042318-f200-4fbb-bd6d-b1e056b07aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896334913-172.17.0.20-1598690921575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-630155e3-e554-4551-a29b-93ebaa39707e,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-ae25631c-d389-4e3f-ba89-8fc81a4eac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-4e14f618-77f6-4ed7-b172-8df8d9c930d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-560f162b-34d4-4a63-b157-8d1e1cabc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-67665296-6423-4b85-8993-cfc8b2d929ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-67156918-7678-4dcd-a672-5443c5cb810d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-6a5e6579-4d46-4f69-9a6c-4b8c79cd87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-5dfadf80-a9a0-42cf-9997-17b26a6fe2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896334913-172.17.0.20-1598690921575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-630155e3-e554-4551-a29b-93ebaa39707e,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-ae25631c-d389-4e3f-ba89-8fc81a4eac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-4e14f618-77f6-4ed7-b172-8df8d9c930d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-560f162b-34d4-4a63-b157-8d1e1cabc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-67665296-6423-4b85-8993-cfc8b2d929ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-67156918-7678-4dcd-a672-5443c5cb810d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-6a5e6579-4d46-4f69-9a6c-4b8c79cd87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-5dfadf80-a9a0-42cf-9997-17b26a6fe2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060160320-172.17.0.20-1598690956332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-514d6b74-e1d5-478b-a5a1-593149f6997c,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-454242ab-b950-4476-bc5d-af291e80f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-e78521db-1c84-4362-b93d-606ecf588ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-1d64e1d2-5e72-484b-9386-6acfd21e4408,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-38e85931-08d3-4368-85a0-e3e6ece86d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-d49c2427-6c91-4adb-bcde-13f7de82ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-9208663d-a543-47ab-9944-7ed82ec2ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-c5384d67-73c8-4b39-ac53-26b6ec8c2222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060160320-172.17.0.20-1598690956332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-514d6b74-e1d5-478b-a5a1-593149f6997c,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-454242ab-b950-4476-bc5d-af291e80f55f,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-e78521db-1c84-4362-b93d-606ecf588ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-1d64e1d2-5e72-484b-9386-6acfd21e4408,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-38e85931-08d3-4368-85a0-e3e6ece86d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-d49c2427-6c91-4adb-bcde-13f7de82ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-9208663d-a543-47ab-9944-7ed82ec2ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-c5384d67-73c8-4b39-ac53-26b6ec8c2222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556204722-172.17.0.20-1598691319555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-3fdcc3da-13a0-4988-a789-347ba69d67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-629bd32a-b5ff-4544-a993-208961e3371e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-3e4bc2a3-0110-461a-bcc9-1b1199eae0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-12fa59e3-00d1-4a90-9b9c-e74fb7b21983,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-3f05879c-b4e4-40c2-a45a-61f27339a37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-163a5357-4876-4e35-b6d5-b052f04743bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-173a9c47-087a-4ba7-997b-5910e9273177,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-d28523cd-60aa-4ea6-b4f8-c0d8c88db8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556204722-172.17.0.20-1598691319555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-3fdcc3da-13a0-4988-a789-347ba69d67c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-629bd32a-b5ff-4544-a993-208961e3371e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-3e4bc2a3-0110-461a-bcc9-1b1199eae0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-12fa59e3-00d1-4a90-9b9c-e74fb7b21983,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-3f05879c-b4e4-40c2-a45a-61f27339a37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-163a5357-4876-4e35-b6d5-b052f04743bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-173a9c47-087a-4ba7-997b-5910e9273177,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-d28523cd-60aa-4ea6-b4f8-c0d8c88db8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919443392-172.17.0.20-1598691452772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-43f6bebe-da8b-473f-8e36-76ceb04a4868,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-35792865-6992-4d9b-a533-c4779a998cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-38944bb6-6720-438c-9de4-12aa61f67e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1aaeb9fc-c06a-45e5-a384-bd888ad39888,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-daa99070-7c71-4fed-88f0-37445163b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-4c01adca-894e-4839-a187-4417a47ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-c65a0391-82ee-46f1-b1dd-621589ac3d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-c2a017bc-efb9-4245-9346-56876ae48cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919443392-172.17.0.20-1598691452772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-43f6bebe-da8b-473f-8e36-76ceb04a4868,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-35792865-6992-4d9b-a533-c4779a998cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-38944bb6-6720-438c-9de4-12aa61f67e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1aaeb9fc-c06a-45e5-a384-bd888ad39888,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-daa99070-7c71-4fed-88f0-37445163b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-4c01adca-894e-4839-a187-4417a47ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-c65a0391-82ee-46f1-b1dd-621589ac3d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-c2a017bc-efb9-4245-9346-56876ae48cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64653939-172.17.0.20-1598691624581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-ca837e04-f173-4666-b780-170e4eebef38,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-86b8075d-5fd3-40d3-b944-9ba37a07caad,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a7b3503b-8e36-4b6a-9784-92e60e972ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-eb1d4635-ff75-4e08-8c77-43e1a6989140,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-03035099-f114-492f-b434-a2fc7b71cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-69a4aef9-2097-4a43-b4b9-e2db44bae4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-4abc6830-a9ba-4e58-9927-ced5118c3313,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-ede5079a-511b-4aed-856a-0b9e15bf05b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64653939-172.17.0.20-1598691624581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-ca837e04-f173-4666-b780-170e4eebef38,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-86b8075d-5fd3-40d3-b944-9ba37a07caad,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-a7b3503b-8e36-4b6a-9784-92e60e972ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-eb1d4635-ff75-4e08-8c77-43e1a6989140,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-03035099-f114-492f-b434-a2fc7b71cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-69a4aef9-2097-4a43-b4b9-e2db44bae4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-4abc6830-a9ba-4e58-9927-ced5118c3313,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-ede5079a-511b-4aed-856a-0b9e15bf05b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941567534-172.17.0.20-1598691956093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-7247f61e-9c91-4e1f-ab16-879302ef03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-fd168858-79b6-46c6-a3c4-72717458a037,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-80cbfcd5-0187-4f07-8d96-8735a7f0c67f,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-3e005acd-89b8-4e79-be55-4c7e9d41da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4c7d079a-ea24-4ac6-bb1e-354bdf10c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-1bb91c52-5122-4718-8ce8-66063bea88be,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-f741404f-b1ef-413d-91b3-c766c17ed84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-18fb7470-9a40-4ea0-a3c2-4acd200ad9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941567534-172.17.0.20-1598691956093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-7247f61e-9c91-4e1f-ab16-879302ef03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-fd168858-79b6-46c6-a3c4-72717458a037,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-80cbfcd5-0187-4f07-8d96-8735a7f0c67f,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-3e005acd-89b8-4e79-be55-4c7e9d41da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-4c7d079a-ea24-4ac6-bb1e-354bdf10c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-1bb91c52-5122-4718-8ce8-66063bea88be,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-f741404f-b1ef-413d-91b3-c766c17ed84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-18fb7470-9a40-4ea0-a3c2-4acd200ad9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343083542-172.17.0.20-1598692023183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-4130b8ad-4818-437a-ac39-b1296391719a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-177bafe1-8ca3-4e8a-94a7-62885ec9ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-6a0287f6-c61d-4f7d-a46c-e98a585686f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-7e0ac166-9a72-466e-9459-447fdc8b12f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-8bba26a6-35e8-4569-8ae5-a93226fd2031,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-101da342-225d-4cea-a3af-8c71239fdd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-6f4b952f-2c4f-490a-90f6-54ab39c64562,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-c4427810-e145-454d-81fc-c73c4a2543fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343083542-172.17.0.20-1598692023183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-4130b8ad-4818-437a-ac39-b1296391719a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-177bafe1-8ca3-4e8a-94a7-62885ec9ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-6a0287f6-c61d-4f7d-a46c-e98a585686f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-7e0ac166-9a72-466e-9459-447fdc8b12f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-8bba26a6-35e8-4569-8ae5-a93226fd2031,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-101da342-225d-4cea-a3af-8c71239fdd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-6f4b952f-2c4f-490a-90f6-54ab39c64562,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-c4427810-e145-454d-81fc-c73c4a2543fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015506195-172.17.0.20-1598692236747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-b205f24c-d171-4320-9afa-128e26df02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3610415c-a141-46d6-b3c4-a442add2c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-719f1aeb-1889-46f9-be8c-138b7b0f2ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-6308e840-ae39-40f0-9013-942057bbc364,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-4525b388-f892-40e2-8f81-c956be92163f,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-cbbd2ef8-4382-4cd3-83fc-18fedf687c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-decfafa1-2695-4a3a-8a1b-1bb63ce3b0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c3891ed2-6846-4ea8-be7a-dc018d64cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015506195-172.17.0.20-1598692236747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-b205f24c-d171-4320-9afa-128e26df02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3610415c-a141-46d6-b3c4-a442add2c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-719f1aeb-1889-46f9-be8c-138b7b0f2ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-6308e840-ae39-40f0-9013-942057bbc364,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-4525b388-f892-40e2-8f81-c956be92163f,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-cbbd2ef8-4382-4cd3-83fc-18fedf687c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-decfafa1-2695-4a3a-8a1b-1bb63ce3b0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c3891ed2-6846-4ea8-be7a-dc018d64cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841240394-172.17.0.20-1598692697951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-4a349004-fb0b-444b-8e5e-423f751d0c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-0a663cd1-4b2d-411b-b946-65db3e51e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5bf83638-7d0e-447c-bcdd-34ca3a77350e,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-c7a42644-62b8-4614-8d23-32006319f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-4aa2f63b-0bbe-45fb-beeb-521f60993638,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-f9590221-a1b6-4512-bbcf-06e3738bfd68,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f1f842a0-39d7-44e9-8233-f96ba188a075,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-c96ac196-c878-4f59-8e82-8bff0c3dd55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841240394-172.17.0.20-1598692697951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-4a349004-fb0b-444b-8e5e-423f751d0c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-0a663cd1-4b2d-411b-b946-65db3e51e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-5bf83638-7d0e-447c-bcdd-34ca3a77350e,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-c7a42644-62b8-4614-8d23-32006319f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-4aa2f63b-0bbe-45fb-beeb-521f60993638,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-f9590221-a1b6-4512-bbcf-06e3738bfd68,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f1f842a0-39d7-44e9-8233-f96ba188a075,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-c96ac196-c878-4f59-8e82-8bff0c3dd55d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808117022-172.17.0.20-1598693002002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-19285d3b-fda6-423b-839d-82946e9c243c,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-fee34e73-328d-4c04-ba2f-6b03604a61a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-38db7c6a-6cd2-4817-a32e-69d6dfe1dcba,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-1b5afa93-bb6c-4696-8298-b2623560320e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-238b1163-ee91-4ac2-abe3-c45a6cb6862b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-ec28821f-dbf3-48f5-a042-f23753e36b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-7391e88d-0652-4090-9869-1b10292200b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-29826ea3-0a4d-48e8-8558-7e26524cc560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808117022-172.17.0.20-1598693002002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-19285d3b-fda6-423b-839d-82946e9c243c,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-fee34e73-328d-4c04-ba2f-6b03604a61a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-38db7c6a-6cd2-4817-a32e-69d6dfe1dcba,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-1b5afa93-bb6c-4696-8298-b2623560320e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-238b1163-ee91-4ac2-abe3-c45a6cb6862b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-ec28821f-dbf3-48f5-a042-f23753e36b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-7391e88d-0652-4090-9869-1b10292200b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-29826ea3-0a4d-48e8-8558-7e26524cc560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007632806-172.17.0.20-1598693671430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-54fa0d84-4b85-4346-94b1-19240b039c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-997bd2a5-cc87-4391-851d-2e207b7dea68,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-c24ea521-5539-49bc-9d6f-c4b43f747160,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-10d24538-330d-46a9-9174-572134382be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-3881963a-5d5a-4518-85ed-57f2c23e36fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-d0aa3947-7c48-4d9a-93b0-83570b38f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-340b62d1-2494-4bb2-ac6d-7f837d37de09,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-b8e282c9-7eb5-47ab-b043-6f031c775879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007632806-172.17.0.20-1598693671430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-54fa0d84-4b85-4346-94b1-19240b039c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-997bd2a5-cc87-4391-851d-2e207b7dea68,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-c24ea521-5539-49bc-9d6f-c4b43f747160,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-10d24538-330d-46a9-9174-572134382be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-3881963a-5d5a-4518-85ed-57f2c23e36fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-d0aa3947-7c48-4d9a-93b0-83570b38f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-340b62d1-2494-4bb2-ac6d-7f837d37de09,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-b8e282c9-7eb5-47ab-b043-6f031c775879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299639445-172.17.0.20-1598693929444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-2314c0df-df0d-4550-9e46-792273e4548f,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-bd19ea19-36be-471c-8257-b91165f1d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-2418a92e-4681-4ae0-9a1a-4bd503298a82,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-704ec9ca-cb58-4cc5-ad73-1690e9bbc839,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-3a0a3641-48a2-429a-9757-31df97f866d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-874c6355-edeb-49bf-9d90-874a5cdf398b,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-a6e9d7fa-c683-451b-b353-80dcbd122058,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-269d9d69-b550-4e9c-b8eb-e72a2a38c980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299639445-172.17.0.20-1598693929444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-2314c0df-df0d-4550-9e46-792273e4548f,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-bd19ea19-36be-471c-8257-b91165f1d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-2418a92e-4681-4ae0-9a1a-4bd503298a82,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-704ec9ca-cb58-4cc5-ad73-1690e9bbc839,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-3a0a3641-48a2-429a-9757-31df97f866d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-874c6355-edeb-49bf-9d90-874a5cdf398b,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-a6e9d7fa-c683-451b-b353-80dcbd122058,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-269d9d69-b550-4e9c-b8eb-e72a2a38c980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849940281-172.17.0.20-1598694065955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-ff906f8c-59d7-4bc1-873e-21402f9a7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-b4c15738-a704-4cf6-96f0-daf233b2d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-80810ca3-b155-473e-903e-44a793f117c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-d3d7e721-858d-48de-905d-efa4cafd5ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-19291a11-57d9-4739-87ad-e2b8a04e0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-7b1cc06b-19ad-4155-a9fe-745db9c363dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-a5d39f60-7101-42ca-a18e-ed1309f5ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-4eb76106-16e9-4c94-bc97-d454e4d2d081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849940281-172.17.0.20-1598694065955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-ff906f8c-59d7-4bc1-873e-21402f9a7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-b4c15738-a704-4cf6-96f0-daf233b2d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-80810ca3-b155-473e-903e-44a793f117c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-d3d7e721-858d-48de-905d-efa4cafd5ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-19291a11-57d9-4739-87ad-e2b8a04e0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-7b1cc06b-19ad-4155-a9fe-745db9c363dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-a5d39f60-7101-42ca-a18e-ed1309f5ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-4eb76106-16e9-4c94-bc97-d454e4d2d081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5229
