reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647492934-172.17.0.12-1598548719970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-ff1daa4f-dcf1-4996-82ba-f589a59c90e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-703aaa08-a110-4844-ae16-a865a9f8995f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d9308100-59db-4e40-8e52-c59e83fa9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-ad8dfb00-f017-4d6e-b6dc-5eb39292ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-3df97c15-1b26-495b-acce-78b039b6ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c4e246b3-8ba4-4987-9345-779c36b416f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-c3d4b9e1-b7d5-491d-8919-3530c7f98bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-574e69e8-33aa-4692-82ef-59ee9716351f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647492934-172.17.0.12-1598548719970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-ff1daa4f-dcf1-4996-82ba-f589a59c90e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-703aaa08-a110-4844-ae16-a865a9f8995f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d9308100-59db-4e40-8e52-c59e83fa9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-ad8dfb00-f017-4d6e-b6dc-5eb39292ebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-3df97c15-1b26-495b-acce-78b039b6ef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c4e246b3-8ba4-4987-9345-779c36b416f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-c3d4b9e1-b7d5-491d-8919-3530c7f98bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-574e69e8-33aa-4692-82ef-59ee9716351f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754233360-172.17.0.12-1598549397224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35443,DS-470c20d5-7fad-4aba-b276-3ecd14c52f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-bf81aa9c-d8dd-4ce0-869f-6ab08c001422,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-8cf32809-108c-4073-ba22-86856f6bca85,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-ab287077-c46c-4ec3-b223-9f73a31033e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-47c2542d-b01c-4026-afd9-2e2bd42ec20a,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-2d1062b8-1007-42c1-8556-b78cbe818d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c000f5bc-e4c5-43a8-b903-397afde41257,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-6972fb95-b127-4a14-bfce-b439c3f82639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754233360-172.17.0.12-1598549397224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35443,DS-470c20d5-7fad-4aba-b276-3ecd14c52f88,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-bf81aa9c-d8dd-4ce0-869f-6ab08c001422,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-8cf32809-108c-4073-ba22-86856f6bca85,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-ab287077-c46c-4ec3-b223-9f73a31033e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-47c2542d-b01c-4026-afd9-2e2bd42ec20a,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-2d1062b8-1007-42c1-8556-b78cbe818d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-c000f5bc-e4c5-43a8-b903-397afde41257,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-6972fb95-b127-4a14-bfce-b439c3f82639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88030703-172.17.0.12-1598549967721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-6fba46cb-0ea2-4f9e-8685-a3470539dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-6f60f3ac-eb0d-4a67-a849-f829999a4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-f0833682-7d3d-4ed2-a441-c6a53e8eefdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-a4563b04-d430-48c9-bc16-b9bc08c83dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-c39331b6-bbee-4712-a482-ad80a53044e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9bc45646-5b1a-4f69-970b-51676ffdeedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-2ae9acf0-ae53-4203-8cbd-c5b421bd3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-27c560d2-559a-46cc-aced-f60a22d9f503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88030703-172.17.0.12-1598549967721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-6fba46cb-0ea2-4f9e-8685-a3470539dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-6f60f3ac-eb0d-4a67-a849-f829999a4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-f0833682-7d3d-4ed2-a441-c6a53e8eefdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-a4563b04-d430-48c9-bc16-b9bc08c83dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-c39331b6-bbee-4712-a482-ad80a53044e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-9bc45646-5b1a-4f69-970b-51676ffdeedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-2ae9acf0-ae53-4203-8cbd-c5b421bd3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-27c560d2-559a-46cc-aced-f60a22d9f503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105590839-172.17.0.12-1598550789761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-e725f32a-1573-43db-b4ee-97370c83fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-15d65dcf-2b39-4d35-8b47-69a6224dff04,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-d75c9bff-5b83-43e6-b18d-79f6b6c7f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-ca4a604a-d0d4-4f94-bf2e-4e4a89556474,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-45185e7c-2bbf-4aac-9b7c-69d5c626867e,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-4d5413d0-0c0b-4e72-a89d-b08c54a436be,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-bf0e2aa4-f0ed-42b2-8c86-ab5412cb0345,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-9672057e-c063-496c-8998-3da97896c04d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105590839-172.17.0.12-1598550789761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-e725f32a-1573-43db-b4ee-97370c83fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-15d65dcf-2b39-4d35-8b47-69a6224dff04,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-d75c9bff-5b83-43e6-b18d-79f6b6c7f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-ca4a604a-d0d4-4f94-bf2e-4e4a89556474,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-45185e7c-2bbf-4aac-9b7c-69d5c626867e,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-4d5413d0-0c0b-4e72-a89d-b08c54a436be,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-bf0e2aa4-f0ed-42b2-8c86-ab5412cb0345,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-9672057e-c063-496c-8998-3da97896c04d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802309549-172.17.0.12-1598550992226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-e7b1f34c-8c31-4212-aa5c-a1a278066761,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-1ee706d5-9565-4644-89ec-6e0c7bcb7245,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-2dcb905b-e5fd-41c0-a3f2-a2b7aec30612,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-5bfbe036-ed2b-46d3-aa50-b968cd73a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-31713196-48a8-4ffa-b97f-0e69bff4062c,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-007c28ed-08e0-44a8-8f58-5e2c412af0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-a63d1a3e-daf5-494d-8ec6-b178b0f48e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8c860821-2afd-4c80-881f-4481dee0fc3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802309549-172.17.0.12-1598550992226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34219,DS-e7b1f34c-8c31-4212-aa5c-a1a278066761,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-1ee706d5-9565-4644-89ec-6e0c7bcb7245,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-2dcb905b-e5fd-41c0-a3f2-a2b7aec30612,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-5bfbe036-ed2b-46d3-aa50-b968cd73a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-31713196-48a8-4ffa-b97f-0e69bff4062c,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-007c28ed-08e0-44a8-8f58-5e2c412af0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-a63d1a3e-daf5-494d-8ec6-b178b0f48e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8c860821-2afd-4c80-881f-4481dee0fc3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738894241-172.17.0.12-1598551219328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-d7eb4917-b2ad-404d-9b27-1f39ca3f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-b4bfe2cb-cb78-4606-aef1-6f9474df6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9c5263b1-e0f7-4f5c-b99b-5284baff2c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-ead6a40f-54a5-40d1-bee0-25531ba01a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-6235f386-4256-40c3-b80d-04a1cdd8aded,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-99c859be-fe7e-4e6c-9d1d-8c98d12a30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-6607e75c-d356-4356-86f8-4c69c78bb2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-438dbc8e-1d8f-453a-ac10-6e62bb7f66bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738894241-172.17.0.12-1598551219328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-d7eb4917-b2ad-404d-9b27-1f39ca3f7786,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-b4bfe2cb-cb78-4606-aef1-6f9474df6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-9c5263b1-e0f7-4f5c-b99b-5284baff2c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-ead6a40f-54a5-40d1-bee0-25531ba01a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-6235f386-4256-40c3-b80d-04a1cdd8aded,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-99c859be-fe7e-4e6c-9d1d-8c98d12a30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-6607e75c-d356-4356-86f8-4c69c78bb2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-438dbc8e-1d8f-453a-ac10-6e62bb7f66bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768540695-172.17.0.12-1598551447253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-f7374c51-3bfa-484d-bdb0-be8dd19fcc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-bd50b2cd-d715-42c8-8aae-93b54006551f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-41c1f96a-f8e0-4369-8bab-cf6d9bb2e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-4db9878b-db85-49fa-b363-0676d380c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-bc3ae6d4-d1ad-42bd-ba03-332e73146ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-d3867ff2-f73e-4776-b02e-a0d2e90af978,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-76691575-0605-450f-99eb-14f0a32f21fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-55b1dac2-65e6-4b07-b24b-633cc663b30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768540695-172.17.0.12-1598551447253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-f7374c51-3bfa-484d-bdb0-be8dd19fcc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-bd50b2cd-d715-42c8-8aae-93b54006551f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-41c1f96a-f8e0-4369-8bab-cf6d9bb2e1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-4db9878b-db85-49fa-b363-0676d380c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-bc3ae6d4-d1ad-42bd-ba03-332e73146ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-d3867ff2-f73e-4776-b02e-a0d2e90af978,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-76691575-0605-450f-99eb-14f0a32f21fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-55b1dac2-65e6-4b07-b24b-633cc663b30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461878610-172.17.0.12-1598552199393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-1b032bd8-72d9-4da8-8710-50ff3c636c74,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-b376ef1d-f897-4cc7-b512-76e2a2ed6799,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-47cc7569-f79d-48cb-8b37-a53c20d17bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-e53c8d78-15f7-47b9-b7ff-d2fb627faf51,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-318418c4-38ee-40d0-ae6e-0002ab30c00e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-adcc778f-7432-4dd1-9862-cb0f603b1023,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-7bd6d92b-4d16-4a1f-a7a4-e2b78bf36b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-87b544ad-b0ab-41c4-a4f1-f90130f2cd82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461878610-172.17.0.12-1598552199393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-1b032bd8-72d9-4da8-8710-50ff3c636c74,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-b376ef1d-f897-4cc7-b512-76e2a2ed6799,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-47cc7569-f79d-48cb-8b37-a53c20d17bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-e53c8d78-15f7-47b9-b7ff-d2fb627faf51,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-318418c4-38ee-40d0-ae6e-0002ab30c00e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-adcc778f-7432-4dd1-9862-cb0f603b1023,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-7bd6d92b-4d16-4a1f-a7a4-e2b78bf36b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-87b544ad-b0ab-41c4-a4f1-f90130f2cd82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77674268-172.17.0.12-1598553016619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-04662b78-225d-4b21-8d24-ef952467360f,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-7d8cfb72-18a5-46a3-83df-460c18fe62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-09e17222-d8f7-4703-b04f-6819523560b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-eb3aa4f2-ad7b-43b6-acfb-ab5c3a03afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d35c249e-63d2-4129-a0cf-b2c8370380e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-ac00c5cc-f8e0-4962-afb5-a4a50d52d686,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-72690f22-05b9-4b6c-a70b-49b924b3f406,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-4b4448a2-249e-40a6-81b2-f23ac24e5f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77674268-172.17.0.12-1598553016619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-04662b78-225d-4b21-8d24-ef952467360f,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-7d8cfb72-18a5-46a3-83df-460c18fe62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-09e17222-d8f7-4703-b04f-6819523560b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-eb3aa4f2-ad7b-43b6-acfb-ab5c3a03afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d35c249e-63d2-4129-a0cf-b2c8370380e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-ac00c5cc-f8e0-4962-afb5-a4a50d52d686,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-72690f22-05b9-4b6c-a70b-49b924b3f406,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-4b4448a2-249e-40a6-81b2-f23ac24e5f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998016362-172.17.0.12-1598553069937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-c5544379-68c6-4388-8148-d79b473cf4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-d938a1ce-00b1-4b7e-b516-3e2e991f5ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-168a30bf-7ba5-4f3d-a757-dc12f8e175e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-d02cddb6-d8b5-41f3-a70f-70189be976a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-352c5bbb-e2cf-4bfe-ac7d-dbd6c2c7e058,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-31e1e81a-17b3-4771-82cb-271b52ce2b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-af95e5ac-af31-4c07-997f-90c938fe78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-3875b643-6574-4120-a437-853364ac5e73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998016362-172.17.0.12-1598553069937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-c5544379-68c6-4388-8148-d79b473cf4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-d938a1ce-00b1-4b7e-b516-3e2e991f5ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-168a30bf-7ba5-4f3d-a757-dc12f8e175e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-d02cddb6-d8b5-41f3-a70f-70189be976a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-352c5bbb-e2cf-4bfe-ac7d-dbd6c2c7e058,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-31e1e81a-17b3-4771-82cb-271b52ce2b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-af95e5ac-af31-4c07-997f-90c938fe78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-3875b643-6574-4120-a437-853364ac5e73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792388888-172.17.0.12-1598553320180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-4ba81b2c-7aa9-44d4-ba61-4cff77c421d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-087b8d52-4673-4ebf-9c99-26dd3631dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-0f98c513-6c23-426a-a589-a31af8d21d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1490d050-ad39-4a89-a0d6-fbf76d100385,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-09750d20-aaf6-4bb5-bdd0-698b4b7a086b,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-605e9bc1-912a-406d-8b83-3f4ea234de61,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-d93288cd-f556-4f80-8807-4c9b943dfe61,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-73a5d7a4-ee76-4e8c-9daf-674451c22d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792388888-172.17.0.12-1598553320180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-4ba81b2c-7aa9-44d4-ba61-4cff77c421d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-087b8d52-4673-4ebf-9c99-26dd3631dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-0f98c513-6c23-426a-a589-a31af8d21d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1490d050-ad39-4a89-a0d6-fbf76d100385,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-09750d20-aaf6-4bb5-bdd0-698b4b7a086b,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-605e9bc1-912a-406d-8b83-3f4ea234de61,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-d93288cd-f556-4f80-8807-4c9b943dfe61,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-73a5d7a4-ee76-4e8c-9daf-674451c22d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733603632-172.17.0.12-1598553379666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-7fd991e5-bb36-4be3-9386-e5208577b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-a5935638-3b5c-42da-a611-1d030357bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-fca3ee8e-f909-412d-8fa8-e3213f29c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-56b3d1fc-5d1c-46c6-b5a9-78d896f2b396,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-edfd3228-1e93-4e48-ad66-748ca877c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-cc00a844-a51c-4a8b-8781-9fdf46e6336e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-c0e0537f-d454-4a2a-a583-8a121d43c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-a1bf88e9-64fe-441e-8399-4286a0a1e1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733603632-172.17.0.12-1598553379666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-7fd991e5-bb36-4be3-9386-e5208577b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-a5935638-3b5c-42da-a611-1d030357bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-fca3ee8e-f909-412d-8fa8-e3213f29c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-56b3d1fc-5d1c-46c6-b5a9-78d896f2b396,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-edfd3228-1e93-4e48-ad66-748ca877c3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-cc00a844-a51c-4a8b-8781-9fdf46e6336e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-c0e0537f-d454-4a2a-a583-8a121d43c84a,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-a1bf88e9-64fe-441e-8399-4286a0a1e1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5145
