reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043737751-172.17.0.15-1598608708405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-3c9187ee-f5cd-4e7b-847f-57529dc9d844,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-47c78c81-5373-4f81-94bf-bc1a9bff2192,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-701dfad8-e0de-4b17-9bfa-7fee1d327180,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-20875b1f-9b06-4ea9-9e86-5c21b52381c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-ac788ec5-eb5b-42be-b552-0094eb42a183,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-8b676b1f-926a-40bb-b941-04ef9a8d13b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-a1fcdc10-69e0-4693-8d78-1c1a864f3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-e0894bf3-7984-4acf-9fa5-63fd228318a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043737751-172.17.0.15-1598608708405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-3c9187ee-f5cd-4e7b-847f-57529dc9d844,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-47c78c81-5373-4f81-94bf-bc1a9bff2192,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-701dfad8-e0de-4b17-9bfa-7fee1d327180,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-20875b1f-9b06-4ea9-9e86-5c21b52381c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-ac788ec5-eb5b-42be-b552-0094eb42a183,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-8b676b1f-926a-40bb-b941-04ef9a8d13b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-a1fcdc10-69e0-4693-8d78-1c1a864f3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-e0894bf3-7984-4acf-9fa5-63fd228318a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820215537-172.17.0.15-1598608987743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42802,DS-c7255306-143a-40d2-b2e3-85f19490fe94,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-d184570a-7132-440f-baf6-3b3f1782f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-4d8d34ef-1063-4178-b62b-96d211f92b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-4f709149-a884-414a-b4ca-fe055bb7c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2869fd68-b81b-406a-9d23-b7dc68db23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-72d87ea4-8908-4818-a39c-a78577464ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-8b14ae73-d0fc-430c-b535-a54927c154a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-1ccb5b46-4a20-47b9-918b-69e6ff19c8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820215537-172.17.0.15-1598608987743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42802,DS-c7255306-143a-40d2-b2e3-85f19490fe94,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-d184570a-7132-440f-baf6-3b3f1782f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-4d8d34ef-1063-4178-b62b-96d211f92b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-4f709149-a884-414a-b4ca-fe055bb7c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2869fd68-b81b-406a-9d23-b7dc68db23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-72d87ea4-8908-4818-a39c-a78577464ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-8b14ae73-d0fc-430c-b535-a54927c154a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-1ccb5b46-4a20-47b9-918b-69e6ff19c8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777615717-172.17.0.15-1598609612858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-33ab8470-8f25-4559-af17-812571c02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-a4083536-eb87-4caa-aa2a-e5c40ecf4cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-ddcd0f31-f29f-434e-8ef5-4509b9a12bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-ff1e3e6a-bd2b-4103-8f07-df9ab71f503a,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-1949067d-acc6-445d-b1c9-7eeef72f3374,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-5a31b9df-14f5-4213-b733-5a80ab3d17ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-d022b2c4-1e2d-46ba-bf31-2b82340c7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-70eb2df5-f621-4108-8c89-49970e7b6c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777615717-172.17.0.15-1598609612858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-33ab8470-8f25-4559-af17-812571c02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-a4083536-eb87-4caa-aa2a-e5c40ecf4cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-ddcd0f31-f29f-434e-8ef5-4509b9a12bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-ff1e3e6a-bd2b-4103-8f07-df9ab71f503a,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-1949067d-acc6-445d-b1c9-7eeef72f3374,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-5a31b9df-14f5-4213-b733-5a80ab3d17ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-d022b2c4-1e2d-46ba-bf31-2b82340c7e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-70eb2df5-f621-4108-8c89-49970e7b6c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638940023-172.17.0.15-1598609689221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-4d13c13a-48f3-4eb7-9930-069ee7b1deff,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a5ead184-69cd-4571-929b-691c79eca908,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-4e966cb8-5356-4f11-8df3-27227adb7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-bc6556f5-60de-47d0-b856-ce80d11f8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-5a66da7b-8023-4d28-b60f-5f7f4991a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-89f7906f-abef-46c4-95da-c1f861c502e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-a1e11850-8dae-419e-8d1d-2ee60031a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-04317087-07a8-4b16-b870-1f9eba6e0ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638940023-172.17.0.15-1598609689221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-4d13c13a-48f3-4eb7-9930-069ee7b1deff,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a5ead184-69cd-4571-929b-691c79eca908,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-4e966cb8-5356-4f11-8df3-27227adb7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-bc6556f5-60de-47d0-b856-ce80d11f8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-5a66da7b-8023-4d28-b60f-5f7f4991a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-89f7906f-abef-46c4-95da-c1f861c502e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-a1e11850-8dae-419e-8d1d-2ee60031a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-04317087-07a8-4b16-b870-1f9eba6e0ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802888775-172.17.0.15-1598609726803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-321c9894-1a72-42dd-b51e-932fef71fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-c37c4768-ab36-4eca-b734-aa429b4001fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-2a6a01bc-405d-45c7-a599-39613b8350df,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-596d704c-c07d-49cd-8d4c-60b65e33d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-cb40d5e1-ea94-4b6f-8384-be409cad7d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-9ccd39cf-75cf-4819-b20f-b82443901986,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-6cc362ad-4885-4e74-9cac-116836a29064,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-22a6ee4a-7353-4a4b-8ae6-64ad32260c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802888775-172.17.0.15-1598609726803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-321c9894-1a72-42dd-b51e-932fef71fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-c37c4768-ab36-4eca-b734-aa429b4001fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-2a6a01bc-405d-45c7-a599-39613b8350df,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-596d704c-c07d-49cd-8d4c-60b65e33d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-cb40d5e1-ea94-4b6f-8384-be409cad7d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-9ccd39cf-75cf-4819-b20f-b82443901986,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-6cc362ad-4885-4e74-9cac-116836a29064,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-22a6ee4a-7353-4a4b-8ae6-64ad32260c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701475195-172.17.0.15-1598611662399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-00aaa43d-1cba-425d-94f4-9de8d16edbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-08e9241f-ee7e-4b2c-80f2-5f24132b9290,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-45421c96-c626-4f31-b089-d1cccaa12c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-fdce419e-a155-4424-91d3-751dfb43dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-b7786a6f-eadb-4c3a-8f34-8bd728a32880,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-ced63069-285c-4e39-9398-65fceb4a062e,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-e98af2fb-8f40-4a01-8e25-43a10553999a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-8051b9da-2110-422c-995d-90224a56f38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701475195-172.17.0.15-1598611662399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-00aaa43d-1cba-425d-94f4-9de8d16edbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-08e9241f-ee7e-4b2c-80f2-5f24132b9290,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-45421c96-c626-4f31-b089-d1cccaa12c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-fdce419e-a155-4424-91d3-751dfb43dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-b7786a6f-eadb-4c3a-8f34-8bd728a32880,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-ced63069-285c-4e39-9398-65fceb4a062e,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-e98af2fb-8f40-4a01-8e25-43a10553999a,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-8051b9da-2110-422c-995d-90224a56f38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020833263-172.17.0.15-1598612255950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-060dbccf-ce8e-4e73-9153-75644db61722,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-85a8b34d-e08b-4472-9c17-83ae88f7c219,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-c461e55b-820f-4fe2-a4b5-9556d201b773,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-a8e99dba-7be3-4d68-b006-58ab6a6bfc06,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-76aab10f-0410-418c-8f08-ff747f736f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-2872810f-e8e9-45ca-aecf-891aa796d0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-fd002bf8-32ca-4002-85ca-10c1a36b422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-3b95147c-26e8-49d6-874e-75089268d947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020833263-172.17.0.15-1598612255950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-060dbccf-ce8e-4e73-9153-75644db61722,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-85a8b34d-e08b-4472-9c17-83ae88f7c219,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-c461e55b-820f-4fe2-a4b5-9556d201b773,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-a8e99dba-7be3-4d68-b006-58ab6a6bfc06,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-76aab10f-0410-418c-8f08-ff747f736f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-2872810f-e8e9-45ca-aecf-891aa796d0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-fd002bf8-32ca-4002-85ca-10c1a36b422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-3b95147c-26e8-49d6-874e-75089268d947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800933734-172.17.0.15-1598612565833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-75c6b52c-4701-4111-a542-c099a12dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-3f7f6152-f292-4df8-b520-e0b6c2ad15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-846e4616-fc80-4ce3-8fb5-e6d6d19543bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-afe514c3-47d4-4e21-b85c-bc12f730fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5b9c2382-1f82-4ff7-8d89-dd6ed65b4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-dad19044-45d7-4cee-9b6d-bf1f21402034,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-68b79bea-025c-4237-a25c-7658c008bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-5bea749f-5052-4194-aa86-f10d8ac06a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800933734-172.17.0.15-1598612565833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-75c6b52c-4701-4111-a542-c099a12dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-3f7f6152-f292-4df8-b520-e0b6c2ad15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-846e4616-fc80-4ce3-8fb5-e6d6d19543bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-afe514c3-47d4-4e21-b85c-bc12f730fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5b9c2382-1f82-4ff7-8d89-dd6ed65b4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-dad19044-45d7-4cee-9b6d-bf1f21402034,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-68b79bea-025c-4237-a25c-7658c008bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-5bea749f-5052-4194-aa86-f10d8ac06a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49302877-172.17.0.15-1598612594481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-8cbefe67-aa3f-44ad-b84c-70ae0c094292,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-20569e3b-bbc8-44fc-947d-107af12a7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-06ebc095-64cc-44a4-929c-229a8160fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f479d95b-44f3-47ad-8c5a-30696914aac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-c84f1cea-7f89-4d83-922c-a8f18d2a3ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-06ecf4de-5704-4a10-bb80-79efc4528199,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-6d85921f-58c7-4576-bb57-8b2792393ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-76aeef45-b696-4149-945e-798b86d8dbd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49302877-172.17.0.15-1598612594481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-8cbefe67-aa3f-44ad-b84c-70ae0c094292,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-20569e3b-bbc8-44fc-947d-107af12a7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-06ebc095-64cc-44a4-929c-229a8160fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f479d95b-44f3-47ad-8c5a-30696914aac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-c84f1cea-7f89-4d83-922c-a8f18d2a3ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-06ecf4de-5704-4a10-bb80-79efc4528199,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-6d85921f-58c7-4576-bb57-8b2792393ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-76aeef45-b696-4149-945e-798b86d8dbd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580153123-172.17.0.15-1598612703965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-9ff2df2d-b6a9-494c-91f9-e937f49fd350,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-417b0b68-de70-485d-aaf1-b3fb80796c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1bc60471-0dca-487f-9e4f-0c088ffedad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-5f980d38-c62c-48c3-b5b2-8740f5a024de,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-f587cf47-72c5-4714-9282-807e43c3e573,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-ade090ee-e1f7-46f0-83b6-6061c45d710a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-3559c86a-d6d6-471b-87d0-e9c189b47076,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-155bec66-90e3-4d94-8e42-eed329667be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580153123-172.17.0.15-1598612703965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-9ff2df2d-b6a9-494c-91f9-e937f49fd350,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-417b0b68-de70-485d-aaf1-b3fb80796c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1bc60471-0dca-487f-9e4f-0c088ffedad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-5f980d38-c62c-48c3-b5b2-8740f5a024de,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-f587cf47-72c5-4714-9282-807e43c3e573,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-ade090ee-e1f7-46f0-83b6-6061c45d710a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-3559c86a-d6d6-471b-87d0-e9c189b47076,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-155bec66-90e3-4d94-8e42-eed329667be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748365577-172.17.0.15-1598613012682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-d4780735-24ad-4caa-8592-f217a760ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-9209db6f-dd4f-4309-bfd5-5af115eb2831,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d697d82f-cd88-428a-8bc2-3c37fa28566a,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-9428ae29-4b61-4948-8316-d85a77e5997a,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-991589bc-ff06-4ad4-b72f-8af967990c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-3116cce9-4c27-40dc-bde0-f5c67e04989f,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-dd212cce-817d-434e-b74e-ab94139274ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4cb77f83-ae38-4dec-9475-ed39ebfb036a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748365577-172.17.0.15-1598613012682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-d4780735-24ad-4caa-8592-f217a760ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-9209db6f-dd4f-4309-bfd5-5af115eb2831,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-d697d82f-cd88-428a-8bc2-3c37fa28566a,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-9428ae29-4b61-4948-8316-d85a77e5997a,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-991589bc-ff06-4ad4-b72f-8af967990c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-3116cce9-4c27-40dc-bde0-f5c67e04989f,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-dd212cce-817d-434e-b74e-ab94139274ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4cb77f83-ae38-4dec-9475-ed39ebfb036a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 0
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475265690-172.17.0.15-1598613774439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-5c61c8ad-e04d-4254-afc5-7a5da627b837,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-8cc2eb39-a386-4da1-b00f-7465d69ae492,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-26d502f3-65aa-4984-a1a7-3ee918e5d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-b7693a7a-c8df-46fc-a458-5060374a8ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-28422c1c-fef5-45db-9ae8-8b90f85c99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-18e2897b-020a-41f2-b016-0f56e9e53260,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-a4fd8c71-5a11-48dc-bc00-e5252f2522eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b2a4a571-cac5-4556-b3da-b9c5cde3305c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475265690-172.17.0.15-1598613774439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-5c61c8ad-e04d-4254-afc5-7a5da627b837,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-8cc2eb39-a386-4da1-b00f-7465d69ae492,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-26d502f3-65aa-4984-a1a7-3ee918e5d1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-b7693a7a-c8df-46fc-a458-5060374a8ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-28422c1c-fef5-45db-9ae8-8b90f85c99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-18e2897b-020a-41f2-b016-0f56e9e53260,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-a4fd8c71-5a11-48dc-bc00-e5252f2522eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b2a4a571-cac5-4556-b3da-b9c5cde3305c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5364
