reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097752893-172.17.0.14-1598678119789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-aac3a94a-9ed4-4b76-8c35-17188ed4d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-70069417-8e88-4f59-a05b-e425dc7f05e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-0bc4b91c-b4d4-4718-81ef-b54a88155017,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-5a4df300-4801-42b2-b015-18b95d8b54fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-b8f522bf-5a52-41f2-a34f-239cf1fe7fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-2044c865-6771-46fd-b248-8d9ec05d697c,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-a5f340e4-f48b-4c45-aba2-eab71e0107bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-63c26330-978c-4788-a1b1-69aef075f00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097752893-172.17.0.14-1598678119789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-aac3a94a-9ed4-4b76-8c35-17188ed4d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-70069417-8e88-4f59-a05b-e425dc7f05e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-0bc4b91c-b4d4-4718-81ef-b54a88155017,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-5a4df300-4801-42b2-b015-18b95d8b54fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-b8f522bf-5a52-41f2-a34f-239cf1fe7fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-2044c865-6771-46fd-b248-8d9ec05d697c,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-a5f340e4-f48b-4c45-aba2-eab71e0107bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-63c26330-978c-4788-a1b1-69aef075f00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347396302-172.17.0.14-1598678560798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-e9a10101-39c0-4f6c-8fb6-6440440e6378,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-d111dfa5-c451-463f-b99f-43f8e83c0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-a7a9d011-b0da-4bf8-b320-a37ed39ad4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-0d8325c0-f4e2-4a19-89f0-94b8ad7fd106,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-375e3f05-34b3-4c2f-9cbe-3bd06f41b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ca1dedb7-e751-4b39-b9a9-c340323b09c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-3cafda86-3262-4779-851a-e58396df7bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-7413e7db-f0e4-4497-b615-f4d8e07d2339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347396302-172.17.0.14-1598678560798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-e9a10101-39c0-4f6c-8fb6-6440440e6378,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-d111dfa5-c451-463f-b99f-43f8e83c0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-a7a9d011-b0da-4bf8-b320-a37ed39ad4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-0d8325c0-f4e2-4a19-89f0-94b8ad7fd106,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-375e3f05-34b3-4c2f-9cbe-3bd06f41b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ca1dedb7-e751-4b39-b9a9-c340323b09c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-3cafda86-3262-4779-851a-e58396df7bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-7413e7db-f0e4-4497-b615-f4d8e07d2339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871674424-172.17.0.14-1598678791718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-c046e63c-fe76-4e65-9462-2ca240e76a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-7a8a3abf-42d7-40bf-b82b-4695c6eeb98a,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-08fd9610-a0ca-4927-b51f-579bd2892b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-8c50179f-6a4d-47bd-bf7d-3270c1997692,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-3fa2bbb0-eafc-4639-92dd-0d32d91670bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-cfac188a-69c5-46ce-a264-1434606de5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-098f6151-f868-4f52-b4b2-148f887ab0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-c1700d54-dc19-471a-87ef-708d3d22284b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871674424-172.17.0.14-1598678791718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-c046e63c-fe76-4e65-9462-2ca240e76a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-7a8a3abf-42d7-40bf-b82b-4695c6eeb98a,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-08fd9610-a0ca-4927-b51f-579bd2892b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-8c50179f-6a4d-47bd-bf7d-3270c1997692,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-3fa2bbb0-eafc-4639-92dd-0d32d91670bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-cfac188a-69c5-46ce-a264-1434606de5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-098f6151-f868-4f52-b4b2-148f887ab0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-c1700d54-dc19-471a-87ef-708d3d22284b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759283010-172.17.0.14-1598678904606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37635,DS-702e6627-1980-4db8-8e78-c5915752dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-6e2f1954-b5b5-4a0b-b16b-9416549844c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-f3ea057e-4df7-4f87-9606-40da44c814df,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0516c3cb-9fc3-46e1-b046-d6c2147418a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-17ad77bc-5f1f-497c-b5a6-b00aae6c894e,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-7c47913a-ff20-4275-8208-f0347778e072,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-096e83e8-e0ab-4d34-9cb6-802fbd262d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-e9ce1afe-8fae-4427-9ecd-756c3fd6ab45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759283010-172.17.0.14-1598678904606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37635,DS-702e6627-1980-4db8-8e78-c5915752dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-6e2f1954-b5b5-4a0b-b16b-9416549844c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-f3ea057e-4df7-4f87-9606-40da44c814df,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0516c3cb-9fc3-46e1-b046-d6c2147418a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-17ad77bc-5f1f-497c-b5a6-b00aae6c894e,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-7c47913a-ff20-4275-8208-f0347778e072,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-096e83e8-e0ab-4d34-9cb6-802fbd262d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-e9ce1afe-8fae-4427-9ecd-756c3fd6ab45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405190269-172.17.0.14-1598678987278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-9b3d350d-739a-42df-ad61-6a21533cb777,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-73488851-7084-439a-a744-14b49705e2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-3bd6bff5-ecd4-4fa8-a291-46bc471d3f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-3e1dc266-11da-41a0-ac4f-5085b702570d,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-40eb03db-0a4a-4225-83e9-632d66b1b04a,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-79d72272-def1-4e90-9db1-6fe5efeb90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-9afbd2a5-e3b4-45bf-b1c6-6ec7af077057,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-1ddcccc8-866a-4bd6-937b-b73f9dabbf34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405190269-172.17.0.14-1598678987278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-9b3d350d-739a-42df-ad61-6a21533cb777,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-73488851-7084-439a-a744-14b49705e2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-3bd6bff5-ecd4-4fa8-a291-46bc471d3f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-3e1dc266-11da-41a0-ac4f-5085b702570d,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-40eb03db-0a4a-4225-83e9-632d66b1b04a,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-79d72272-def1-4e90-9db1-6fe5efeb90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-9afbd2a5-e3b4-45bf-b1c6-6ec7af077057,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-1ddcccc8-866a-4bd6-937b-b73f9dabbf34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046613371-172.17.0.14-1598679253260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-933c6971-7002-4ef4-ba7f-5445350cb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-71ed4844-2415-4c40-a612-888e6dd2c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-9b0d6b51-65d4-45db-86d8-f24bbf93fd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-2edf2356-10f5-471e-9f09-4c53129a03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d7954f80-326a-4d98-a104-8d11cbc863b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-09fca331-f0f8-4fa8-a1ad-21e46f9f89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5336c9e7-8ee0-4ad9-a1b4-7b0f0704e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-0c6dd010-7f89-4e12-a5da-6e9c9701958b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046613371-172.17.0.14-1598679253260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35778,DS-933c6971-7002-4ef4-ba7f-5445350cb84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-71ed4844-2415-4c40-a612-888e6dd2c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-9b0d6b51-65d4-45db-86d8-f24bbf93fd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-2edf2356-10f5-471e-9f09-4c53129a03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d7954f80-326a-4d98-a104-8d11cbc863b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-09fca331-f0f8-4fa8-a1ad-21e46f9f89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5336c9e7-8ee0-4ad9-a1b4-7b0f0704e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-0c6dd010-7f89-4e12-a5da-6e9c9701958b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201111928-172.17.0.14-1598679931570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-ea5ec05d-a3a3-46f1-8d83-85b2f52f68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-5c942c44-9ef3-475a-8203-ca993c734f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-dc6a7949-f659-459e-a659-08b14742e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-e870cf4d-911c-40d3-8143-2ecc1f9d6183,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-bd724c95-1034-42a0-af19-b96f9c5a90b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-970b0e24-373e-497d-b1a5-3315c6efb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-180268ec-6fc1-4e8c-b942-89c09d414e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-f2017920-0c92-4833-b9e9-1ad853b0f2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201111928-172.17.0.14-1598679931570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-ea5ec05d-a3a3-46f1-8d83-85b2f52f68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-5c942c44-9ef3-475a-8203-ca993c734f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-dc6a7949-f659-459e-a659-08b14742e16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-e870cf4d-911c-40d3-8143-2ecc1f9d6183,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-bd724c95-1034-42a0-af19-b96f9c5a90b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-970b0e24-373e-497d-b1a5-3315c6efb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-180268ec-6fc1-4e8c-b942-89c09d414e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-f2017920-0c92-4833-b9e9-1ad853b0f2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426043216-172.17.0.14-1598680042034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40045,DS-20da4f58-8884-44b2-90b4-f15efc22ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-6ac0d2a9-9f21-4845-8155-baa2aa32654f,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-89f4762f-587c-4b59-84f8-529184c357f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-ce2da58d-39ed-420d-9907-7f898a720e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-e582cb1b-a837-4b3c-9f65-584561ef037f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-abec51d8-5bfb-4bd8-b972-15681a9be7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-a6f8c73c-4eec-479f-a6f6-9a70f9aff7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-3c39eaae-9660-4e7e-a1ab-85b090a37bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426043216-172.17.0.14-1598680042034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40045,DS-20da4f58-8884-44b2-90b4-f15efc22ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-6ac0d2a9-9f21-4845-8155-baa2aa32654f,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-89f4762f-587c-4b59-84f8-529184c357f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-ce2da58d-39ed-420d-9907-7f898a720e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-e582cb1b-a837-4b3c-9f65-584561ef037f,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-abec51d8-5bfb-4bd8-b972-15681a9be7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-a6f8c73c-4eec-479f-a6f6-9a70f9aff7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-3c39eaae-9660-4e7e-a1ab-85b090a37bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352977025-172.17.0.14-1598680077492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33204,DS-d26ee4f0-76ea-4c85-8676-1587042f715b,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-85e70b32-5da9-4d11-bb77-1b099b07d928,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-fc20aca1-eea2-4543-a1ad-9b43774b4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ea368f90-83cb-4d98-9ce4-5a0d81ee51a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-db0b093e-4a19-4dba-b125-815b8800c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8dbbe0a0-d626-4b3c-a28b-5d7950e415b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-69cfe40b-7ac3-444b-ad2b-f35b1b049131,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-bb6b6fdc-625c-438f-8724-1e59687c0fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352977025-172.17.0.14-1598680077492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33204,DS-d26ee4f0-76ea-4c85-8676-1587042f715b,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-85e70b32-5da9-4d11-bb77-1b099b07d928,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-fc20aca1-eea2-4543-a1ad-9b43774b4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-ea368f90-83cb-4d98-9ce4-5a0d81ee51a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-db0b093e-4a19-4dba-b125-815b8800c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8dbbe0a0-d626-4b3c-a28b-5d7950e415b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-69cfe40b-7ac3-444b-ad2b-f35b1b049131,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-bb6b6fdc-625c-438f-8724-1e59687c0fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16022519-172.17.0.14-1598680692871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-c42d7884-1b51-4453-bd5e-ef31d65e2d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-219188fb-5ce1-4638-8b15-bd48c30f2066,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f2ec7bf0-f306-451a-905b-90babe42aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-79a7a5bb-88fd-469c-b873-57449ea0c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-facefa6b-9aa2-4eb3-ab14-864560425816,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-0fc15141-5135-418e-ad16-a2e6149b3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-08926eff-0807-45b7-9946-e30e532410a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-44efdebd-d3a7-4975-b6a5-b9b0093f49c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16022519-172.17.0.14-1598680692871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-c42d7884-1b51-4453-bd5e-ef31d65e2d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-219188fb-5ce1-4638-8b15-bd48c30f2066,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f2ec7bf0-f306-451a-905b-90babe42aeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-79a7a5bb-88fd-469c-b873-57449ea0c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-facefa6b-9aa2-4eb3-ab14-864560425816,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-0fc15141-5135-418e-ad16-a2e6149b3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-08926eff-0807-45b7-9946-e30e532410a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-44efdebd-d3a7-4975-b6a5-b9b0093f49c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991991176-172.17.0.14-1598681087963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-071ab9d4-feba-4590-860f-70924d1155ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-3160ebaf-a3ab-45ff-be8f-7b57cf49081d,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-35a4d416-7fcd-4270-8a5b-23f15e866d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-c6542814-1a81-4c4a-8686-44ddc708f814,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-2ec531eb-a9de-4ff9-8078-b1d6e09efdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-e6525a24-7b82-46b9-ab49-23da6e4e9778,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-0f163db6-6dfd-4fd4-aee8-614617d48f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b800f094-8492-4b6b-b55f-ae05a3b2ab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991991176-172.17.0.14-1598681087963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-071ab9d4-feba-4590-860f-70924d1155ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-3160ebaf-a3ab-45ff-be8f-7b57cf49081d,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-35a4d416-7fcd-4270-8a5b-23f15e866d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-c6542814-1a81-4c4a-8686-44ddc708f814,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-2ec531eb-a9de-4ff9-8078-b1d6e09efdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-e6525a24-7b82-46b9-ab49-23da6e4e9778,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-0f163db6-6dfd-4fd4-aee8-614617d48f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b800f094-8492-4b6b-b55f-ae05a3b2ab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240925532-172.17.0.14-1598681246972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-3da47447-66b9-4815-a442-92f7be5eeea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-2b38db9e-f743-48d0-a8b4-2b5a81327560,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-ea973039-eb52-433a-bc6f-c4b6d6b5f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-cc92a3e6-868d-452e-bd85-26bb94f2e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-57835fa0-a437-407b-a536-a6260bc7c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-30019554-b62d-438a-8f5d-41e545c24d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-e0a94fab-e32f-4c6b-821f-f479a7855cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-ddb2b9ef-b5ee-44ac-b0a6-776b2f2ae7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240925532-172.17.0.14-1598681246972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-3da47447-66b9-4815-a442-92f7be5eeea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-2b38db9e-f743-48d0-a8b4-2b5a81327560,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-ea973039-eb52-433a-bc6f-c4b6d6b5f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-cc92a3e6-868d-452e-bd85-26bb94f2e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-57835fa0-a437-407b-a536-a6260bc7c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-30019554-b62d-438a-8f5d-41e545c24d36,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-e0a94fab-e32f-4c6b-821f-f479a7855cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-ddb2b9ef-b5ee-44ac-b0a6-776b2f2ae7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526536302-172.17.0.14-1598681331823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-4dc09448-21c8-4836-b7a6-a266ab672ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-30e2ab89-e897-4cfc-9a1e-981f124739a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-5d64f56e-0e24-47bb-95b2-494c04865ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-b0768aa7-310f-444d-8c0f-516b9610f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-99c82eb9-0541-4823-83a4-2bfdcf55bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-f87686ec-39c3-4690-9197-7d13aaa88629,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-51098f33-de8c-4dbc-a816-5259886fd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-cb71bdf0-a3ee-412e-969b-5d0c3f5aa7c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526536302-172.17.0.14-1598681331823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-4dc09448-21c8-4836-b7a6-a266ab672ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-30e2ab89-e897-4cfc-9a1e-981f124739a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-5d64f56e-0e24-47bb-95b2-494c04865ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-b0768aa7-310f-444d-8c0f-516b9610f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-99c82eb9-0541-4823-83a4-2bfdcf55bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-f87686ec-39c3-4690-9197-7d13aaa88629,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-51098f33-de8c-4dbc-a816-5259886fd9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-cb71bdf0-a3ee-412e-969b-5d0c3f5aa7c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069371755-172.17.0.14-1598681484692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-e03b5d39-53c5-4bc8-a5f5-27c644f48a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-efde2714-b73e-4dfd-a61f-bf41ac381be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-73d9bd1f-1348-40fb-bf9c-d7567ac382e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-10882150-df8c-447c-bf1b-9dd63c65b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-a2ffae42-850d-4f13-a9a5-cfe073386ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-7cd992df-4b4e-4a39-a551-6165d237d16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ce822ca5-25d9-4115-b498-b5c84eec40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-25a75df2-acc0-405a-87fe-4639b022567d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069371755-172.17.0.14-1598681484692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-e03b5d39-53c5-4bc8-a5f5-27c644f48a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-efde2714-b73e-4dfd-a61f-bf41ac381be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-73d9bd1f-1348-40fb-bf9c-d7567ac382e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-10882150-df8c-447c-bf1b-9dd63c65b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-a2ffae42-850d-4f13-a9a5-cfe073386ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-7cd992df-4b4e-4a39-a551-6165d237d16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ce822ca5-25d9-4115-b498-b5c84eec40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-25a75df2-acc0-405a-87fe-4639b022567d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832270562-172.17.0.14-1598681608894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-b56246ea-9b7d-4c1f-bc68-97ad66ed0332,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-0c24db54-5f6d-4488-a8de-8068cb1e069b,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-a1d7b956-57c2-45c4-8be0-bdcb31548bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-96cdc29e-f7df-4dff-8300-fda0f99283f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-d09babf6-edad-4f46-8254-ba15218ca6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-5e1729b7-e086-487d-8228-66dcbaafabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-a75bd670-d5ed-422b-b8f3-dbe3ba03223b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c601d756-df38-4ae8-8590-1886401ebd74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832270562-172.17.0.14-1598681608894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-b56246ea-9b7d-4c1f-bc68-97ad66ed0332,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-0c24db54-5f6d-4488-a8de-8068cb1e069b,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-a1d7b956-57c2-45c4-8be0-bdcb31548bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-96cdc29e-f7df-4dff-8300-fda0f99283f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-d09babf6-edad-4f46-8254-ba15218ca6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-5e1729b7-e086-487d-8228-66dcbaafabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-a75bd670-d5ed-422b-b8f3-dbe3ba03223b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c601d756-df38-4ae8-8590-1886401ebd74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895610876-172.17.0.14-1598681899367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44395,DS-dde3af59-a578-4612-83b7-0ef76e69512e,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f028728d-1adb-4479-a3d7-03c00d33afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-0330f707-f0fa-47bd-b1da-7b44a2310f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-5eedb803-f8b9-4683-a1cb-47d534caf46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-2a08c19c-e809-438b-9c3e-b3f7b60b7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e93fe36b-8134-4a4b-b177-dae8e757e6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5b15b137-fe15-46f6-846c-77e4b1935b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-9031efea-a362-4924-a034-37c2b6f98431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895610876-172.17.0.14-1598681899367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44395,DS-dde3af59-a578-4612-83b7-0ef76e69512e,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f028728d-1adb-4479-a3d7-03c00d33afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-0330f707-f0fa-47bd-b1da-7b44a2310f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-5eedb803-f8b9-4683-a1cb-47d534caf46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-2a08c19c-e809-438b-9c3e-b3f7b60b7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e93fe36b-8134-4a4b-b177-dae8e757e6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5b15b137-fe15-46f6-846c-77e4b1935b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-9031efea-a362-4924-a034-37c2b6f98431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274584746-172.17.0.14-1598682163423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-a1931f05-480d-4fec-a808-ae870816fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-cfd55077-677a-43f3-81e8-f93c82c92ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1593f09a-8b62-4abe-a116-318203d43b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-8a2c80fa-c123-4586-8bb5-2ea61f4d8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-07c2c577-b36f-47f9-84b2-7aebe2e5d3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-fc04b05a-9601-479b-990b-fa963426d73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-23476274-cda7-4434-8c35-c14af1af7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-922de2c3-d2eb-4842-a144-a1b5a0544d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274584746-172.17.0.14-1598682163423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-a1931f05-480d-4fec-a808-ae870816fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-cfd55077-677a-43f3-81e8-f93c82c92ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-1593f09a-8b62-4abe-a116-318203d43b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-8a2c80fa-c123-4586-8bb5-2ea61f4d8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-07c2c577-b36f-47f9-84b2-7aebe2e5d3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-fc04b05a-9601-479b-990b-fa963426d73a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-23476274-cda7-4434-8c35-c14af1af7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-922de2c3-d2eb-4842-a144-a1b5a0544d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859303295-172.17.0.14-1598682539987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-f404cd1a-20d7-4a76-a5ad-4303f0c5def2,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-d20c7db6-fcc6-45ca-ab95-f915cce9ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-dce07d8f-e079-467e-a6fb-6e8798108768,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-adda43b1-7feb-4d9a-a757-b794207e50f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-1d6b54e6-abb4-426a-bae8-69596f21fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-3e45e9b5-af9a-41fa-8e78-968b1637d702,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-1190550d-ca8b-4730-bc70-82e2bb4204b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-a083acb8-dd30-4bc0-ab81-104d6fd079aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859303295-172.17.0.14-1598682539987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-f404cd1a-20d7-4a76-a5ad-4303f0c5def2,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-d20c7db6-fcc6-45ca-ab95-f915cce9ffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-dce07d8f-e079-467e-a6fb-6e8798108768,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-adda43b1-7feb-4d9a-a757-b794207e50f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-1d6b54e6-abb4-426a-bae8-69596f21fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-3e45e9b5-af9a-41fa-8e78-968b1637d702,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-1190550d-ca8b-4730-bc70-82e2bb4204b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-a083acb8-dd30-4bc0-ab81-104d6fd079aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414588342-172.17.0.14-1598682665634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-1364844d-bbde-4e06-9d1f-1ece8857d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cb701cdb-9410-4691-affb-81142977b697,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-b44c4363-2d53-4c4d-b12c-586f6b62bca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-e9ea0d35-31ff-4fd9-af11-e965add6711f,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-3b118a6e-61df-4dc3-83a6-d9dcaf89e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-eb7e77b7-9d93-4c83-bf7a-7b5f5ef54f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-949dd9e3-f07b-4232-b87d-8784cac385dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-5f58be99-4bcd-4453-b850-3bfc9bf08d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414588342-172.17.0.14-1598682665634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-1364844d-bbde-4e06-9d1f-1ece8857d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cb701cdb-9410-4691-affb-81142977b697,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-b44c4363-2d53-4c4d-b12c-586f6b62bca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-e9ea0d35-31ff-4fd9-af11-e965add6711f,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-3b118a6e-61df-4dc3-83a6-d9dcaf89e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-eb7e77b7-9d93-4c83-bf7a-7b5f5ef54f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-949dd9e3-f07b-4232-b87d-8784cac385dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-5f58be99-4bcd-4453-b850-3bfc9bf08d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73030589-172.17.0.14-1598683636747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-4100dac4-f76f-495a-a878-c40ba31bb0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b2323a2f-2216-48a9-adb8-c8897ecdf263,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-e7c94a76-aa3a-4cfb-a7d0-cbcb302af796,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-c1967490-6140-4785-9fd0-9411a794aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-602e64ed-2515-4085-984a-770f5bebbd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-a595f7b8-e05f-4826-bed7-40b5ce1a27f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-26f285a6-4199-4c08-8a94-be2a71b1e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-432f8401-be0b-4224-a436-352a7e8cf046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73030589-172.17.0.14-1598683636747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-4100dac4-f76f-495a-a878-c40ba31bb0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-b2323a2f-2216-48a9-adb8-c8897ecdf263,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-e7c94a76-aa3a-4cfb-a7d0-cbcb302af796,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-c1967490-6140-4785-9fd0-9411a794aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-602e64ed-2515-4085-984a-770f5bebbd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-a595f7b8-e05f-4826-bed7-40b5ce1a27f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-26f285a6-4199-4c08-8a94-be2a71b1e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-432f8401-be0b-4224-a436-352a7e8cf046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5594
