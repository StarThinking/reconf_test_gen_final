reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201739080-172.17.0.18-1598519842619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-2188f90a-2da9-4606-ac20-d89a3556ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-5d8cf099-5c39-4081-bd95-9ee2dc9dca20,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-63778493-9f19-4a2d-8622-fd38107d18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-f99a4eae-7c00-4f02-bf05-5fc755b499a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-167d1fcc-1a9a-45f6-9ac9-f1eb7dbf5d70,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-150d0d2a-10f5-4171-82fa-4f4bb5b27e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-8bfc778e-6d60-4cff-bee2-8430305447e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-2c42922a-87fe-41db-b496-b7535cd73a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201739080-172.17.0.18-1598519842619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-2188f90a-2da9-4606-ac20-d89a3556ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-5d8cf099-5c39-4081-bd95-9ee2dc9dca20,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-63778493-9f19-4a2d-8622-fd38107d18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-f99a4eae-7c00-4f02-bf05-5fc755b499a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-167d1fcc-1a9a-45f6-9ac9-f1eb7dbf5d70,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-150d0d2a-10f5-4171-82fa-4f4bb5b27e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-8bfc778e-6d60-4cff-bee2-8430305447e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-2c42922a-87fe-41db-b496-b7535cd73a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146691930-172.17.0.18-1598521193980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-4b5d01ce-4e3c-469b-9b21-923aaf4ede10,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-9f121bc5-33b9-4d18-bc89-593b5eddb9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-44ce97c4-db3c-4c33-9fda-9bbeb822a437,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-2fc418fc-b5e7-4c68-b078-23ca84b2e053,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-ad114ee2-d560-4df8-81f1-21bf0739bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-fa180440-fcf9-4b57-a4dc-0ac7a1b0c0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-6ea8705c-b39a-47e1-8ae4-40995738ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-5f931f41-f172-49fd-a85a-336a36b2c285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146691930-172.17.0.18-1598521193980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-4b5d01ce-4e3c-469b-9b21-923aaf4ede10,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-9f121bc5-33b9-4d18-bc89-593b5eddb9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-44ce97c4-db3c-4c33-9fda-9bbeb822a437,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-2fc418fc-b5e7-4c68-b078-23ca84b2e053,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-ad114ee2-d560-4df8-81f1-21bf0739bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-fa180440-fcf9-4b57-a4dc-0ac7a1b0c0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-6ea8705c-b39a-47e1-8ae4-40995738ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-5f931f41-f172-49fd-a85a-336a36b2c285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695324822-172.17.0.18-1598521656664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-213b5d05-ac7d-41db-b275-ef00d7fdc32d,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-887a1022-e43b-4aa3-a180-818676c82c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e2d1a865-0ff8-4b62-80ae-f10cc6b90b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-55feff3c-b99a-449e-8036-4cb113e7399e,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-47541aa7-ccbc-496a-bc44-8f9c7200085b,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-341b4a0b-889d-4e78-baf9-7ead84d67e36,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-06d7c1b6-4410-4fb7-be53-f91229e8a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-4bd0185a-1e18-4aff-b729-8dffae34935b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695324822-172.17.0.18-1598521656664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-213b5d05-ac7d-41db-b275-ef00d7fdc32d,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-887a1022-e43b-4aa3-a180-818676c82c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e2d1a865-0ff8-4b62-80ae-f10cc6b90b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-55feff3c-b99a-449e-8036-4cb113e7399e,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-47541aa7-ccbc-496a-bc44-8f9c7200085b,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-341b4a0b-889d-4e78-baf9-7ead84d67e36,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-06d7c1b6-4410-4fb7-be53-f91229e8a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-4bd0185a-1e18-4aff-b729-8dffae34935b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864544640-172.17.0.18-1598521915854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-6cfacbd4-bc48-460c-8633-e5317b3c96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-f9d94091-d913-4de8-a99c-18a3a3d1d8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-b306cfc6-e166-4843-a976-a57e0c938e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-69a6ebca-fdf8-4e51-8163-597c9a788abf,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-02bbd821-28f6-45c8-b7f2-7869f1f0dab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-5ac64468-6836-4367-8450-7f86256869f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a725c14c-3f1e-44c4-9e32-26fe22b9818b,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-fc7b809f-946f-47ff-a613-1785ecdc3e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864544640-172.17.0.18-1598521915854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-6cfacbd4-bc48-460c-8633-e5317b3c96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-f9d94091-d913-4de8-a99c-18a3a3d1d8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-b306cfc6-e166-4843-a976-a57e0c938e41,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-69a6ebca-fdf8-4e51-8163-597c9a788abf,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-02bbd821-28f6-45c8-b7f2-7869f1f0dab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-5ac64468-6836-4367-8450-7f86256869f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a725c14c-3f1e-44c4-9e32-26fe22b9818b,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-fc7b809f-946f-47ff-a613-1785ecdc3e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821467343-172.17.0.18-1598522247033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-bae4d204-7164-4a6d-ae7a-69df8dc66d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f048f50b-9b97-41e2-9ab2-2e744d8905bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-5b67a0f1-02a7-4d3f-b337-920344c5d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e3b0b787-121d-445d-9331-92188f98da80,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-85971036-aa16-4b23-a805-970120fb52b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c36eb362-5dc6-430e-b7dc-0f9b029f5621,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-efb1a1eb-1894-4261-b2f0-848791f09879,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-f1764baa-4c44-453f-a61c-f0062a3e45c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821467343-172.17.0.18-1598522247033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-bae4d204-7164-4a6d-ae7a-69df8dc66d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f048f50b-9b97-41e2-9ab2-2e744d8905bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-5b67a0f1-02a7-4d3f-b337-920344c5d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e3b0b787-121d-445d-9331-92188f98da80,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-85971036-aa16-4b23-a805-970120fb52b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c36eb362-5dc6-430e-b7dc-0f9b029f5621,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-efb1a1eb-1894-4261-b2f0-848791f09879,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-f1764baa-4c44-453f-a61c-f0062a3e45c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304210263-172.17.0.18-1598523025547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-0a3b1fd6-9923-45f4-b6fc-d097b61860dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-391160e8-db53-4eaa-913a-8da23efdccee,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-114c40e7-4ed8-403f-8d5c-28e97953e392,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-ad5437f2-ffdf-4324-abf6-d742f074e0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-572f7169-9044-40d5-acd6-1079497dac34,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-6a949380-3d63-46b2-801b-94ef9bbfd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-70949cae-635a-4287-a16f-6aa37de9f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-cb2a02ce-a54f-439b-8765-b15cdeb39f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304210263-172.17.0.18-1598523025547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42425,DS-0a3b1fd6-9923-45f4-b6fc-d097b61860dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-391160e8-db53-4eaa-913a-8da23efdccee,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-114c40e7-4ed8-403f-8d5c-28e97953e392,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-ad5437f2-ffdf-4324-abf6-d742f074e0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-572f7169-9044-40d5-acd6-1079497dac34,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-6a949380-3d63-46b2-801b-94ef9bbfd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-70949cae-635a-4287-a16f-6aa37de9f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-cb2a02ce-a54f-439b-8765-b15cdeb39f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87381764-172.17.0.18-1598523291384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-09736830-2955-4718-b7fc-73c090176a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-1bb3af4a-7aad-4e09-85cb-1fefce754470,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-be2026dd-a97a-44ba-abe5-820b53f17e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-b2bdc070-50ac-4b2b-b90e-c8aa91cf1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-6852b601-1d2a-40df-85f4-ca6ee374502d,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-2e0fe3c8-43f1-40d9-bd4a-b380aac9f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-d9614da1-10f3-4bdb-a854-b3367239be20,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-7308cda0-a3ec-4ffb-9808-e5bce12d392a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87381764-172.17.0.18-1598523291384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32893,DS-09736830-2955-4718-b7fc-73c090176a93,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-1bb3af4a-7aad-4e09-85cb-1fefce754470,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-be2026dd-a97a-44ba-abe5-820b53f17e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-b2bdc070-50ac-4b2b-b90e-c8aa91cf1e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-6852b601-1d2a-40df-85f4-ca6ee374502d,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-2e0fe3c8-43f1-40d9-bd4a-b380aac9f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-d9614da1-10f3-4bdb-a854-b3367239be20,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-7308cda0-a3ec-4ffb-9808-e5bce12d392a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395639810-172.17.0.18-1598523622160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-e28f0ca4-dcfc-45a8-ba92-8a424d8c886d,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-9f83bb56-1faf-43ef-9ca7-182971a7d3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-73ffa60f-c151-48b7-af38-40fdbbd48793,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-c4fdcd63-4144-42a8-8498-69ceed55d673,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-bbb948a5-03dc-4ff7-bbb8-819ef656e136,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0a9e8689-5132-4ae6-9c43-6e9c3634faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-9af02229-5647-4d10-a9d0-3af9ce5d5d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-8406dede-bf95-4238-a906-56d9c229b297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395639810-172.17.0.18-1598523622160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-e28f0ca4-dcfc-45a8-ba92-8a424d8c886d,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-9f83bb56-1faf-43ef-9ca7-182971a7d3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-73ffa60f-c151-48b7-af38-40fdbbd48793,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-c4fdcd63-4144-42a8-8498-69ceed55d673,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-bbb948a5-03dc-4ff7-bbb8-819ef656e136,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0a9e8689-5132-4ae6-9c43-6e9c3634faa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-9af02229-5647-4d10-a9d0-3af9ce5d5d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-8406dede-bf95-4238-a906-56d9c229b297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556908736-172.17.0.18-1598524124295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-1b74d2f8-4c0f-4ec3-9911-1b5060a7cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-b46f1f38-52bd-4325-8078-d5f457dc09c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-9e76df1c-fd7e-4e37-85d0-50c446620547,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-4d951e41-fae2-410e-94df-c998d289e764,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-a9726733-048c-4eaa-a74e-25e6a46d271c,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-b166be41-9632-42b4-93d2-dd406d1cd87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-bb2bacbd-eeb6-4b30-8fe3-191b25cecbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-0e4e8039-0170-41f2-83a7-9a19ba633959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556908736-172.17.0.18-1598524124295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-1b74d2f8-4c0f-4ec3-9911-1b5060a7cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-b46f1f38-52bd-4325-8078-d5f457dc09c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-9e76df1c-fd7e-4e37-85d0-50c446620547,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-4d951e41-fae2-410e-94df-c998d289e764,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-a9726733-048c-4eaa-a74e-25e6a46d271c,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-b166be41-9632-42b4-93d2-dd406d1cd87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-bb2bacbd-eeb6-4b30-8fe3-191b25cecbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-0e4e8039-0170-41f2-83a7-9a19ba633959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550589872-172.17.0.18-1598524333368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-4068f941-4dbf-458a-b4e9-3ce535698e09,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-6fa8a324-b5eb-44d8-992f-2ec73a3cb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-6d65a19d-2f3e-4935-9358-52792eaf73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-eebd3087-20ce-43e5-b6ed-425e3b1d0b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4267b319-a2e0-4f12-882b-d6d72d7650c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-71697ece-8ab9-472a-a562-c62cdfd1576e,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-3f4b7f3c-21d8-4cc7-a1c6-4ea40d6d107d,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-573b8db5-0117-435d-8323-fd113117391e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550589872-172.17.0.18-1598524333368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-4068f941-4dbf-458a-b4e9-3ce535698e09,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-6fa8a324-b5eb-44d8-992f-2ec73a3cb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-6d65a19d-2f3e-4935-9358-52792eaf73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-eebd3087-20ce-43e5-b6ed-425e3b1d0b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-4267b319-a2e0-4f12-882b-d6d72d7650c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-71697ece-8ab9-472a-a562-c62cdfd1576e,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-3f4b7f3c-21d8-4cc7-a1c6-4ea40d6d107d,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-573b8db5-0117-435d-8323-fd113117391e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5133
