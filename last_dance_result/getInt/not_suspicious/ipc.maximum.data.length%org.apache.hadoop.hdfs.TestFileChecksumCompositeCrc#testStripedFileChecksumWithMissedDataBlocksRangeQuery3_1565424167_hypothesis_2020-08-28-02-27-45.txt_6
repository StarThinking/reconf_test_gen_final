reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642638637-172.17.0.3-1598581920414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-ba00df83-36cd-4461-9003-c537e00027d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-da1b6176-7f38-48b8-add1-6212031a5d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-590f3994-5a08-4cb7-b972-d4bc33ee07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-f27ba727-a1a1-4452-9caf-36a6c2a6d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-8c5997c9-6f13-4c2c-934b-654aa0d8e579,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-22a3a256-9d14-45fb-8ddd-223bfa2fc5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-5800a362-7fb2-4399-865b-a4f79c80d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-712be85c-f7cc-49a5-90ed-90dd42993df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642638637-172.17.0.3-1598581920414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-ba00df83-36cd-4461-9003-c537e00027d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-da1b6176-7f38-48b8-add1-6212031a5d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-590f3994-5a08-4cb7-b972-d4bc33ee07a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-f27ba727-a1a1-4452-9caf-36a6c2a6d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-8c5997c9-6f13-4c2c-934b-654aa0d8e579,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-22a3a256-9d14-45fb-8ddd-223bfa2fc5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-5800a362-7fb2-4399-865b-a4f79c80d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-712be85c-f7cc-49a5-90ed-90dd42993df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51545832-172.17.0.3-1598582119207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-fa7e74a9-8ea1-4309-bcaa-e7acc792397c,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-1b94eed7-5245-47fd-b4c3-dc3722e04b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-76c0f2e6-ad95-4819-b87a-3584e03f43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-45afd5b8-607d-4c07-a8ac-1ff1222f569f,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-781932c3-c22a-44c8-85d0-a55f8979b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-56a784c1-e436-4da1-a974-397ce9ae6b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-89c1f6aa-f585-4cda-b869-7fb70a79b132,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-ac8931e9-f716-4036-b452-0599c07d841d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51545832-172.17.0.3-1598582119207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-fa7e74a9-8ea1-4309-bcaa-e7acc792397c,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-1b94eed7-5245-47fd-b4c3-dc3722e04b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-76c0f2e6-ad95-4819-b87a-3584e03f43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-45afd5b8-607d-4c07-a8ac-1ff1222f569f,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-781932c3-c22a-44c8-85d0-a55f8979b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-56a784c1-e436-4da1-a974-397ce9ae6b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-89c1f6aa-f585-4cda-b869-7fb70a79b132,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-ac8931e9-f716-4036-b452-0599c07d841d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391232074-172.17.0.3-1598582352613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-b751d074-9466-46e2-98e0-c05178c5a355,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-f35806d7-3496-402a-b192-c2ca12e40f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-e6f86247-70ce-49cc-8248-a045e8db2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-d72e8a60-d661-4406-ad5a-f9254331f615,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-b12f6262-a205-4ba4-8855-8702d61d4deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-88260c8d-8f93-4532-a508-acd4dfcf20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-7017c986-9897-452b-9eda-9892141850e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3897f9e6-245a-4887-aa03-bf764de7c105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391232074-172.17.0.3-1598582352613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-b751d074-9466-46e2-98e0-c05178c5a355,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-f35806d7-3496-402a-b192-c2ca12e40f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-e6f86247-70ce-49cc-8248-a045e8db2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-d72e8a60-d661-4406-ad5a-f9254331f615,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-b12f6262-a205-4ba4-8855-8702d61d4deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-88260c8d-8f93-4532-a508-acd4dfcf20a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-7017c986-9897-452b-9eda-9892141850e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3897f9e6-245a-4887-aa03-bf764de7c105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777206659-172.17.0.3-1598582433711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46828,DS-6b073c88-c2f3-42f9-82ae-3c4ffad03c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d32c1e70-80a8-4b6b-9530-53582c19e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-e030256d-4b91-4531-864f-d132f074fbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-105d69bb-0ce1-4b60-8cd6-b3dd5b4ec377,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-aede4f94-0c73-4fd4-9b45-a9e64266e401,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-5161e153-9e15-4d35-9e56-983b651fa55b,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e8aab161-cd4e-4a8b-b8f1-c366eb479812,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-d5b32984-b155-4793-b6d8-ae1ba8138231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777206659-172.17.0.3-1598582433711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46828,DS-6b073c88-c2f3-42f9-82ae-3c4ffad03c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d32c1e70-80a8-4b6b-9530-53582c19e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-e030256d-4b91-4531-864f-d132f074fbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-105d69bb-0ce1-4b60-8cd6-b3dd5b4ec377,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-aede4f94-0c73-4fd4-9b45-a9e64266e401,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-5161e153-9e15-4d35-9e56-983b651fa55b,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e8aab161-cd4e-4a8b-b8f1-c366eb479812,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-d5b32984-b155-4793-b6d8-ae1ba8138231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205808636-172.17.0.3-1598582499886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7015078b-1c70-45ce-942d-13dfbe6524ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-578674e6-086c-4013-b687-922d1a8442be,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-42054536-905b-4129-84cc-6377c50ea234,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-2b5f17e3-e9fd-4e1e-a0e9-5038527252ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-1272c074-8e27-4b9d-8dc0-6d2cca6f45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-ff9f5fc6-e9c7-4bc8-9a88-fb7911a3d453,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-a2f1ca46-2b19-4a71-a1b0-2bb446e5ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-b142a8d3-6e4a-431c-93bf-5fe0c5793f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205808636-172.17.0.3-1598582499886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7015078b-1c70-45ce-942d-13dfbe6524ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-578674e6-086c-4013-b687-922d1a8442be,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-42054536-905b-4129-84cc-6377c50ea234,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-2b5f17e3-e9fd-4e1e-a0e9-5038527252ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-1272c074-8e27-4b9d-8dc0-6d2cca6f45c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-ff9f5fc6-e9c7-4bc8-9a88-fb7911a3d453,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-a2f1ca46-2b19-4a71-a1b0-2bb446e5ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-b142a8d3-6e4a-431c-93bf-5fe0c5793f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86502150-172.17.0.3-1598582669976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-aa131f59-cfc3-44ef-89d3-366890f6c383,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-ee540c92-46b3-4781-8280-82d668852504,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-8531bcd9-754f-473f-8783-88e20e5db419,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b20f0f66-a1f8-4205-9a4c-20ab5f0e4b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-1544a431-9e8c-4575-9a03-6505d1319b25,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-17884a68-241a-4681-b7ae-ef40c7c5790b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d6a51284-d8dc-4390-8909-b5e129636fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9d9ce43f-ff18-4688-ad61-60c7af7255b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86502150-172.17.0.3-1598582669976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-aa131f59-cfc3-44ef-89d3-366890f6c383,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-ee540c92-46b3-4781-8280-82d668852504,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-8531bcd9-754f-473f-8783-88e20e5db419,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-b20f0f66-a1f8-4205-9a4c-20ab5f0e4b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-1544a431-9e8c-4575-9a03-6505d1319b25,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-17884a68-241a-4681-b7ae-ef40c7c5790b,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d6a51284-d8dc-4390-8909-b5e129636fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9d9ce43f-ff18-4688-ad61-60c7af7255b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147375904-172.17.0.3-1598582821593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-585d6c32-66ca-4793-96ea-e1a0e8b1c148,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-79d47197-5cd6-4232-af6f-f853db37f482,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-bf92b8a1-152f-4d57-9493-40cd485cb861,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-a9e59e02-83e2-4334-b605-87ec6f9325a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-5ffc7398-f605-4734-a112-ccb8b3f4c626,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-15e538f7-a773-467d-bc69-62eb2c2c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-3a75ba44-5ab6-477f-aa33-e43781e53d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-52a385fa-e94d-4bc0-a49a-ad60ac01ff80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147375904-172.17.0.3-1598582821593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-585d6c32-66ca-4793-96ea-e1a0e8b1c148,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-79d47197-5cd6-4232-af6f-f853db37f482,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-bf92b8a1-152f-4d57-9493-40cd485cb861,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-a9e59e02-83e2-4334-b605-87ec6f9325a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-5ffc7398-f605-4734-a112-ccb8b3f4c626,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-15e538f7-a773-467d-bc69-62eb2c2c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-3a75ba44-5ab6-477f-aa33-e43781e53d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-52a385fa-e94d-4bc0-a49a-ad60ac01ff80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566081438-172.17.0.3-1598583006260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-93e13cf0-4ed4-4d15-a932-225df390ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-d1cebde0-877e-4c1b-b753-d950a6edb090,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c0385e03-42cb-4628-99ab-fc7851a20104,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-38320377-092a-48d3-b5c8-8da7457bdca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f32a09fa-a038-44fb-8c6b-e26adad94e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-3de397ac-a5bc-473f-9f14-39283887cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-687a739c-03ba-4833-8a6c-f6c0d9fd69ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-dcc9d767-3594-46bb-8b08-b24ab666c7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566081438-172.17.0.3-1598583006260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-93e13cf0-4ed4-4d15-a932-225df390ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-d1cebde0-877e-4c1b-b753-d950a6edb090,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c0385e03-42cb-4628-99ab-fc7851a20104,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-38320377-092a-48d3-b5c8-8da7457bdca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f32a09fa-a038-44fb-8c6b-e26adad94e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-3de397ac-a5bc-473f-9f14-39283887cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-687a739c-03ba-4833-8a6c-f6c0d9fd69ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-dcc9d767-3594-46bb-8b08-b24ab666c7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981915609-172.17.0.3-1598583049019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-fe9b62a7-ff6f-4e81-98bc-ddde768653a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-80fe88f8-112a-4e17-b2a6-8779c67e0176,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-0c548718-0a8d-431e-9263-ee281ad6ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-6bd9b0f3-15bc-4c9d-ba94-6166092899ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-665ab19e-d563-4427-9879-a0d96386a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-7d855d36-8720-4989-a488-829f73dd4509,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-0a5bda65-7331-45c0-90ca-6cc48b64d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-df09ddd7-ff2e-4dd2-bf16-459966d6cbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981915609-172.17.0.3-1598583049019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-fe9b62a7-ff6f-4e81-98bc-ddde768653a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-80fe88f8-112a-4e17-b2a6-8779c67e0176,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-0c548718-0a8d-431e-9263-ee281ad6ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-6bd9b0f3-15bc-4c9d-ba94-6166092899ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-665ab19e-d563-4427-9879-a0d96386a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-7d855d36-8720-4989-a488-829f73dd4509,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-0a5bda65-7331-45c0-90ca-6cc48b64d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-df09ddd7-ff2e-4dd2-bf16-459966d6cbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127403662-172.17.0.3-1598583088754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-5c182f4b-6b0b-485b-9306-53b4267483c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-9e62b1fd-1d7a-495c-a4a0-d02f7278b512,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-585ac490-55e0-47ea-ab7d-f7cd34126e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-69428da0-9b17-4e72-a2b3-da84a8a8e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-0060d3ab-1453-47e5-bc78-84020d7d447e,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-8266c8f5-af53-4e89-9af8-2ae3438f0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-61817763-9302-4c9a-8012-58b965eaaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7f56a2b7-7ce3-47f7-9a31-4ea0f929e81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127403662-172.17.0.3-1598583088754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-5c182f4b-6b0b-485b-9306-53b4267483c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-9e62b1fd-1d7a-495c-a4a0-d02f7278b512,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-585ac490-55e0-47ea-ab7d-f7cd34126e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-69428da0-9b17-4e72-a2b3-da84a8a8e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-0060d3ab-1453-47e5-bc78-84020d7d447e,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-8266c8f5-af53-4e89-9af8-2ae3438f0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-61817763-9302-4c9a-8012-58b965eaaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7f56a2b7-7ce3-47f7-9a31-4ea0f929e81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252084065-172.17.0.3-1598583208042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-88440c07-5057-4dc0-94c1-452f99f8708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-61b7de12-37fb-4a63-8acf-9fc267d5dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-31ca580c-c6f2-471e-8083-79ae7661f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-43d3d05b-1894-4693-bf1c-6d890b778930,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-e6d447ca-34f8-443a-9aa6-4509955ca3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-28273f8a-a783-479d-80cf-5da97772734b,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-4703b6c4-bfb2-41d3-bb03-5ac4425eb1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-b8942170-a57f-4699-8a72-8b9e7a12cac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252084065-172.17.0.3-1598583208042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-88440c07-5057-4dc0-94c1-452f99f8708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-61b7de12-37fb-4a63-8acf-9fc267d5dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-31ca580c-c6f2-471e-8083-79ae7661f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-43d3d05b-1894-4693-bf1c-6d890b778930,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-e6d447ca-34f8-443a-9aa6-4509955ca3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-28273f8a-a783-479d-80cf-5da97772734b,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-4703b6c4-bfb2-41d3-bb03-5ac4425eb1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-b8942170-a57f-4699-8a72-8b9e7a12cac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393241930-172.17.0.3-1598583356898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37672,DS-c6551684-b91e-4ffb-87b8-db95fcfc1886,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-a4f9ecaf-f655-4bd6-b092-3ff65686cfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-ec639bfa-f81c-4694-8dab-2308859384b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-25729ff9-e05b-4d4d-b042-4e86829ae898,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-a4bb61f5-befe-48c8-8e89-45cf57bbe57e,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-23e23cbb-11c3-4580-9514-82a1aaef968b,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-a6e043b1-4d64-4f35-91c4-98ea48520e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-a1b549a5-c73a-46b5-8777-87cef3553b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393241930-172.17.0.3-1598583356898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37672,DS-c6551684-b91e-4ffb-87b8-db95fcfc1886,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-a4f9ecaf-f655-4bd6-b092-3ff65686cfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-ec639bfa-f81c-4694-8dab-2308859384b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-25729ff9-e05b-4d4d-b042-4e86829ae898,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-a4bb61f5-befe-48c8-8e89-45cf57bbe57e,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-23e23cbb-11c3-4580-9514-82a1aaef968b,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-a6e043b1-4d64-4f35-91c4-98ea48520e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-a1b549a5-c73a-46b5-8777-87cef3553b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885680757-172.17.0.3-1598583742059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-8774857c-665d-4d2d-afe3-b2d4a5bf39db,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-4134094c-8f5e-4eec-a386-670040a09eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-283937e3-4030-4cd6-ba2e-bb13dd9ad801,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-3d3347ff-192d-45e6-8939-bb3f3abf0273,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-87d83187-8f09-4610-8fcd-b40c84f61f20,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-0a97a629-811f-4670-bbb1-c2c46018d953,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-97e18a44-95d6-45de-8b87-314b7b937f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-5c889828-215e-4ad7-a2fd-c820ef075be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885680757-172.17.0.3-1598583742059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39099,DS-8774857c-665d-4d2d-afe3-b2d4a5bf39db,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-4134094c-8f5e-4eec-a386-670040a09eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-283937e3-4030-4cd6-ba2e-bb13dd9ad801,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-3d3347ff-192d-45e6-8939-bb3f3abf0273,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-87d83187-8f09-4610-8fcd-b40c84f61f20,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-0a97a629-811f-4670-bbb1-c2c46018d953,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-97e18a44-95d6-45de-8b87-314b7b937f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-5c889828-215e-4ad7-a2fd-c820ef075be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299098889-172.17.0.3-1598584025705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-9480edaa-df33-4d64-bbf4-00fba970e298,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-d7f7e345-537c-4351-b142-519cb63d124e,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-13020ca0-8ddc-42a5-874b-df2b6f2e0699,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-c864ced1-b93c-48e6-be53-77c6261761ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-7bcfd840-a00e-48b6-baf5-a3d858b38828,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-a914a373-9f01-48f0-893e-75ad62dc8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-e01b21a3-3141-46e0-acad-b3e5422bf2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-f0efb327-b0c6-45ce-ace6-15e26cf8c738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299098889-172.17.0.3-1598584025705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-9480edaa-df33-4d64-bbf4-00fba970e298,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-d7f7e345-537c-4351-b142-519cb63d124e,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-13020ca0-8ddc-42a5-874b-df2b6f2e0699,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-c864ced1-b93c-48e6-be53-77c6261761ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-7bcfd840-a00e-48b6-baf5-a3d858b38828,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-a914a373-9f01-48f0-893e-75ad62dc8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-e01b21a3-3141-46e0-acad-b3e5422bf2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-f0efb327-b0c6-45ce-ace6-15e26cf8c738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236130914-172.17.0.3-1598584377164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-b0f5a32e-fd67-4063-921a-3eb3b6660f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-5506c352-27da-476f-bd0d-1db17ebf48b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-6e31553f-66d3-47bf-814f-14ddaed05f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-816b7a10-5b8b-4953-952a-e3523f872573,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-02982036-8275-42cb-bc75-9caf204ee577,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-0308842d-516f-40de-b544-d1e65809d184,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-cf0c0d32-fd22-4bdb-8035-b2f715e03233,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-692efe77-6cad-4a29-924c-1f72103be110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236130914-172.17.0.3-1598584377164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-b0f5a32e-fd67-4063-921a-3eb3b6660f89,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-5506c352-27da-476f-bd0d-1db17ebf48b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-6e31553f-66d3-47bf-814f-14ddaed05f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-816b7a10-5b8b-4953-952a-e3523f872573,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-02982036-8275-42cb-bc75-9caf204ee577,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-0308842d-516f-40de-b544-d1e65809d184,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-cf0c0d32-fd22-4bdb-8035-b2f715e03233,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-692efe77-6cad-4a29-924c-1f72103be110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085720226-172.17.0.3-1598584745237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-d4af7c2a-5680-4b42-be48-955330b275eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-019fd23f-cbae-4202-9396-e997242c554e,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-9c458a65-e962-47b7-800a-66a14abbef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-6aa2f6bb-9c32-4d5b-a318-9a627a1d6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f638c5f5-6bb7-4ed2-9f8e-38ed7893bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-912cdae6-fa40-4c0a-beca-c4e83c77cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-eea72c93-39fd-4172-99b5-f0aba3cc6b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-19caa044-6790-47ba-b99f-17dbf3edece0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085720226-172.17.0.3-1598584745237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-d4af7c2a-5680-4b42-be48-955330b275eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-019fd23f-cbae-4202-9396-e997242c554e,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-9c458a65-e962-47b7-800a-66a14abbef1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-6aa2f6bb-9c32-4d5b-a318-9a627a1d6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f638c5f5-6bb7-4ed2-9f8e-38ed7893bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-912cdae6-fa40-4c0a-beca-c4e83c77cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-eea72c93-39fd-4172-99b5-f0aba3cc6b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-19caa044-6790-47ba-b99f-17dbf3edece0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966821374-172.17.0.3-1598585348380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43880,DS-9017d9bc-6484-4f49-ae29-73677aa24bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-86bf4e5f-1892-4576-b55e-eb2c1b5afb26,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-f5711ac2-32f4-46a4-844b-527ddf12cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-94949540-661b-4021-b183-5e685cf1393c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-f2d0a6db-911d-4a2d-83a9-9a24660f6e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-c1525663-188e-4a65-b0f2-b20adb1569c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-7136f7fc-2981-4dad-8310-41dbe9dbd17f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-c7492336-6372-4d0a-91d7-c252b5756b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966821374-172.17.0.3-1598585348380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43880,DS-9017d9bc-6484-4f49-ae29-73677aa24bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-86bf4e5f-1892-4576-b55e-eb2c1b5afb26,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-f5711ac2-32f4-46a4-844b-527ddf12cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-94949540-661b-4021-b183-5e685cf1393c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-f2d0a6db-911d-4a2d-83a9-9a24660f6e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-c1525663-188e-4a65-b0f2-b20adb1569c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-7136f7fc-2981-4dad-8310-41dbe9dbd17f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-c7492336-6372-4d0a-91d7-c252b5756b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851601358-172.17.0.3-1598585786091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-b28dd92a-b09b-40cf-a747-e709b194f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-0ce86aaa-543a-4993-81a9-c4f264cc8619,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-097bfc8f-24a2-4712-bb54-6dc71bde9397,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-59612185-4415-4384-b0cc-ccfb1a441030,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-a2f16b14-7572-4596-b048-80723f16074a,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-4102fd06-25b1-43d7-afb6-9abfd48a966f,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-a6ee84dc-318f-42db-9f69-364c4b73925c,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-ab72cab6-94cc-4433-b27f-82bd26c0df89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851601358-172.17.0.3-1598585786091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-b28dd92a-b09b-40cf-a747-e709b194f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-0ce86aaa-543a-4993-81a9-c4f264cc8619,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-097bfc8f-24a2-4712-bb54-6dc71bde9397,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-59612185-4415-4384-b0cc-ccfb1a441030,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-a2f16b14-7572-4596-b048-80723f16074a,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-4102fd06-25b1-43d7-afb6-9abfd48a966f,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-a6ee84dc-318f-42db-9f69-364c4b73925c,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-ab72cab6-94cc-4433-b27f-82bd26c0df89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514009191-172.17.0.3-1598585852305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-1bf34058-dace-4846-b497-a3bc2e9d9714,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-86797093-d650-467d-8dcb-0e95c86ca360,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-0967872c-8741-42c5-8119-97c103d5a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f8510ea9-a3e5-41f7-8902-1ae0f027645e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-2a79f81d-af0a-42e6-99a8-67960a132113,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0726a06e-e0e8-4d41-bde4-1c5693ca6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-834ac56d-888c-4ef6-bb3b-9d3f03645dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-1d68f8f7-b3da-4d28-93a7-3e795f9b03ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514009191-172.17.0.3-1598585852305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-1bf34058-dace-4846-b497-a3bc2e9d9714,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-86797093-d650-467d-8dcb-0e95c86ca360,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-0967872c-8741-42c5-8119-97c103d5a3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f8510ea9-a3e5-41f7-8902-1ae0f027645e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-2a79f81d-af0a-42e6-99a8-67960a132113,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0726a06e-e0e8-4d41-bde4-1c5693ca6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-834ac56d-888c-4ef6-bb3b-9d3f03645dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-1d68f8f7-b3da-4d28-93a7-3e795f9b03ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497601334-172.17.0.3-1598585919335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-16b65007-52a5-4a50-9ee9-69060b120a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-84e6f108-7827-4e04-8e6c-72da9d6c4a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b1db973f-54d5-434d-be10-773bf21e0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-17256cf9-123a-4069-a508-cecef0a2a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-b64affbd-eff2-434c-ab5d-14659cc04187,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-0d547540-7860-43cc-93d5-bde971b71698,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-65c754fa-9b9f-4a00-bca7-3471fa565830,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-1bde9aff-6356-4cac-983c-4fb62bb2dfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497601334-172.17.0.3-1598585919335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-16b65007-52a5-4a50-9ee9-69060b120a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-84e6f108-7827-4e04-8e6c-72da9d6c4a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-b1db973f-54d5-434d-be10-773bf21e0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-17256cf9-123a-4069-a508-cecef0a2a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-b64affbd-eff2-434c-ab5d-14659cc04187,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-0d547540-7860-43cc-93d5-bde971b71698,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-65c754fa-9b9f-4a00-bca7-3471fa565830,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-1bde9aff-6356-4cac-983c-4fb62bb2dfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510921540-172.17.0.3-1598586121930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-81e2b6f0-ecf3-4844-a932-f35199de45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-f954bdf3-7b15-4c8a-af02-32ddc9f51118,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-3b5f6613-5c07-483a-a24f-e0c0bdbcee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-70c20030-51b1-44bb-97e1-ea2f08def636,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-4cf8d10b-c4c3-41f8-8872-3da772cfeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-195d4bc0-9e36-48a6-922e-863af6296af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-287fc4d0-bc41-4b7d-9560-6a45dbbbad88,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-ea1369b5-58d7-4194-8be2-c732141920fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510921540-172.17.0.3-1598586121930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-81e2b6f0-ecf3-4844-a932-f35199de45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-f954bdf3-7b15-4c8a-af02-32ddc9f51118,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-3b5f6613-5c07-483a-a24f-e0c0bdbcee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-70c20030-51b1-44bb-97e1-ea2f08def636,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-4cf8d10b-c4c3-41f8-8872-3da772cfeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-195d4bc0-9e36-48a6-922e-863af6296af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-287fc4d0-bc41-4b7d-9560-6a45dbbbad88,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-ea1369b5-58d7-4194-8be2-c732141920fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531971128-172.17.0.3-1598586312312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-77afd4da-a12e-4927-9e77-9a350a64cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-d243497b-bcf7-4ba7-9888-06df2a169db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-33464166-283c-4be6-8703-3a9f35713e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-a5462997-d119-4952-8500-11adf04ca6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-bf3728a9-e428-49a5-8ced-5e406f8d5970,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-7fc4ecc7-258b-46c7-9c64-f1d378e08175,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-07bafdbc-7809-4a46-8c19-d404f446c404,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ee4fadab-193c-446c-99aa-1d03e9277a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531971128-172.17.0.3-1598586312312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-77afd4da-a12e-4927-9e77-9a350a64cf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-d243497b-bcf7-4ba7-9888-06df2a169db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-33464166-283c-4be6-8703-3a9f35713e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-a5462997-d119-4952-8500-11adf04ca6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-bf3728a9-e428-49a5-8ced-5e406f8d5970,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-7fc4ecc7-258b-46c7-9c64-f1d378e08175,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-07bafdbc-7809-4a46-8c19-d404f446c404,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ee4fadab-193c-446c-99aa-1d03e9277a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846757674-172.17.0.3-1598586377343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-04e06747-40f4-41b3-8b14-89429902e6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-dded6903-a673-4468-a7a5-33054c5ad379,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-2a25bb3a-3233-4ead-bc29-e0d27ddeed03,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-df7e0438-4133-4cbb-92be-a1bd96561345,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0f265547-a13f-4066-9857-38e5f55664d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-4a5ccfe7-6c8d-4079-9017-d745b3d9ed4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5e750cff-c271-4413-8313-d33f5839403d,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-e67b72ef-a974-4a68-81cb-5d4f9e29ae17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846757674-172.17.0.3-1598586377343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-04e06747-40f4-41b3-8b14-89429902e6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-dded6903-a673-4468-a7a5-33054c5ad379,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-2a25bb3a-3233-4ead-bc29-e0d27ddeed03,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-df7e0438-4133-4cbb-92be-a1bd96561345,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0f265547-a13f-4066-9857-38e5f55664d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-4a5ccfe7-6c8d-4079-9017-d745b3d9ed4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5e750cff-c271-4413-8313-d33f5839403d,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-e67b72ef-a974-4a68-81cb-5d4f9e29ae17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641906789-172.17.0.3-1598586407591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-ea1684d9-128b-4d78-9d15-0f347d78aa14,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b236e367-a8fb-4c87-9605-16a4475b8fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a10a78b4-f54a-4299-82a7-8ca9a678446a,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-0142e51d-5346-4804-b519-0c6710b10682,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-3e4fa8d9-8f59-43b9-8a7f-85419776e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-f0e46bfa-ec55-4faf-835e-36f8911b2536,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-04dd6d42-46d5-45a9-bc2c-c0b2c5d0fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-ec1b46bc-725f-4630-a906-9042afee32ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641906789-172.17.0.3-1598586407591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-ea1684d9-128b-4d78-9d15-0f347d78aa14,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b236e367-a8fb-4c87-9605-16a4475b8fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a10a78b4-f54a-4299-82a7-8ca9a678446a,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-0142e51d-5346-4804-b519-0c6710b10682,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-3e4fa8d9-8f59-43b9-8a7f-85419776e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-f0e46bfa-ec55-4faf-835e-36f8911b2536,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-04dd6d42-46d5-45a9-bc2c-c0b2c5d0fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-ec1b46bc-725f-4630-a906-9042afee32ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5147
