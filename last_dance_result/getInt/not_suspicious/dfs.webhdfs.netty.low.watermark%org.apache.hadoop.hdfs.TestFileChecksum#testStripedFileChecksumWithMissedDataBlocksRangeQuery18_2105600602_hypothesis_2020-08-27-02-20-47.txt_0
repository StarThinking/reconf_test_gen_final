reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431210549-172.17.0.6-1598494930732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-e7eca40b-9cb8-4219-a0e3-627f663b9834,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-e084175e-83d7-4967-b24a-7c55abed60ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-22b6080f-23cc-47d7-9c92-ed99477a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-0150ede2-2aea-4134-a2c6-6b849ffd885e,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-e222362c-a7f9-423d-8e2a-e28c3b5d7609,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-14d4ab5c-7624-4a6f-8bcd-7fcef39dcca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-1d2f5550-9559-4770-81a6-8ce04980eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f1667354-7b9f-4533-bc0e-ad8c8f1da792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431210549-172.17.0.6-1598494930732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-e7eca40b-9cb8-4219-a0e3-627f663b9834,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-e084175e-83d7-4967-b24a-7c55abed60ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-22b6080f-23cc-47d7-9c92-ed99477a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-0150ede2-2aea-4134-a2c6-6b849ffd885e,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-e222362c-a7f9-423d-8e2a-e28c3b5d7609,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-14d4ab5c-7624-4a6f-8bcd-7fcef39dcca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-1d2f5550-9559-4770-81a6-8ce04980eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-f1667354-7b9f-4533-bc0e-ad8c8f1da792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711628321-172.17.0.6-1598495137121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-00982ffc-362e-4fba-b5aa-e4884269f041,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-501868b7-9473-45ce-b6ee-cbd07157f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-5d73bd16-e448-4d5e-9064-fc142dfc4bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-eaa3f114-c319-4310-8f7f-970ae899059c,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-7ced38a7-e8f5-49ac-a7b8-c2fc5a142ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-22a1e094-2452-4442-83a2-edcd2db6c564,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-9dc03f7a-c48a-4dc5-9a07-9e8771bdf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-3251c642-27ee-4e27-ae2f-1b279f2bcc01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711628321-172.17.0.6-1598495137121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40361,DS-00982ffc-362e-4fba-b5aa-e4884269f041,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-501868b7-9473-45ce-b6ee-cbd07157f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-5d73bd16-e448-4d5e-9064-fc142dfc4bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-eaa3f114-c319-4310-8f7f-970ae899059c,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-7ced38a7-e8f5-49ac-a7b8-c2fc5a142ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-22a1e094-2452-4442-83a2-edcd2db6c564,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-9dc03f7a-c48a-4dc5-9a07-9e8771bdf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-3251c642-27ee-4e27-ae2f-1b279f2bcc01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443922985-172.17.0.6-1598495390696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-df0816a1-78bd-468a-9c17-67a8f342ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-e4c4dd2d-a624-4636-a665-bd0acb9219f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-ae11b7c1-f933-40d7-80fb-503f3e2716f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-0aa824ce-6a0d-4138-959e-190e785fb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-55477efe-b3a6-4694-b293-56034073a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-a6c56cfb-a4d2-4dda-bfa9-3e31d17d68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-48d63b96-abcd-426d-aa4e-559af97c52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-2d37bc95-51d7-481d-b339-3df33a4245b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443922985-172.17.0.6-1598495390696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-df0816a1-78bd-468a-9c17-67a8f342ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-e4c4dd2d-a624-4636-a665-bd0acb9219f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-ae11b7c1-f933-40d7-80fb-503f3e2716f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-0aa824ce-6a0d-4138-959e-190e785fb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-55477efe-b3a6-4694-b293-56034073a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-a6c56cfb-a4d2-4dda-bfa9-3e31d17d68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-48d63b96-abcd-426d-aa4e-559af97c52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-2d37bc95-51d7-481d-b339-3df33a4245b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015344653-172.17.0.6-1598495662586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-4e79068a-de5e-4878-aa80-8c2b1bc359be,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-67bfc6f0-d60b-4615-b2ce-03689b537ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-5ba38043-5f7e-4071-86f1-d63fe195fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-d345c40a-2083-4975-83d9-1bb7e8dc937c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-6ac65505-383e-4a90-888a-ecea7cad192f,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-e2700ab4-9f87-46cd-b297-f2af5b2afac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-990bf499-f3c1-4e23-8e46-a6d21a6d7f23,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-645e563f-b882-47e6-92fc-94dada453368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015344653-172.17.0.6-1598495662586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-4e79068a-de5e-4878-aa80-8c2b1bc359be,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-67bfc6f0-d60b-4615-b2ce-03689b537ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-5ba38043-5f7e-4071-86f1-d63fe195fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-d345c40a-2083-4975-83d9-1bb7e8dc937c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-6ac65505-383e-4a90-888a-ecea7cad192f,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-e2700ab4-9f87-46cd-b297-f2af5b2afac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-990bf499-f3c1-4e23-8e46-a6d21a6d7f23,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-645e563f-b882-47e6-92fc-94dada453368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054095388-172.17.0.6-1598495921514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-b8b08d88-6ea5-4d15-8622-c08b69b6af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-63ebe18b-e6c1-4df1-8d26-c944e9430810,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5b7d1579-c337-4abc-93bf-3241444c6208,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-4ed7a359-63b8-4d81-a040-37d5ac5d73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-496dcd42-5024-4274-a372-eb930b75b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-541855e7-8a83-473f-a155-97d3c6690dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-9d27c368-f4ab-4e1c-a8f2-36270a693ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-b4eb5d4a-0ca7-49f3-9961-2c6f20db701d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054095388-172.17.0.6-1598495921514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-b8b08d88-6ea5-4d15-8622-c08b69b6af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-63ebe18b-e6c1-4df1-8d26-c944e9430810,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5b7d1579-c337-4abc-93bf-3241444c6208,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-4ed7a359-63b8-4d81-a040-37d5ac5d73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-496dcd42-5024-4274-a372-eb930b75b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-541855e7-8a83-473f-a155-97d3c6690dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-9d27c368-f4ab-4e1c-a8f2-36270a693ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-b4eb5d4a-0ca7-49f3-9961-2c6f20db701d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059670501-172.17.0.6-1598496073124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-b6dd3dfc-adcc-4d65-bfc8-5cc34235e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-3f7ada62-c350-4491-a5f2-af9c7c6a9e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c60dfe11-6315-4f66-93dd-b99c7c63cb99,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-a09eec5e-a21f-413f-817d-81a7ef639248,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-67c75779-4ea7-44c9-a32a-795ed99c8d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-87250c24-7159-49f3-8a64-966e2f24d298,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-b05d9f4d-b014-4c48-ad3f-ef1bb42bb34b,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-9fa6795c-115f-48d6-a1b8-b2d896166a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059670501-172.17.0.6-1598496073124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-b6dd3dfc-adcc-4d65-bfc8-5cc34235e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-3f7ada62-c350-4491-a5f2-af9c7c6a9e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c60dfe11-6315-4f66-93dd-b99c7c63cb99,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-a09eec5e-a21f-413f-817d-81a7ef639248,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-67c75779-4ea7-44c9-a32a-795ed99c8d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-87250c24-7159-49f3-8a64-966e2f24d298,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-b05d9f4d-b014-4c48-ad3f-ef1bb42bb34b,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-9fa6795c-115f-48d6-a1b8-b2d896166a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078249466-172.17.0.6-1598496385584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-2018ff16-8775-4e8d-8ba2-2a3c0d01daae,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-f057df8e-f1d7-43db-a7f6-a7441948c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-8eca9f63-0a5c-4322-9ac6-17394674b335,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-2ca1b8a6-2ce6-40a5-85cd-03bc690d74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-b3919bf0-8326-4667-afb8-90dddade2c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-9d75a7e2-ec33-4785-8b81-11e4d1c500d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-762281e8-64be-40a8-a1a1-462ce404f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-c8a1cf37-4ee4-4e98-99ed-c8470381feda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078249466-172.17.0.6-1598496385584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-2018ff16-8775-4e8d-8ba2-2a3c0d01daae,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-f057df8e-f1d7-43db-a7f6-a7441948c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-8eca9f63-0a5c-4322-9ac6-17394674b335,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-2ca1b8a6-2ce6-40a5-85cd-03bc690d74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-b3919bf0-8326-4667-afb8-90dddade2c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-9d75a7e2-ec33-4785-8b81-11e4d1c500d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-762281e8-64be-40a8-a1a1-462ce404f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-c8a1cf37-4ee4-4e98-99ed-c8470381feda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343038692-172.17.0.6-1598496948030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-1a5ee570-b3d0-4cf4-bb8e-4db7ed563099,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-12222401-4e5d-441d-a35b-0961aa235eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-fa201f07-cc1d-486b-9157-330bc2da9f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-dc95f277-b991-4f8e-a34e-d4e98c10b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c99e7088-694a-4673-be51-b52852cb218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-4f9d7016-04da-4346-b69a-c9cbff907179,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-566d3ee3-aed8-4906-83a3-0929b2af4829,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-32cb293e-b20e-4cb2-bf1c-75815d617d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343038692-172.17.0.6-1598496948030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-1a5ee570-b3d0-4cf4-bb8e-4db7ed563099,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-12222401-4e5d-441d-a35b-0961aa235eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-fa201f07-cc1d-486b-9157-330bc2da9f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-dc95f277-b991-4f8e-a34e-d4e98c10b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c99e7088-694a-4673-be51-b52852cb218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-4f9d7016-04da-4346-b69a-c9cbff907179,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-566d3ee3-aed8-4906-83a3-0929b2af4829,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-32cb293e-b20e-4cb2-bf1c-75815d617d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494654963-172.17.0.6-1598497143182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-518c70e8-a39c-40da-8d14-ca7c2a7671c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-79d5eff2-47d6-49bb-97be-2dc9810343c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-9373342d-3efc-4208-a522-d433d7a01237,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5762c1d2-105e-4dad-82e5-93435c53e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-43a21f21-83f2-4130-88da-c7a0c0819887,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8e55e531-f143-4141-8470-5f6fb4d14dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-33c09eb9-bbe6-45e2-a288-de575e83db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-49a10837-b622-421a-922a-6e554173d049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494654963-172.17.0.6-1598497143182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-518c70e8-a39c-40da-8d14-ca7c2a7671c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-79d5eff2-47d6-49bb-97be-2dc9810343c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-9373342d-3efc-4208-a522-d433d7a01237,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5762c1d2-105e-4dad-82e5-93435c53e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-43a21f21-83f2-4130-88da-c7a0c0819887,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8e55e531-f143-4141-8470-5f6fb4d14dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-33c09eb9-bbe6-45e2-a288-de575e83db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-49a10837-b622-421a-922a-6e554173d049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047651800-172.17.0.6-1598497417381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-964cca71-713a-4fda-bb8e-8aaa5f0384c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-e6a01b93-ce3d-4da1-a8b6-15d604501143,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-17027918-402a-4b99-b947-54331ef48016,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-5a25866b-d905-4269-8a4c-445c5c983703,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-e11bf850-69b7-45db-a269-125db6a27150,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-9dd6ad37-edd9-42e0-a2cc-6d1d71d1a016,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-7b151c76-9571-4f1f-b2d4-65aac6046cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-23358188-dc34-4918-8c57-6eceeee797c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047651800-172.17.0.6-1598497417381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-964cca71-713a-4fda-bb8e-8aaa5f0384c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-e6a01b93-ce3d-4da1-a8b6-15d604501143,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-17027918-402a-4b99-b947-54331ef48016,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-5a25866b-d905-4269-8a4c-445c5c983703,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-e11bf850-69b7-45db-a269-125db6a27150,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-9dd6ad37-edd9-42e0-a2cc-6d1d71d1a016,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-7b151c76-9571-4f1f-b2d4-65aac6046cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-23358188-dc34-4918-8c57-6eceeee797c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630474875-172.17.0.6-1598497700463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-4c0357b6-e693-4418-a356-01e4a5f7b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-6976f425-465f-49f5-b332-baad17fc2e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b900f30d-4d4f-4de2-8cb5-2fff90dcdd34,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-7fad6d0a-ec52-4536-a955-d8cfffda8e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-b2654e81-a111-4dec-b36f-871415f23e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-30035198-0d74-4776-8b27-1f8eaef25104,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-5543d565-73ef-48d6-ba72-d0b9ed77c2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-766dd35c-f040-4c12-96ad-ea2ab7c5c883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630474875-172.17.0.6-1598497700463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-4c0357b6-e693-4418-a356-01e4a5f7b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-6976f425-465f-49f5-b332-baad17fc2e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b900f30d-4d4f-4de2-8cb5-2fff90dcdd34,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-7fad6d0a-ec52-4536-a955-d8cfffda8e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-b2654e81-a111-4dec-b36f-871415f23e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-30035198-0d74-4776-8b27-1f8eaef25104,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-5543d565-73ef-48d6-ba72-d0b9ed77c2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-766dd35c-f040-4c12-96ad-ea2ab7c5c883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671857668-172.17.0.6-1598497799899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-a122b058-29bb-46ba-a0c5-7c0f935ffafa,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e9360472-c9aa-417a-a817-4523b79379e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-8ff47448-c3d6-4cb1-9253-93b9ebd37402,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-63fc7db7-4b12-490c-9072-a589d4a9a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-a978f0b8-1d96-4810-8662-6683974ae246,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-846b91d4-9c38-4abb-a22e-d2b106fdad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-574a0f4b-5af1-43fd-b52d-3f17d17dde37,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-8e8b9efe-d47a-4832-8482-19a9b27137b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671857668-172.17.0.6-1598497799899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-a122b058-29bb-46ba-a0c5-7c0f935ffafa,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-e9360472-c9aa-417a-a817-4523b79379e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-8ff47448-c3d6-4cb1-9253-93b9ebd37402,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-63fc7db7-4b12-490c-9072-a589d4a9a06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-a978f0b8-1d96-4810-8662-6683974ae246,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-846b91d4-9c38-4abb-a22e-d2b106fdad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-574a0f4b-5af1-43fd-b52d-3f17d17dde37,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-8e8b9efe-d47a-4832-8482-19a9b27137b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100016118-172.17.0.6-1598498211750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-ecc8bab8-e2cf-4308-abcd-ebf62491bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-49b8e9ed-e98b-49c5-82d8-6edb15d1a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-c24a9166-d600-47b5-9917-a596420fd87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-5e70ca7e-e6de-4c9f-b6d2-cc8b107026d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-595a5188-2f70-4c4c-a03f-92ccb822ea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-d5e85ba0-e9ab-4c5b-b7bc-452c35a423c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-1b085bd4-2d6c-4d5a-9ff7-fe163932894d,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-8bd26a0d-d070-4ed5-9d51-4a40b0fd26df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100016118-172.17.0.6-1598498211750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42821,DS-ecc8bab8-e2cf-4308-abcd-ebf62491bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-49b8e9ed-e98b-49c5-82d8-6edb15d1a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-c24a9166-d600-47b5-9917-a596420fd87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-5e70ca7e-e6de-4c9f-b6d2-cc8b107026d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-595a5188-2f70-4c4c-a03f-92ccb822ea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-d5e85ba0-e9ab-4c5b-b7bc-452c35a423c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-1b085bd4-2d6c-4d5a-9ff7-fe163932894d,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-8bd26a0d-d070-4ed5-9d51-4a40b0fd26df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896267619-172.17.0.6-1598498657087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-0098d763-8ae4-4ff9-a3af-386f2426e322,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-e2e6da3c-71e6-41f7-bddd-a04205bf43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-09584e3e-1a44-4ae2-8ea3-868d298e3536,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-292dc751-180f-4773-b062-975c5cb85eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-b3a6d3f4-8db6-49a4-a97e-e79cf29c6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-bdf6f30b-fa85-4d1d-9f98-3a5a51b1377a,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-8166736e-df0f-46c7-a8b6-17f2533aa464,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-5f3bf9a7-b927-4fc0-a3d1-046598345df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896267619-172.17.0.6-1598498657087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-0098d763-8ae4-4ff9-a3af-386f2426e322,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-e2e6da3c-71e6-41f7-bddd-a04205bf43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-09584e3e-1a44-4ae2-8ea3-868d298e3536,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-292dc751-180f-4773-b062-975c5cb85eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-b3a6d3f4-8db6-49a4-a97e-e79cf29c6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-bdf6f30b-fa85-4d1d-9f98-3a5a51b1377a,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-8166736e-df0f-46c7-a8b6-17f2533aa464,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-5f3bf9a7-b927-4fc0-a3d1-046598345df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429089112-172.17.0.6-1598498889474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44473,DS-85b0dc54-04f4-4e7a-b9a7-dfbe14f37e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-656d61f4-aca8-4eef-a1f6-1215382d7c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-e9d83374-e47d-4355-b4a3-c9b9e834a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-2d9eb8a8-543a-494b-a6b3-c9122f9c7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-a6cee3d3-79af-41ce-ad7a-21a89c2652ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9870e5d4-c40a-4e8c-85a0-c5cf608d614a,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-322f7ea1-4440-4259-80a4-7d1db67fae20,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-4c062d92-4da1-4d3e-852b-c13226d01fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429089112-172.17.0.6-1598498889474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44473,DS-85b0dc54-04f4-4e7a-b9a7-dfbe14f37e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-656d61f4-aca8-4eef-a1f6-1215382d7c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-e9d83374-e47d-4355-b4a3-c9b9e834a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-2d9eb8a8-543a-494b-a6b3-c9122f9c7ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-a6cee3d3-79af-41ce-ad7a-21a89c2652ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9870e5d4-c40a-4e8c-85a0-c5cf608d614a,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-322f7ea1-4440-4259-80a4-7d1db67fae20,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-4c062d92-4da1-4d3e-852b-c13226d01fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119944729-172.17.0.6-1598499310095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-3d3fc148-8f44-4c31-9f5a-54e190ce2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2636bace-3d28-49d8-a590-680c9ef0ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-0305a43f-bdf1-44f8-b2ac-3c52561b60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-334e00a2-7cb0-43ef-bfc8-dd222bc4901f,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-4a973dae-d1d3-43d2-bc67-6c215486ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ffcd42b3-3676-444c-95b5-4adb71c0003d,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9a56a448-c4af-4a4b-9f96-207daed7a296,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-87a70e3a-6ee1-4ade-96c3-e9fd54c0711f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119944729-172.17.0.6-1598499310095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-3d3fc148-8f44-4c31-9f5a-54e190ce2a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2636bace-3d28-49d8-a590-680c9ef0ec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-0305a43f-bdf1-44f8-b2ac-3c52561b60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-334e00a2-7cb0-43ef-bfc8-dd222bc4901f,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-4a973dae-d1d3-43d2-bc67-6c215486ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ffcd42b3-3676-444c-95b5-4adb71c0003d,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9a56a448-c4af-4a4b-9f96-207daed7a296,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-87a70e3a-6ee1-4ade-96c3-e9fd54c0711f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5501
