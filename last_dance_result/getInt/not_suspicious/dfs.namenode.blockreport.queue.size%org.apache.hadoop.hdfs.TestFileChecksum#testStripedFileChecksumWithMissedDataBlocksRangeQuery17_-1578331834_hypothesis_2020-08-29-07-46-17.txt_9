reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278431147-172.17.0.2-1598687187889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-099ee276-1fc9-4138-a982-46f06d42b138,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-9c255599-bd47-4d38-a671-97074c851b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-db340b38-65f1-4c85-ace5-1b86bfde759b,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-aeefd560-53b9-4c20-90b8-5dc9794df48b,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-8ecbc1d4-b066-4f14-bc5e-29bb239df8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-cc3a18e1-bf38-4b36-8eb9-13448512510a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-fa4c73a8-e027-4502-b5c4-9f46e0b02205,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-0f496183-94e7-4f5b-82a8-7d58a81fd842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278431147-172.17.0.2-1598687187889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-099ee276-1fc9-4138-a982-46f06d42b138,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-9c255599-bd47-4d38-a671-97074c851b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-db340b38-65f1-4c85-ace5-1b86bfde759b,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-aeefd560-53b9-4c20-90b8-5dc9794df48b,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-8ecbc1d4-b066-4f14-bc5e-29bb239df8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-cc3a18e1-bf38-4b36-8eb9-13448512510a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-fa4c73a8-e027-4502-b5c4-9f46e0b02205,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-0f496183-94e7-4f5b-82a8-7d58a81fd842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758718484-172.17.0.2-1598687250847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-c7d4e3e5-42e3-4791-97d9-59eb72e49a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-93ea6ac6-53ca-4868-b603-5e1818876fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-2c0407fa-4549-41bc-ac0e-5564b4e82af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-f849b6ae-365c-4cf1-8988-603545a7d200,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-50325bde-ff14-4f9c-bac9-85a987a6ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-a0e65d70-b518-421a-94c3-92ae0dc279de,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-7bec6cd0-3ade-4687-86db-35b2feafc142,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-e5cc5c44-dd9b-48ea-bb1d-614d7c217401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758718484-172.17.0.2-1598687250847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-c7d4e3e5-42e3-4791-97d9-59eb72e49a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-93ea6ac6-53ca-4868-b603-5e1818876fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-2c0407fa-4549-41bc-ac0e-5564b4e82af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-f849b6ae-365c-4cf1-8988-603545a7d200,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-50325bde-ff14-4f9c-bac9-85a987a6ad81,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-a0e65d70-b518-421a-94c3-92ae0dc279de,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-7bec6cd0-3ade-4687-86db-35b2feafc142,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-e5cc5c44-dd9b-48ea-bb1d-614d7c217401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730509830-172.17.0.2-1598687890842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-2345d6c9-f375-4f74-af97-e0902ec15f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-84700d32-7a52-40ad-8ad4-a9bb03f6a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-e25d731c-4055-4d92-90ea-f6520287647b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-bf5d5f14-2702-4579-9726-30b869cab262,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0ac68ded-4e1c-46f8-9c08-34afa4dc3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-23f33fc0-b36b-4315-aac7-45c03c0e5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-775b7e5f-ae1b-455c-9581-2963dd0214f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-05e6738e-6cb1-4722-983f-231994e71184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730509830-172.17.0.2-1598687890842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-2345d6c9-f375-4f74-af97-e0902ec15f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-84700d32-7a52-40ad-8ad4-a9bb03f6a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-e25d731c-4055-4d92-90ea-f6520287647b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-bf5d5f14-2702-4579-9726-30b869cab262,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-0ac68ded-4e1c-46f8-9c08-34afa4dc3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-23f33fc0-b36b-4315-aac7-45c03c0e5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-775b7e5f-ae1b-455c-9581-2963dd0214f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-05e6738e-6cb1-4722-983f-231994e71184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749554128-172.17.0.2-1598687995684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-98798dd7-9a47-43b3-8c6b-5d355243b042,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-0b9c33db-3a55-46bb-8c7b-1bd2907e4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-5a6de229-27ff-42e7-b359-83203b1bcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-9c8ae7e6-8bc5-4508-b6cc-e4b526043794,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-46dcbd57-6383-4199-9b02-b4cbb0a675fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-37a59f41-0d19-4fca-b439-239b4d5a7698,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-578008b3-d4cc-4e60-b908-f0ee917c2d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-efe1a898-8cd4-4f27-bd12-8a271ea038be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749554128-172.17.0.2-1598687995684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-98798dd7-9a47-43b3-8c6b-5d355243b042,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-0b9c33db-3a55-46bb-8c7b-1bd2907e4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-5a6de229-27ff-42e7-b359-83203b1bcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-9c8ae7e6-8bc5-4508-b6cc-e4b526043794,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-46dcbd57-6383-4199-9b02-b4cbb0a675fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-37a59f41-0d19-4fca-b439-239b4d5a7698,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-578008b3-d4cc-4e60-b908-f0ee917c2d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-efe1a898-8cd4-4f27-bd12-8a271ea038be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977329118-172.17.0.2-1598688794401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-7b27fbe1-789f-4473-a7b7-ed11def09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9d8020ab-5212-4c0b-8d84-4c63317a29f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-9fd56351-258e-45d4-ab79-2bbfcfee0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-3a12acb4-109b-4c3f-912f-38b32d97bb89,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-cbee235d-00e3-4c35-8e20-9a7996d81c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-1a7ff337-df65-4555-b12e-08a121ee36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-1026ce04-7876-4c00-814a-dbcf710fad69,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-b1ef9c38-9afe-40a6-8cdb-1c977ae34ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977329118-172.17.0.2-1598688794401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-7b27fbe1-789f-4473-a7b7-ed11def09ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-9d8020ab-5212-4c0b-8d84-4c63317a29f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-9fd56351-258e-45d4-ab79-2bbfcfee0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-3a12acb4-109b-4c3f-912f-38b32d97bb89,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-cbee235d-00e3-4c35-8e20-9a7996d81c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-1a7ff337-df65-4555-b12e-08a121ee36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-1026ce04-7876-4c00-814a-dbcf710fad69,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-b1ef9c38-9afe-40a6-8cdb-1c977ae34ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054056520-172.17.0.2-1598688831035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-a84a0adf-2f1b-4e9f-b14f-448e6d9479ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9634c121-ad87-49a5-a5bd-f1c8c69e9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-af368a11-a744-4085-bdb6-4c5c1a36d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-c5b7d7f4-31b9-43f1-a49c-caffbcbb778b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-e01c61be-e9a9-43b3-9707-c3cccca83bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-70fa9b43-7a4f-4e7c-afde-986f63b48f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-a39de149-72d5-4ea4-80fc-4eab3d511185,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-1e9871fa-3f53-4438-909a-e9266c141240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054056520-172.17.0.2-1598688831035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-a84a0adf-2f1b-4e9f-b14f-448e6d9479ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9634c121-ad87-49a5-a5bd-f1c8c69e9a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-af368a11-a744-4085-bdb6-4c5c1a36d2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-c5b7d7f4-31b9-43f1-a49c-caffbcbb778b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-e01c61be-e9a9-43b3-9707-c3cccca83bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-70fa9b43-7a4f-4e7c-afde-986f63b48f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-a39de149-72d5-4ea4-80fc-4eab3d511185,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-1e9871fa-3f53-4438-909a-e9266c141240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694537524-172.17.0.2-1598688866484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-2a0aaa7b-c84d-4d62-8ab7-ef1c7343b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-9e8b7935-7194-4b20-8192-4d4d170f822f,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-75dae532-8279-4269-9f87-058a6abf6321,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-74e9fcff-6d1d-4dcf-885e-c2b4889e4dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-725a944f-9280-4802-92c5-394b43207060,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-a2708d3b-1aab-4eb3-ad26-f04d6b60b633,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-f4848509-e585-4e1b-8e5f-98a2bc4e8a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-f16518f4-0e9a-49bf-b9cd-75003407e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694537524-172.17.0.2-1598688866484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-2a0aaa7b-c84d-4d62-8ab7-ef1c7343b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-9e8b7935-7194-4b20-8192-4d4d170f822f,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-75dae532-8279-4269-9f87-058a6abf6321,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-74e9fcff-6d1d-4dcf-885e-c2b4889e4dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-725a944f-9280-4802-92c5-394b43207060,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-a2708d3b-1aab-4eb3-ad26-f04d6b60b633,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-f4848509-e585-4e1b-8e5f-98a2bc4e8a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-f16518f4-0e9a-49bf-b9cd-75003407e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093040690-172.17.0.2-1598689638556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-5caa8f00-c5f5-4a54-80ab-664f2f6693d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-efa60ec7-2ad2-4f38-8b4d-0bb7f5c3a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-b02a666f-1343-4f5e-a420-76aaecf14b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-cf23d8e3-f950-4466-96ee-dc5961667119,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-fc391f38-089b-4ce7-868b-e76820ac0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-2dd81767-8636-4085-9c65-5265867c41b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-c969dfdb-3c1e-4090-ba2c-fd4af16c25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-370b5d12-93e7-456c-98c8-3f6ef66896f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093040690-172.17.0.2-1598689638556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-5caa8f00-c5f5-4a54-80ab-664f2f6693d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-efa60ec7-2ad2-4f38-8b4d-0bb7f5c3a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-b02a666f-1343-4f5e-a420-76aaecf14b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-cf23d8e3-f950-4466-96ee-dc5961667119,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-fc391f38-089b-4ce7-868b-e76820ac0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-2dd81767-8636-4085-9c65-5265867c41b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-c969dfdb-3c1e-4090-ba2c-fd4af16c25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-370b5d12-93e7-456c-98c8-3f6ef66896f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193899308-172.17.0.2-1598690074515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-bfda2652-b855-4b35-888b-f51d393fd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0e9b5e20-3092-450e-aa39-a4473d2e28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-19c81e7a-015c-4b52-8335-6c350101cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-873e7a56-219c-4692-b4ef-0f43aefc0b65,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-58db9e03-4187-4bff-97f5-428970ecfb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-b549bf9c-c648-46c5-911b-15ac240c90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-612add3b-ae14-4461-91d8-fbfbe7e5a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-30f1c2af-2db8-46c5-ab8e-702fee6b9dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193899308-172.17.0.2-1598690074515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-bfda2652-b855-4b35-888b-f51d393fd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0e9b5e20-3092-450e-aa39-a4473d2e28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-19c81e7a-015c-4b52-8335-6c350101cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-873e7a56-219c-4692-b4ef-0f43aefc0b65,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-58db9e03-4187-4bff-97f5-428970ecfb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-b549bf9c-c648-46c5-911b-15ac240c90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-612add3b-ae14-4461-91d8-fbfbe7e5a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-30f1c2af-2db8-46c5-ab8e-702fee6b9dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638234088-172.17.0.2-1598690286964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-30a54c20-e80b-42c2-b16e-4475c34ee509,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-61eaf90c-20b4-43b5-a601-5ca0659190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-555f8c4b-a11e-4adb-97ff-fa9bdcfaca64,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-0bfd047f-e0e4-46ec-b20f-328df5f55611,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-c6a6ec09-81f8-4a86-a7ea-93a842b8fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-adc6ea26-31d8-4e78-9a09-7fb62f61e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-663c4890-d5cd-4334-a23d-d3f3cea99388,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-2e8fb397-fbd4-4f1c-aac7-94276557bc80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638234088-172.17.0.2-1598690286964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-30a54c20-e80b-42c2-b16e-4475c34ee509,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-61eaf90c-20b4-43b5-a601-5ca0659190f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-555f8c4b-a11e-4adb-97ff-fa9bdcfaca64,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-0bfd047f-e0e4-46ec-b20f-328df5f55611,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-c6a6ec09-81f8-4a86-a7ea-93a842b8fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-adc6ea26-31d8-4e78-9a09-7fb62f61e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-663c4890-d5cd-4334-a23d-d3f3cea99388,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-2e8fb397-fbd4-4f1c-aac7-94276557bc80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207378934-172.17.0.2-1598690324175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-f85cb39c-951d-4279-9c77-c3f94d85a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-7e052864-9645-4959-a5ec-7a6112a4e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-88bfdd8b-e161-4fb4-aa55-a040eb08beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-a5113cf7-73e6-4119-a9ca-ab230a58ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-623cb965-4a43-4dc7-8dcc-8a2ef1503523,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-bf547711-3630-4b80-ad84-08179c4c9174,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-56c44873-e98f-4ff7-80e6-1191a8ac6a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-bb3d52a0-6f1b-4a16-9150-5e87cfa7aa1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207378934-172.17.0.2-1598690324175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-f85cb39c-951d-4279-9c77-c3f94d85a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-7e052864-9645-4959-a5ec-7a6112a4e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-88bfdd8b-e161-4fb4-aa55-a040eb08beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-a5113cf7-73e6-4119-a9ca-ab230a58ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-623cb965-4a43-4dc7-8dcc-8a2ef1503523,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-bf547711-3630-4b80-ad84-08179c4c9174,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-56c44873-e98f-4ff7-80e6-1191a8ac6a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-bb3d52a0-6f1b-4a16-9150-5e87cfa7aa1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76379542-172.17.0.2-1598690487446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-5a48b2ee-a2da-46d6-bbc4-40b27e75e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-7531c01e-3160-4b1b-9e51-576ee8cd4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-9b053221-24e4-4cf7-841e-c4e053c7aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-fb2f2828-0b7f-4a69-aa9c-94ecac651082,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-7529d129-c3c6-42c9-bab2-40b087d3ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-dcfa20ad-6d0a-4591-988f-03e7644b4860,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-bcbabfaf-fed1-409b-acda-0bb17cf7d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1d7bf89c-af7c-4e8c-b4fd-f6852d3514d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76379542-172.17.0.2-1598690487446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-5a48b2ee-a2da-46d6-bbc4-40b27e75e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-7531c01e-3160-4b1b-9e51-576ee8cd4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-9b053221-24e4-4cf7-841e-c4e053c7aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-fb2f2828-0b7f-4a69-aa9c-94ecac651082,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-7529d129-c3c6-42c9-bab2-40b087d3ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-dcfa20ad-6d0a-4591-988f-03e7644b4860,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-bcbabfaf-fed1-409b-acda-0bb17cf7d8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-1d7bf89c-af7c-4e8c-b4fd-f6852d3514d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930711758-172.17.0.2-1598690556668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-b6eed0f8-9b67-4d90-a07c-42c7d18c7694,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-5ff98fe6-c2ba-489d-966e-cf6f24434530,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-0bcf1ae4-8d41-45d1-8182-5b896af92a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-d82cb55e-cdbb-48d5-9982-9a38f4c682e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d3bf1466-4194-4ef4-a0fd-5da92bababa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-5dacef92-777e-4cd4-9e31-d12c45127c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-04ec3f09-1cff-47a0-9ac3-2ba178f86937,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c31238c2-76ea-4c86-849f-7a1483d6ef2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930711758-172.17.0.2-1598690556668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-b6eed0f8-9b67-4d90-a07c-42c7d18c7694,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-5ff98fe6-c2ba-489d-966e-cf6f24434530,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-0bcf1ae4-8d41-45d1-8182-5b896af92a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-d82cb55e-cdbb-48d5-9982-9a38f4c682e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d3bf1466-4194-4ef4-a0fd-5da92bababa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-5dacef92-777e-4cd4-9e31-d12c45127c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-04ec3f09-1cff-47a0-9ac3-2ba178f86937,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c31238c2-76ea-4c86-849f-7a1483d6ef2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203813143-172.17.0.2-1598690968701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-63dbfa7c-4e02-41b6-9fed-4c9d6b491949,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-b1ab9f4d-099d-4ce9-9eac-58d2b429fbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-77a70647-cf0b-4473-be42-449d56a6ae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-9d8abaea-2bf1-429f-a3c5-9e45624bc6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-8a5f0c41-c974-426d-bb6d-e196874d2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-bcdc9149-3e00-499e-9563-e6aa412844ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-5253a4d2-2b6e-4485-8f71-303f00027f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4a6326c2-9cbb-4304-8193-b22181ad7d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203813143-172.17.0.2-1598690968701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-63dbfa7c-4e02-41b6-9fed-4c9d6b491949,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-b1ab9f4d-099d-4ce9-9eac-58d2b429fbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-77a70647-cf0b-4473-be42-449d56a6ae4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-9d8abaea-2bf1-429f-a3c5-9e45624bc6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-8a5f0c41-c974-426d-bb6d-e196874d2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-bcdc9149-3e00-499e-9563-e6aa412844ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-5253a4d2-2b6e-4485-8f71-303f00027f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4a6326c2-9cbb-4304-8193-b22181ad7d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835284707-172.17.0.2-1598691005174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-bca55e2c-12e5-49a5-8b1a-677d8a6be6df,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-f740f9f9-4328-4c6d-b0b2-4a3d1bd9b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-0c368318-b9d1-44c6-a627-3ebbb2811429,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-1609a26b-feb6-4648-b38d-f8c1b307e880,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-b932bb51-846a-4ad1-9312-194e3b7d06b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-11f26836-29a4-45dc-929e-f4c01f7952b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-0fe22d4f-fc3b-44e5-8e8d-6bef21159472,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-c5506fa2-b67f-43cd-b03c-a45b9225f7fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835284707-172.17.0.2-1598691005174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-bca55e2c-12e5-49a5-8b1a-677d8a6be6df,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-f740f9f9-4328-4c6d-b0b2-4a3d1bd9b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-0c368318-b9d1-44c6-a627-3ebbb2811429,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-1609a26b-feb6-4648-b38d-f8c1b307e880,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-b932bb51-846a-4ad1-9312-194e3b7d06b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-11f26836-29a4-45dc-929e-f4c01f7952b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-0fe22d4f-fc3b-44e5-8e8d-6bef21159472,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-c5506fa2-b67f-43cd-b03c-a45b9225f7fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424364182-172.17.0.2-1598691213841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-ce11acd3-fe41-4e67-9a38-e5c1ba336f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-b77e411e-9fdd-4666-bf3b-3ba5316e091b,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-d8655aff-cf74-44b7-a675-303a900277f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-6c067b74-be4b-4c0b-a9ff-3c22df39d931,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e825ebee-b0c3-443b-bf30-85668a1e26e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-7275be38-ccf9-400d-bd2e-6cb29b727b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-109a514b-a407-4d63-8785-060fbd249081,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-95d1442b-f95e-405e-8d72-58af99ed4236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424364182-172.17.0.2-1598691213841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-ce11acd3-fe41-4e67-9a38-e5c1ba336f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-b77e411e-9fdd-4666-bf3b-3ba5316e091b,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-d8655aff-cf74-44b7-a675-303a900277f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-6c067b74-be4b-4c0b-a9ff-3c22df39d931,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e825ebee-b0c3-443b-bf30-85668a1e26e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-7275be38-ccf9-400d-bd2e-6cb29b727b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-109a514b-a407-4d63-8785-060fbd249081,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-95d1442b-f95e-405e-8d72-58af99ed4236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701179961-172.17.0.2-1598691251317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-e6a61cdc-e8f7-47f0-844b-99bd36745965,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-7c34b29f-71b7-405c-888a-cc707f66492f,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-528b13ca-ee8b-4ff8-893d-b203f28e32aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fad2ef5e-49e6-416e-b8e8-9ad1d326e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-65dfa75c-bea7-46a8-8796-da0c89387a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-4cbaf68b-2a4d-4818-9281-f9b99fb4e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-dbcf85f0-5e14-4123-b6e7-17455615475a,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-123b318c-4bc1-4446-9bbb-be4d24d70f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701179961-172.17.0.2-1598691251317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-e6a61cdc-e8f7-47f0-844b-99bd36745965,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-7c34b29f-71b7-405c-888a-cc707f66492f,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-528b13ca-ee8b-4ff8-893d-b203f28e32aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fad2ef5e-49e6-416e-b8e8-9ad1d326e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-65dfa75c-bea7-46a8-8796-da0c89387a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-4cbaf68b-2a4d-4818-9281-f9b99fb4e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-dbcf85f0-5e14-4123-b6e7-17455615475a,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-123b318c-4bc1-4446-9bbb-be4d24d70f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262486251-172.17.0.2-1598691553731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-d7bb0ed3-ff73-454b-8e59-2ceebd00163a,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-23cec6a5-8a8f-4e8d-ad2f-c12395e1e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-61a82abb-699b-4063-90df-695edc48e251,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-8e947862-9639-44c6-848f-8193df60a127,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-b94bd2b7-af75-4606-98e2-038810efa630,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-da569b75-e6f9-4185-8be3-8b33f7547180,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-827f7d55-c21c-4727-a92f-041656bec86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-cbdcd9da-c962-4931-ac5d-3957aa0a6628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262486251-172.17.0.2-1598691553731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-d7bb0ed3-ff73-454b-8e59-2ceebd00163a,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-23cec6a5-8a8f-4e8d-ad2f-c12395e1e6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-61a82abb-699b-4063-90df-695edc48e251,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-8e947862-9639-44c6-848f-8193df60a127,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-b94bd2b7-af75-4606-98e2-038810efa630,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-da569b75-e6f9-4185-8be3-8b33f7547180,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-827f7d55-c21c-4727-a92f-041656bec86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-cbdcd9da-c962-4931-ac5d-3957aa0a6628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4957
