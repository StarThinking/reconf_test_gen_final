reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906685507-172.17.0.17-1598587424462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-7d20af25-fa41-47fb-a5fa-6ce28c7ca538,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-fb138051-42b6-4e7d-9ea0-f8732be57e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-8ac40c62-efc1-4bec-adf2-ae51d06b47de,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-e4c3c9f0-4ec9-42ef-b18b-a8a097ab5271,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-f4c8d117-54ad-4a8a-ab79-e5ac4bfacb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-88261abb-b809-4cc0-8b3d-27b0c4bddd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-6b3b6c44-c1c1-4e2f-a25b-b425212bee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-8bd3b7d0-6acf-4cd3-9f16-a30136004c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906685507-172.17.0.17-1598587424462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-7d20af25-fa41-47fb-a5fa-6ce28c7ca538,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-fb138051-42b6-4e7d-9ea0-f8732be57e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-8ac40c62-efc1-4bec-adf2-ae51d06b47de,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-e4c3c9f0-4ec9-42ef-b18b-a8a097ab5271,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-f4c8d117-54ad-4a8a-ab79-e5ac4bfacb18,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-88261abb-b809-4cc0-8b3d-27b0c4bddd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-6b3b6c44-c1c1-4e2f-a25b-b425212bee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-8bd3b7d0-6acf-4cd3-9f16-a30136004c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439116920-172.17.0.17-1598588038522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-35785c98-9070-445e-b7df-06ff3098b917,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a8028307-24df-4731-95e4-9f4351fc3877,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-747e7d59-223e-411a-8bdd-19876b02c961,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-7db18281-30e0-4406-818a-066a08efc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-1c060e01-ecb9-454b-8dee-c0dc8b70c95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-d7472039-e738-41b8-901a-8f469c89043c,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-0842084a-18f4-43b0-82d0-dc9edf7e1126,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-df55a260-bee1-4254-a3ed-4b21b04c3a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439116920-172.17.0.17-1598588038522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-35785c98-9070-445e-b7df-06ff3098b917,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a8028307-24df-4731-95e4-9f4351fc3877,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-747e7d59-223e-411a-8bdd-19876b02c961,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-7db18281-30e0-4406-818a-066a08efc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-1c060e01-ecb9-454b-8dee-c0dc8b70c95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-d7472039-e738-41b8-901a-8f469c89043c,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-0842084a-18f4-43b0-82d0-dc9edf7e1126,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-df55a260-bee1-4254-a3ed-4b21b04c3a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551188076-172.17.0.17-1598588933179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-9434bfc8-7c23-498d-92c4-eb5e51bc9b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-3234cc65-a910-4b9c-83e4-20e1b7eed6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e7e68991-197a-40a6-ab38-fde8b56bc024,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-16f4a65f-191b-4263-aef6-00b9c9ab310c,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-9e08afa2-d78d-414c-b619-56fdd57614b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-23e24b67-6be2-43ef-8c96-41b95cc53620,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-519c8c91-edfd-4369-bb0a-fe8392b2d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-9adfdf90-5063-407c-9e2d-46ac7e5aadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551188076-172.17.0.17-1598588933179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-9434bfc8-7c23-498d-92c4-eb5e51bc9b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-3234cc65-a910-4b9c-83e4-20e1b7eed6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e7e68991-197a-40a6-ab38-fde8b56bc024,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-16f4a65f-191b-4263-aef6-00b9c9ab310c,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-9e08afa2-d78d-414c-b619-56fdd57614b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-23e24b67-6be2-43ef-8c96-41b95cc53620,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-519c8c91-edfd-4369-bb0a-fe8392b2d681,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-9adfdf90-5063-407c-9e2d-46ac7e5aadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209743847-172.17.0.17-1598589011063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-6325c56e-47f7-44d9-a9d8-d60111ba64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-05392dfd-1236-4a89-a345-4c6da7d78056,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-5f42fc75-2f0c-4648-9e2d-b230b6cb78bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f93e6e99-d96a-41f6-a741-7d9dbf8b80cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-a73b248d-8c70-4cc8-b4dc-c50c9c1aa19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-aad1d91d-0f9b-4d86-8838-80216f350a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-74d5913c-73ad-41a9-8993-6d4693ce2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-5bc427c1-5db9-4ac4-b839-6731dba7af5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209743847-172.17.0.17-1598589011063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-6325c56e-47f7-44d9-a9d8-d60111ba64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-05392dfd-1236-4a89-a345-4c6da7d78056,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-5f42fc75-2f0c-4648-9e2d-b230b6cb78bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f93e6e99-d96a-41f6-a741-7d9dbf8b80cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-a73b248d-8c70-4cc8-b4dc-c50c9c1aa19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-aad1d91d-0f9b-4d86-8838-80216f350a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-74d5913c-73ad-41a9-8993-6d4693ce2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-5bc427c1-5db9-4ac4-b839-6731dba7af5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435081112-172.17.0.17-1598589981990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-cab0827a-32cb-463a-a2fe-528ebbf0378d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-3f2d7efa-19e7-43d5-81ae-0b680d464a86,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c0905349-a389-42ad-a8e0-686cca5cbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-c7e2b75b-2b99-41ca-bf28-6558c6a31bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-cff5d011-3deb-4bb7-97ed-fa11ffc081b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-79bc796d-41da-4e65-bac1-c7ace982b820,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-557c736a-57fa-4200-b96a-93bb34f26d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-619fab20-7cf3-4949-b4de-53745e80e8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435081112-172.17.0.17-1598589981990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37350,DS-cab0827a-32cb-463a-a2fe-528ebbf0378d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-3f2d7efa-19e7-43d5-81ae-0b680d464a86,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-c0905349-a389-42ad-a8e0-686cca5cbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-c7e2b75b-2b99-41ca-bf28-6558c6a31bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-cff5d011-3deb-4bb7-97ed-fa11ffc081b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-79bc796d-41da-4e65-bac1-c7ace982b820,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-557c736a-57fa-4200-b96a-93bb34f26d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-619fab20-7cf3-4949-b4de-53745e80e8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765062980-172.17.0.17-1598590129063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-e981193b-d5a6-43fe-b648-618befcbf68d,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-d5388049-9611-412d-8416-6ce6419123df,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-8c2c4274-4055-44b7-80fa-0ff4e87c01cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-77a6d698-8cee-472d-898e-39fa0502c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-bfff3b41-f593-48b9-9e4e-c1628b366d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8263d8a5-3b51-4a16-8f81-377716ab418a,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-5459d9ad-1f5b-4f94-b8e3-05951ac0a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-ec069c4f-0537-4462-878b-30bf2ded7e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765062980-172.17.0.17-1598590129063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-e981193b-d5a6-43fe-b648-618befcbf68d,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-d5388049-9611-412d-8416-6ce6419123df,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-8c2c4274-4055-44b7-80fa-0ff4e87c01cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-77a6d698-8cee-472d-898e-39fa0502c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-bfff3b41-f593-48b9-9e4e-c1628b366d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8263d8a5-3b51-4a16-8f81-377716ab418a,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-5459d9ad-1f5b-4f94-b8e3-05951ac0a7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-ec069c4f-0537-4462-878b-30bf2ded7e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006309567-172.17.0.17-1598590562233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-8806c029-3685-4ff1-8a37-7020ab76d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-2b9fbbb2-97f3-4530-a0cd-59b0fc9e8a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-20a19853-1d79-48d7-931b-c03a208e5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-d54fcbb0-2d74-49fb-b690-d69ffb4c4b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-d0806a90-20e2-4263-b187-f7c0b68ed208,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-06719a6a-0d24-4ec4-85e4-0f59ae60181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-ba8d2802-80e5-4d38-8344-49c705003f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-22ca605e-dfaa-4008-854e-d9ae99ef7e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006309567-172.17.0.17-1598590562233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-8806c029-3685-4ff1-8a37-7020ab76d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-2b9fbbb2-97f3-4530-a0cd-59b0fc9e8a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-20a19853-1d79-48d7-931b-c03a208e5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-d54fcbb0-2d74-49fb-b690-d69ffb4c4b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-d0806a90-20e2-4263-b187-f7c0b68ed208,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-06719a6a-0d24-4ec4-85e4-0f59ae60181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-ba8d2802-80e5-4d38-8344-49c705003f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-22ca605e-dfaa-4008-854e-d9ae99ef7e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5583
