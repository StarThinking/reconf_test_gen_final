reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564007094-172.17.0.9-1598632491915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-17e00a5d-1288-48e3-922f-abdb446c3df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-0e0ef98a-88b4-466a-b30b-a8d4d69a903a,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-b6be1b17-345a-4d89-9529-e1d2ae0cc3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-204b1218-d2b2-4164-92b3-0275a0a5bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-60756e47-a429-483d-b68b-900de19e28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-5eee1d46-ca74-483b-bd2f-62e42b0dea02,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-606c5791-49db-4171-9b4a-6e00ff9845ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9a3f9a52-1663-4edb-b15f-998c60c9c16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564007094-172.17.0.9-1598632491915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-17e00a5d-1288-48e3-922f-abdb446c3df4,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-0e0ef98a-88b4-466a-b30b-a8d4d69a903a,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-b6be1b17-345a-4d89-9529-e1d2ae0cc3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-204b1218-d2b2-4164-92b3-0275a0a5bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-60756e47-a429-483d-b68b-900de19e28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-5eee1d46-ca74-483b-bd2f-62e42b0dea02,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-606c5791-49db-4171-9b4a-6e00ff9845ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9a3f9a52-1663-4edb-b15f-998c60c9c16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8532949-172.17.0.9-1598632635752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-115dcb34-a610-483b-963a-4e40134a36de,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-b685d9b3-d6dc-447b-abc0-34a559284cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-72f294da-d9bc-42be-b0bf-99f44b9eaef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-cf0110df-ff15-4704-b068-97b1bb4fafea,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-289d0751-37aa-4dde-9dcf-37970c7ee361,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-d98ef380-b2b3-41fe-aa66-68846a225c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-cf6bd223-5c60-4e45-b4e4-ce6ecdf123c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-ccc4fc91-39e5-4454-8c62-d28e9f27cd30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8532949-172.17.0.9-1598632635752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-115dcb34-a610-483b-963a-4e40134a36de,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-b685d9b3-d6dc-447b-abc0-34a559284cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-72f294da-d9bc-42be-b0bf-99f44b9eaef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-cf0110df-ff15-4704-b068-97b1bb4fafea,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-289d0751-37aa-4dde-9dcf-37970c7ee361,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-d98ef380-b2b3-41fe-aa66-68846a225c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-cf6bd223-5c60-4e45-b4e4-ce6ecdf123c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-ccc4fc91-39e5-4454-8c62-d28e9f27cd30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223177724-172.17.0.9-1598632824195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40831,DS-37ea7d3f-abdd-46a5-adeb-e69a9069bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-b010df30-b07e-4b56-8700-f2b55f19363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-d43fd599-0da3-48b1-bf76-114b7087fea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-961634e3-e9e6-4ff5-8f4b-1eb0ac68dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aa56e9bf-54e4-405c-8214-f1f094c39c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-53fea347-1946-4219-90c4-60957ae23667,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-ad98f216-1a06-42eb-a8aa-855727d0bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-858acb74-2235-48f4-9269-f9b93eb4decd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223177724-172.17.0.9-1598632824195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40831,DS-37ea7d3f-abdd-46a5-adeb-e69a9069bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-b010df30-b07e-4b56-8700-f2b55f19363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-d43fd599-0da3-48b1-bf76-114b7087fea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-961634e3-e9e6-4ff5-8f4b-1eb0ac68dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aa56e9bf-54e4-405c-8214-f1f094c39c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-53fea347-1946-4219-90c4-60957ae23667,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-ad98f216-1a06-42eb-a8aa-855727d0bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-858acb74-2235-48f4-9269-f9b93eb4decd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115605709-172.17.0.9-1598632901683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-8905dee3-527c-4cc7-8a15-3d3e45a95b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-5f2e91ea-14fc-45d1-89f7-0aecf30444c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-17029dbc-321a-444c-be8f-d219e749c521,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-557a6382-253d-47c5-ae52-057aff8a70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1111265e-ed86-43ef-a5e4-857bcc18f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-7e6a6af0-ebe1-45bb-b75e-735a58ff3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-ce427e14-6c58-49ef-81a3-976034e0c227,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1150a74a-523a-4cc8-bfb4-591f06b13164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115605709-172.17.0.9-1598632901683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-8905dee3-527c-4cc7-8a15-3d3e45a95b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-5f2e91ea-14fc-45d1-89f7-0aecf30444c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-17029dbc-321a-444c-be8f-d219e749c521,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-557a6382-253d-47c5-ae52-057aff8a70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-1111265e-ed86-43ef-a5e4-857bcc18f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-7e6a6af0-ebe1-45bb-b75e-735a58ff3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-ce427e14-6c58-49ef-81a3-976034e0c227,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1150a74a-523a-4cc8-bfb4-591f06b13164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68150426-172.17.0.9-1598632937463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32990,DS-38034b2c-1738-45de-8266-f58665dff347,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-26ce64e4-adae-496b-a26a-83520ab1d2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-baf8e5e4-ac53-404e-8e2d-0bf39f9f73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-cc5992d9-c498-4777-8296-dc6106e7512b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-b0da2fe7-72dc-457d-a928-f74aab8610a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-42766e15-058c-49fd-bf88-51f6f0b2eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-51972dae-c179-4fb2-8856-ecd79517824d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0534f19f-6cb9-44d4-801d-a713ce8ad56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68150426-172.17.0.9-1598632937463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32990,DS-38034b2c-1738-45de-8266-f58665dff347,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-26ce64e4-adae-496b-a26a-83520ab1d2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-baf8e5e4-ac53-404e-8e2d-0bf39f9f73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-cc5992d9-c498-4777-8296-dc6106e7512b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-b0da2fe7-72dc-457d-a928-f74aab8610a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-42766e15-058c-49fd-bf88-51f6f0b2eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-51972dae-c179-4fb2-8856-ecd79517824d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0534f19f-6cb9-44d4-801d-a713ce8ad56d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803894538-172.17.0.9-1598633078129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-04515d5e-710c-4ff5-ba0a-aa22c6a1c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b3ac15a6-8538-46a3-85c2-a3274d10092e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-96f97cf5-dd71-4148-b9c3-376ce19dc846,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-7baa3960-7350-4512-b804-48dd71bde989,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-1afc687e-e986-47b9-ba66-9f8eab206934,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-978b9976-3e0d-45d4-8767-9dbc4a603044,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-34d36aee-241d-4622-ae53-a0ff34a38412,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-baf81ecb-15c7-4947-a88f-770329b44ae3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803894538-172.17.0.9-1598633078129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-04515d5e-710c-4ff5-ba0a-aa22c6a1c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b3ac15a6-8538-46a3-85c2-a3274d10092e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-96f97cf5-dd71-4148-b9c3-376ce19dc846,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-7baa3960-7350-4512-b804-48dd71bde989,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-1afc687e-e986-47b9-ba66-9f8eab206934,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-978b9976-3e0d-45d4-8767-9dbc4a603044,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-34d36aee-241d-4622-ae53-a0ff34a38412,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-baf81ecb-15c7-4947-a88f-770329b44ae3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935728314-172.17.0.9-1598633320188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-de988e02-96de-4d71-b02b-197d318758e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d74d867a-2510-4970-b3b8-8758acb95303,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-f4c958f6-fe32-4c54-9fe3-16fc443ea775,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8ec5365b-70ce-4597-bfdf-776293e94612,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-51a80aa7-4c6d-453e-a440-72fb7903dac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-66dcd5e3-fbc8-4203-8743-fda0c084a113,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2c8b0b2c-d4e4-4556-a0ff-48457c1d2127,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-238a8d5a-5e5c-47af-803d-a621cb5583ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935728314-172.17.0.9-1598633320188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-de988e02-96de-4d71-b02b-197d318758e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d74d867a-2510-4970-b3b8-8758acb95303,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-f4c958f6-fe32-4c54-9fe3-16fc443ea775,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8ec5365b-70ce-4597-bfdf-776293e94612,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-51a80aa7-4c6d-453e-a440-72fb7903dac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-66dcd5e3-fbc8-4203-8743-fda0c084a113,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2c8b0b2c-d4e4-4556-a0ff-48457c1d2127,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-238a8d5a-5e5c-47af-803d-a621cb5583ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263100255-172.17.0.9-1598633429799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-c9322521-ed06-473b-8c92-58776535b655,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-3afd8a5e-2b7d-44d3-950a-b44326f513a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4a6bc9b2-25b6-4e7f-b675-d242f7e8d835,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-a09190d9-57d2-4699-ba21-3df80ea4c88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-f14d3d7a-9604-4b1b-86a4-c55ba0b5d743,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-b62ce47f-08e1-42ef-b6fc-d7522bc1e616,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-50368461-5bc1-4474-a567-c2326c5fcd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-80827153-6f20-4fb4-bb16-3f1a71a096b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263100255-172.17.0.9-1598633429799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-c9322521-ed06-473b-8c92-58776535b655,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-3afd8a5e-2b7d-44d3-950a-b44326f513a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-4a6bc9b2-25b6-4e7f-b675-d242f7e8d835,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-a09190d9-57d2-4699-ba21-3df80ea4c88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-f14d3d7a-9604-4b1b-86a4-c55ba0b5d743,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-b62ce47f-08e1-42ef-b6fc-d7522bc1e616,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-50368461-5bc1-4474-a567-c2326c5fcd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-80827153-6f20-4fb4-bb16-3f1a71a096b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637297563-172.17.0.9-1598633466406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-79cc11ba-0481-4971-ad8e-3d20325b8972,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-e0edfc64-ef94-457c-9080-de4f2c0ca7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b70f22d0-f8a9-4aab-b419-fd1ddd3db4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-b5e97a5c-d4ce-47bb-b9c8-49f95e532067,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-75b95c21-2a29-4dd9-8b6a-f5df8dd1ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-8687d7da-e245-40b5-b781-135b1aacc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-a735d4a3-bd5c-4335-8604-b5cf8f464e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d4db45b8-db1d-4030-a17a-6a06c8e9d635,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637297563-172.17.0.9-1598633466406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-79cc11ba-0481-4971-ad8e-3d20325b8972,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-e0edfc64-ef94-457c-9080-de4f2c0ca7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b70f22d0-f8a9-4aab-b419-fd1ddd3db4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-b5e97a5c-d4ce-47bb-b9c8-49f95e532067,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-75b95c21-2a29-4dd9-8b6a-f5df8dd1ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-8687d7da-e245-40b5-b781-135b1aacc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-a735d4a3-bd5c-4335-8604-b5cf8f464e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d4db45b8-db1d-4030-a17a-6a06c8e9d635,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12795354-172.17.0.9-1598633847553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-b6043b7c-9365-422b-85e2-1d14257350ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-59b83f5e-9b44-4b4a-a90b-f986dab89890,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-bf13a0da-368b-4f1a-b076-34c6587846c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-fe989e21-11fc-44b9-8af7-a1f4f5b33f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-6103d882-6215-4277-8b47-430174bc7796,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-10db4cf9-b8b0-4df5-951a-483e2238975b,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-32c83987-27cc-4f78-aeb3-d18d2befd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-c4c74947-6098-432a-9317-c06273b7fd98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12795354-172.17.0.9-1598633847553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-b6043b7c-9365-422b-85e2-1d14257350ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-59b83f5e-9b44-4b4a-a90b-f986dab89890,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-bf13a0da-368b-4f1a-b076-34c6587846c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-fe989e21-11fc-44b9-8af7-a1f4f5b33f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-6103d882-6215-4277-8b47-430174bc7796,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-10db4cf9-b8b0-4df5-951a-483e2238975b,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-32c83987-27cc-4f78-aeb3-d18d2befd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-c4c74947-6098-432a-9317-c06273b7fd98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9267667-172.17.0.9-1598634037628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-c71d551d-11bd-4c2b-8637-9cc6af5f54bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-ad05e8b2-af1a-422a-b78a-f4895efb7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-9f3cc110-2d28-4485-b8f3-701fa526ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-608a5a01-f2ae-49cc-89a7-d02e0067af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-4c425df4-bbc9-470d-96b1-cfb21918567d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-c6dd352e-b28c-4721-89e5-0510ddaa3e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-69b41307-ae0d-4b21-b5a6-ce9b5eee0255,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-bcabb9ec-0a66-4108-8cb7-5731c56f808c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9267667-172.17.0.9-1598634037628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-c71d551d-11bd-4c2b-8637-9cc6af5f54bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-ad05e8b2-af1a-422a-b78a-f4895efb7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-9f3cc110-2d28-4485-b8f3-701fa526ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-608a5a01-f2ae-49cc-89a7-d02e0067af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-4c425df4-bbc9-470d-96b1-cfb21918567d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-c6dd352e-b28c-4721-89e5-0510ddaa3e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-69b41307-ae0d-4b21-b5a6-ce9b5eee0255,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-bcabb9ec-0a66-4108-8cb7-5731c56f808c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58152054-172.17.0.9-1598634108835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-4f283d84-fd7a-4dc1-a4f6-4bf49506bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-9e74b594-a155-44c9-9afc-74cb694d9818,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-3e6dd1bc-d2d5-4792-bb3c-ac454572aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-7183db00-3854-47b0-9295-171cf7415d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-15b9712b-03f4-4ab2-ace6-58e62ad3b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-fa9144bf-7797-4519-a47b-dbf62f8ce08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c2bbafb6-bf1a-4edf-9e44-604c655fc559,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-bad6b46a-659d-4ea9-b3f9-c15765e8355b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58152054-172.17.0.9-1598634108835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-4f283d84-fd7a-4dc1-a4f6-4bf49506bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-9e74b594-a155-44c9-9afc-74cb694d9818,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-3e6dd1bc-d2d5-4792-bb3c-ac454572aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-7183db00-3854-47b0-9295-171cf7415d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-15b9712b-03f4-4ab2-ace6-58e62ad3b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-fa9144bf-7797-4519-a47b-dbf62f8ce08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c2bbafb6-bf1a-4edf-9e44-604c655fc559,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-bad6b46a-659d-4ea9-b3f9-c15765e8355b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916539932-172.17.0.9-1598634248538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36377,DS-2bd3f581-264d-43a5-ab58-28ed49035573,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-ee4028f5-fbb0-4bf5-9b79-ec47076f1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-38183e1e-2661-4e74-9b5f-6b3dbde0f062,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-694bc61f-c7ba-4bc0-a6f0-a1f3bbb0cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7e9b07be-4bd1-4406-b62e-a59b43543c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6106d753-c145-4d8e-84c6-be6888f4a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-605b5f65-95ab-49f6-b7bb-6f30d001e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-5e923d46-2c90-4c24-9ffb-dcfbcd173227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916539932-172.17.0.9-1598634248538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36377,DS-2bd3f581-264d-43a5-ab58-28ed49035573,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-ee4028f5-fbb0-4bf5-9b79-ec47076f1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-38183e1e-2661-4e74-9b5f-6b3dbde0f062,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-694bc61f-c7ba-4bc0-a6f0-a1f3bbb0cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7e9b07be-4bd1-4406-b62e-a59b43543c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6106d753-c145-4d8e-84c6-be6888f4a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-605b5f65-95ab-49f6-b7bb-6f30d001e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-5e923d46-2c90-4c24-9ffb-dcfbcd173227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52398021-172.17.0.9-1598634318415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-fbdee2dd-fe9b-46bb-ab95-9655681ae353,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-9bbe5d94-13c2-4a40-bedd-ded7583f856c,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-dd97699f-30cf-4e1a-88a8-2d4d2dd903b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-f865c2d4-e331-480a-bfe9-b7927eb9de13,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-fa95d35b-cdf2-4049-b9f6-4be365c4653b,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-515eae23-5ffd-411e-be73-cb82652f4f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6ab7e850-7fb7-4c93-825d-b90b4e6a13b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-5040cf5a-d426-4ac3-970e-471c9c37dc1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52398021-172.17.0.9-1598634318415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-fbdee2dd-fe9b-46bb-ab95-9655681ae353,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-9bbe5d94-13c2-4a40-bedd-ded7583f856c,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-dd97699f-30cf-4e1a-88a8-2d4d2dd903b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-f865c2d4-e331-480a-bfe9-b7927eb9de13,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-fa95d35b-cdf2-4049-b9f6-4be365c4653b,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-515eae23-5ffd-411e-be73-cb82652f4f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6ab7e850-7fb7-4c93-825d-b90b4e6a13b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-5040cf5a-d426-4ac3-970e-471c9c37dc1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008310669-172.17.0.9-1598634453003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-87c679c4-0cad-43a1-86df-b29efe99baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-d4f55596-18bb-4aed-aa05-aad6bc455510,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-f14af881-b170-4311-943c-d3f929ef8921,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-bf0907a0-4e85-449b-9c2a-4dd67923c935,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-20051cd5-0a47-44f6-93ed-f24c38d944d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-051d493f-a497-43e9-b607-c2952f925724,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-ef12be31-78f7-4f35-bfc5-d2a5ed621123,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-35b38bd5-834e-4d1c-8e46-a72113d2b93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008310669-172.17.0.9-1598634453003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-87c679c4-0cad-43a1-86df-b29efe99baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-d4f55596-18bb-4aed-aa05-aad6bc455510,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-f14af881-b170-4311-943c-d3f929ef8921,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-bf0907a0-4e85-449b-9c2a-4dd67923c935,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-20051cd5-0a47-44f6-93ed-f24c38d944d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-051d493f-a497-43e9-b607-c2952f925724,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-ef12be31-78f7-4f35-bfc5-d2a5ed621123,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-35b38bd5-834e-4d1c-8e46-a72113d2b93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137658694-172.17.0.9-1598634521394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-3ca016e7-03c5-4e9c-ba6c-60afb490f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-aee5659f-6025-46b7-8f0e-a38991753e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-192709e8-7896-4374-8e69-c7947573646f,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-f167c57c-ca01-4874-9d0b-851133e734a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-5fe34bdf-0311-4e3c-8f62-71fcc6f75efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-f8a430d6-6f4e-4bab-b28d-f22f147f6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-de28bdc8-b8da-47bf-b714-211e4f03ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-99f74a47-17d7-4996-a33b-2962c28dca8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137658694-172.17.0.9-1598634521394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-3ca016e7-03c5-4e9c-ba6c-60afb490f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-aee5659f-6025-46b7-8f0e-a38991753e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-192709e8-7896-4374-8e69-c7947573646f,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-f167c57c-ca01-4874-9d0b-851133e734a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-5fe34bdf-0311-4e3c-8f62-71fcc6f75efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-f8a430d6-6f4e-4bab-b28d-f22f147f6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-de28bdc8-b8da-47bf-b714-211e4f03ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-99f74a47-17d7-4996-a33b-2962c28dca8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490229490-172.17.0.9-1598634549046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-5d75397f-bde3-4cf6-a08b-88a6dea84db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-0352cfa5-6fa4-42ed-a9c9-4497fa4ca95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-57e588eb-f48c-4326-b278-803d97766d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-1fcceaed-35e3-480d-9e98-e256379a9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-76a1a2cf-76e3-454a-a26d-c84e023f2781,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-e94b0d17-e2b4-41b1-9666-af8754c86dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8c90d34d-617a-4894-96a9-e520f32bbb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-a95f5d0d-188a-48f6-935c-32d01c313b17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490229490-172.17.0.9-1598634549046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-5d75397f-bde3-4cf6-a08b-88a6dea84db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-0352cfa5-6fa4-42ed-a9c9-4497fa4ca95c,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-57e588eb-f48c-4326-b278-803d97766d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-1fcceaed-35e3-480d-9e98-e256379a9fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-76a1a2cf-76e3-454a-a26d-c84e023f2781,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-e94b0d17-e2b4-41b1-9666-af8754c86dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8c90d34d-617a-4894-96a9-e520f32bbb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-a95f5d0d-188a-48f6-935c-32d01c313b17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822055863-172.17.0.9-1598634722911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-03693148-ddc1-46e9-aafb-e1ef634634fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-1abfa0f2-0dcd-43bc-8596-5994ee82f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ba7cfcc6-937e-4421-a9b0-3feff8d14284,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-ea066ed5-6782-4222-86a4-96dde8391811,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-486a910f-6c9d-4822-a401-492fa402bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-c29459d5-29c8-425f-acf9-c956de8dfd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3f8ce375-2b92-4a9f-99d3-2b04ade8788d,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-61a7655a-387b-4b24-9c59-5f7ed7561eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822055863-172.17.0.9-1598634722911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-03693148-ddc1-46e9-aafb-e1ef634634fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-1abfa0f2-0dcd-43bc-8596-5994ee82f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ba7cfcc6-937e-4421-a9b0-3feff8d14284,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-ea066ed5-6782-4222-86a4-96dde8391811,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-486a910f-6c9d-4822-a401-492fa402bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-c29459d5-29c8-425f-acf9-c956de8dfd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3f8ce375-2b92-4a9f-99d3-2b04ade8788d,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-61a7655a-387b-4b24-9c59-5f7ed7561eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785701967-172.17.0.9-1598634785868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-29de842c-508c-4efc-90d7-990f3115df59,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-5e4cd86b-344d-4748-9a98-b61a5f7ea2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-305be0af-acd0-4d10-81e0-8538fb52980b,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-6f7b4981-6c64-4648-93c2-5f2fc3592cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-fe861dab-6697-45a0-bf4e-653de747bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-bcb32db8-26e0-46a2-af88-99648c3d8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-61e3f2a4-c755-4d93-9d15-209d5c680385,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-24eeef25-0aad-4714-a226-8f8ac379803f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785701967-172.17.0.9-1598634785868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-29de842c-508c-4efc-90d7-990f3115df59,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-5e4cd86b-344d-4748-9a98-b61a5f7ea2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-305be0af-acd0-4d10-81e0-8538fb52980b,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-6f7b4981-6c64-4648-93c2-5f2fc3592cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-fe861dab-6697-45a0-bf4e-653de747bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-bcb32db8-26e0-46a2-af88-99648c3d8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-61e3f2a4-c755-4d93-9d15-209d5c680385,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-24eeef25-0aad-4714-a226-8f8ac379803f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119135414-172.17.0.9-1598635048534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-87d4cf4c-55bd-4ba7-86a3-02ee75e965fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-5dd00d65-5de7-4a6b-b9c1-2d2bec2ad0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-e13b777f-0a1e-4f2e-96c5-902920e7e254,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-14f83670-6c22-4d37-a101-adb97752c37f,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-a9c6a9bb-3c0f-4bde-a671-73711566d147,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-ec88d94e-c5fa-430c-917d-34d6907c4298,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-140a759f-c6d6-4d0a-a6e2-99fbdb60a678,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e7b62d45-b965-433c-9884-613590615d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119135414-172.17.0.9-1598635048534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-87d4cf4c-55bd-4ba7-86a3-02ee75e965fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-5dd00d65-5de7-4a6b-b9c1-2d2bec2ad0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-e13b777f-0a1e-4f2e-96c5-902920e7e254,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-14f83670-6c22-4d37-a101-adb97752c37f,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-a9c6a9bb-3c0f-4bde-a671-73711566d147,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-ec88d94e-c5fa-430c-917d-34d6907c4298,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-140a759f-c6d6-4d0a-a6e2-99fbdb60a678,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e7b62d45-b965-433c-9884-613590615d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285679592-172.17.0.9-1598635108059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-268ebf79-7180-4057-a493-04a48e953acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-76e29c6c-0445-4d8a-baa4-f4520ff47dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-9668b89a-5783-427c-aa13-6016a969bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-ae04b284-3e12-4ef0-9b3b-b191d94b6ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-3d500c14-1325-4638-9a83-d9f759fcf5af,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-472cb5f8-7c89-48cc-b0cc-e809b1591fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-d53446e8-4940-4541-91d9-ae66f9bfa745,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-602b71e4-f55a-4646-8909-d41173ee073d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285679592-172.17.0.9-1598635108059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-268ebf79-7180-4057-a493-04a48e953acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-76e29c6c-0445-4d8a-baa4-f4520ff47dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-9668b89a-5783-427c-aa13-6016a969bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-ae04b284-3e12-4ef0-9b3b-b191d94b6ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-3d500c14-1325-4638-9a83-d9f759fcf5af,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-472cb5f8-7c89-48cc-b0cc-e809b1591fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-d53446e8-4940-4541-91d9-ae66f9bfa745,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-602b71e4-f55a-4646-8909-d41173ee073d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161207260-172.17.0.9-1598635220052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-4b9e713f-4fd1-4db7-98a0-f47018515698,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-4a4eb735-c092-4bf2-a318-ed28afb23ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-62c82a34-9f57-44aa-aa30-d49635c2c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-9adf48d5-4e77-4b0e-b255-cbbac32fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-5048c142-c8ed-458a-a652-594c16373db7,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d004a004-d9fc-4ce4-b478-5c48cbd1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f4a262d7-1675-4c17-922c-fb07c4d9d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-940be8f6-4334-49b9-a806-f8bec4853a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161207260-172.17.0.9-1598635220052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-4b9e713f-4fd1-4db7-98a0-f47018515698,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-4a4eb735-c092-4bf2-a318-ed28afb23ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-62c82a34-9f57-44aa-aa30-d49635c2c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-9adf48d5-4e77-4b0e-b255-cbbac32fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-5048c142-c8ed-458a-a652-594c16373db7,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d004a004-d9fc-4ce4-b478-5c48cbd1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f4a262d7-1675-4c17-922c-fb07c4d9d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-940be8f6-4334-49b9-a806-f8bec4853a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180460125-172.17.0.9-1598635589001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-a4186f57-e7b0-452a-8c69-d4c954d98f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-c4c4e55c-d5d5-4a73-b97d-2671a5e2dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-c3e2cf3c-470f-4e4d-bae7-70e13d94c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-56a8d075-fa6e-4443-a680-d985f4bc653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-059215e3-e039-45f4-a98d-eec4011e5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-baaf7930-29c4-43fd-a6e6-ac2bf0f7a402,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-884e9533-75ba-4715-82bf-00e04e1e208b,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8e3213fa-ccd9-40ae-99d3-200875c4fa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180460125-172.17.0.9-1598635589001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-a4186f57-e7b0-452a-8c69-d4c954d98f00,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-c4c4e55c-d5d5-4a73-b97d-2671a5e2dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-c3e2cf3c-470f-4e4d-bae7-70e13d94c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-56a8d075-fa6e-4443-a680-d985f4bc653e,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-059215e3-e039-45f4-a98d-eec4011e5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-baaf7930-29c4-43fd-a6e6-ac2bf0f7a402,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-884e9533-75ba-4715-82bf-00e04e1e208b,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8e3213fa-ccd9-40ae-99d3-200875c4fa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364327319-172.17.0.9-1598635663233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-a2e68508-e67d-4999-8f50-414573fbbc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-aa09c7e5-58f5-4564-919f-e806c808fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-b18f771d-399e-4407-b2ee-304bbf1ba742,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-db354ef0-9e15-4d14-8094-c62ab3187bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-ab88889b-8c15-49fd-abc9-c073999485dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-7a40c2fe-fd9d-4e77-98d0-a47425b86830,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-19872431-4460-4077-95e1-be3ed19cf87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-2743446c-8d7f-42a0-b5cb-d097915718ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364327319-172.17.0.9-1598635663233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-a2e68508-e67d-4999-8f50-414573fbbc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-aa09c7e5-58f5-4564-919f-e806c808fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-b18f771d-399e-4407-b2ee-304bbf1ba742,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-db354ef0-9e15-4d14-8094-c62ab3187bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-ab88889b-8c15-49fd-abc9-c073999485dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-7a40c2fe-fd9d-4e77-98d0-a47425b86830,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-19872431-4460-4077-95e1-be3ed19cf87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-2743446c-8d7f-42a0-b5cb-d097915718ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807685994-172.17.0.9-1598635890250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-8408d404-b07b-433b-95b1-7a4a8f2a6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-1d266f1d-8396-404a-95c8-3222dc96ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-fd9a5560-c924-4b57-bd3b-a46ff7681dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-65ef5d6c-b2d0-463f-a446-531f282cbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2cdba2bd-1d11-4b47-b541-ba4f201f2d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3d921fc6-30f4-4fe3-9a08-0113286e7889,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-4c64767e-4b7b-4fb6-8744-15f33c7f6fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-6f324eda-b851-446d-bd3e-43cfd16196b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807685994-172.17.0.9-1598635890250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-8408d404-b07b-433b-95b1-7a4a8f2a6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-1d266f1d-8396-404a-95c8-3222dc96ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-fd9a5560-c924-4b57-bd3b-a46ff7681dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-65ef5d6c-b2d0-463f-a446-531f282cbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-2cdba2bd-1d11-4b47-b541-ba4f201f2d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3d921fc6-30f4-4fe3-9a08-0113286e7889,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-4c64767e-4b7b-4fb6-8744-15f33c7f6fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-6f324eda-b851-446d-bd3e-43cfd16196b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587268174-172.17.0.9-1598636116477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-f0f2c3f3-5c16-4f45-a33f-dc8e27641461,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-567b49ea-f7c1-49f8-a229-bd4f55ca2213,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-d5fac186-f59f-4a85-8ca8-03d38d6ce623,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-62531965-6afd-4cda-9722-dc27079027d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-7fd49dad-462f-4594-b560-6c9c5a6052ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-49440804-8f19-4555-abb2-de5febdd1095,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-5f489ad1-e48d-4978-952d-fadb06f3850e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-34eaa361-0ee2-4597-8614-72e9d17c4c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587268174-172.17.0.9-1598636116477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-f0f2c3f3-5c16-4f45-a33f-dc8e27641461,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-567b49ea-f7c1-49f8-a229-bd4f55ca2213,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-d5fac186-f59f-4a85-8ca8-03d38d6ce623,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-62531965-6afd-4cda-9722-dc27079027d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-7fd49dad-462f-4594-b560-6c9c5a6052ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-49440804-8f19-4555-abb2-de5febdd1095,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-5f489ad1-e48d-4978-952d-fadb06f3850e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-34eaa361-0ee2-4597-8614-72e9d17c4c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050816355-172.17.0.9-1598636193936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38298,DS-b7f2815d-7857-474f-bace-a3cf09231916,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-ebc05dfb-bfe3-4c54-b5c8-b6116c9a16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-53f3242d-d95f-4400-8292-ff77ccca6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-950f31e0-bc0c-4d7b-bb1e-67da947d384c,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c6d36047-b099-4565-97d6-7c584b5c33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-327db07f-438b-4c48-a2b1-b60fd3bd8996,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-778f2b7e-2a15-43d3-93e3-539597eff142,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-2115cf8f-f180-463c-b34d-67747ff61325,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050816355-172.17.0.9-1598636193936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38298,DS-b7f2815d-7857-474f-bace-a3cf09231916,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-ebc05dfb-bfe3-4c54-b5c8-b6116c9a16b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-53f3242d-d95f-4400-8292-ff77ccca6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-950f31e0-bc0c-4d7b-bb1e-67da947d384c,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c6d36047-b099-4565-97d6-7c584b5c33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-327db07f-438b-4c48-a2b1-b60fd3bd8996,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-778f2b7e-2a15-43d3-93e3-539597eff142,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-2115cf8f-f180-463c-b34d-67747ff61325,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849211456-172.17.0.9-1598636386348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33617,DS-326dfd30-cf70-4baa-bd22-e5c3e1c5827f,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-60ae8f9e-35ce-4a87-adf2-62b339a7e4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-3f940370-41ca-4fc2-90e6-8044c9c6c440,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-d6244500-a1ab-4485-9af0-189b494debb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-3c4c55cd-fef6-4281-8cd7-7ed4d1ee8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-49fa84db-b5b2-4b07-adb6-5e73d3c7e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-353dac50-b6f2-4f9d-a515-a926b787ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-b7804887-c8f3-400c-9eee-52a8e2625776,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849211456-172.17.0.9-1598636386348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33617,DS-326dfd30-cf70-4baa-bd22-e5c3e1c5827f,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-60ae8f9e-35ce-4a87-adf2-62b339a7e4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-3f940370-41ca-4fc2-90e6-8044c9c6c440,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-d6244500-a1ab-4485-9af0-189b494debb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-3c4c55cd-fef6-4281-8cd7-7ed4d1ee8f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-49fa84db-b5b2-4b07-adb6-5e73d3c7e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-353dac50-b6f2-4f9d-a515-a926b787ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-b7804887-c8f3-400c-9eee-52a8e2625776,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831857853-172.17.0.9-1598636524049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-54164977-a0d5-4e97-9884-3ef2c44cbdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-cf90aa80-c1b1-47e6-84dd-6a1e2148c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-4fae066e-7216-43f2-9cdb-5ad5313741fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-571c6b41-8c48-47f8-b887-4d5465cb09cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-703a1c94-f01a-43e1-9078-4c7efd2707c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-26a80bd2-5d44-450a-979e-2c54a218ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-b95f432c-1999-48f0-bc7f-6078f2af1280,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-1eb7bd0c-cd95-4e82-bcc0-40ffbae6dc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831857853-172.17.0.9-1598636524049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-54164977-a0d5-4e97-9884-3ef2c44cbdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-cf90aa80-c1b1-47e6-84dd-6a1e2148c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-4fae066e-7216-43f2-9cdb-5ad5313741fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-571c6b41-8c48-47f8-b887-4d5465cb09cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-703a1c94-f01a-43e1-9078-4c7efd2707c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-26a80bd2-5d44-450a-979e-2c54a218ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-b95f432c-1999-48f0-bc7f-6078f2af1280,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-1eb7bd0c-cd95-4e82-bcc0-40ffbae6dc88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076303070-172.17.0.9-1598636727711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-46d02288-4662-4329-b87a-6d208538f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-0d87d5a0-040e-40b5-9cef-5d3a924a96c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-57f6fafc-a89e-46e8-98b3-5e966add81cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-35ff26ed-0340-48e5-8387-8f5ba47dd881,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-db77c214-de6c-4d12-b98e-ef34f561c211,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-6fd1647d-a0c8-4f22-804e-2db7ddefe32a,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-f69e1a40-84fc-4ee6-8b55-95b92bca214f,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-61392ba1-fdac-40ba-9b2b-4c2d0457b500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076303070-172.17.0.9-1598636727711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-46d02288-4662-4329-b87a-6d208538f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-0d87d5a0-040e-40b5-9cef-5d3a924a96c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-57f6fafc-a89e-46e8-98b3-5e966add81cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-35ff26ed-0340-48e5-8387-8f5ba47dd881,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-db77c214-de6c-4d12-b98e-ef34f561c211,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-6fd1647d-a0c8-4f22-804e-2db7ddefe32a,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-f69e1a40-84fc-4ee6-8b55-95b92bca214f,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-61392ba1-fdac-40ba-9b2b-4c2d0457b500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542693915-172.17.0.9-1598636933572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-3f170fa6-9223-4f62-a7f8-0e1815b61c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-854f1615-4c75-42dd-9dd4-c11f0aa00bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-fe553d73-6546-4fc4-ad68-2b5f4acdfd49,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-dc724916-162d-4828-a748-cc4810133d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-30d302b5-df76-400b-9cc8-448ad85e0193,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-963fe774-c3be-418e-b5c8-df7f7f7de4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-dde2db13-4310-4b4b-b7f2-b154829d0e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-2fbea802-30e6-415d-9a49-eb38ac146098,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542693915-172.17.0.9-1598636933572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-3f170fa6-9223-4f62-a7f8-0e1815b61c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-854f1615-4c75-42dd-9dd4-c11f0aa00bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-fe553d73-6546-4fc4-ad68-2b5f4acdfd49,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-dc724916-162d-4828-a748-cc4810133d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-30d302b5-df76-400b-9cc8-448ad85e0193,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-963fe774-c3be-418e-b5c8-df7f7f7de4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-dde2db13-4310-4b4b-b7f2-b154829d0e92,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-2fbea802-30e6-415d-9a49-eb38ac146098,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661409982-172.17.0.9-1598636968951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-5b557680-91a2-4398-928f-3addc0ebb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-3bb99bb3-ada0-498c-ae05-ff3c210b1327,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-435f77ad-66a0-4167-beb4-7d88c1725610,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2e345f8c-3209-4c84-9d90-0706ff91a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-c1d904d0-51b1-481a-b95c-7cd035b0e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-6605b9e4-cb9c-4e2f-984b-51cb55b69572,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-0928f063-85d7-4c35-bd98-5b62440dea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-1c164bc3-5549-4a48-adf3-519bf6be4739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661409982-172.17.0.9-1598636968951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-5b557680-91a2-4398-928f-3addc0ebb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-3bb99bb3-ada0-498c-ae05-ff3c210b1327,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-435f77ad-66a0-4167-beb4-7d88c1725610,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2e345f8c-3209-4c84-9d90-0706ff91a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-c1d904d0-51b1-481a-b95c-7cd035b0e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-6605b9e4-cb9c-4e2f-984b-51cb55b69572,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-0928f063-85d7-4c35-bd98-5b62440dea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-1c164bc3-5549-4a48-adf3-519bf6be4739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854394176-172.17.0.9-1598637099443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-ba89bde1-7496-468e-b5c8-3d89557746c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-adaceb0b-c285-4aa6-9526-1d41bae24a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6c1250b9-0a31-4aae-bb32-e8e5489b9306,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-29a08390-7e74-4ce5-aad6-34b286028bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-d6a53149-1fe3-4834-9be7-d4b56d205297,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-cfaaf0a1-56a9-461d-b158-c81e27f6babd,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7bb01f18-9326-467e-875a-eea8cb962b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-db927953-b969-4d53-8e41-6bb403c070d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854394176-172.17.0.9-1598637099443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-ba89bde1-7496-468e-b5c8-3d89557746c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-adaceb0b-c285-4aa6-9526-1d41bae24a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6c1250b9-0a31-4aae-bb32-e8e5489b9306,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-29a08390-7e74-4ce5-aad6-34b286028bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-d6a53149-1fe3-4834-9be7-d4b56d205297,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-cfaaf0a1-56a9-461d-b158-c81e27f6babd,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7bb01f18-9326-467e-875a-eea8cb962b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-db927953-b969-4d53-8e41-6bb403c070d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965312931-172.17.0.9-1598637128680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-a973fb6d-bfaf-4bf9-919b-b7f9432cfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-156cd789-88ba-4c9d-bd68-8c6a02df2728,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-405157bc-8670-46c9-8816-ef6f852fc23e,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-e5688be1-6f97-4080-99a1-db526cf2e852,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-8eb949b2-dec7-480f-aad8-58fbe351a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-7b996129-17c5-46ed-acb8-0c8d04505a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-540e6d42-884d-4f5b-9e15-2e72edf6abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-833d05b8-d380-41c5-9a78-a26b17316efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965312931-172.17.0.9-1598637128680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-a973fb6d-bfaf-4bf9-919b-b7f9432cfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-156cd789-88ba-4c9d-bd68-8c6a02df2728,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-405157bc-8670-46c9-8816-ef6f852fc23e,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-e5688be1-6f97-4080-99a1-db526cf2e852,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-8eb949b2-dec7-480f-aad8-58fbe351a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-7b996129-17c5-46ed-acb8-0c8d04505a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-540e6d42-884d-4f5b-9e15-2e72edf6abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-833d05b8-d380-41c5-9a78-a26b17316efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582738955-172.17.0.9-1598637186465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-d709cc5b-d7df-4c9a-a81b-7e274043f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-0c54bf0f-2c2c-4a92-88ec-40e74a3d2624,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-1b0a896c-99df-43aa-84bc-ff1250840178,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-d2087c4c-30f6-4f60-a7d3-762b42a41005,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-341413c2-4cd9-499c-85aa-64397d682e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-cab9c437-3c3e-435e-b492-af674a722446,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-049ac5ee-30a2-42c0-8841-85183e0c4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3c6f5497-fc48-4a6d-bc6e-f2e509eb3e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582738955-172.17.0.9-1598637186465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-d709cc5b-d7df-4c9a-a81b-7e274043f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-0c54bf0f-2c2c-4a92-88ec-40e74a3d2624,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-1b0a896c-99df-43aa-84bc-ff1250840178,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-d2087c4c-30f6-4f60-a7d3-762b42a41005,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-341413c2-4cd9-499c-85aa-64397d682e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-cab9c437-3c3e-435e-b492-af674a722446,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-049ac5ee-30a2-42c0-8841-85183e0c4b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3c6f5497-fc48-4a6d-bc6e-f2e509eb3e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217194384-172.17.0.9-1598637219294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-a7a91934-92b3-4083-9afa-e4b5095bbbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-85224a1c-a1c3-492c-8c07-475f81224c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-71c1fee7-b8df-4650-9997-498b4bfa4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-0728dac9-3df9-4876-ac1b-ca82418daa70,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-1ed946e8-6072-4605-ae23-513336ef7eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-b2a75a1c-9fe9-40cc-b445-c19ba36384fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-84023177-7f32-42b3-b2a1-7e90d03018cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-b1742f5c-a1dc-472c-8e53-cea651a3a0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217194384-172.17.0.9-1598637219294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-a7a91934-92b3-4083-9afa-e4b5095bbbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-85224a1c-a1c3-492c-8c07-475f81224c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-71c1fee7-b8df-4650-9997-498b4bfa4ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-0728dac9-3df9-4876-ac1b-ca82418daa70,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-1ed946e8-6072-4605-ae23-513336ef7eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-b2a75a1c-9fe9-40cc-b445-c19ba36384fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-84023177-7f32-42b3-b2a1-7e90d03018cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-b1742f5c-a1dc-472c-8e53-cea651a3a0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253227883-172.17.0.9-1598637311105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-f2aacea9-ff7f-4a84-acb0-8b9e4c76a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-13bd8877-9cd2-4086-bbd0-bf477f105b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-5eaa3b86-7c97-4a26-9176-cb7f62036f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b24e6133-8b07-4c3c-b9d6-0b78e09fc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-61471321-fbbf-414f-8868-29106ca2114c,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-2a5499e6-8fc3-4921-a041-d475e6a46188,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-ad66c544-266a-4bbe-b3aa-1d87bee49042,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-a60065db-dff8-449f-aec8-4163ab918b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253227883-172.17.0.9-1598637311105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43506,DS-f2aacea9-ff7f-4a84-acb0-8b9e4c76a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-13bd8877-9cd2-4086-bbd0-bf477f105b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-5eaa3b86-7c97-4a26-9176-cb7f62036f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b24e6133-8b07-4c3c-b9d6-0b78e09fc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-61471321-fbbf-414f-8868-29106ca2114c,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-2a5499e6-8fc3-4921-a041-d475e6a46188,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-ad66c544-266a-4bbe-b3aa-1d87bee49042,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-a60065db-dff8-449f-aec8-4163ab918b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068711804-172.17.0.9-1598637374327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-c3f59533-6a5a-4ae6-96b0-1eda5f4ac267,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-1e06c151-db1a-4e68-8885-bf0c7bf96461,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-d743ae18-855e-4960-ac34-0dd5b78503ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-bf95a163-233e-416a-a6db-8a31841e5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-d4033a49-abfe-475a-8716-295878860d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-8dd0eb87-3834-4577-b8a9-c0c5f2fb9302,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-674e3a40-e0ac-4127-bcf8-d55fde61913d,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-9ac17efd-d866-45e0-b27f-66b93197d38e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068711804-172.17.0.9-1598637374327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-c3f59533-6a5a-4ae6-96b0-1eda5f4ac267,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-1e06c151-db1a-4e68-8885-bf0c7bf96461,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-d743ae18-855e-4960-ac34-0dd5b78503ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-bf95a163-233e-416a-a6db-8a31841e5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-d4033a49-abfe-475a-8716-295878860d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-8dd0eb87-3834-4577-b8a9-c0c5f2fb9302,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-674e3a40-e0ac-4127-bcf8-d55fde61913d,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-9ac17efd-d866-45e0-b27f-66b93197d38e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 600000
v2: 1200000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192655818-172.17.0.9-1598637565409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44473,DS-92380177-bc2b-4745-b729-953ba3d2c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-2fbe375b-2cf5-4820-abad-873ca5447e39,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-972fc888-d6cf-429d-8080-1bb0bee9cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-8c05f6aa-0f3f-419f-8f1b-dee8ca24f830,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-4344fcd8-4e39-45c3-bd11-a4e993058295,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-9df22c7d-ed74-4a59-8ee6-9a74f80956dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-4f064b2e-9bec-4b60-b012-5d9557a02e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-e0df4f5e-1032-4697-b3c4-df552ed8b756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192655818-172.17.0.9-1598637565409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44473,DS-92380177-bc2b-4745-b729-953ba3d2c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-2fbe375b-2cf5-4820-abad-873ca5447e39,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-972fc888-d6cf-429d-8080-1bb0bee9cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-8c05f6aa-0f3f-419f-8f1b-dee8ca24f830,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-4344fcd8-4e39-45c3-bd11-a4e993058295,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-9df22c7d-ed74-4a59-8ee6-9a74f80956dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-4f064b2e-9bec-4b60-b012-5d9557a02e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-e0df4f5e-1032-4697-b3c4-df552ed8b756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5291
