reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175299157-172.17.0.8-1598508441528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-fe844e09-401a-447b-80dc-6d128df06d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-43f3589c-729d-4411-b0c3-2e15de7f939f,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-016fad9c-da77-4976-8482-4157ea3cabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-b7b03bbe-c1c7-4cd3-b005-34262dad9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-982e161e-b631-45f9-856d-32ae5f5e6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-23842b8f-1b7c-40e8-93c4-7f1ce185db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-c4d2c0ed-9e8a-4946-a225-9c21d2318d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5de6baa3-1b51-4efe-86fd-3bc93392a436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175299157-172.17.0.8-1598508441528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-fe844e09-401a-447b-80dc-6d128df06d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-43f3589c-729d-4411-b0c3-2e15de7f939f,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-016fad9c-da77-4976-8482-4157ea3cabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-b7b03bbe-c1c7-4cd3-b005-34262dad9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-982e161e-b631-45f9-856d-32ae5f5e6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-23842b8f-1b7c-40e8-93c4-7f1ce185db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-c4d2c0ed-9e8a-4946-a225-9c21d2318d76,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5de6baa3-1b51-4efe-86fd-3bc93392a436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159153592-172.17.0.8-1598508475344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-20a6bf63-54d5-487d-b4b5-b548fb0631b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-ece9a7f5-4221-499c-b5a0-a96b59429e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-50af743a-dbd7-49aa-aeee-beb5ec4b76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5fbef85f-fb12-4cad-887d-99c6978e256a,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-45bc03b6-1e9b-4c9a-a00f-3656164814a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c0676c14-30e7-45dd-b6f7-87237afc8900,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-405ffc55-87ae-448a-85d3-170d2da22474,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-2a0f77c5-7e15-4713-b670-75a59e39c209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159153592-172.17.0.8-1598508475344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-20a6bf63-54d5-487d-b4b5-b548fb0631b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-ece9a7f5-4221-499c-b5a0-a96b59429e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-50af743a-dbd7-49aa-aeee-beb5ec4b76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5fbef85f-fb12-4cad-887d-99c6978e256a,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-45bc03b6-1e9b-4c9a-a00f-3656164814a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c0676c14-30e7-45dd-b6f7-87237afc8900,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-405ffc55-87ae-448a-85d3-170d2da22474,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-2a0f77c5-7e15-4713-b670-75a59e39c209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236632315-172.17.0.8-1598508830893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-1a7dc2cc-347b-4a8e-a88d-1e4de3d5809b,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-89981d8c-44a0-4900-bea0-a7977ed6e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-116ce8db-1182-4687-be16-869b86651326,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-86aa660d-18d3-4f41-8539-8cb48848080c,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-19f3d7f6-7ead-4e45-bfb6-57905bed00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-0a1a44d7-281a-4065-9522-ee9ff698f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e867852f-e82d-4e43-ab54-04591e6b18f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-0a2a1141-d21e-4d83-87b8-e3f84c718ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236632315-172.17.0.8-1598508830893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-1a7dc2cc-347b-4a8e-a88d-1e4de3d5809b,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-89981d8c-44a0-4900-bea0-a7977ed6e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-116ce8db-1182-4687-be16-869b86651326,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-86aa660d-18d3-4f41-8539-8cb48848080c,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-19f3d7f6-7ead-4e45-bfb6-57905bed00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-0a1a44d7-281a-4065-9522-ee9ff698f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e867852f-e82d-4e43-ab54-04591e6b18f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-0a2a1141-d21e-4d83-87b8-e3f84c718ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401305069-172.17.0.8-1598508978602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-fb2cf720-7e1d-4263-ac4b-93f276417093,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e786879b-2a7c-4611-aec6-3266988b52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-10808813-b308-4708-a764-73546675396d,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-19051efe-991e-4acd-ae5f-ead5719410e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7ce25c05-7b50-47bd-9a13-e6328e26c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-067c8ace-103f-4a46-a390-a5d0f77a2794,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-f51273d3-ff1d-4a24-8fb2-546d391466f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-2d17319d-d793-4506-be53-a015f3f5973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401305069-172.17.0.8-1598508978602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-fb2cf720-7e1d-4263-ac4b-93f276417093,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-e786879b-2a7c-4611-aec6-3266988b52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-10808813-b308-4708-a764-73546675396d,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-19051efe-991e-4acd-ae5f-ead5719410e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-7ce25c05-7b50-47bd-9a13-e6328e26c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-067c8ace-103f-4a46-a390-a5d0f77a2794,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-f51273d3-ff1d-4a24-8fb2-546d391466f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-2d17319d-d793-4506-be53-a015f3f5973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354453423-172.17.0.8-1598509045658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-9843c2e4-31d2-4254-9d69-2177dab9c9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-86a9caaf-7b98-41f4-b115-03fc8b4ad9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-2e273306-ba7c-4e9b-b767-c11b9b06815e,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-d7c8e65d-159c-461c-b8c1-ecf1cb33997a,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c90624ac-994e-41dc-9d09-38720144cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-57fe2ea7-14e5-4fba-b7ca-7451ad581710,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f7d84344-8ae5-4297-9c79-bd3031f66f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-769f4255-7b97-4473-91e0-45eb0a26c866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354453423-172.17.0.8-1598509045658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-9843c2e4-31d2-4254-9d69-2177dab9c9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-86a9caaf-7b98-41f4-b115-03fc8b4ad9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-2e273306-ba7c-4e9b-b767-c11b9b06815e,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-d7c8e65d-159c-461c-b8c1-ecf1cb33997a,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c90624ac-994e-41dc-9d09-38720144cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-57fe2ea7-14e5-4fba-b7ca-7451ad581710,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f7d84344-8ae5-4297-9c79-bd3031f66f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-769f4255-7b97-4473-91e0-45eb0a26c866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756564334-172.17.0.8-1598509269962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-95b201b1-0830-4d72-a124-5e2600a31bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4d262d1c-68de-4900-a86a-a9b3b0900718,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-ba00bb34-bd53-4c99-bbcd-306bd846b803,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-e51df9fb-a7be-44f5-9979-cdba8d6f3361,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ab064834-666e-4874-8787-4015f219bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-b4684135-a019-441f-804e-0618ce3c8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-b51a68cb-75f8-402b-b222-0f987e5d0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-6b677fed-246a-4f6b-af13-15a08005c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756564334-172.17.0.8-1598509269962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-95b201b1-0830-4d72-a124-5e2600a31bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4d262d1c-68de-4900-a86a-a9b3b0900718,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-ba00bb34-bd53-4c99-bbcd-306bd846b803,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-e51df9fb-a7be-44f5-9979-cdba8d6f3361,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-ab064834-666e-4874-8787-4015f219bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-b4684135-a019-441f-804e-0618ce3c8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-b51a68cb-75f8-402b-b222-0f987e5d0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-6b677fed-246a-4f6b-af13-15a08005c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269002079-172.17.0.8-1598509309120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38224,DS-f1960ae9-87af-40e2-acf2-c9e0513c147f,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-10188226-dd61-46f6-ad64-60a71ba9c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-80b6e0b9-e293-4276-90b8-41e4c7c6d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-97d42233-734f-4edc-9643-87b5d55bedce,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-d6ad737d-4ed5-4fa0-8110-c019a267b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-6276e766-c10c-408b-ba79-2d899457b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-f1bb5c69-e932-40cd-b510-cbcb9b5142cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-a42c1331-648a-4e1d-a379-1613b33f0dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269002079-172.17.0.8-1598509309120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38224,DS-f1960ae9-87af-40e2-acf2-c9e0513c147f,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-10188226-dd61-46f6-ad64-60a71ba9c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-80b6e0b9-e293-4276-90b8-41e4c7c6d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-97d42233-734f-4edc-9643-87b5d55bedce,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-d6ad737d-4ed5-4fa0-8110-c019a267b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-6276e766-c10c-408b-ba79-2d899457b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-f1bb5c69-e932-40cd-b510-cbcb9b5142cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-a42c1331-648a-4e1d-a379-1613b33f0dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102617275-172.17.0.8-1598509338847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-45edba77-0cbb-4dbc-94cc-96c78b33fd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-aff9885a-d7d4-4e1b-9af6-871c519a5efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-418708e5-6978-475a-a468-c6d0f76a1067,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-d5724cee-e6df-4ba3-a4fb-9bb1b7545995,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-2bf8c36e-298c-40f5-a094-8b95353c7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-9ccefd0b-7e60-4baa-87c7-1e2400900cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1e78494c-d87f-46b5-bd90-0ee8b2667d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-54d5543d-3b5d-4b89-aa94-ecba969aff83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102617275-172.17.0.8-1598509338847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-45edba77-0cbb-4dbc-94cc-96c78b33fd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-aff9885a-d7d4-4e1b-9af6-871c519a5efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-418708e5-6978-475a-a468-c6d0f76a1067,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-d5724cee-e6df-4ba3-a4fb-9bb1b7545995,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-2bf8c36e-298c-40f5-a094-8b95353c7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-9ccefd0b-7e60-4baa-87c7-1e2400900cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1e78494c-d87f-46b5-bd90-0ee8b2667d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-54d5543d-3b5d-4b89-aa94-ecba969aff83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342130994-172.17.0.8-1598509376174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-6547a0eb-a570-43a9-bb75-0d76aded6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-acc0896d-2423-4d23-bedb-559ebbb96ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-27ef3666-408f-49d4-a9fd-033c34511ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-85381493-43ca-4528-ae76-73e19c9b0b27,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-fe9c9178-d6fc-49b7-85eb-09e4e30f424c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-3c9fac73-afb9-4ad8-b076-15ae84581753,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-6cb6928d-f9e6-48fb-926b-a541e1e17653,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-7f55858b-13c7-4eb8-b442-4c14c7c7b144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342130994-172.17.0.8-1598509376174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-6547a0eb-a570-43a9-bb75-0d76aded6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-acc0896d-2423-4d23-bedb-559ebbb96ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-27ef3666-408f-49d4-a9fd-033c34511ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-85381493-43ca-4528-ae76-73e19c9b0b27,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-fe9c9178-d6fc-49b7-85eb-09e4e30f424c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-3c9fac73-afb9-4ad8-b076-15ae84581753,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-6cb6928d-f9e6-48fb-926b-a541e1e17653,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-7f55858b-13c7-4eb8-b442-4c14c7c7b144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792126982-172.17.0.8-1598509625749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-66a9cd4f-2818-439e-b52b-f6e8a211e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-1d882774-3374-4cd3-be95-c2e0a9b3a4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-8b18cbed-3583-465f-b217-c306eef14846,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-f44a6040-de71-4ae5-9cdc-2f9dcd1d8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-399a7e19-7024-4c58-bd58-85ce46de6dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-65c33f3b-9480-4f1b-8d22-6d08b99dfc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-4636d0b7-ce23-487c-b659-dda9fac74367,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f0bfa909-9bbf-4e98-acf2-c02ed8f75997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792126982-172.17.0.8-1598509625749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-66a9cd4f-2818-439e-b52b-f6e8a211e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-1d882774-3374-4cd3-be95-c2e0a9b3a4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-8b18cbed-3583-465f-b217-c306eef14846,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-f44a6040-de71-4ae5-9cdc-2f9dcd1d8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-399a7e19-7024-4c58-bd58-85ce46de6dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-65c33f3b-9480-4f1b-8d22-6d08b99dfc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-4636d0b7-ce23-487c-b659-dda9fac74367,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f0bfa909-9bbf-4e98-acf2-c02ed8f75997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274422841-172.17.0.8-1598510669159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-1275d38a-ad0b-4274-9fd0-21578ae2cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-41118aed-d80d-4be3-bfee-b06cf839f5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a71c0c52-2003-4d55-86ea-e706b49792c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-321307b0-ae0b-4523-9503-725576c5cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-8df810d4-1b4e-42ae-a6c9-420d75fd4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d09a3d75-9906-4638-8336-82db458235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-7baced8c-d5d3-44df-8268-02d1bb2aeb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-6257a51e-4582-48d9-af20-3d9b0f9cc28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274422841-172.17.0.8-1598510669159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-1275d38a-ad0b-4274-9fd0-21578ae2cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-41118aed-d80d-4be3-bfee-b06cf839f5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-a71c0c52-2003-4d55-86ea-e706b49792c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-321307b0-ae0b-4523-9503-725576c5cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-8df810d4-1b4e-42ae-a6c9-420d75fd4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d09a3d75-9906-4638-8336-82db458235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-7baced8c-d5d3-44df-8268-02d1bb2aeb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-6257a51e-4582-48d9-af20-3d9b0f9cc28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696623585-172.17.0.8-1598510963008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-ee0803fd-4fd0-4fe2-86ea-e7a70059ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-d2e69e79-ab91-4602-9881-5f831c0f0645,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-015dd62a-77a1-40bf-8d6c-3c384668bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-7d01b3b5-b211-4abf-b869-8d9cc9459993,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-c9a25750-30cf-49ed-a4ee-510f6324405e,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-eb94fa72-22e2-437d-88a3-4860c9bde37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-27718a1d-d255-4912-a63a-76b8e581d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-4f02eaed-055b-465e-9e64-0b6476e16a4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696623585-172.17.0.8-1598510963008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-ee0803fd-4fd0-4fe2-86ea-e7a70059ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-d2e69e79-ab91-4602-9881-5f831c0f0645,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-015dd62a-77a1-40bf-8d6c-3c384668bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-7d01b3b5-b211-4abf-b869-8d9cc9459993,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-c9a25750-30cf-49ed-a4ee-510f6324405e,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-eb94fa72-22e2-437d-88a3-4860c9bde37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-27718a1d-d255-4912-a63a-76b8e581d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-4f02eaed-055b-465e-9e64-0b6476e16a4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219840257-172.17.0.8-1598511293958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-c680872f-b87f-41ae-90c6-5d61baa48d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-24e5f01a-3c0f-4bfd-acdd-59d0e7ff598c,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-56c3c4a7-7966-44b7-b18e-348482e927d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-68daccd7-21f3-4a32-a57d-c8e50f3a872a,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-5362cb12-35e0-4421-85ef-ece104a748cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-5806b983-cb50-4aef-b3f7-b47d951fe0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-638c6bce-b0ed-4a80-9311-d3ebe03dd493,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4201c008-c1ba-418e-ab9d-7363a313cfeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219840257-172.17.0.8-1598511293958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-c680872f-b87f-41ae-90c6-5d61baa48d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-24e5f01a-3c0f-4bfd-acdd-59d0e7ff598c,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-56c3c4a7-7966-44b7-b18e-348482e927d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-68daccd7-21f3-4a32-a57d-c8e50f3a872a,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-5362cb12-35e0-4421-85ef-ece104a748cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-5806b983-cb50-4aef-b3f7-b47d951fe0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-638c6bce-b0ed-4a80-9311-d3ebe03dd493,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-4201c008-c1ba-418e-ab9d-7363a313cfeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120449418-172.17.0.8-1598511800929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-9dd56bd7-6781-4d9c-9f2f-2d19e0ed8e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-fbe3d191-2772-4d5b-a00a-ea8c796990c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-e323d994-0c97-4ca6-a4c5-1d3b351c4a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-21883aca-3a4b-4d19-a9fb-3da4a523d754,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-441014a2-f55e-45d0-85f5-0f4df23a0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-48b026b3-b70d-4c10-a05d-82ebdd36d9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6387d04b-b2bc-40f2-afca-31b840c269d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-e97d9bfc-6b63-4db9-a841-593209588f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120449418-172.17.0.8-1598511800929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41920,DS-9dd56bd7-6781-4d9c-9f2f-2d19e0ed8e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-fbe3d191-2772-4d5b-a00a-ea8c796990c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-e323d994-0c97-4ca6-a4c5-1d3b351c4a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-21883aca-3a4b-4d19-a9fb-3da4a523d754,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-441014a2-f55e-45d0-85f5-0f4df23a0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-48b026b3-b70d-4c10-a05d-82ebdd36d9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6387d04b-b2bc-40f2-afca-31b840c269d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-e97d9bfc-6b63-4db9-a841-593209588f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505244172-172.17.0.8-1598511876076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36180,DS-78174ece-ed0f-4454-9cf6-d73e63e37508,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-11cfe285-9578-434e-8c5c-a671b6784dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-86a30f5c-3047-4aac-b0f5-0ecd18b91054,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-403a09d4-606a-4d20-93c0-6bd623538c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-d1a62953-fc16-4219-82da-19285b68a7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-fe04f95c-e8f9-4cf7-ad72-7f5732af0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-e1955f72-e237-47a0-a648-0a773bf96554,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-2b77ad8a-c5f9-48c1-ad60-d0ba2b15363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505244172-172.17.0.8-1598511876076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36180,DS-78174ece-ed0f-4454-9cf6-d73e63e37508,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-11cfe285-9578-434e-8c5c-a671b6784dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-86a30f5c-3047-4aac-b0f5-0ecd18b91054,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-403a09d4-606a-4d20-93c0-6bd623538c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-d1a62953-fc16-4219-82da-19285b68a7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-fe04f95c-e8f9-4cf7-ad72-7f5732af0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-e1955f72-e237-47a0-a648-0a773bf96554,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-2b77ad8a-c5f9-48c1-ad60-d0ba2b15363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700066979-172.17.0.8-1598512248385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-cfb42b8a-aedd-4876-9272-5bf83e55a030,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-d21ea55d-cc5d-43e3-afcf-2b696520c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-50c5fa6d-a800-4089-ba7b-f57f18b5d544,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-b190df10-83d1-4dbb-b28e-76b11e164197,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-997de511-25a4-4849-b33f-c4de7323c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-643a1bcc-2d94-4d55-85f6-2ed12d09cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-c55a752d-54ff-4cbe-bba0-fb9cee66946f,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-56ab29ea-b7b8-4085-ad89-e5af988fc770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700066979-172.17.0.8-1598512248385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-cfb42b8a-aedd-4876-9272-5bf83e55a030,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-d21ea55d-cc5d-43e3-afcf-2b696520c682,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-50c5fa6d-a800-4089-ba7b-f57f18b5d544,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-b190df10-83d1-4dbb-b28e-76b11e164197,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-997de511-25a4-4849-b33f-c4de7323c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-643a1bcc-2d94-4d55-85f6-2ed12d09cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-c55a752d-54ff-4cbe-bba0-fb9cee66946f,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-56ab29ea-b7b8-4085-ad89-e5af988fc770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881468540-172.17.0.8-1598512289013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-94f51bbe-51fe-47f6-9ff9-b8b8eee47c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-35d61f2c-fdb6-4358-8042-3a3524d26cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e997d1eb-51a3-4ae5-accb-e72945c68092,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-d14e4cb6-9c36-425c-a80d-352c48673573,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-19426980-a518-48e2-b3f1-7918297b887d,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-69c537e2-ffe2-49b9-9e90-74c9fae468ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-27eed53b-92a4-46e0-9130-1859dbcdb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-a668aa8c-31c7-44b2-92d1-3ddd6aa659fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881468540-172.17.0.8-1598512289013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-94f51bbe-51fe-47f6-9ff9-b8b8eee47c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-35d61f2c-fdb6-4358-8042-3a3524d26cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e997d1eb-51a3-4ae5-accb-e72945c68092,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-d14e4cb6-9c36-425c-a80d-352c48673573,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-19426980-a518-48e2-b3f1-7918297b887d,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-69c537e2-ffe2-49b9-9e90-74c9fae468ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-27eed53b-92a4-46e0-9130-1859dbcdb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-a668aa8c-31c7-44b2-92d1-3ddd6aa659fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940326285-172.17.0.8-1598512370156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-5a9e6ccc-04c4-41fe-a05e-88c3593a410e,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-e94935ea-a284-4a83-93f4-113e81cb399e,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-eff336c1-85f8-41d4-83a2-59ccd82128f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-fd0ab3e2-86d8-4e31-a76c-4ba4fcb5d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-164c252e-ea6f-4106-84fb-65b0f1da7ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f08c1361-6eda-4dd7-ab03-f6e7dcc52821,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-beec4d75-5e61-4f3a-bc58-da460e0c7217,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ad26c701-060e-4976-8510-4fba5f32e32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940326285-172.17.0.8-1598512370156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-5a9e6ccc-04c4-41fe-a05e-88c3593a410e,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-e94935ea-a284-4a83-93f4-113e81cb399e,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-eff336c1-85f8-41d4-83a2-59ccd82128f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-fd0ab3e2-86d8-4e31-a76c-4ba4fcb5d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-164c252e-ea6f-4106-84fb-65b0f1da7ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f08c1361-6eda-4dd7-ab03-f6e7dcc52821,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-beec4d75-5e61-4f3a-bc58-da460e0c7217,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ad26c701-060e-4976-8510-4fba5f32e32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742663404-172.17.0.8-1598512409229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-b4804b65-2786-48eb-9b2b-5caef6a4dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-f877c661-eeaf-43d0-b4ee-43d149237a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-ac2e04c0-08ff-4283-b8ee-de9374d78ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-b72caf62-5676-4bdf-95bb-dba58d3014c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-d78aa488-5f54-4192-b1fa-d6f5415059e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-6f56dc82-9b4a-48f2-952b-a3d0e7f93ace,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-4cc1ba3c-8e81-47de-9c44-1ee0bb76b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cfce3f3d-70b4-4652-88bc-465d0943f87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742663404-172.17.0.8-1598512409229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45896,DS-b4804b65-2786-48eb-9b2b-5caef6a4dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-f877c661-eeaf-43d0-b4ee-43d149237a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-ac2e04c0-08ff-4283-b8ee-de9374d78ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-b72caf62-5676-4bdf-95bb-dba58d3014c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-d78aa488-5f54-4192-b1fa-d6f5415059e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-6f56dc82-9b4a-48f2-952b-a3d0e7f93ace,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-4cc1ba3c-8e81-47de-9c44-1ee0bb76b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cfce3f3d-70b4-4652-88bc-465d0943f87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 64
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589397912-172.17.0.8-1598512871306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-daba4b5b-edee-4174-b6ff-99926934f694,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-a1a77c2b-ae53-4b8d-881d-97e510e888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-9674ad3f-c469-4817-b71c-1c2cc5e63e95,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-a732e055-107b-4d4c-87b9-740361e6a980,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-210cf60a-d1f8-4f2f-80be-7fa0f1c6582d,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3cb810cf-d76c-42cc-b683-c980e489fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-47b68a67-c0fa-4d0a-982e-95996aeb751e,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-04bac2b8-572e-4e38-93a2-aedc8032480f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589397912-172.17.0.8-1598512871306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-daba4b5b-edee-4174-b6ff-99926934f694,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-a1a77c2b-ae53-4b8d-881d-97e510e888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-9674ad3f-c469-4817-b71c-1c2cc5e63e95,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-a732e055-107b-4d4c-87b9-740361e6a980,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-210cf60a-d1f8-4f2f-80be-7fa0f1c6582d,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3cb810cf-d76c-42cc-b683-c980e489fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-47b68a67-c0fa-4d0a-982e-95996aeb751e,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-04bac2b8-572e-4e38-93a2-aedc8032480f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5284
