reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026249209-172.17.0.10-1598487658833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41791,DS-e3c6f976-bdf2-468a-88fb-84d369274f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-668fb2d4-0dc7-4ef2-845d-27f32cb84b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-25fb6517-c6c4-46f9-af43-d9c4806681f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-e3223d70-f19a-40df-925a-826a9b5efa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-13c084e3-860e-4606-be8c-b0ef1561d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-8defcd77-09fe-4aa8-998d-04a7ff0f8675,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-a77cc9da-bee1-4fa2-a0bd-2181bee11564,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-f5261c7a-41f4-4bf7-878e-be74b778acda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026249209-172.17.0.10-1598487658833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41791,DS-e3c6f976-bdf2-468a-88fb-84d369274f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-668fb2d4-0dc7-4ef2-845d-27f32cb84b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-25fb6517-c6c4-46f9-af43-d9c4806681f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-e3223d70-f19a-40df-925a-826a9b5efa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-13c084e3-860e-4606-be8c-b0ef1561d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-8defcd77-09fe-4aa8-998d-04a7ff0f8675,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-a77cc9da-bee1-4fa2-a0bd-2181bee11564,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-f5261c7a-41f4-4bf7-878e-be74b778acda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015731403-172.17.0.10-1598488655346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33014,DS-aa47abec-db64-4d3c-83eb-89540ceaf230,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-520060e4-82d0-4513-b0ab-407052348e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-df93ddc2-437f-47e3-bfa1-075a0b56eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-b4c13a39-e446-412e-890f-9be7f0ec0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-80e92979-5538-48de-81d7-9603d85997c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2f3efe42-c362-4416-b16b-b8a5f6098cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-d0e1a6eb-81bc-4bbb-ab1c-a23627e0a685,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-734b1e01-518d-4d33-acce-cae33baefd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015731403-172.17.0.10-1598488655346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33014,DS-aa47abec-db64-4d3c-83eb-89540ceaf230,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-520060e4-82d0-4513-b0ab-407052348e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-df93ddc2-437f-47e3-bfa1-075a0b56eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-b4c13a39-e446-412e-890f-9be7f0ec0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-80e92979-5538-48de-81d7-9603d85997c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2f3efe42-c362-4416-b16b-b8a5f6098cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-d0e1a6eb-81bc-4bbb-ab1c-a23627e0a685,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-734b1e01-518d-4d33-acce-cae33baefd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897619822-172.17.0.10-1598488697276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-70edddfb-493a-4f58-bd65-0d43623a1b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7a641707-8a4b-4fd9-a965-c83464a24eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-68a0825b-d70c-4f18-913b-877b3487f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-9a35932a-7063-49d4-a83b-3990755b62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-454635c3-4948-4781-b7d5-b0a05fc789ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-62c0b538-2d22-4f3c-93c8-bd7e992badfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c154cc98-995e-4113-9604-4270a66fa21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-66d1df14-967a-4022-9972-aabe383fb8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897619822-172.17.0.10-1598488697276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-70edddfb-493a-4f58-bd65-0d43623a1b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7a641707-8a4b-4fd9-a965-c83464a24eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-68a0825b-d70c-4f18-913b-877b3487f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-9a35932a-7063-49d4-a83b-3990755b62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-454635c3-4948-4781-b7d5-b0a05fc789ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-62c0b538-2d22-4f3c-93c8-bd7e992badfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c154cc98-995e-4113-9604-4270a66fa21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-66d1df14-967a-4022-9972-aabe383fb8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425638981-172.17.0.10-1598488776818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-c811cd41-7703-425d-be90-2cbc755fefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-86784e82-0bae-4eee-bc19-e9bab5f3d457,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-862c5273-1f89-4006-8aac-7c72aa0f6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-c85336f4-a6f7-4bd1-b21c-1d833cd768ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-66a5560b-1f82-49d9-9b8c-72e6f33ea68c,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-866d1f5b-43a0-4b51-adbf-d260f1916483,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-bcc9e100-88db-4b17-ba82-16a405c7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8f775598-c2d3-4cb6-b44d-61dc301cdda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425638981-172.17.0.10-1598488776818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-c811cd41-7703-425d-be90-2cbc755fefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-86784e82-0bae-4eee-bc19-e9bab5f3d457,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-862c5273-1f89-4006-8aac-7c72aa0f6fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-c85336f4-a6f7-4bd1-b21c-1d833cd768ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-66a5560b-1f82-49d9-9b8c-72e6f33ea68c,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-866d1f5b-43a0-4b51-adbf-d260f1916483,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-bcc9e100-88db-4b17-ba82-16a405c7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-8f775598-c2d3-4cb6-b44d-61dc301cdda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488293630-172.17.0.10-1598488890766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34138,DS-9f858569-0a44-4ad5-8fcc-4912d194bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-09341785-768b-4fd5-b086-d5dfbe0ca442,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-9997dc7e-d16e-4062-bc89-a01403617f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-a15fcce5-e1a7-4826-a1f2-acd6095aa64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-af66bc1a-2047-434f-8561-964d19553313,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-215a706c-a314-437e-b2d1-c79901c96343,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-04535c95-ca8a-4ec6-bf93-bfbaa4a77fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-bf2ab4dc-0d89-44c7-a1f8-d2bac48c86d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488293630-172.17.0.10-1598488890766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34138,DS-9f858569-0a44-4ad5-8fcc-4912d194bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-09341785-768b-4fd5-b086-d5dfbe0ca442,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-9997dc7e-d16e-4062-bc89-a01403617f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-a15fcce5-e1a7-4826-a1f2-acd6095aa64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-af66bc1a-2047-434f-8561-964d19553313,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-215a706c-a314-437e-b2d1-c79901c96343,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-04535c95-ca8a-4ec6-bf93-bfbaa4a77fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-bf2ab4dc-0d89-44c7-a1f8-d2bac48c86d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031858082-172.17.0.10-1598489141141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-27d1d13c-29a6-4362-9574-efff6eb65c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-5bfc11b7-a158-487c-a7ab-c290aead4077,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-d455d42a-4947-4f6d-9c8f-7170d398a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4b2ac584-9bbb-436d-917c-7c2775c9234a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-fb64bb2a-8388-4961-9b62-4b4755f96ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-83ce187a-0fdf-4422-982d-98ff4f9a634b,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-3f753ecf-4cce-4b74-8a93-80cee38674e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-7ca453a2-c6e0-4a86-a68a-23b8be054ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031858082-172.17.0.10-1598489141141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-27d1d13c-29a6-4362-9574-efff6eb65c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-5bfc11b7-a158-487c-a7ab-c290aead4077,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-d455d42a-4947-4f6d-9c8f-7170d398a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4b2ac584-9bbb-436d-917c-7c2775c9234a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-fb64bb2a-8388-4961-9b62-4b4755f96ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-83ce187a-0fdf-4422-982d-98ff4f9a634b,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-3f753ecf-4cce-4b74-8a93-80cee38674e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-7ca453a2-c6e0-4a86-a68a-23b8be054ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382072267-172.17.0.10-1598489549891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-4aa992a6-9083-4935-9f5c-d5cf109403ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-9914b933-5d61-421e-8b8f-c4d1e10f9828,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-018871a0-daff-42a3-8bfe-30f713883e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5b24acd8-fae0-4443-8466-c02bfe6b07bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-209e0f24-ab93-43a3-a2f3-eda8d3df342d,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-23155ed2-be3f-43e8-aa76-81fb197f042d,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-432b441b-81bd-4e13-89be-4472cd912210,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-c4b8c1db-3c6d-4098-9b75-4985ed6a7cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382072267-172.17.0.10-1598489549891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-4aa992a6-9083-4935-9f5c-d5cf109403ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-9914b933-5d61-421e-8b8f-c4d1e10f9828,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-018871a0-daff-42a3-8bfe-30f713883e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-5b24acd8-fae0-4443-8466-c02bfe6b07bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-209e0f24-ab93-43a3-a2f3-eda8d3df342d,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-23155ed2-be3f-43e8-aa76-81fb197f042d,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-432b441b-81bd-4e13-89be-4472cd912210,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-c4b8c1db-3c6d-4098-9b75-4985ed6a7cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220009347-172.17.0.10-1598490136688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-08dcf511-5b5b-43fd-9b50-cdd941837944,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-4db6da30-07d8-40b5-8b7b-a5750a591bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-751ae80d-9941-48ac-a78e-644407315430,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b3214ba6-7709-48d2-9aeb-dc20e078be94,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-8fb7dc5a-87f5-4e6f-920c-209ff975264e,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-95d570dd-e250-47f7-b116-e9692fa6504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-42dc9117-ba89-4232-845f-e69f72dda7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-0461044a-170f-419f-b5e4-a88bca726161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220009347-172.17.0.10-1598490136688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-08dcf511-5b5b-43fd-9b50-cdd941837944,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-4db6da30-07d8-40b5-8b7b-a5750a591bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-751ae80d-9941-48ac-a78e-644407315430,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b3214ba6-7709-48d2-9aeb-dc20e078be94,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-8fb7dc5a-87f5-4e6f-920c-209ff975264e,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-95d570dd-e250-47f7-b116-e9692fa6504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-42dc9117-ba89-4232-845f-e69f72dda7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-0461044a-170f-419f-b5e4-a88bca726161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853219342-172.17.0.10-1598490582979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-6d33868b-67ee-4350-8abf-c82b0d68d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-88e7f082-8cd1-454f-a540-4ff631e520b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ecbf71fb-9681-4626-9d50-b2333db9fd63,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-5975f95b-e2c2-47bf-8455-b13e0cf4f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c8982227-01fc-4938-a0e8-5674d32ba081,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-5707989c-2eaa-4b7b-9314-e832d293e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-581a8896-9df8-4810-91fb-b23adaedf9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-32f91ec0-d889-459c-974e-24f322d0bc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853219342-172.17.0.10-1598490582979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-6d33868b-67ee-4350-8abf-c82b0d68d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-88e7f082-8cd1-454f-a540-4ff631e520b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ecbf71fb-9681-4626-9d50-b2333db9fd63,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-5975f95b-e2c2-47bf-8455-b13e0cf4f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c8982227-01fc-4938-a0e8-5674d32ba081,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-5707989c-2eaa-4b7b-9314-e832d293e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-581a8896-9df8-4810-91fb-b23adaedf9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-32f91ec0-d889-459c-974e-24f322d0bc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563524073-172.17.0.10-1598491092304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-c8decc97-58a0-405b-9155-b72d81effaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-60f13e99-92f3-40a9-b441-7840ea666ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-d5063dc2-f33f-4bc1-bdd2-1002237489e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-6b9f1978-c2ff-41c9-bfdd-22bef13ed823,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f8d76632-ad33-4c9b-8510-919d15bfcbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-ca2008bf-6d0b-4582-ab42-a477e30963e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-79b18064-2fcb-458f-a903-e264a7a92eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-e492cf51-fa1d-429f-88e3-ced9176db15c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563524073-172.17.0.10-1598491092304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-c8decc97-58a0-405b-9155-b72d81effaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-60f13e99-92f3-40a9-b441-7840ea666ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-d5063dc2-f33f-4bc1-bdd2-1002237489e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-6b9f1978-c2ff-41c9-bfdd-22bef13ed823,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f8d76632-ad33-4c9b-8510-919d15bfcbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-ca2008bf-6d0b-4582-ab42-a477e30963e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-79b18064-2fcb-458f-a903-e264a7a92eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-e492cf51-fa1d-429f-88e3-ced9176db15c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310111622-172.17.0.10-1598491841011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-6af052d3-312e-40a0-999b-0ea172b515d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-f104bc9a-bb57-4f28-9b54-b1b2ee02ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-13bc7a53-b2af-4c85-9e05-b2727e15d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-7f646b94-36cf-4802-b966-c53298b7f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-f7a3f5c5-0fec-4180-b674-ed8be3de18af,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-049d2d08-44db-4d42-a36b-2279cbde4d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7440699e-6d18-4bb6-b145-bc45fbb865da,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-ff5f5627-fe06-40a0-bfb7-aaacb5bde350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310111622-172.17.0.10-1598491841011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-6af052d3-312e-40a0-999b-0ea172b515d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-f104bc9a-bb57-4f28-9b54-b1b2ee02ebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-13bc7a53-b2af-4c85-9e05-b2727e15d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-7f646b94-36cf-4802-b966-c53298b7f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-f7a3f5c5-0fec-4180-b674-ed8be3de18af,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-049d2d08-44db-4d42-a36b-2279cbde4d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7440699e-6d18-4bb6-b145-bc45fbb865da,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-ff5f5627-fe06-40a0-bfb7-aaacb5bde350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934211616-172.17.0.10-1598491902165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-d5c3617d-0976-4716-a36b-d5cbfe93845c,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-61aaf3e9-4e76-485c-aae5-c1ae89b3cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-cf3cfd1c-eafe-41ab-b971-990da5673397,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-5abc7304-b2f4-460f-8d1a-1a6aa9b8dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-373279a9-fdbe-4d96-930e-80d36fb35366,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c46ad0d1-e610-49c7-b2fe-9bb6d2b45d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-e7567d86-0628-4163-9f44-7e89866ba03b,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-1fbd1d26-fa1a-47bc-8884-e803c0c9f204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934211616-172.17.0.10-1598491902165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-d5c3617d-0976-4716-a36b-d5cbfe93845c,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-61aaf3e9-4e76-485c-aae5-c1ae89b3cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-cf3cfd1c-eafe-41ab-b971-990da5673397,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-5abc7304-b2f4-460f-8d1a-1a6aa9b8dc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-373279a9-fdbe-4d96-930e-80d36fb35366,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c46ad0d1-e610-49c7-b2fe-9bb6d2b45d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-e7567d86-0628-4163-9f44-7e89866ba03b,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-1fbd1d26-fa1a-47bc-8884-e803c0c9f204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356941368-172.17.0.10-1598492065322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-91c1a494-0254-47d8-bcf2-8089f99427ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-dc56ce06-de3c-47a0-9b6a-6f72930dcbba,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-af1a3dff-6239-4cbc-a406-45f2527a4799,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-412d3495-0ba4-4664-8175-3db4fcf6e195,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-ecc86437-1c02-4843-8e6e-8613042c4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-454c0d1e-c706-4db1-bc54-bd175fb2e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-261b354b-f786-4943-9dbd-721c2e70234d,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-e87cd816-003b-4388-a475-f30fa8f9e822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356941368-172.17.0.10-1598492065322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-91c1a494-0254-47d8-bcf2-8089f99427ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-dc56ce06-de3c-47a0-9b6a-6f72930dcbba,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-af1a3dff-6239-4cbc-a406-45f2527a4799,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-412d3495-0ba4-4664-8175-3db4fcf6e195,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-ecc86437-1c02-4843-8e6e-8613042c4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-454c0d1e-c706-4db1-bc54-bd175fb2e8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-261b354b-f786-4943-9dbd-721c2e70234d,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-e87cd816-003b-4388-a475-f30fa8f9e822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101343156-172.17.0.10-1598492294184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-82ce1359-fece-4718-b683-71fe8487fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-6c7b7b70-6022-48f3-9b1e-6abdcf3d8245,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-18096823-c843-46a7-8dc0-65064c75b838,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-f89b9ccc-64ed-44d3-8078-94e73b6939eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-94cd5b49-a59e-401e-bf01-98c303d7df81,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-206a6950-3f1a-4f37-ad93-8e0770f19334,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-f2a12467-f5f0-4465-92fc-46ae5fb6efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1d706626-70e5-4642-9f18-afd51dfb1ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101343156-172.17.0.10-1598492294184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-82ce1359-fece-4718-b683-71fe8487fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-6c7b7b70-6022-48f3-9b1e-6abdcf3d8245,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-18096823-c843-46a7-8dc0-65064c75b838,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-f89b9ccc-64ed-44d3-8078-94e73b6939eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-94cd5b49-a59e-401e-bf01-98c303d7df81,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-206a6950-3f1a-4f37-ad93-8e0770f19334,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-f2a12467-f5f0-4465-92fc-46ae5fb6efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1d706626-70e5-4642-9f18-afd51dfb1ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011852936-172.17.0.10-1598492539198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-27df5eca-e6e4-466a-a360-015f30304dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-5caf2e6c-f4bc-4e9b-ad68-44491837d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-b284d534-3990-4eb1-86af-99f50c47dfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-eb41f77e-554f-4cf3-9253-9d8693ac835d,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-1a13d3e7-7d3a-42c8-89c7-3d49361e0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-1a9603d6-593d-4e2e-ada2-b7b8d4190b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-35c76507-142a-4668-9ae9-7cac12953f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-45e5b578-9397-4ded-99f6-669c0717fec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011852936-172.17.0.10-1598492539198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-27df5eca-e6e4-466a-a360-015f30304dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-5caf2e6c-f4bc-4e9b-ad68-44491837d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-b284d534-3990-4eb1-86af-99f50c47dfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-eb41f77e-554f-4cf3-9253-9d8693ac835d,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-1a13d3e7-7d3a-42c8-89c7-3d49361e0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-1a9603d6-593d-4e2e-ada2-b7b8d4190b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-35c76507-142a-4668-9ae9-7cac12953f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-45e5b578-9397-4ded-99f6-669c0717fec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047596122-172.17.0.10-1598492723353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-4e2d4794-a2c2-45d0-9302-9ed2d21051d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-abef28bb-227d-4251-98a3-49e8847450b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-1f09dae0-93a4-4a77-979f-1b63a8609958,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-83b2b15b-d546-4e4f-a88e-db8025b394ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-b8b1a044-89d2-42ac-b145-94788d40d489,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-2f8c779f-b216-4ca7-8ee5-88fc98246458,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-2f2dcd5d-0af8-4dcf-9265-0ac42dce473d,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-cd8eb923-0f21-4475-9b36-2ebefec02a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047596122-172.17.0.10-1598492723353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-4e2d4794-a2c2-45d0-9302-9ed2d21051d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-abef28bb-227d-4251-98a3-49e8847450b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-1f09dae0-93a4-4a77-979f-1b63a8609958,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-83b2b15b-d546-4e4f-a88e-db8025b394ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-b8b1a044-89d2-42ac-b145-94788d40d489,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-2f8c779f-b216-4ca7-8ee5-88fc98246458,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-2f2dcd5d-0af8-4dcf-9265-0ac42dce473d,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-cd8eb923-0f21-4475-9b36-2ebefec02a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243056680-172.17.0.10-1598492803647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-c15a03ea-bc6e-4efc-8b39-a98009346267,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c378a2e6-285a-4d82-b74e-7cb07583868e,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-27c7bb21-878d-4c89-ba75-cf6ceaa61f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-77cd1ebb-b8d5-445d-874d-ca7b60f2dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-bcb05950-9d05-418b-911a-646d6647cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-463c8d0a-9a33-4a30-9a60-48267e85cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-6b107fbc-07e4-42cd-8456-1dbc7bf60e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-be4c1d2d-cf00-40b4-8871-ac50ef29c941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243056680-172.17.0.10-1598492803647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-c15a03ea-bc6e-4efc-8b39-a98009346267,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c378a2e6-285a-4d82-b74e-7cb07583868e,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-27c7bb21-878d-4c89-ba75-cf6ceaa61f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-77cd1ebb-b8d5-445d-874d-ca7b60f2dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-bcb05950-9d05-418b-911a-646d6647cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-463c8d0a-9a33-4a30-9a60-48267e85cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-6b107fbc-07e4-42cd-8456-1dbc7bf60e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-be4c1d2d-cf00-40b4-8871-ac50ef29c941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5210
