reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190756096-172.17.0.7-1598631095065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-b4dda744-a9d2-4058-bbf8-257978d299d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-7f535603-06be-4828-b462-0d08c4324972,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-7ab074e5-af91-4f6e-bd3d-3dd46f9677d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-b4fd0f4a-e189-4b4e-864e-a8452ff0bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b310f8e4-7b4e-4241-a2d8-a1067de3e095,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-f42b804a-57ff-48d3-86fb-59b3cfc89a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-d3659199-94aa-47b7-bee5-e44b2bfe66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-208750a4-a57a-41c1-a105-cf1d3d5fe0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190756096-172.17.0.7-1598631095065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-b4dda744-a9d2-4058-bbf8-257978d299d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-7f535603-06be-4828-b462-0d08c4324972,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-7ab074e5-af91-4f6e-bd3d-3dd46f9677d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-b4fd0f4a-e189-4b4e-864e-a8452ff0bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-b310f8e4-7b4e-4241-a2d8-a1067de3e095,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-f42b804a-57ff-48d3-86fb-59b3cfc89a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-d3659199-94aa-47b7-bee5-e44b2bfe66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-208750a4-a57a-41c1-a105-cf1d3d5fe0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525417269-172.17.0.7-1598631235254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-2f76a627-cc2b-485e-8f7b-5eef3cdf2ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-045cfb16-94f6-4d97-89a7-c1e0d46918eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-1df8cb42-45ee-4f2f-945f-3bda90904868,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-1f36c2d5-0e43-48d0-a1d9-ca7bb4e3286c,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-c4837bde-27b0-47f4-b552-77207b3d6682,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-425a4ed1-3992-4dea-a020-2eb492f0cdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-d0b5d918-22b7-4e9e-9298-b05316b2d094,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-b26443c9-e348-4748-830c-afe31f99f2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525417269-172.17.0.7-1598631235254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-2f76a627-cc2b-485e-8f7b-5eef3cdf2ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-045cfb16-94f6-4d97-89a7-c1e0d46918eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-1df8cb42-45ee-4f2f-945f-3bda90904868,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-1f36c2d5-0e43-48d0-a1d9-ca7bb4e3286c,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-c4837bde-27b0-47f4-b552-77207b3d6682,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-425a4ed1-3992-4dea-a020-2eb492f0cdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-d0b5d918-22b7-4e9e-9298-b05316b2d094,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-b26443c9-e348-4748-830c-afe31f99f2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028964526-172.17.0.7-1598631343483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-a9ae71ed-aae6-409c-952b-b04fafbbcf68,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9fe0c4b2-77bc-4813-9468-954e6ee7a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-6431c60e-20a4-449f-ba6d-a5fbcf3de8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-62fd6df8-aaf1-41fb-a7a6-56f3df89b008,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-58cb1543-5c8d-43aa-8e48-5997095e995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f02aa751-72cc-4863-bafd-fb1b95354514,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-3e2ad069-1866-4be8-af90-7b6f972372c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-1ec57b4e-36c5-4c76-8e40-713a4c83dec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028964526-172.17.0.7-1598631343483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-a9ae71ed-aae6-409c-952b-b04fafbbcf68,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-9fe0c4b2-77bc-4813-9468-954e6ee7a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-6431c60e-20a4-449f-ba6d-a5fbcf3de8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-62fd6df8-aaf1-41fb-a7a6-56f3df89b008,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-58cb1543-5c8d-43aa-8e48-5997095e995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f02aa751-72cc-4863-bafd-fb1b95354514,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-3e2ad069-1866-4be8-af90-7b6f972372c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-1ec57b4e-36c5-4c76-8e40-713a4c83dec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990437542-172.17.0.7-1598631634883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-1e4a87f1-635e-485c-a4ab-155a1e42f48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a70b1424-8041-4b94-97df-9a267ada6382,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-6264421b-3c37-4b4f-a45e-02700324561d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-39b3e5a9-a9e2-495c-aca8-243c880fbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-4d6ec501-196e-43e5-82b4-8238ba256604,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-dace557b-2aa6-4948-923b-32f863702a17,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-d98e68d8-e215-463f-bf6d-c542a919a000,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1559054b-1594-4fda-a8f1-79b0c08eec70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990437542-172.17.0.7-1598631634883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40387,DS-1e4a87f1-635e-485c-a4ab-155a1e42f48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a70b1424-8041-4b94-97df-9a267ada6382,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-6264421b-3c37-4b4f-a45e-02700324561d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-39b3e5a9-a9e2-495c-aca8-243c880fbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-4d6ec501-196e-43e5-82b4-8238ba256604,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-dace557b-2aa6-4948-923b-32f863702a17,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-d98e68d8-e215-463f-bf6d-c542a919a000,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1559054b-1594-4fda-a8f1-79b0c08eec70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232911992-172.17.0.7-1598631710386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42125,DS-38152683-e5c0-4141-988c-c8d2d80c8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-e5846a61-2cec-4b0e-963c-51c3bb0ba440,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-049ebcf3-28a1-4e0b-a399-f7840f8369ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-fa363b91-9b69-4581-bfd3-c4642b50b416,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-4f57d7e6-c82c-465f-8104-6c65a2e48ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-4f7de912-3369-4552-af9b-ab40b29397a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-12173dca-5ae8-4005-bdab-847e3989d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-71d5b075-3c08-4a02-9b5c-11e0b6289e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232911992-172.17.0.7-1598631710386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42125,DS-38152683-e5c0-4141-988c-c8d2d80c8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-e5846a61-2cec-4b0e-963c-51c3bb0ba440,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-049ebcf3-28a1-4e0b-a399-f7840f8369ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-fa363b91-9b69-4581-bfd3-c4642b50b416,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-4f57d7e6-c82c-465f-8104-6c65a2e48ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-4f7de912-3369-4552-af9b-ab40b29397a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-12173dca-5ae8-4005-bdab-847e3989d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-71d5b075-3c08-4a02-9b5c-11e0b6289e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172249748-172.17.0.7-1598632005053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42875,DS-b913043d-5222-4fbc-80d3-47cbec8b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7be6ad22-ab14-444d-a2e3-a117df310e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-5ad1067d-7410-4aa1-a67b-1f5a95726a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-8aff90dd-7e74-4b2a-bbe9-a95465136193,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-a667d2df-b48d-4589-9287-65586e1647a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-8b41350f-c1b2-4d41-a5a6-562be2eb5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-eb20b39d-c78a-45e7-8353-5881a4a93c28,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-ed88cc8f-17d7-4ec5-8943-8355fdbe8ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172249748-172.17.0.7-1598632005053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42875,DS-b913043d-5222-4fbc-80d3-47cbec8b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7be6ad22-ab14-444d-a2e3-a117df310e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-5ad1067d-7410-4aa1-a67b-1f5a95726a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-8aff90dd-7e74-4b2a-bbe9-a95465136193,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-a667d2df-b48d-4589-9287-65586e1647a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-8b41350f-c1b2-4d41-a5a6-562be2eb5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-eb20b39d-c78a-45e7-8353-5881a4a93c28,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-ed88cc8f-17d7-4ec5-8943-8355fdbe8ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118729689-172.17.0.7-1598632046899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-b48e96f4-1b46-4e94-9ca1-97a78eb358ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ad288d64-3234-4ed0-8599-17f9b06846a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d7ccb6e8-1e46-45b1-9df4-d0f4cb043d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-5da063e0-73ce-459e-8097-535c95228d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-57702d28-b2e8-4352-b90b-a03077cd1281,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8523ba75-993b-4387-b9b2-95dd09a5b416,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-7f2fe196-0639-4223-b831-f6adedab81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-6fbca255-4e6e-4b55-8b67-c1fef2caa400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118729689-172.17.0.7-1598632046899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-b48e96f4-1b46-4e94-9ca1-97a78eb358ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-ad288d64-3234-4ed0-8599-17f9b06846a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-d7ccb6e8-1e46-45b1-9df4-d0f4cb043d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-5da063e0-73ce-459e-8097-535c95228d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-57702d28-b2e8-4352-b90b-a03077cd1281,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8523ba75-993b-4387-b9b2-95dd09a5b416,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-7f2fe196-0639-4223-b831-f6adedab81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-6fbca255-4e6e-4b55-8b67-c1fef2caa400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565094562-172.17.0.7-1598632077517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-37ba0567-5094-469b-a09d-d4cd16a7baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-85552b09-01ba-4466-8a83-b2c3fc29e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-60db5e2e-ed63-4fab-adbf-add518cf0453,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-60e633c4-1156-481e-b26d-681eb84f688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-7664749e-b01d-4382-b957-8474a474b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-5da8eed3-55a4-4f77-ad79-9ff8d7b8aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-39e65ecd-3733-42c4-896d-90cb0cb15788,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-48509d22-b1de-4af5-b7a9-85d3147cc35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565094562-172.17.0.7-1598632077517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-37ba0567-5094-469b-a09d-d4cd16a7baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-85552b09-01ba-4466-8a83-b2c3fc29e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-60db5e2e-ed63-4fab-adbf-add518cf0453,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-60e633c4-1156-481e-b26d-681eb84f688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-7664749e-b01d-4382-b957-8474a474b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-5da8eed3-55a4-4f77-ad79-9ff8d7b8aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-39e65ecd-3733-42c4-896d-90cb0cb15788,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-48509d22-b1de-4af5-b7a9-85d3147cc35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984437948-172.17.0.7-1598632416936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34941,DS-8373933e-6704-4a9a-bbbf-59e30579c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-b522c587-2dff-40df-b95a-6c3ae7b68bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-44bb96d1-d3da-4d51-a6f7-ac7fa89a575e,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-634b7d21-669a-47e5-83f2-fcfb6e251800,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d11ee995-933e-4713-9c97-f4083229b416,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-98774631-d175-4a99-9e96-281578f16d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-4642a6af-8143-4d26-8519-5d6efce5c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-14e03943-17b8-4c65-a0f0-9a9d1545cae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984437948-172.17.0.7-1598632416936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34941,DS-8373933e-6704-4a9a-bbbf-59e30579c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-b522c587-2dff-40df-b95a-6c3ae7b68bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-44bb96d1-d3da-4d51-a6f7-ac7fa89a575e,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-634b7d21-669a-47e5-83f2-fcfb6e251800,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d11ee995-933e-4713-9c97-f4083229b416,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-98774631-d175-4a99-9e96-281578f16d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-4642a6af-8143-4d26-8519-5d6efce5c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-14e03943-17b8-4c65-a0f0-9a9d1545cae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883215889-172.17.0.7-1598633070158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38904,DS-b6ad591b-d84d-4e2a-ba50-47a4f1f7d878,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-84105a44-0a56-4875-86d6-dd6a7fd23b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-cd9206c3-087b-43e7-be7f-24b207ad3461,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-a75b4463-1f82-4ba0-908c-f32d60289dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-0c7b2855-8995-4d2b-a784-ed421d278661,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-7248675e-651f-4037-b62d-32a3bd82909b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-45b551cd-c428-48d0-90e3-9a67c300842e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-83883835-dcff-4bc4-97f2-c7cf5abd522f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883215889-172.17.0.7-1598633070158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38904,DS-b6ad591b-d84d-4e2a-ba50-47a4f1f7d878,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-84105a44-0a56-4875-86d6-dd6a7fd23b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-cd9206c3-087b-43e7-be7f-24b207ad3461,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-a75b4463-1f82-4ba0-908c-f32d60289dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-0c7b2855-8995-4d2b-a784-ed421d278661,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-7248675e-651f-4037-b62d-32a3bd82909b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-45b551cd-c428-48d0-90e3-9a67c300842e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-83883835-dcff-4bc4-97f2-c7cf5abd522f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973130131-172.17.0.7-1598633747648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-c061a3a9-59dc-4c6e-bc5d-a3f1e8155bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-3144d33e-87c4-40c0-9b20-9af854b4df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-6288c504-c0c2-42c6-9e7f-582ac8e3b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-efa8a5d1-3ff4-4c34-91b1-0992e2b95141,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-548ec55b-6e2c-40fc-a807-99edf5c5aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-9c21a6ef-d495-4298-b70a-626347e745c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-0b5b1f6d-73df-4f5c-b465-6b33a0fc7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-db7c0664-9f5a-48e0-a7cb-902c89a5afaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973130131-172.17.0.7-1598633747648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-c061a3a9-59dc-4c6e-bc5d-a3f1e8155bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-3144d33e-87c4-40c0-9b20-9af854b4df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-6288c504-c0c2-42c6-9e7f-582ac8e3b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-efa8a5d1-3ff4-4c34-91b1-0992e2b95141,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-548ec55b-6e2c-40fc-a807-99edf5c5aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-9c21a6ef-d495-4298-b70a-626347e745c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-0b5b1f6d-73df-4f5c-b465-6b33a0fc7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-db7c0664-9f5a-48e0-a7cb-902c89a5afaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856689226-172.17.0.7-1598633845084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-61949b1f-3763-4593-bdcc-be009766ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-ff93d6eb-8517-400e-8985-503524277003,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-c1a0a4ad-1db5-40dd-aa92-9d768c314238,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-50342899-9b5a-4b9f-90a7-9efdb54dff82,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-40e3733e-6ff1-4470-ab31-5c53116d5b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-6f74b1b1-2737-4778-8696-f2d967d143d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-0be06975-dffa-4e8a-b35a-8d91d833703d,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-bc6855a5-b99b-4367-871e-efb6a35cf945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856689226-172.17.0.7-1598633845084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-61949b1f-3763-4593-bdcc-be009766ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-ff93d6eb-8517-400e-8985-503524277003,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-c1a0a4ad-1db5-40dd-aa92-9d768c314238,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-50342899-9b5a-4b9f-90a7-9efdb54dff82,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-40e3733e-6ff1-4470-ab31-5c53116d5b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-6f74b1b1-2737-4778-8696-f2d967d143d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-0be06975-dffa-4e8a-b35a-8d91d833703d,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-bc6855a5-b99b-4367-871e-efb6a35cf945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906487131-172.17.0.7-1598634014891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-52c9e943-e146-4a8f-8281-8bb87f77e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-c5466676-af3c-475f-bcd3-1f225338bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-d3c266f5-f987-4d7d-bd5f-e144dc31f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d638d4d9-c478-467f-b4a1-ad309181862e,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-8a7e43ba-dff6-4fa3-929b-23e4afa35266,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-a628afde-7ea5-4283-8bfa-e3e9a6677ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-36ec6bce-910d-43fd-bf3d-dbf6232c5b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-92ad62da-102e-46be-9a81-e754103abd35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906487131-172.17.0.7-1598634014891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-52c9e943-e146-4a8f-8281-8bb87f77e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-c5466676-af3c-475f-bcd3-1f225338bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-d3c266f5-f987-4d7d-bd5f-e144dc31f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d638d4d9-c478-467f-b4a1-ad309181862e,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-8a7e43ba-dff6-4fa3-929b-23e4afa35266,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-a628afde-7ea5-4283-8bfa-e3e9a6677ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-36ec6bce-910d-43fd-bf3d-dbf6232c5b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-92ad62da-102e-46be-9a81-e754103abd35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24702605-172.17.0.7-1598634150520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-b6041ceb-b6ae-4fc6-8265-e267f160b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fc2d38c3-d086-48e9-836e-32e534eb9e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-9b8c52c5-b523-4921-ac1f-51502d950fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-ed34901d-6e34-408b-a5b8-35bc7212b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-56398ffb-0baf-42bd-8264-a1479c74edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fdacf674-5ecb-4315-9596-51663e655621,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8682d7cf-1a4c-4884-999f-e5677040df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-dbad234d-88c5-4db3-9c25-a3fcfa71e066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24702605-172.17.0.7-1598634150520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-b6041ceb-b6ae-4fc6-8265-e267f160b81d,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fc2d38c3-d086-48e9-836e-32e534eb9e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-9b8c52c5-b523-4921-ac1f-51502d950fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-ed34901d-6e34-408b-a5b8-35bc7212b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-56398ffb-0baf-42bd-8264-a1479c74edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fdacf674-5ecb-4315-9596-51663e655621,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8682d7cf-1a4c-4884-999f-e5677040df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-dbad234d-88c5-4db3-9c25-a3fcfa71e066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536290466-172.17.0.7-1598634435420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-3f47d524-7f32-4ecc-9a5d-ffb5fdac148e,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8fec1a9c-8d25-407d-ac08-fad6bff8fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-a2590e1f-c4bc-4c5e-84b3-9690c08eb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-d535aae3-6d77-40ce-bd4f-bb2ec8481777,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-894346b3-7e89-42f6-9f7d-2acce029732a,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-9a0f1160-505f-4754-8562-6b2bc7e274c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-2068a12c-14b7-4a87-a889-304c12a1dadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-932eb0a0-607c-42f5-b6bc-87efd527e230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536290466-172.17.0.7-1598634435420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-3f47d524-7f32-4ecc-9a5d-ffb5fdac148e,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8fec1a9c-8d25-407d-ac08-fad6bff8fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-a2590e1f-c4bc-4c5e-84b3-9690c08eb52b,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-d535aae3-6d77-40ce-bd4f-bb2ec8481777,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-894346b3-7e89-42f6-9f7d-2acce029732a,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-9a0f1160-505f-4754-8562-6b2bc7e274c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-2068a12c-14b7-4a87-a889-304c12a1dadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-932eb0a0-607c-42f5-b6bc-87efd527e230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856842911-172.17.0.7-1598634588270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-f12838ac-e313-41db-97de-fa6187776f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a8a4a9a2-c467-484b-901f-021abf4afd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a12265f7-75d9-48e9-a0b5-70058254b0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-ed1b5698-2a70-4c12-bb0f-b392c0348f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-a3b6bdc9-cac5-400f-b5a4-61c1febe0624,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-60aed982-7c1e-4ec5-a6d8-a92afb80f202,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-51250271-8ca3-4fd6-a2f9-d565f579f608,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-e5c1c78f-8086-4532-b52c-79e06ea60e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856842911-172.17.0.7-1598634588270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-f12838ac-e313-41db-97de-fa6187776f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a8a4a9a2-c467-484b-901f-021abf4afd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a12265f7-75d9-48e9-a0b5-70058254b0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-ed1b5698-2a70-4c12-bb0f-b392c0348f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-a3b6bdc9-cac5-400f-b5a4-61c1febe0624,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-60aed982-7c1e-4ec5-a6d8-a92afb80f202,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-51250271-8ca3-4fd6-a2f9-d565f579f608,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-e5c1c78f-8086-4532-b52c-79e06ea60e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472335079-172.17.0.7-1598634700246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-86102094-b0fd-4b24-ab84-a661e2962250,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-5baaf36e-f7c4-415f-8a91-40332bb182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e8955380-c0a6-42eb-b589-ded0390363a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-e4c39a3d-8719-415a-9250-fc5980d88e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-834205c9-3e36-4a2a-b573-e079fe0fc13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-2cef9e0e-d3de-43ee-a62b-8ae379fc2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-47a3770f-1c65-407b-a3e7-9f6b2dff4e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-b4dd4cae-aeac-428f-8a43-1ec2b9016a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472335079-172.17.0.7-1598634700246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-86102094-b0fd-4b24-ab84-a661e2962250,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-5baaf36e-f7c4-415f-8a91-40332bb182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e8955380-c0a6-42eb-b589-ded0390363a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-e4c39a3d-8719-415a-9250-fc5980d88e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-834205c9-3e36-4a2a-b573-e079fe0fc13c,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-2cef9e0e-d3de-43ee-a62b-8ae379fc2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-47a3770f-1c65-407b-a3e7-9f6b2dff4e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-b4dd4cae-aeac-428f-8a43-1ec2b9016a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208682526-172.17.0.7-1598634809520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-155a70e0-dee7-4095-9c41-0a188e4df711,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-33995f7c-fd45-4f89-8651-d15315688430,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-6746a434-ac92-4032-bcf4-08be63377934,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-18a90d3b-0fa8-4ecb-bd97-78e18ccf67b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-2fd5dbb2-dc97-4f73-83f3-755c24746583,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-bc3f0070-dd6e-42e0-8d72-1d179638f558,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-f3810edf-c95a-4963-b890-90498238a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-4de5e183-0d59-44de-844e-758e480bb094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208682526-172.17.0.7-1598634809520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-155a70e0-dee7-4095-9c41-0a188e4df711,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-33995f7c-fd45-4f89-8651-d15315688430,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-6746a434-ac92-4032-bcf4-08be63377934,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-18a90d3b-0fa8-4ecb-bd97-78e18ccf67b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-2fd5dbb2-dc97-4f73-83f3-755c24746583,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-bc3f0070-dd6e-42e0-8d72-1d179638f558,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-f3810edf-c95a-4963-b890-90498238a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-4de5e183-0d59-44de-844e-758e480bb094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285599832-172.17.0.7-1598634919996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-15fa5ab6-d533-4f2a-992d-69f889c90d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-9690eda4-e79a-495a-9d20-08d5f3f00afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-112ab90b-ccd5-4e2c-bbac-e19a6be745dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-9a32eaff-3b62-4282-96b5-e63b27e163b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-5b21ad2b-45ac-43da-946f-691b54e2ed28,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-aaa32656-ac01-4ef1-a191-9a6db1646281,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-1e6d6b2e-de7c-4720-9684-7baae210d492,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-c1061d51-724b-4b8e-b27c-db9e79d06c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285599832-172.17.0.7-1598634919996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-15fa5ab6-d533-4f2a-992d-69f889c90d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-9690eda4-e79a-495a-9d20-08d5f3f00afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-112ab90b-ccd5-4e2c-bbac-e19a6be745dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-9a32eaff-3b62-4282-96b5-e63b27e163b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-5b21ad2b-45ac-43da-946f-691b54e2ed28,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-aaa32656-ac01-4ef1-a191-9a6db1646281,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-1e6d6b2e-de7c-4720-9684-7baae210d492,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-c1061d51-724b-4b8e-b27c-db9e79d06c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819058805-172.17.0.7-1598635036480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-ce6e67b3-a9b7-4ee3-a46b-d667ff1b8465,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-9a776cd6-db66-4301-80e0-826aa9351c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-aa7641b7-6370-4f53-be42-c3b445979527,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-10520487-e118-41a3-b3ac-fa61cb065518,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b0e78649-cf49-477f-abb6-6aa0b2e9229d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-fb33bd69-739e-45dd-b2c3-d7f3bdee889f,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-997abc49-9017-4b99-b325-c2da2d3aab20,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b2424275-42a7-4302-94ec-1d204981e7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819058805-172.17.0.7-1598635036480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-ce6e67b3-a9b7-4ee3-a46b-d667ff1b8465,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-9a776cd6-db66-4301-80e0-826aa9351c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-aa7641b7-6370-4f53-be42-c3b445979527,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-10520487-e118-41a3-b3ac-fa61cb065518,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b0e78649-cf49-477f-abb6-6aa0b2e9229d,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-fb33bd69-739e-45dd-b2c3-d7f3bdee889f,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-997abc49-9017-4b99-b325-c2da2d3aab20,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b2424275-42a7-4302-94ec-1d204981e7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269979890-172.17.0.7-1598635188475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35289,DS-2e3b4482-e1fd-4f8a-b347-5f54564e6122,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-dc4fd6a6-d31e-435a-bc73-51c052f1f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-433abb1a-4d31-47b8-b40b-595907b6ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-bd8ea34e-4a5e-4922-a4e1-61eb2512fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-11fa3785-f09e-4648-bffc-c193df9460d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-4606d334-07ec-4d2a-9a79-0cc589eb34e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-f98ede1f-5d24-49cc-b831-c38a380f690d,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-43d87db6-04e7-43f8-9433-816a045efeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269979890-172.17.0.7-1598635188475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35289,DS-2e3b4482-e1fd-4f8a-b347-5f54564e6122,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-dc4fd6a6-d31e-435a-bc73-51c052f1f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-433abb1a-4d31-47b8-b40b-595907b6ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-bd8ea34e-4a5e-4922-a4e1-61eb2512fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-11fa3785-f09e-4648-bffc-c193df9460d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-4606d334-07ec-4d2a-9a79-0cc589eb34e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-f98ede1f-5d24-49cc-b831-c38a380f690d,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-43d87db6-04e7-43f8-9433-816a045efeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249080938-172.17.0.7-1598635261361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-2715d1e0-cf1a-4b51-9de1-fa13e566c155,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-25209489-1bdd-4a5c-9eb4-093553c17096,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-f109f385-eaa9-4c43-b53c-8ec41e514436,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-0289a748-7f74-48ee-a179-2846d49e1679,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4b02006b-3843-4dbf-a77e-53375804e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-c6727913-0953-4699-b223-ffabc0f7647f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-aafa168b-3fd6-411b-808c-b7de08422668,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-3d2229ce-862b-45eb-b3f3-03d5413f531a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249080938-172.17.0.7-1598635261361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-2715d1e0-cf1a-4b51-9de1-fa13e566c155,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-25209489-1bdd-4a5c-9eb4-093553c17096,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-f109f385-eaa9-4c43-b53c-8ec41e514436,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-0289a748-7f74-48ee-a179-2846d49e1679,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4b02006b-3843-4dbf-a77e-53375804e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-c6727913-0953-4699-b223-ffabc0f7647f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-aafa168b-3fd6-411b-808c-b7de08422668,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-3d2229ce-862b-45eb-b3f3-03d5413f531a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597328307-172.17.0.7-1598635524314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41261,DS-a4b99dd3-5444-4e29-9867-c4b52b55a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-e012bffc-9e52-4b19-af43-22d7a62b6bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-163ea483-1be7-43c3-96d6-3d4e90ceaa62,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-3d08af0c-ba55-4af0-a57f-035496870f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-888ec471-fb29-4a0d-a237-2374a1b3c973,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-00e2d679-fe82-4fcf-925b-254c0eb82164,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-90604fa3-7994-49a5-8f1d-f06aea399a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-27d6e0e8-907b-47dd-83f7-fb1ba3e195ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597328307-172.17.0.7-1598635524314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41261,DS-a4b99dd3-5444-4e29-9867-c4b52b55a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-e012bffc-9e52-4b19-af43-22d7a62b6bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-163ea483-1be7-43c3-96d6-3d4e90ceaa62,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-3d08af0c-ba55-4af0-a57f-035496870f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-888ec471-fb29-4a0d-a237-2374a1b3c973,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-00e2d679-fe82-4fcf-925b-254c0eb82164,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-90604fa3-7994-49a5-8f1d-f06aea399a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-27d6e0e8-907b-47dd-83f7-fb1ba3e195ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5384
