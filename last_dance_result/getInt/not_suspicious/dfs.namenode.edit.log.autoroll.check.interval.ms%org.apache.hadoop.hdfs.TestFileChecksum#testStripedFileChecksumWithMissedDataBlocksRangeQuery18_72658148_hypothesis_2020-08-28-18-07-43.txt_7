reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106035039-172.17.0.17-1598638839628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-1c2f2617-5be3-4b24-b561-820dcdff9cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-15aa3798-fb5b-4572-ae05-4625ac5fe2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-04af577f-8fcc-4356-b965-513e4c685963,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-5bedfc4a-6fae-492a-ad58-ed9a6fcd34fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-851ec0af-3975-43da-bf4b-6376475d3811,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-5d2f806c-b5fc-439b-bea9-f16600dcdd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-2c5f661c-d40a-4b10-93e7-9329c592d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-0c0249ef-9463-4c2c-ba69-dd3a870c49c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106035039-172.17.0.17-1598638839628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-1c2f2617-5be3-4b24-b561-820dcdff9cde,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-15aa3798-fb5b-4572-ae05-4625ac5fe2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-04af577f-8fcc-4356-b965-513e4c685963,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-5bedfc4a-6fae-492a-ad58-ed9a6fcd34fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-851ec0af-3975-43da-bf4b-6376475d3811,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-5d2f806c-b5fc-439b-bea9-f16600dcdd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-2c5f661c-d40a-4b10-93e7-9329c592d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-0c0249ef-9463-4c2c-ba69-dd3a870c49c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287220956-172.17.0.17-1598639489384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36991,DS-bf623383-1a65-4f29-9287-1b6e86ecb425,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-a31830dd-42bc-483d-b8bb-085e47751291,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-762d723f-634a-4be5-8e0e-bba145d91f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-bc90cda9-434f-414f-963a-e092a173694e,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-15d30741-c0dd-4c8d-915f-61fb6f8e0026,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-9ba48654-2cff-48f2-af0d-fad93ee65d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-3d84b403-2a0a-45ee-b62a-c8c120710933,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d85faf6c-f49c-4da4-bcb9-043c8c26e8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287220956-172.17.0.17-1598639489384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36991,DS-bf623383-1a65-4f29-9287-1b6e86ecb425,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-a31830dd-42bc-483d-b8bb-085e47751291,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-762d723f-634a-4be5-8e0e-bba145d91f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-bc90cda9-434f-414f-963a-e092a173694e,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-15d30741-c0dd-4c8d-915f-61fb6f8e0026,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-9ba48654-2cff-48f2-af0d-fad93ee65d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-3d84b403-2a0a-45ee-b62a-c8c120710933,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d85faf6c-f49c-4da4-bcb9-043c8c26e8ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074418569-172.17.0.17-1598639579902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-a8e8781b-b99f-4b83-b37b-d0d78cb3e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-34a984c1-6d32-4b27-b102-1f81f11273ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-0a2035ad-273a-48cc-a50f-826b6b24a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-75909998-9772-4093-bec9-60dafe042de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-1dc42894-a2b1-467e-b762-c860af0bc812,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-3d77806a-ddcf-4af4-a14c-3ef0c8f8f8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-11403e77-23eb-4ed0-9722-35a3c5d3410e,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-8e51e4ec-ac28-4f7b-aaba-f61983f7e660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074418569-172.17.0.17-1598639579902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-a8e8781b-b99f-4b83-b37b-d0d78cb3e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-34a984c1-6d32-4b27-b102-1f81f11273ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-0a2035ad-273a-48cc-a50f-826b6b24a04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-75909998-9772-4093-bec9-60dafe042de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-1dc42894-a2b1-467e-b762-c860af0bc812,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-3d77806a-ddcf-4af4-a14c-3ef0c8f8f8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-11403e77-23eb-4ed0-9722-35a3c5d3410e,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-8e51e4ec-ac28-4f7b-aaba-f61983f7e660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529783662-172.17.0.17-1598639829387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42277,DS-42bbf546-ec67-40c0-b13a-a2910eab0709,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-ef9c0152-61a5-4db5-aad6-0144c158521c,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fa58b356-2adf-4154-b565-4d778b540efc,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-a3bbf122-d789-46d1-adc8-46e6bf093c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-13f570a2-32cf-4e47-a315-c15b779f9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-76ce6b79-588b-48f5-a1d3-2395e3570987,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-8f884abf-7134-41f1-8ebc-7937d57bb4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-ea1e3037-4051-4f3d-b51c-172add3bc251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529783662-172.17.0.17-1598639829387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42277,DS-42bbf546-ec67-40c0-b13a-a2910eab0709,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-ef9c0152-61a5-4db5-aad6-0144c158521c,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fa58b356-2adf-4154-b565-4d778b540efc,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-a3bbf122-d789-46d1-adc8-46e6bf093c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-13f570a2-32cf-4e47-a315-c15b779f9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-76ce6b79-588b-48f5-a1d3-2395e3570987,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-8f884abf-7134-41f1-8ebc-7937d57bb4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-ea1e3037-4051-4f3d-b51c-172add3bc251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389679546-172.17.0.17-1598639934484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-fb15d38b-2b82-44ef-8920-69581bea326f,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-877b614c-4e61-4886-8fdd-9f342cb14c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-cde1c94d-a41d-4064-8711-526dfb86a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-6d21ef22-de89-473a-9329-a56cfb0717a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-2d53e909-b3f6-425b-a97f-91d409db733c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-1a1a82fc-bc34-44d8-b102-47bbabf0f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-d059b5b2-95d0-41f7-b513-a533475f8231,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-76f89b15-6753-4386-9508-96155dc54b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389679546-172.17.0.17-1598639934484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-fb15d38b-2b82-44ef-8920-69581bea326f,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-877b614c-4e61-4886-8fdd-9f342cb14c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-cde1c94d-a41d-4064-8711-526dfb86a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-6d21ef22-de89-473a-9329-a56cfb0717a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-2d53e909-b3f6-425b-a97f-91d409db733c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-1a1a82fc-bc34-44d8-b102-47bbabf0f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-d059b5b2-95d0-41f7-b513-a533475f8231,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-76f89b15-6753-4386-9508-96155dc54b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642218725-172.17.0.17-1598641189971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42884,DS-d0423d0c-0a9b-4e0c-8480-4240bd8f79eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9e4bfeea-f95d-4148-8196-3cb506808921,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-da59dc36-e562-40d0-94d9-65589acee708,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-04508eee-2e40-465d-9616-760813ec106d,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-d3a2538d-557f-4ee1-89ef-f412a64b5df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5fe74510-f72c-489a-b5e9-7173cddd9f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-cf71e9a1-2c7e-47a4-9fd7-9d4e12619550,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-55bcc79c-e1c8-437a-af8b-1152666b9da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642218725-172.17.0.17-1598641189971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42884,DS-d0423d0c-0a9b-4e0c-8480-4240bd8f79eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9e4bfeea-f95d-4148-8196-3cb506808921,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-da59dc36-e562-40d0-94d9-65589acee708,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-04508eee-2e40-465d-9616-760813ec106d,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-d3a2538d-557f-4ee1-89ef-f412a64b5df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-5fe74510-f72c-489a-b5e9-7173cddd9f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-cf71e9a1-2c7e-47a4-9fd7-9d4e12619550,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-55bcc79c-e1c8-437a-af8b-1152666b9da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068899830-172.17.0.17-1598641537855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44322,DS-0178748f-4581-422d-a553-eca14e7771c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-44d7eea5-91f3-4382-a470-e0faffdcaa99,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-0b9b2c8d-f274-472a-9403-34e43f61a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-08e5dc4b-3147-49b8-be47-1b021649fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-90a6c734-b995-4aa1-a767-9b119eec6781,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d01e872a-35fb-44bc-92f4-b97e24e832b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-76109150-a5eb-4ddd-a099-705ce41278ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-dc35e596-d448-4084-bf91-12d0e91414f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068899830-172.17.0.17-1598641537855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44322,DS-0178748f-4581-422d-a553-eca14e7771c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-44d7eea5-91f3-4382-a470-e0faffdcaa99,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-0b9b2c8d-f274-472a-9403-34e43f61a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-08e5dc4b-3147-49b8-be47-1b021649fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-90a6c734-b995-4aa1-a767-9b119eec6781,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d01e872a-35fb-44bc-92f4-b97e24e832b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-76109150-a5eb-4ddd-a099-705ce41278ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-dc35e596-d448-4084-bf91-12d0e91414f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475593814-172.17.0.17-1598641712474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-f76fd8cc-76d8-42c6-b435-13a0bb7a41e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-22e64910-876a-4d1d-83d4-7d3311d02a20,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-ee431ed2-3689-416b-b07c-af5f9a48a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-3b75122a-d9b4-4e6c-9f39-30b6b5575ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-3be5b34f-5dc2-42d1-97b6-2276ee95acc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-91e5245f-4cb3-4b45-9069-e833450cc7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e39265dc-b299-46d5-88aa-bdf3edccadc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-4f32d88d-8f56-4798-8195-5ffae761dcd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475593814-172.17.0.17-1598641712474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-f76fd8cc-76d8-42c6-b435-13a0bb7a41e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-22e64910-876a-4d1d-83d4-7d3311d02a20,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-ee431ed2-3689-416b-b07c-af5f9a48a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-3b75122a-d9b4-4e6c-9f39-30b6b5575ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-3be5b34f-5dc2-42d1-97b6-2276ee95acc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-91e5245f-4cb3-4b45-9069-e833450cc7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e39265dc-b299-46d5-88aa-bdf3edccadc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-4f32d88d-8f56-4798-8195-5ffae761dcd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128419138-172.17.0.17-1598641896058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-0b65eeea-70bd-47bb-beef-f3e1103d1808,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-155acb0a-55d2-4a2f-8c98-3c6f02716fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-470c87d9-b13a-43de-9356-49aff7132597,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-4a51521d-5443-4014-8ec8-7f6ed83e2d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-85f7376c-8c40-40c3-b976-b3f72d35e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-036d8fc9-f51d-44da-a8a3-55701d8c9df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-30a166fe-49ef-45b6-8ce0-aa7f678751e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-4a53c4da-c798-4c6a-b8bc-b4bafb8bcde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128419138-172.17.0.17-1598641896058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-0b65eeea-70bd-47bb-beef-f3e1103d1808,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-155acb0a-55d2-4a2f-8c98-3c6f02716fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-470c87d9-b13a-43de-9356-49aff7132597,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-4a51521d-5443-4014-8ec8-7f6ed83e2d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-85f7376c-8c40-40c3-b976-b3f72d35e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-036d8fc9-f51d-44da-a8a3-55701d8c9df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-30a166fe-49ef-45b6-8ce0-aa7f678751e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-4a53c4da-c798-4c6a-b8bc-b4bafb8bcde6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680767319-172.17.0.17-1598642222484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a78f5f49-abb7-4bcc-930e-96d19e6b7d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-a0d76b95-9542-498c-a70f-2a79f7d37c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-bca78b0f-c22d-47a8-acd4-a3bd4964c889,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-e1a22c83-c042-4f9b-a608-74649946a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-e1dd8aa7-dd04-412a-beac-157a237eab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-78afc11c-3de3-4da9-a455-38209687297b,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5618a36a-859c-4616-93b9-84bb2147c612,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-365720a4-537e-47e8-9fac-2b76f1972722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680767319-172.17.0.17-1598642222484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41274,DS-a78f5f49-abb7-4bcc-930e-96d19e6b7d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-a0d76b95-9542-498c-a70f-2a79f7d37c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-bca78b0f-c22d-47a8-acd4-a3bd4964c889,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-e1a22c83-c042-4f9b-a608-74649946a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-e1dd8aa7-dd04-412a-beac-157a237eab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-78afc11c-3de3-4da9-a455-38209687297b,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-5618a36a-859c-4616-93b9-84bb2147c612,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-365720a4-537e-47e8-9fac-2b76f1972722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864813016-172.17.0.17-1598642290797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-b76dadf1-3f15-4fe9-92e5-dea30aae61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-86df7894-1f3a-4791-bd20-2b78e52c527a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-49e19040-d212-4d0f-b657-1e769c1f6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-3de40fd9-9b93-4fef-a697-4c4918d9f635,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-14db3a72-2336-47d6-afb2-fca50db84454,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-a172a14b-9583-4144-ba30-a2417f38d1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-e9b71be9-c983-465d-834e-6ddfa8285a95,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-66136a1e-4bf4-4ce9-9711-332b2eceadba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864813016-172.17.0.17-1598642290797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-b76dadf1-3f15-4fe9-92e5-dea30aae61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-86df7894-1f3a-4791-bd20-2b78e52c527a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-49e19040-d212-4d0f-b657-1e769c1f6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-3de40fd9-9b93-4fef-a697-4c4918d9f635,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-14db3a72-2336-47d6-afb2-fca50db84454,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-a172a14b-9583-4144-ba30-a2417f38d1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-e9b71be9-c983-465d-834e-6ddfa8285a95,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-66136a1e-4bf4-4ce9-9711-332b2eceadba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877948858-172.17.0.17-1598642417381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-822b66e2-deb1-411d-a417-f6f2a779d3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-8e83fbca-6ba1-4ff8-ab73-f06379e723b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-247d92e9-4011-4a70-a535-4d43ef4294a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-35c51dc6-30a6-49d5-a401-c7fbe44f523d,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6fb17ff2-5952-41df-85ca-172788edafd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-f2992d74-88fe-4eff-ab3b-ff9ba574c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-14203f6d-dd85-4d22-99be-10b406758f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-6a77877d-90c2-4d8a-9fb1-7d26dfa55bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877948858-172.17.0.17-1598642417381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-822b66e2-deb1-411d-a417-f6f2a779d3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-8e83fbca-6ba1-4ff8-ab73-f06379e723b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-247d92e9-4011-4a70-a535-4d43ef4294a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-35c51dc6-30a6-49d5-a401-c7fbe44f523d,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6fb17ff2-5952-41df-85ca-172788edafd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-f2992d74-88fe-4eff-ab3b-ff9ba574c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-14203f6d-dd85-4d22-99be-10b406758f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-6a77877d-90c2-4d8a-9fb1-7d26dfa55bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719569155-172.17.0.17-1598642784737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-a34df804-1dc2-4b7e-ae54-e82940007b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-04f67a0e-a3e2-4f87-8ba7-f2bccc0d8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1f7d1020-ffc3-42fe-bb74-ed642aa3a0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-897c962d-0ebd-4462-963f-bc500d4c5497,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-082ce78a-a874-440a-b066-9c130b12498d,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-fdaeee01-6cc9-4fd3-a4f0-1892fdf4cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-13a1788b-8c50-447b-8567-7a3967700e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-b2f12f5f-1f1a-4a48-b4a3-8a9f76ddbbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719569155-172.17.0.17-1598642784737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-a34df804-1dc2-4b7e-ae54-e82940007b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-04f67a0e-a3e2-4f87-8ba7-f2bccc0d8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1f7d1020-ffc3-42fe-bb74-ed642aa3a0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-897c962d-0ebd-4462-963f-bc500d4c5497,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-082ce78a-a874-440a-b066-9c130b12498d,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-fdaeee01-6cc9-4fd3-a4f0-1892fdf4cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-13a1788b-8c50-447b-8567-7a3967700e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-b2f12f5f-1f1a-4a48-b4a3-8a9f76ddbbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4863
