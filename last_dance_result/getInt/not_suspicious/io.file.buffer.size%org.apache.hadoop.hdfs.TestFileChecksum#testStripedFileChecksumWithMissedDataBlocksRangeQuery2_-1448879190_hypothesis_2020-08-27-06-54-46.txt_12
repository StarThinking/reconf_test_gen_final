reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846692055-172.17.0.14-1598511302049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38734,DS-92ebd82d-2821-4d86-ba2a-6b672f445759,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-8ea51df3-e5cd-4774-ace3-a0e02a9f09d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-4ddd45b6-88d1-4fbc-bef3-410901994632,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-e45499b5-0902-42be-9948-025019420cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-940b7cfe-82be-4a13-aa4b-fc325ba9f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-5ce04282-c9e1-4b29-879b-3ee99f74ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-9e9f71d3-be53-48ab-8f68-dd06a513c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-bba53856-e4d1-4fd4-a2b6-a8f65ca60cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846692055-172.17.0.14-1598511302049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38734,DS-92ebd82d-2821-4d86-ba2a-6b672f445759,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-8ea51df3-e5cd-4774-ace3-a0e02a9f09d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-4ddd45b6-88d1-4fbc-bef3-410901994632,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-e45499b5-0902-42be-9948-025019420cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-940b7cfe-82be-4a13-aa4b-fc325ba9f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-5ce04282-c9e1-4b29-879b-3ee99f74ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-9e9f71d3-be53-48ab-8f68-dd06a513c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-bba53856-e4d1-4fd4-a2b6-a8f65ca60cbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990978950-172.17.0.14-1598511398060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-c15e2810-d62f-467f-874c-57e8f9822a44,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-a0ce6ef8-39d8-4a1d-b907-516581835b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-afee7887-62a3-44f5-896e-78665fc5d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-5a7010e1-daa0-4917-902e-5f555c42cf74,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-70a32f19-f968-45d4-89c9-5cd053fd02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-77d49bfe-7b7c-43d2-b932-de4d951aed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-a7d36a71-fd86-49a1-9e63-2c454d63545b,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-eb6970cc-f0ad-49fd-9fda-a525d5487e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990978950-172.17.0.14-1598511398060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-c15e2810-d62f-467f-874c-57e8f9822a44,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-a0ce6ef8-39d8-4a1d-b907-516581835b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-afee7887-62a3-44f5-896e-78665fc5d9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-5a7010e1-daa0-4917-902e-5f555c42cf74,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-70a32f19-f968-45d4-89c9-5cd053fd02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-77d49bfe-7b7c-43d2-b932-de4d951aed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-a7d36a71-fd86-49a1-9e63-2c454d63545b,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-eb6970cc-f0ad-49fd-9fda-a525d5487e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865716756-172.17.0.14-1598511853147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-9db7253b-984c-4cee-99c8-9d615bd25e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2ab3d892-1ef1-4cd4-bd72-a6731c3f971f,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-55a6f1e5-48ea-4c9d-a3fb-24fa7963384a,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-6fd5dfce-28bc-4262-98e1-fece2047e0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-4a745ca9-6b1a-49c2-ae12-bf0f08321b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-0c546d21-6733-40d4-bb3a-f7909ef670a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-ff0034ef-491d-4f34-bda4-2bf24ea904d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-1e5efe5c-9c04-426c-b37d-c7dd20c66f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865716756-172.17.0.14-1598511853147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-9db7253b-984c-4cee-99c8-9d615bd25e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2ab3d892-1ef1-4cd4-bd72-a6731c3f971f,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-55a6f1e5-48ea-4c9d-a3fb-24fa7963384a,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-6fd5dfce-28bc-4262-98e1-fece2047e0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-4a745ca9-6b1a-49c2-ae12-bf0f08321b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-0c546d21-6733-40d4-bb3a-f7909ef670a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-ff0034ef-491d-4f34-bda4-2bf24ea904d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-1e5efe5c-9c04-426c-b37d-c7dd20c66f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303478068-172.17.0.14-1598513477241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-5acde884-a759-4283-ba97-50bcda9f3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-c61ce3f3-bb12-43bd-b1dd-1f9e5cadef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-6953ef90-5d0b-4bfe-ab5a-6d8fdffca4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-0199786f-0366-4905-90bd-aee0cf842589,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-ec6cb50d-22f4-423e-a9bc-89a35bba4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-ad48a8a3-b6d7-4ab9-a864-b3b31de74548,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-96296c26-8c85-4a18-92c9-c512d8fd3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-565e0847-c48f-4bc5-9fa8-f39897ecad13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303478068-172.17.0.14-1598513477241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-5acde884-a759-4283-ba97-50bcda9f3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-c61ce3f3-bb12-43bd-b1dd-1f9e5cadef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-6953ef90-5d0b-4bfe-ab5a-6d8fdffca4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-0199786f-0366-4905-90bd-aee0cf842589,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-ec6cb50d-22f4-423e-a9bc-89a35bba4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-ad48a8a3-b6d7-4ab9-a864-b3b31de74548,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-96296c26-8c85-4a18-92c9-c512d8fd3c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-565e0847-c48f-4bc5-9fa8-f39897ecad13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636417655-172.17.0.14-1598513542674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-6088c17b-c257-474a-861f-e95e737c625e,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-9fb0e2db-f007-42f0-b307-fbeabaf6614c,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-61915fa6-dba7-474b-8404-7b8a37abd857,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-999696e3-5472-4598-a108-72f3d7a3ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-19f2c7cc-36b3-4184-8fd9-6622ed423860,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-70b48ae4-3a0c-4a59-be8e-7f59b7cb4805,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-f2a769bc-8ae8-4949-bde1-2dbf7d855c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-45763361-5f6a-44cb-a98f-66e27e5e1649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636417655-172.17.0.14-1598513542674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-6088c17b-c257-474a-861f-e95e737c625e,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-9fb0e2db-f007-42f0-b307-fbeabaf6614c,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-61915fa6-dba7-474b-8404-7b8a37abd857,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-999696e3-5472-4598-a108-72f3d7a3ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-19f2c7cc-36b3-4184-8fd9-6622ed423860,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-70b48ae4-3a0c-4a59-be8e-7f59b7cb4805,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-f2a769bc-8ae8-4949-bde1-2dbf7d855c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-45763361-5f6a-44cb-a98f-66e27e5e1649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867833046-172.17.0.14-1598513779436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-2160c1d1-5a44-439e-bb00-e7db05c24e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-9527bf66-cfd0-4b9d-a617-2a184a9be30f,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-1902f5b1-1dd8-4942-8127-091b56fa93d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d3eaae36-6e96-466e-a2c3-4acf15039f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-debfbcea-0994-4e78-bfcd-9c0b9c53b547,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c04c2ef9-11af-4b35-8777-d1c8de90eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-caf830cf-35b5-407c-9b4b-c39b9211635b,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-676607a9-1803-4fe7-a869-00a75fb6a2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867833046-172.17.0.14-1598513779436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-2160c1d1-5a44-439e-bb00-e7db05c24e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-9527bf66-cfd0-4b9d-a617-2a184a9be30f,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-1902f5b1-1dd8-4942-8127-091b56fa93d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d3eaae36-6e96-466e-a2c3-4acf15039f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-debfbcea-0994-4e78-bfcd-9c0b9c53b547,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c04c2ef9-11af-4b35-8777-d1c8de90eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-caf830cf-35b5-407c-9b4b-c39b9211635b,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-676607a9-1803-4fe7-a869-00a75fb6a2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744810364-172.17.0.14-1598515401451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-c45b0c63-3ef1-4032-954f-537f31c0232f,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8157413b-55ef-42c3-abf6-47f9f0a39ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-dbe92c09-97fb-4a6f-8c93-bff6a33437b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-7a2a303c-0221-49b7-ab84-ea9ef540e413,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-6cac26fb-6547-4fd2-9025-59ad077e30a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-fadb70b1-5df4-41fc-8453-13654a69e05d,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-647255f5-3af9-44c7-b194-1d41edbf052a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-c7242c90-96ae-4b48-bfd3-ee5cc995d63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744810364-172.17.0.14-1598515401451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-c45b0c63-3ef1-4032-954f-537f31c0232f,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8157413b-55ef-42c3-abf6-47f9f0a39ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-dbe92c09-97fb-4a6f-8c93-bff6a33437b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-7a2a303c-0221-49b7-ab84-ea9ef540e413,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-6cac26fb-6547-4fd2-9025-59ad077e30a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-fadb70b1-5df4-41fc-8453-13654a69e05d,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-647255f5-3af9-44c7-b194-1d41edbf052a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-c7242c90-96ae-4b48-bfd3-ee5cc995d63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256554934-172.17.0.14-1598515601147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-e361054f-eefe-43a4-ada8-d15c6f828ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-dd70f8f7-35a5-4553-a9c2-54c723e61384,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-ba5554a3-893f-4bb3-b1d2-b2319d1862cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-7a91e48f-b9d6-4249-a13c-93e75ce26113,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-a372f122-e91a-4503-a857-97ad8b2f5030,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-3bcd8839-c089-4563-ba27-08c2be993faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-20a0e610-e353-4d31-b8a8-39cbda9a175c,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-739cb6e3-d691-4c32-9dec-546ac6f0a243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256554934-172.17.0.14-1598515601147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-e361054f-eefe-43a4-ada8-d15c6f828ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-dd70f8f7-35a5-4553-a9c2-54c723e61384,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-ba5554a3-893f-4bb3-b1d2-b2319d1862cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-7a91e48f-b9d6-4249-a13c-93e75ce26113,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-a372f122-e91a-4503-a857-97ad8b2f5030,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-3bcd8839-c089-4563-ba27-08c2be993faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-20a0e610-e353-4d31-b8a8-39cbda9a175c,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-739cb6e3-d691-4c32-9dec-546ac6f0a243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184281027-172.17.0.14-1598516071043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-eef9511f-ca67-4026-b9dd-b19a97b27270,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-40c325b2-2299-4452-8635-7fc4e6ac9d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-d7cb9f10-91fb-4400-b123-7fc5f3a493f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-bb2f0f4b-4cdb-41bc-b9fc-8dd4803bee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-9e29539d-3f99-4c70-ab60-f270a992bd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-c8391b3b-2f86-4402-ad29-477d92e87a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-aaac1cd4-50cd-41ff-aea2-bffa56a4a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-5e0c0d9e-4fb5-475f-91ba-4024b9909cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184281027-172.17.0.14-1598516071043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-eef9511f-ca67-4026-b9dd-b19a97b27270,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-40c325b2-2299-4452-8635-7fc4e6ac9d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-d7cb9f10-91fb-4400-b123-7fc5f3a493f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-bb2f0f4b-4cdb-41bc-b9fc-8dd4803bee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-9e29539d-3f99-4c70-ab60-f270a992bd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-c8391b3b-2f86-4402-ad29-477d92e87a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-aaac1cd4-50cd-41ff-aea2-bffa56a4a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-5e0c0d9e-4fb5-475f-91ba-4024b9909cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705784017-172.17.0.14-1598516494022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-6ac6c060-59ef-47a7-bd82-216803d847e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-8afd3e15-5bbc-46b3-9d81-493eb6521ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-382fb14c-802f-4bef-91a0-8d449cd889ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-564d60e8-5780-4d72-b165-144e1c9c3dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-08cf5aec-51cc-4410-9122-267419ccac17,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-e6f5518e-3b6a-456d-a3b4-b3bfb048894e,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3105153f-0d48-4e00-b16f-2f8dab4965a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-6cef5ec6-e517-42d4-a883-b2b945841bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705784017-172.17.0.14-1598516494022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-6ac6c060-59ef-47a7-bd82-216803d847e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-8afd3e15-5bbc-46b3-9d81-493eb6521ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-382fb14c-802f-4bef-91a0-8d449cd889ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-564d60e8-5780-4d72-b165-144e1c9c3dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-08cf5aec-51cc-4410-9122-267419ccac17,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-e6f5518e-3b6a-456d-a3b4-b3bfb048894e,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3105153f-0d48-4e00-b16f-2f8dab4965a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-6cef5ec6-e517-42d4-a883-b2b945841bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5602
