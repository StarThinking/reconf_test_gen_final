reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944848619-172.17.0.18-1598552705755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32962,DS-88778d15-9363-4256-892e-1224cd54563d,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-8205b711-6e4f-4b31-bfe2-03e9e3bf8b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-2b0c8d88-041d-4309-b8df-cd8c8f8b791f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-77eb5a0b-4191-468b-b998-acca046e11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7636ae7e-9096-4e9c-97bd-7e3c1cce8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-40ca97d6-5532-469e-9ae5-e82cc3979603,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-1448dbd1-5bac-4081-85db-9deeed43418d,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-e8782d1a-f123-4444-b16b-9ff6bacee609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944848619-172.17.0.18-1598552705755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32962,DS-88778d15-9363-4256-892e-1224cd54563d,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-8205b711-6e4f-4b31-bfe2-03e9e3bf8b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-2b0c8d88-041d-4309-b8df-cd8c8f8b791f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-77eb5a0b-4191-468b-b998-acca046e11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-7636ae7e-9096-4e9c-97bd-7e3c1cce8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-40ca97d6-5532-469e-9ae5-e82cc3979603,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-1448dbd1-5bac-4081-85db-9deeed43418d,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-e8782d1a-f123-4444-b16b-9ff6bacee609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349897526-172.17.0.18-1598552774604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-a2bec384-f853-45bc-9313-8b44a78db768,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f73c2f2e-f4be-4d7f-8e83-24bdab4fe2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-0bbe952b-4a2e-47de-841d-418207c0d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-91e260ee-5a93-4c41-bb3e-f7b0740ca8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-679016d3-af41-4261-aeab-f8e1738ec1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-cd1d48ac-7f3a-4e95-babc-4ae3426a0847,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-83e440fb-9db0-46a3-b44a-fd4820e18611,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-ae8e6673-5a2b-49c9-81f5-24efd3155910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349897526-172.17.0.18-1598552774604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-a2bec384-f853-45bc-9313-8b44a78db768,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f73c2f2e-f4be-4d7f-8e83-24bdab4fe2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-0bbe952b-4a2e-47de-841d-418207c0d6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-91e260ee-5a93-4c41-bb3e-f7b0740ca8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-679016d3-af41-4261-aeab-f8e1738ec1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-cd1d48ac-7f3a-4e95-babc-4ae3426a0847,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-83e440fb-9db0-46a3-b44a-fd4820e18611,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-ae8e6673-5a2b-49c9-81f5-24efd3155910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28184004-172.17.0.18-1598553465833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34844,DS-6b4e8709-1110-4616-b0bd-36e4b4cb5752,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-f9aa8b89-4ca0-4c2f-91f4-8441c11425ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-ace8dc09-3e79-4711-9701-ab0436a368be,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-27f55925-8cce-4faf-b155-e7051cc83575,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-623f7fe4-5e3b-4f8a-8992-e260ba64bd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-224d3349-1093-499b-be94-cfd43f003fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-4dc2b9f8-9639-46a0-b05a-1425a0f37a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-c77687ff-7644-42d8-bbdd-feaf1d4b9c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28184004-172.17.0.18-1598553465833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34844,DS-6b4e8709-1110-4616-b0bd-36e4b4cb5752,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-f9aa8b89-4ca0-4c2f-91f4-8441c11425ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-ace8dc09-3e79-4711-9701-ab0436a368be,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-27f55925-8cce-4faf-b155-e7051cc83575,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-623f7fe4-5e3b-4f8a-8992-e260ba64bd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-224d3349-1093-499b-be94-cfd43f003fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-4dc2b9f8-9639-46a0-b05a-1425a0f37a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-c77687ff-7644-42d8-bbdd-feaf1d4b9c70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643421768-172.17.0.18-1598553600089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-08510f6f-2be2-478b-bbd9-9f0d8d77cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-71f6a0ef-0651-46da-8ce1-419d8a1dfc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a02a8e72-eeaf-4bef-a002-22ca1c00c7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-08dcd079-3d6a-43e2-bde0-ab0372260741,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-90f48518-8393-4c7e-9051-4f17413992ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-91c22042-d977-4d48-9af1-9e11b2beaf55,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-2c09cf83-e3d7-4ef7-bcd3-05f2bc494b69,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2d9a9998-aa71-4ea2-9928-630f9a71c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643421768-172.17.0.18-1598553600089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-08510f6f-2be2-478b-bbd9-9f0d8d77cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-71f6a0ef-0651-46da-8ce1-419d8a1dfc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a02a8e72-eeaf-4bef-a002-22ca1c00c7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-08dcd079-3d6a-43e2-bde0-ab0372260741,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-90f48518-8393-4c7e-9051-4f17413992ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-91c22042-d977-4d48-9af1-9e11b2beaf55,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-2c09cf83-e3d7-4ef7-bcd3-05f2bc494b69,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2d9a9998-aa71-4ea2-9928-630f9a71c1a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936164116-172.17.0.18-1598553759673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39191,DS-bfd4cbd2-607c-40c3-890a-cbf5ee902847,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-5d7fe72f-3d05-431a-9790-8638c3e0c714,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-1ed04e08-f087-4c5c-bda1-be45995cee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-3f60a69e-72f5-4ae0-b4af-737683d31f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-6b1a4133-c8e4-479a-b07d-000cecb4042f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-db468fee-332e-412d-913f-463d4a954672,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a752ed11-62fa-4abd-aa15-12590e17aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5948eef4-7aa2-47c8-8fec-68c7132e066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936164116-172.17.0.18-1598553759673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39191,DS-bfd4cbd2-607c-40c3-890a-cbf5ee902847,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-5d7fe72f-3d05-431a-9790-8638c3e0c714,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-1ed04e08-f087-4c5c-bda1-be45995cee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-3f60a69e-72f5-4ae0-b4af-737683d31f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-6b1a4133-c8e4-479a-b07d-000cecb4042f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-db468fee-332e-412d-913f-463d4a954672,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a752ed11-62fa-4abd-aa15-12590e17aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5948eef4-7aa2-47c8-8fec-68c7132e066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544994009-172.17.0.18-1598553943660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-e5dc9809-676e-4b0a-a021-cab3d70c83d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-881d1929-400e-47e5-ba16-4e116821af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-81a93fe7-ec5b-4eb2-b56c-9fceb8cb9e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-237f96ea-897c-4338-900a-039c7fa84c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-b27831b5-9a33-4886-a1d4-517814f486a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-690d7f47-0443-4cda-b75a-2525f6ab655b,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-9f1b798f-2887-442d-9a4f-7412d381c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-8fd26e86-e4d6-4509-873e-f9f80634ef5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544994009-172.17.0.18-1598553943660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-e5dc9809-676e-4b0a-a021-cab3d70c83d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-881d1929-400e-47e5-ba16-4e116821af2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-81a93fe7-ec5b-4eb2-b56c-9fceb8cb9e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-237f96ea-897c-4338-900a-039c7fa84c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-b27831b5-9a33-4886-a1d4-517814f486a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-690d7f47-0443-4cda-b75a-2525f6ab655b,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-9f1b798f-2887-442d-9a4f-7412d381c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-8fd26e86-e4d6-4509-873e-f9f80634ef5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514486380-172.17.0.18-1598553975224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-2d79e02e-e678-43a0-a78c-eb5f6ddace72,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-c1d1fad7-e7bb-4612-bb87-a123f1acb09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-5b018eae-db11-4f0d-8e62-d1284843a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b40197c0-ebd8-486f-a281-100a857b3c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-c1fc5069-35dd-49f9-b405-a8341c930e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0d7a39ee-7ea2-4f72-972f-95491e8c8249,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-48b1bc1f-4b24-49bf-a2ec-6888becfb2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-c5c175b7-2da3-4d89-af02-5df0e3348cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514486380-172.17.0.18-1598553975224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-2d79e02e-e678-43a0-a78c-eb5f6ddace72,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-c1d1fad7-e7bb-4612-bb87-a123f1acb09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-5b018eae-db11-4f0d-8e62-d1284843a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b40197c0-ebd8-486f-a281-100a857b3c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-c1fc5069-35dd-49f9-b405-a8341c930e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0d7a39ee-7ea2-4f72-972f-95491e8c8249,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-48b1bc1f-4b24-49bf-a2ec-6888becfb2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-c5c175b7-2da3-4d89-af02-5df0e3348cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191934445-172.17.0.18-1598554313604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-53b534db-b51f-4b25-83b4-4538877e4a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-072f3ed0-ff71-4eab-9b71-6377721c6d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-13b96e87-21c7-4b64-95ac-2c20ae8c3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-3736a649-e19f-4cfc-aea8-177a2311206f,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-129e780a-b7ad-4400-a06f-cf331971df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-36e906e3-bfc2-4c66-ba56-390ef531dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-4094d638-c130-4ccd-949b-9a60139ab8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-404ff310-acfe-4ae9-aa90-8ca83455608c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191934445-172.17.0.18-1598554313604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-53b534db-b51f-4b25-83b4-4538877e4a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-072f3ed0-ff71-4eab-9b71-6377721c6d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-13b96e87-21c7-4b64-95ac-2c20ae8c3a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-3736a649-e19f-4cfc-aea8-177a2311206f,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-129e780a-b7ad-4400-a06f-cf331971df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-36e906e3-bfc2-4c66-ba56-390ef531dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-4094d638-c130-4ccd-949b-9a60139ab8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-404ff310-acfe-4ae9-aa90-8ca83455608c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384587193-172.17.0.18-1598554984191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34754,DS-599b3988-da2a-4f09-9b82-9b7808c5ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-769752e3-6864-452c-ba6b-dd6f2d3705f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-87c2af90-b85f-45c1-8301-d2b5d878a5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-b0b194c0-07c6-4052-99b7-f49df59b51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-bbe95bb3-465b-4a91-993d-3cede93a1e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-b436b5d1-ade5-440e-9c67-e36aa9cfab71,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-9b95b58d-71c1-41f8-82a9-516d3d00a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-e7bbc0b8-7eaa-4b13-a332-278750c62494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384587193-172.17.0.18-1598554984191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34754,DS-599b3988-da2a-4f09-9b82-9b7808c5ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-769752e3-6864-452c-ba6b-dd6f2d3705f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-87c2af90-b85f-45c1-8301-d2b5d878a5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-b0b194c0-07c6-4052-99b7-f49df59b51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-bbe95bb3-465b-4a91-993d-3cede93a1e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-b436b5d1-ade5-440e-9c67-e36aa9cfab71,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-9b95b58d-71c1-41f8-82a9-516d3d00a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-e7bbc0b8-7eaa-4b13-a332-278750c62494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775919871-172.17.0.18-1598555339409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-f3aeda8d-bbe6-42e8-8214-696f0f4bf56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-e3a4985c-07f5-42fe-b6eb-9399a146013b,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-836511d8-cada-4514-871b-d052f4d8d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-258d1c2d-ed57-4468-a377-6fe16b243125,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-dfa37cce-d07b-4452-b5e2-30cd950e933b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-25a7fa77-583e-4ee7-af76-8985b5164121,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-5f969800-81e8-4e13-af0c-7642c6a85b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-b61c5352-7c5a-4140-924d-4f8f5d2d4d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775919871-172.17.0.18-1598555339409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-f3aeda8d-bbe6-42e8-8214-696f0f4bf56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-e3a4985c-07f5-42fe-b6eb-9399a146013b,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-836511d8-cada-4514-871b-d052f4d8d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-258d1c2d-ed57-4468-a377-6fe16b243125,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-dfa37cce-d07b-4452-b5e2-30cd950e933b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-25a7fa77-583e-4ee7-af76-8985b5164121,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-5f969800-81e8-4e13-af0c-7642c6a85b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-b61c5352-7c5a-4140-924d-4f8f5d2d4d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349452469-172.17.0.18-1598555434864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-d185d357-64c9-4262-97a4-2c30c8fbb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-1d063294-7428-40ee-8b24-6db7430277a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-3e28b6f0-088a-4f81-a08e-8ca039d99488,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-ae9b1f67-71a3-4c7e-accd-c132b365e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-77273a09-41bd-44e8-b26b-aaea63ce2025,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-941e9950-8c12-48d9-8df1-91b16ca84d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-48e4e9e6-043c-4c21-b1e5-96f82e0778df,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-5bdc1bd9-8770-46f4-b571-6b0890b76e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349452469-172.17.0.18-1598555434864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-d185d357-64c9-4262-97a4-2c30c8fbb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-1d063294-7428-40ee-8b24-6db7430277a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-3e28b6f0-088a-4f81-a08e-8ca039d99488,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-ae9b1f67-71a3-4c7e-accd-c132b365e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-77273a09-41bd-44e8-b26b-aaea63ce2025,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-941e9950-8c12-48d9-8df1-91b16ca84d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-48e4e9e6-043c-4c21-b1e5-96f82e0778df,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-5bdc1bd9-8770-46f4-b571-6b0890b76e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763634691-172.17.0.18-1598555828259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35328,DS-ba953faf-4f39-439a-bfb6-bbe124b0aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7fd46a0c-0da1-48ad-ad65-9ef25d1cd219,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f4c8cb3f-ddb2-464c-b91b-536df953d126,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1e1b41ac-e2f2-4031-b253-988e73c1be48,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c3929c18-2620-4f92-899c-c11f9398f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-7a0af8e4-4a1d-4194-b633-d4918ecda909,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-ff9bea92-d0f0-4404-a358-1d7cab0ba348,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-5478f6c2-a965-458a-a8de-123837543f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763634691-172.17.0.18-1598555828259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35328,DS-ba953faf-4f39-439a-bfb6-bbe124b0aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-7fd46a0c-0da1-48ad-ad65-9ef25d1cd219,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f4c8cb3f-ddb2-464c-b91b-536df953d126,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1e1b41ac-e2f2-4031-b253-988e73c1be48,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c3929c18-2620-4f92-899c-c11f9398f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-7a0af8e4-4a1d-4194-b633-d4918ecda909,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-ff9bea92-d0f0-4404-a358-1d7cab0ba348,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-5478f6c2-a965-458a-a8de-123837543f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962812046-172.17.0.18-1598556076529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-fc5f368d-4e48-4b4e-a0c9-1a5dc774d045,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-c7856451-ec59-4a20-a78c-f2a5bd6ad7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b1dd5d9a-e0ef-4700-9d72-d78ec28a6861,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-166e3b73-619c-4fa5-925a-d2e0f5268e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-a27fa36a-ee4d-4b66-a9fb-3da18bd435c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-1a9865d9-cc88-4b59-b223-9624dc11d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-294d899e-c1cf-46b1-b0ef-73d8fc443f55,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-f83b88f4-ff29-438d-95b8-5f78b36a8a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962812046-172.17.0.18-1598556076529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-fc5f368d-4e48-4b4e-a0c9-1a5dc774d045,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-c7856451-ec59-4a20-a78c-f2a5bd6ad7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b1dd5d9a-e0ef-4700-9d72-d78ec28a6861,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-166e3b73-619c-4fa5-925a-d2e0f5268e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-a27fa36a-ee4d-4b66-a9fb-3da18bd435c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-1a9865d9-cc88-4b59-b223-9624dc11d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-294d899e-c1cf-46b1-b0ef-73d8fc443f55,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-f83b88f4-ff29-438d-95b8-5f78b36a8a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145720930-172.17.0.18-1598556265990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-9fe292a9-922c-40b7-bc5a-5f9500d0dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-a9109caa-50d4-4a52-ac9d-3131e77b4c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-a19325c9-7519-4dcb-9f9b-2c1bc2e9fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-f4e23018-f6fa-47f3-9600-937495c8e933,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-30d48184-c810-4209-afee-6dfb34adfc85,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-5a26dd3a-24c2-46b1-b9e6-42b2597f6a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-21439cb9-b716-4aa0-9003-fcd376da61cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-39acd3b6-ef7c-4f6a-8a7b-3a458c2f5824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145720930-172.17.0.18-1598556265990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-9fe292a9-922c-40b7-bc5a-5f9500d0dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-a9109caa-50d4-4a52-ac9d-3131e77b4c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-a19325c9-7519-4dcb-9f9b-2c1bc2e9fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-f4e23018-f6fa-47f3-9600-937495c8e933,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-30d48184-c810-4209-afee-6dfb34adfc85,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-5a26dd3a-24c2-46b1-b9e6-42b2597f6a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-21439cb9-b716-4aa0-9003-fcd376da61cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-39acd3b6-ef7c-4f6a-8a7b-3a458c2f5824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775605529-172.17.0.18-1598556561921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-71a273c7-9d5b-450e-abed-adfde2fba7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-280971a7-0d8a-4b4b-945b-ba9311a18c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-e8980d52-273a-4297-a29f-14454ef6ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-776dd563-c940-4fee-89d8-8a99139251bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-bda213f5-4578-4173-acc8-469f2330bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c66272fc-26e2-4ea8-a981-d5baf7c5b104,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-39b44faa-99f4-4e22-ad35-ca05e8f74610,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-03aaa163-c938-4f01-8018-6742ec1aca8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775605529-172.17.0.18-1598556561921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-71a273c7-9d5b-450e-abed-adfde2fba7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-280971a7-0d8a-4b4b-945b-ba9311a18c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-e8980d52-273a-4297-a29f-14454ef6ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-776dd563-c940-4fee-89d8-8a99139251bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-bda213f5-4578-4173-acc8-469f2330bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c66272fc-26e2-4ea8-a981-d5baf7c5b104,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-39b44faa-99f4-4e22-ad35-ca05e8f74610,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-03aaa163-c938-4f01-8018-6742ec1aca8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571516900-172.17.0.18-1598556914388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-52f3b1da-e466-4163-b797-933dad2dd050,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-24e6360e-771d-462b-b915-fbcf858a5ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-767d80ab-ac77-472d-bc88-675dd36e04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0e6cb484-fd3b-450d-982f-1d0f3026cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-ced57402-0046-4b60-9732-5d90f0c6e724,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-32ac8329-96de-45d1-97da-912ceb415c21,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-d6a3ac7c-ace9-41b1-81e0-1fab34e0051c,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ede52761-1326-40e5-ae7c-ace04b011dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571516900-172.17.0.18-1598556914388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-52f3b1da-e466-4163-b797-933dad2dd050,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-24e6360e-771d-462b-b915-fbcf858a5ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-767d80ab-ac77-472d-bc88-675dd36e04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0e6cb484-fd3b-450d-982f-1d0f3026cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-ced57402-0046-4b60-9732-5d90f0c6e724,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-32ac8329-96de-45d1-97da-912ceb415c21,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-d6a3ac7c-ace9-41b1-81e0-1fab34e0051c,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ede52761-1326-40e5-ae7c-ace04b011dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207821484-172.17.0.18-1598556978174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-42b4a062-4163-475a-8627-34676176c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2cd43750-6df8-4b93-8e6f-bcb4e8e31a97,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-addc4bbe-648b-4bc0-9a6d-951fbe42f054,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-82118c36-3d57-49b8-a02c-b9dfa271cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-1f16bf25-3296-4ee5-9577-c80fbfb904f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-78966130-8d6b-4e01-b688-b2ee30785f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-ab6abb71-6036-488d-aae5-55630fbacf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-89d24f50-697f-49c9-877a-bf2c27e08e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207821484-172.17.0.18-1598556978174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-42b4a062-4163-475a-8627-34676176c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2cd43750-6df8-4b93-8e6f-bcb4e8e31a97,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-addc4bbe-648b-4bc0-9a6d-951fbe42f054,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-82118c36-3d57-49b8-a02c-b9dfa271cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-1f16bf25-3296-4ee5-9577-c80fbfb904f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-78966130-8d6b-4e01-b688-b2ee30785f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-ab6abb71-6036-488d-aae5-55630fbacf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-89d24f50-697f-49c9-877a-bf2c27e08e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728805979-172.17.0.18-1598557300612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-2e4500ac-c94e-4a80-b0e3-604fc8c4fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-63cdcf3d-e705-4c88-a000-f1fb874e1ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-77ba93d8-6a8a-489c-ab28-a1eebc1d4cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-e9bd484d-381b-4b18-a4ac-443fdcc2ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-b3ccc6a2-6f38-45c1-a35e-edd84639f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-c06cb274-eabc-4548-9f60-21aed5897e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-4ba54390-f6a2-4db2-b1a2-287acfafbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-2289c8e6-916b-4ef2-a938-7fcbd513744c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728805979-172.17.0.18-1598557300612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-2e4500ac-c94e-4a80-b0e3-604fc8c4fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-63cdcf3d-e705-4c88-a000-f1fb874e1ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-77ba93d8-6a8a-489c-ab28-a1eebc1d4cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-e9bd484d-381b-4b18-a4ac-443fdcc2ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-b3ccc6a2-6f38-45c1-a35e-edd84639f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-c06cb274-eabc-4548-9f60-21aed5897e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-4ba54390-f6a2-4db2-b1a2-287acfafbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-2289c8e6-916b-4ef2-a938-7fcbd513744c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320801652-172.17.0.18-1598557336551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-9ae4eaf5-0c5d-41da-b488-85ff04e8c489,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-199763b2-4dc5-4a74-9105-f5dacfcdfc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-bdb71fb4-8082-4a58-9ce5-c4b048e5582b,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-56aefe48-71b3-4df7-9318-d19d2c50265e,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d6814a65-7838-4aec-b2dc-33df176ff2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-8808d4ac-3519-4525-9ce5-6ac69da76355,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-dd7cb31e-dcd8-4253-af71-76acb27cc919,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-40ef1fb1-6a6d-4ba3-89e1-d7d8c69702ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320801652-172.17.0.18-1598557336551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-9ae4eaf5-0c5d-41da-b488-85ff04e8c489,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-199763b2-4dc5-4a74-9105-f5dacfcdfc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-bdb71fb4-8082-4a58-9ce5-c4b048e5582b,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-56aefe48-71b3-4df7-9318-d19d2c50265e,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-d6814a65-7838-4aec-b2dc-33df176ff2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-8808d4ac-3519-4525-9ce5-6ac69da76355,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-dd7cb31e-dcd8-4253-af71-76acb27cc919,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-40ef1fb1-6a6d-4ba3-89e1-d7d8c69702ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4793
