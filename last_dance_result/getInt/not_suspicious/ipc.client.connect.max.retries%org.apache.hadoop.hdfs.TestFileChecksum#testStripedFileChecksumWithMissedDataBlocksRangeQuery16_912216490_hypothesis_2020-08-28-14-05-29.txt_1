reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756849178-172.17.0.16-1598623653278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-7da7f17b-237f-418c-8ef8-8ab73593b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-4dde9bf0-de43-49f5-a936-5121df96c335,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-e8702a66-67b4-4898-9d67-832ddaa3fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-e0011b33-f6ec-412c-9725-1f9214d7a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-48274e88-aeea-4021-a7a1-865ee95c7e30,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-08641f9e-d537-413d-862e-6f4fc28d7924,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8411286d-115b-4ebd-b06b-cdd3fc07e831,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-fbbbf092-4933-4333-9bed-3a7c723de14a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756849178-172.17.0.16-1598623653278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-7da7f17b-237f-418c-8ef8-8ab73593b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-4dde9bf0-de43-49f5-a936-5121df96c335,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-e8702a66-67b4-4898-9d67-832ddaa3fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-e0011b33-f6ec-412c-9725-1f9214d7a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-48274e88-aeea-4021-a7a1-865ee95c7e30,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-08641f9e-d537-413d-862e-6f4fc28d7924,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8411286d-115b-4ebd-b06b-cdd3fc07e831,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-fbbbf092-4933-4333-9bed-3a7c723de14a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983131182-172.17.0.16-1598623693601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-b0f22b7a-ab21-4750-b196-4b957d79fbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-2d78ddbc-204b-4275-ab38-4f832f6ad588,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-0d33de79-59c4-4c34-9f87-f17fad2626d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7e23bc64-1287-4f40-b535-e5d4f0968f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-784fd3da-431c-4465-8756-1fc3a9d9e459,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-0692a209-02cb-44d8-b54e-ebd41f2c8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-ee043a96-d21e-40d0-b6e6-a1d3c2e6fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-2ae31269-15bc-4f22-9048-3dfe27a90a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983131182-172.17.0.16-1598623693601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-b0f22b7a-ab21-4750-b196-4b957d79fbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-2d78ddbc-204b-4275-ab38-4f832f6ad588,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-0d33de79-59c4-4c34-9f87-f17fad2626d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-7e23bc64-1287-4f40-b535-e5d4f0968f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-784fd3da-431c-4465-8756-1fc3a9d9e459,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-0692a209-02cb-44d8-b54e-ebd41f2c8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-ee043a96-d21e-40d0-b6e6-a1d3c2e6fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-2ae31269-15bc-4f22-9048-3dfe27a90a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200885307-172.17.0.16-1598623728573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-f35561d1-a236-4f4f-a5f1-9069f43c148b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-418b7dfe-8ec8-4519-9de9-30277f775726,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-9704693f-8c01-445d-894a-d58fbbacd597,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-c997f7aa-73af-410b-9ff0-b74d33d0cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-44484da3-413f-455f-8097-36e7bbd98d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-104d596f-0204-4bea-84a6-18b1569dbf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-fa057adc-e4e1-4e5c-a2c8-6d22a52f7fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-5696ef47-104b-4444-831b-0f0c2cf8d255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200885307-172.17.0.16-1598623728573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-f35561d1-a236-4f4f-a5f1-9069f43c148b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-418b7dfe-8ec8-4519-9de9-30277f775726,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-9704693f-8c01-445d-894a-d58fbbacd597,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-c997f7aa-73af-410b-9ff0-b74d33d0cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-44484da3-413f-455f-8097-36e7bbd98d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-104d596f-0204-4bea-84a6-18b1569dbf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-fa057adc-e4e1-4e5c-a2c8-6d22a52f7fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-5696ef47-104b-4444-831b-0f0c2cf8d255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944330972-172.17.0.16-1598623807577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34946,DS-3e9eba4a-388d-4438-b821-d7ce47590046,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-da5d5a08-53f2-41fa-a131-5e1a8c268a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-3a1c90d1-cb8c-4265-8a71-0f1279c7b675,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-5582c2e5-f0e5-4115-a7c4-2f5b71a55868,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-1890c844-b045-48c8-ab55-6384d0939090,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-96516d7d-3bdd-46cd-84fc-a9b5f82e7526,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-25a28514-d063-44f0-9e2d-6e166fc42cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3d8e166e-610c-42d6-892b-6d14cd32c562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944330972-172.17.0.16-1598623807577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34946,DS-3e9eba4a-388d-4438-b821-d7ce47590046,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-da5d5a08-53f2-41fa-a131-5e1a8c268a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-3a1c90d1-cb8c-4265-8a71-0f1279c7b675,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-5582c2e5-f0e5-4115-a7c4-2f5b71a55868,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-1890c844-b045-48c8-ab55-6384d0939090,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-96516d7d-3bdd-46cd-84fc-a9b5f82e7526,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-25a28514-d063-44f0-9e2d-6e166fc42cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-3d8e166e-610c-42d6-892b-6d14cd32c562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782870406-172.17.0.16-1598624029476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-ec26eaad-e025-45dc-96cc-0f7cb226366f,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-d85a996a-b378-4786-93ad-1d2b8e53fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-dd05f4e3-ee0e-46d3-bcd5-cd40ecc6cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-60c290d7-5944-4a4c-9925-0964090f5cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-b0071ef3-6eee-414d-b0ca-b36c94dd9d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-47bc52f8-ae78-42d8-9d3a-c52f9a4a25e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-4de62b93-d494-4327-9ab2-6a19c0044d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-dc2b1a55-88fd-45fa-9092-337e6f2557b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782870406-172.17.0.16-1598624029476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-ec26eaad-e025-45dc-96cc-0f7cb226366f,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-d85a996a-b378-4786-93ad-1d2b8e53fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-dd05f4e3-ee0e-46d3-bcd5-cd40ecc6cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-60c290d7-5944-4a4c-9925-0964090f5cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-b0071ef3-6eee-414d-b0ca-b36c94dd9d18,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-47bc52f8-ae78-42d8-9d3a-c52f9a4a25e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-4de62b93-d494-4327-9ab2-6a19c0044d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-dc2b1a55-88fd-45fa-9092-337e6f2557b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594283908-172.17.0.16-1598624189438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-0baed6f7-bb8c-43a8-bb89-f67694ca2c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-83eba978-53b8-41e7-b39d-6143071566e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-27116447-3860-4c81-9fe1-8bd5e9147f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cf748a7a-f9ec-4217-9a0d-8c4630973719,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-7a24276c-6d65-4771-991f-53fe5da84099,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-6a359f0f-f2c7-4c32-bf68-154dd23c1da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-9cbf0bce-5bba-41b9-9a2f-4ffacca2bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-9520c1eb-f773-4a31-a15a-a9c47f994cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594283908-172.17.0.16-1598624189438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34262,DS-0baed6f7-bb8c-43a8-bb89-f67694ca2c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-83eba978-53b8-41e7-b39d-6143071566e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-27116447-3860-4c81-9fe1-8bd5e9147f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cf748a7a-f9ec-4217-9a0d-8c4630973719,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-7a24276c-6d65-4771-991f-53fe5da84099,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-6a359f0f-f2c7-4c32-bf68-154dd23c1da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-9cbf0bce-5bba-41b9-9a2f-4ffacca2bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-9520c1eb-f773-4a31-a15a-a9c47f994cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968071799-172.17.0.16-1598624340750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33081,DS-d34626f9-fabc-42e6-a8ed-6720ab4035fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-ce1adb47-8fc4-40df-a7c9-20bbc095ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-416a73e1-f6c6-4432-9168-25710d192fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7b455d8b-d1bb-4240-ab3a-dc1a7801096e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e4aeb7df-b363-4c99-8d7c-af42f5d96ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-4b6f9e19-eb2f-4d19-924f-ad752e555f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-d7169010-7b99-4fed-9d10-dcf7084ded70,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-9b9ed88d-c2e9-48e3-85a2-5a40cdf7661e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968071799-172.17.0.16-1598624340750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33081,DS-d34626f9-fabc-42e6-a8ed-6720ab4035fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-ce1adb47-8fc4-40df-a7c9-20bbc095ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-416a73e1-f6c6-4432-9168-25710d192fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7b455d8b-d1bb-4240-ab3a-dc1a7801096e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e4aeb7df-b363-4c99-8d7c-af42f5d96ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-4b6f9e19-eb2f-4d19-924f-ad752e555f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-d7169010-7b99-4fed-9d10-dcf7084ded70,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-9b9ed88d-c2e9-48e3-85a2-5a40cdf7661e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708396402-172.17.0.16-1598624465795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-01fb2480-a8f0-46af-831d-3727b1697187,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-c6777ab0-ce01-4b01-ae69-aa510f75f868,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-7aef6c1f-2328-4020-a0cf-9323524fc7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-ed938ba4-c946-4981-b229-7853f87ca905,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ea85a050-e360-40e1-9cc3-0a28d180f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-54a9255c-d2ac-4e38-a7bb-acfd42a03f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-58ede32c-ef24-4ef9-95eb-28b480c1e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-af59caa6-5bdb-415f-b04c-bd0d8d09de8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708396402-172.17.0.16-1598624465795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-01fb2480-a8f0-46af-831d-3727b1697187,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-c6777ab0-ce01-4b01-ae69-aa510f75f868,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-7aef6c1f-2328-4020-a0cf-9323524fc7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-ed938ba4-c946-4981-b229-7853f87ca905,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ea85a050-e360-40e1-9cc3-0a28d180f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-54a9255c-d2ac-4e38-a7bb-acfd42a03f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-58ede32c-ef24-4ef9-95eb-28b480c1e9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-af59caa6-5bdb-415f-b04c-bd0d8d09de8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227804923-172.17.0.16-1598624758256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-852f4598-1935-4540-9027-b0491c9e2dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-26a7a403-d1f3-4d1c-b2e0-d6ec1fccc266,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-ac8f8446-3000-444a-a538-dab2a0103c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-e4f887b1-392b-4cdb-86a5-057fa1ec1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-6430cb84-eaaa-4a1b-8870-e3a51f556245,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-00c2b972-f5e6-470d-9d1f-d383709adda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-e2999347-0ba1-4e09-907b-64e21d54d787,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-ba1eb220-3ae5-42d6-8c5b-d0cf95ce598a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227804923-172.17.0.16-1598624758256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-852f4598-1935-4540-9027-b0491c9e2dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-26a7a403-d1f3-4d1c-b2e0-d6ec1fccc266,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-ac8f8446-3000-444a-a538-dab2a0103c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-e4f887b1-392b-4cdb-86a5-057fa1ec1b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-6430cb84-eaaa-4a1b-8870-e3a51f556245,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-00c2b972-f5e6-470d-9d1f-d383709adda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-e2999347-0ba1-4e09-907b-64e21d54d787,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-ba1eb220-3ae5-42d6-8c5b-d0cf95ce598a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100247505-172.17.0.16-1598625660257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-5df06e19-8854-4318-8e0f-25636b58808c,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-2232a9d1-f8da-4113-8c3a-c70d5e0c4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-082878c0-3683-4191-acf8-cc73cf691069,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-066bebdf-e94e-4c52-99ae-9d59d7d5de1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-e4b39545-aecb-44d2-a5c6-57abffc4007e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-485e3430-e8ae-40b4-9a46-d11d64c0758b,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-54c53cd4-b0cf-4721-852f-54347b1b8e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-2108b692-b1ee-47c2-9d9a-523a79fb31f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100247505-172.17.0.16-1598625660257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38593,DS-5df06e19-8854-4318-8e0f-25636b58808c,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-2232a9d1-f8da-4113-8c3a-c70d5e0c4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-082878c0-3683-4191-acf8-cc73cf691069,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-066bebdf-e94e-4c52-99ae-9d59d7d5de1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-e4b39545-aecb-44d2-a5c6-57abffc4007e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-485e3430-e8ae-40b4-9a46-d11d64c0758b,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-54c53cd4-b0cf-4721-852f-54347b1b8e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-2108b692-b1ee-47c2-9d9a-523a79fb31f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986703466-172.17.0.16-1598625947513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-1bd940e7-bb54-4ced-a2cf-99b9a260e309,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-40be6a21-2a8c-4bcc-8441-e5b78b86ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-ebf22f25-6b6b-446d-b2a6-11f36f895329,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-19f3ff2e-479b-4301-9ed4-afefa699eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-69cd3528-0177-4225-bc0c-75a558730ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-f54428b2-a968-452b-a577-9ef009678b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-dcfa29a0-baba-4cf7-8fdb-433ce9e5f495,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-06f64137-1014-4d73-95e3-d5c3aa648a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986703466-172.17.0.16-1598625947513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-1bd940e7-bb54-4ced-a2cf-99b9a260e309,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-40be6a21-2a8c-4bcc-8441-e5b78b86ea51,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-ebf22f25-6b6b-446d-b2a6-11f36f895329,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-19f3ff2e-479b-4301-9ed4-afefa699eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-69cd3528-0177-4225-bc0c-75a558730ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-f54428b2-a968-452b-a577-9ef009678b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-dcfa29a0-baba-4cf7-8fdb-433ce9e5f495,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-06f64137-1014-4d73-95e3-d5c3aa648a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349046932-172.17.0.16-1598627229408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-a8d63088-e132-40d0-8347-e5df45335397,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-bb6b0d7d-691e-4e2b-8397-6c3ecbae2398,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-9312aa67-92f8-46b1-b96c-8bfe66859ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f6ca3ba2-abea-4071-92cf-434ee8eea1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-aad532cf-4779-442f-a143-e2f3c630df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-8908cefb-9be4-4936-82aa-395c6e471832,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-ab57e79c-fcf5-426a-aadc-e066816f5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-dedb3062-2500-4e09-8260-52ab9dc66c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349046932-172.17.0.16-1598627229408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-a8d63088-e132-40d0-8347-e5df45335397,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-bb6b0d7d-691e-4e2b-8397-6c3ecbae2398,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-9312aa67-92f8-46b1-b96c-8bfe66859ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f6ca3ba2-abea-4071-92cf-434ee8eea1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-aad532cf-4779-442f-a143-e2f3c630df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-8908cefb-9be4-4936-82aa-395c6e471832,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-ab57e79c-fcf5-426a-aadc-e066816f5f26,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-dedb3062-2500-4e09-8260-52ab9dc66c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660753813-172.17.0.16-1598627444042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-2876b11e-7259-45a0-ad08-123c180ba2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-91086769-7a5a-4679-a4b3-69459032feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-eba3f742-4b45-4734-b160-cfd705ee4003,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2fab0bb0-b075-486f-b5bd-d4f9e0e97370,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-c61de301-ee41-46c5-b74f-ddbc0d0f48fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-e8ddc1a8-eba1-4cb0-b23e-a7109c58c956,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c0d43f39-469b-43f4-9055-c5953ccdf9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-db42bf38-32b9-4c3b-8a19-bcaa6fbab2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660753813-172.17.0.16-1598627444042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-2876b11e-7259-45a0-ad08-123c180ba2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-91086769-7a5a-4679-a4b3-69459032feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-eba3f742-4b45-4734-b160-cfd705ee4003,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2fab0bb0-b075-486f-b5bd-d4f9e0e97370,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-c61de301-ee41-46c5-b74f-ddbc0d0f48fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-e8ddc1a8-eba1-4cb0-b23e-a7109c58c956,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c0d43f39-469b-43f4-9055-c5953ccdf9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-db42bf38-32b9-4c3b-8a19-bcaa6fbab2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440683931-172.17.0.16-1598627678299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-11c7e397-b80d-44bf-936f-4b5335b0a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-ac11d036-7459-4c3b-9271-248b5afe5378,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-7222c4bc-3ee6-4c6f-868c-069e4ff2c281,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-1643a967-f0e1-4b9a-8a72-ae3942d2e842,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-6deeda15-ade4-4948-8247-fde20e349985,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-09611e17-68f2-49b6-b90d-a28f7c158a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-daa8c93c-5606-4c88-ba02-a1619fe2d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-c0e90fb4-1a33-4bee-9bb3-598f63fd14d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440683931-172.17.0.16-1598627678299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-11c7e397-b80d-44bf-936f-4b5335b0a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-ac11d036-7459-4c3b-9271-248b5afe5378,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-7222c4bc-3ee6-4c6f-868c-069e4ff2c281,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-1643a967-f0e1-4b9a-8a72-ae3942d2e842,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-6deeda15-ade4-4948-8247-fde20e349985,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-09611e17-68f2-49b6-b90d-a28f7c158a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-daa8c93c-5606-4c88-ba02-a1619fe2d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-c0e90fb4-1a33-4bee-9bb3-598f63fd14d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983760071-172.17.0.16-1598627862173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-e62ee229-25e1-42bb-98ab-6c009890d328,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-76a2ef62-448c-49da-82e3-8c978db76eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-e65796a7-feab-4a8f-ba6b-057fc64f3464,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-dbe89c9d-44c6-4700-83f9-39db68529c08,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-dd97c777-520d-4cbd-8089-af4013fea6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-59027c5c-b45b-4d61-a741-ec45bcb905ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-e07a1ecd-1937-4a31-ae37-fac5deb5425e,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-5a0404a5-bd06-49f6-8ea5-4a1988b83158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983760071-172.17.0.16-1598627862173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-e62ee229-25e1-42bb-98ab-6c009890d328,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-76a2ef62-448c-49da-82e3-8c978db76eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-e65796a7-feab-4a8f-ba6b-057fc64f3464,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-dbe89c9d-44c6-4700-83f9-39db68529c08,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-dd97c777-520d-4cbd-8089-af4013fea6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-59027c5c-b45b-4d61-a741-ec45bcb905ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-e07a1ecd-1937-4a31-ae37-fac5deb5425e,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-5a0404a5-bd06-49f6-8ea5-4a1988b83158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65142591-172.17.0.16-1598628089324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-c6928f7c-4d93-4bb3-be13-cb1241d05163,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-8f64a154-80bf-4d1e-ada4-11c8af51fc46,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-08064f7c-f855-4de6-93d6-d9e0ecd2608a,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-9fb8af5b-e58c-42cd-9355-028ad56ab32b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-dc0ca5c6-ef6c-43bb-b7dc-f3ceb6baa477,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-d4ff012c-dd20-40c0-808c-d8dce11cbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c12e3527-e484-46ac-87da-c78c6cc77b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-5ad227d4-d439-4241-a522-b8c04eabaa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65142591-172.17.0.16-1598628089324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-c6928f7c-4d93-4bb3-be13-cb1241d05163,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-8f64a154-80bf-4d1e-ada4-11c8af51fc46,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-08064f7c-f855-4de6-93d6-d9e0ecd2608a,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-9fb8af5b-e58c-42cd-9355-028ad56ab32b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-dc0ca5c6-ef6c-43bb-b7dc-f3ceb6baa477,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-d4ff012c-dd20-40c0-808c-d8dce11cbe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-c12e3527-e484-46ac-87da-c78c6cc77b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-5ad227d4-d439-4241-a522-b8c04eabaa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590444456-172.17.0.16-1598628563932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-63d1ce18-78e6-4518-a335-c3d36bc0d604,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-4562624c-411f-43b0-ac34-f46b8d56c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-adec9df0-b9cb-45e6-996e-fc602b795baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-e51e7672-6498-4c3d-ae23-020d355bdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-a01e95c5-6145-4826-8428-f900346cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-04c6fe01-bb08-4fda-b3dc-4e3bed8e67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-9cfa70b5-1c99-4420-ba1e-a0a8f264624c,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-36ded639-9d4e-4472-83ba-634afba344b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590444456-172.17.0.16-1598628563932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-63d1ce18-78e6-4518-a335-c3d36bc0d604,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-4562624c-411f-43b0-ac34-f46b8d56c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-adec9df0-b9cb-45e6-996e-fc602b795baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-e51e7672-6498-4c3d-ae23-020d355bdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-a01e95c5-6145-4826-8428-f900346cc127,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-04c6fe01-bb08-4fda-b3dc-4e3bed8e67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-9cfa70b5-1c99-4420-ba1e-a0a8f264624c,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-36ded639-9d4e-4472-83ba-634afba344b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618168931-172.17.0.16-1598628728148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-33d2e86d-a05d-403f-93e2-66989aef47de,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-e08c9028-d55d-4ef0-8bc4-90bbff90c5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6ce1bed0-498b-44b6-8967-4b9083aa50e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-997594fc-9795-4be5-a117-645274610ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-eed1a726-c413-4a96-abf0-95b2351e4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-a3bb4c15-14c7-4727-b570-88e2381de6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e3e08f39-59a7-4739-a498-28fa9e054d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-7a940c46-384a-493a-8705-dd228a550d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618168931-172.17.0.16-1598628728148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-33d2e86d-a05d-403f-93e2-66989aef47de,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-e08c9028-d55d-4ef0-8bc4-90bbff90c5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6ce1bed0-498b-44b6-8967-4b9083aa50e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-997594fc-9795-4be5-a117-645274610ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-eed1a726-c413-4a96-abf0-95b2351e4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-a3bb4c15-14c7-4727-b570-88e2381de6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e3e08f39-59a7-4739-a498-28fa9e054d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-7a940c46-384a-493a-8705-dd228a550d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5555
