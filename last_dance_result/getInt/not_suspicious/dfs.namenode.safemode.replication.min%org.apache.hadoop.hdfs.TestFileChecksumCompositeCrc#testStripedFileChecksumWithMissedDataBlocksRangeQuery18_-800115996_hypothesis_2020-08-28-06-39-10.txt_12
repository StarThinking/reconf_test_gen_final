reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411254330-172.17.0.14-1598596893208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-56e711a6-cd42-4cbb-aac4-2e13718e3172,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-97337dbe-7a82-4fb7-9a17-3c9d4f28c821,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-ab559d1e-49a8-478b-8e80-53b7eba84cda,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-be432e57-8423-48d1-a8d9-b3c5c5a3f829,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-933fcb6a-a808-41c6-84bd-a4052a791e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-db6c7676-e259-4cbe-9d15-2965acadd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-63bad0af-9c2c-453e-9dbe-b35eac868022,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-6eafa782-b6ef-4e87-9fc5-3aecb9cbe621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411254330-172.17.0.14-1598596893208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-56e711a6-cd42-4cbb-aac4-2e13718e3172,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-97337dbe-7a82-4fb7-9a17-3c9d4f28c821,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-ab559d1e-49a8-478b-8e80-53b7eba84cda,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-be432e57-8423-48d1-a8d9-b3c5c5a3f829,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-933fcb6a-a808-41c6-84bd-a4052a791e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-db6c7676-e259-4cbe-9d15-2965acadd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-63bad0af-9c2c-453e-9dbe-b35eac868022,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-6eafa782-b6ef-4e87-9fc5-3aecb9cbe621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536770497-172.17.0.14-1598596929200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-89781119-43a8-4907-b820-3a8059d1f912,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-1b2eadd9-4162-446b-a493-30881cd242b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9ae4eb51-1190-456c-864c-bfe3a460502e,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-d00914dd-4f94-463a-afa2-bcb7d2dfcf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-9f89a366-2c90-419f-acd0-c150e81d5ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-7b06d14c-0f9b-4435-81bc-307a3193e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-86713418-63d6-4152-94c8-619aec0c73f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-e05e013c-4d9d-40d7-b51a-454f59000af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536770497-172.17.0.14-1598596929200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40212,DS-89781119-43a8-4907-b820-3a8059d1f912,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-1b2eadd9-4162-446b-a493-30881cd242b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9ae4eb51-1190-456c-864c-bfe3a460502e,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-d00914dd-4f94-463a-afa2-bcb7d2dfcf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-9f89a366-2c90-419f-acd0-c150e81d5ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-7b06d14c-0f9b-4435-81bc-307a3193e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-86713418-63d6-4152-94c8-619aec0c73f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-e05e013c-4d9d-40d7-b51a-454f59000af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557453046-172.17.0.14-1598597373871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-ba4d56b6-28c7-47f5-ba29-175efdf6bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-64a6dc1e-d0d4-4f7c-9364-d1a2b86f961e,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-97435fd5-653c-4ca8-b270-faba5a515445,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-5b1d39e7-1bd6-496d-b40e-ec980bb1aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-0d615dbe-93b7-469e-979e-90948fa056dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-4f9b463b-ece9-46a5-91c5-974e6323ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-33bf7240-3d1c-406f-bad6-330447e69ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-06260927-553f-4ba7-be6e-41b57ce62b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557453046-172.17.0.14-1598597373871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-ba4d56b6-28c7-47f5-ba29-175efdf6bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-64a6dc1e-d0d4-4f7c-9364-d1a2b86f961e,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-97435fd5-653c-4ca8-b270-faba5a515445,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-5b1d39e7-1bd6-496d-b40e-ec980bb1aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-0d615dbe-93b7-469e-979e-90948fa056dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-4f9b463b-ece9-46a5-91c5-974e6323ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-33bf7240-3d1c-406f-bad6-330447e69ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-06260927-553f-4ba7-be6e-41b57ce62b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114399714-172.17.0.14-1598597402837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-4dbdef07-8e62-4306-a32c-d2b905aa3963,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-5b3beb4d-cbc4-4cd3-998d-9694c4ad6385,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-2c826773-47e1-4853-813d-79c9e2e43087,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-0321f34b-09a0-4661-b305-eba4b133f093,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-f89eb105-513f-4ad3-b61c-fcd19164a884,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-1eb5d7a5-928c-4fc7-980a-95055c4fe795,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-6bf84d3d-5b55-4ef1-ba5f-8bb281fc5a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-82da1b32-4ec3-4751-900a-bed4ac0df35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114399714-172.17.0.14-1598597402837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-4dbdef07-8e62-4306-a32c-d2b905aa3963,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-5b3beb4d-cbc4-4cd3-998d-9694c4ad6385,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-2c826773-47e1-4853-813d-79c9e2e43087,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-0321f34b-09a0-4661-b305-eba4b133f093,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-f89eb105-513f-4ad3-b61c-fcd19164a884,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-1eb5d7a5-928c-4fc7-980a-95055c4fe795,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-6bf84d3d-5b55-4ef1-ba5f-8bb281fc5a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-82da1b32-4ec3-4751-900a-bed4ac0df35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938114024-172.17.0.14-1598597595098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-2db27c34-9993-44e8-9bf7-24111022d0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-94c400a4-87c7-4197-956f-b75ba1d341c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-4e592a10-27da-44d1-9c8d-c782aa387a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-cf28c323-83d1-46a2-a883-bb14484cb871,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-7d04aa65-da90-456f-8fe8-a42c36d9a303,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-ca6ee289-0e77-4f6e-ba6e-5952f25f9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-84a064c6-a4b5-42ea-ad0d-684d5ea00f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-2199cfde-fdc0-49da-b56a-814665ce539a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938114024-172.17.0.14-1598597595098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-2db27c34-9993-44e8-9bf7-24111022d0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-94c400a4-87c7-4197-956f-b75ba1d341c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-4e592a10-27da-44d1-9c8d-c782aa387a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-cf28c323-83d1-46a2-a883-bb14484cb871,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-7d04aa65-da90-456f-8fe8-a42c36d9a303,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-ca6ee289-0e77-4f6e-ba6e-5952f25f9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-84a064c6-a4b5-42ea-ad0d-684d5ea00f76,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-2199cfde-fdc0-49da-b56a-814665ce539a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269872448-172.17.0.14-1598597750001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46622,DS-88070dc5-62a4-4b55-b8c9-1a6ba8a71225,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-391460f3-6b84-4d12-8be0-d4e4b8c7af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-5d60f889-254b-4d2d-a921-559b8417f937,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-154aaa9f-25d0-4edd-9bf9-8d5cd585c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-bd22d8db-f3a0-4d39-830b-e77e6ce15cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f156b9dc-deb3-4ecd-91a7-96ae343041ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-b3de8b8c-e9ea-4cb8-946c-9a10ef62038b,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-5ed1c2a0-c9ef-4b09-a295-6eab652434bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269872448-172.17.0.14-1598597750001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46622,DS-88070dc5-62a4-4b55-b8c9-1a6ba8a71225,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-391460f3-6b84-4d12-8be0-d4e4b8c7af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-5d60f889-254b-4d2d-a921-559b8417f937,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-154aaa9f-25d0-4edd-9bf9-8d5cd585c6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-bd22d8db-f3a0-4d39-830b-e77e6ce15cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f156b9dc-deb3-4ecd-91a7-96ae343041ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-b3de8b8c-e9ea-4cb8-946c-9a10ef62038b,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-5ed1c2a0-c9ef-4b09-a295-6eab652434bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525792662-172.17.0.14-1598597933547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-6f356bd9-eff1-4b9c-a13c-880481e197fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-44c9cf10-e1ee-4c45-9ac9-918dbea49fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-67708333-d43b-4c8b-aa31-94a6a1d27133,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-aa829104-181c-4cee-8c17-00c589b7870e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-0984c8ee-c3b4-402b-a9b7-c0027ba7c724,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-0e49d296-9787-409a-b7f6-58617e4f78ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-10ee3e58-93b5-4901-ae3e-cc02b421be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-6209f54b-2408-45c3-a767-9bdc663ed9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525792662-172.17.0.14-1598597933547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-6f356bd9-eff1-4b9c-a13c-880481e197fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-44c9cf10-e1ee-4c45-9ac9-918dbea49fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-67708333-d43b-4c8b-aa31-94a6a1d27133,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-aa829104-181c-4cee-8c17-00c589b7870e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-0984c8ee-c3b4-402b-a9b7-c0027ba7c724,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-0e49d296-9787-409a-b7f6-58617e4f78ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-10ee3e58-93b5-4901-ae3e-cc02b421be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-6209f54b-2408-45c3-a767-9bdc663ed9d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699675289-172.17.0.14-1598597975053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-1e0f3ed8-2518-4221-aee7-4403ae9a7817,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ff3084bc-23df-402e-b7eb-0d5c25d3747c,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-65d42d3f-fab3-4bd8-93d4-08d56bde0aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-d9c66991-6479-46f3-b88e-c7d70843a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-c69aca7c-7b2c-419f-9cbd-e3190e2570c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-f39629e6-20ed-41bd-b246-7d1f2683871d,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-97161e52-5cac-4a62-8f3b-df707f70cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-b118e940-0b0f-437b-8e5c-cc5c7a7a1fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699675289-172.17.0.14-1598597975053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-1e0f3ed8-2518-4221-aee7-4403ae9a7817,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ff3084bc-23df-402e-b7eb-0d5c25d3747c,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-65d42d3f-fab3-4bd8-93d4-08d56bde0aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-d9c66991-6479-46f3-b88e-c7d70843a88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-c69aca7c-7b2c-419f-9cbd-e3190e2570c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-f39629e6-20ed-41bd-b246-7d1f2683871d,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-97161e52-5cac-4a62-8f3b-df707f70cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-b118e940-0b0f-437b-8e5c-cc5c7a7a1fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460972315-172.17.0.14-1598598066352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39191,DS-58d0f761-4035-451b-96db-b13d725cbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-4eb3105b-048f-4fe1-bb6b-82d2bed49c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-a3abc5c2-f861-46a7-93d0-b2f71798db53,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-84436d71-9da5-455b-8c8a-b8a627e7d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-36ce9778-9e72-4dbb-aeb9-3312cf291d85,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-444abf8c-2a11-4ed7-88ae-4cf69bb66939,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-ad32d318-b924-4ae5-b114-3de0f6d5640c,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-2ffe51dc-49c9-42f2-94f2-c251a97578f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460972315-172.17.0.14-1598598066352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39191,DS-58d0f761-4035-451b-96db-b13d725cbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-4eb3105b-048f-4fe1-bb6b-82d2bed49c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-a3abc5c2-f861-46a7-93d0-b2f71798db53,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-84436d71-9da5-455b-8c8a-b8a627e7d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-36ce9778-9e72-4dbb-aeb9-3312cf291d85,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-444abf8c-2a11-4ed7-88ae-4cf69bb66939,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-ad32d318-b924-4ae5-b114-3de0f6d5640c,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-2ffe51dc-49c9-42f2-94f2-c251a97578f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807866170-172.17.0.14-1598598970173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-9ec098fa-5a89-49b5-9dee-1823f3c94c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-d4d4edd4-d669-4e6e-879c-35fb9c7bc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-00603c71-c8dd-4af9-81c3-b111822e18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-3cff6cb0-9d83-42c1-a7e8-df7a562b940b,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-11dba175-88ad-4a61-a9d5-465fdd01b455,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-afc2bbae-fa9a-4ed6-831c-0ec482d2e922,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-adc3d10f-4363-42ab-ad0d-a161c3849617,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-3d3ec2a1-61d8-4f09-b1a1-3dd505e947b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807866170-172.17.0.14-1598598970173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-9ec098fa-5a89-49b5-9dee-1823f3c94c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-d4d4edd4-d669-4e6e-879c-35fb9c7bc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-00603c71-c8dd-4af9-81c3-b111822e18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-3cff6cb0-9d83-42c1-a7e8-df7a562b940b,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-11dba175-88ad-4a61-a9d5-465fdd01b455,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-afc2bbae-fa9a-4ed6-831c-0ec482d2e922,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-adc3d10f-4363-42ab-ad0d-a161c3849617,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-3d3ec2a1-61d8-4f09-b1a1-3dd505e947b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077576081-172.17.0.14-1598599612093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-8d8ae311-5c15-42be-8d4d-519f95774f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-eb5d4352-882c-4d7d-b1cb-f8ffb178b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-b72e5f8c-fa37-4bd8-b4bf-3e976ad00605,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9d4e91a3-8d17-45d0-84dd-28f5976717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-cc393ec1-b108-4c49-b48a-9ce6ff1a5f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-fbdb3a87-b8c1-4613-829d-6064db52de73,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-24c0e38f-2d0c-42a6-86b6-faa04aecff31,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-304f5b82-9f6b-4955-a13c-3fccc163995a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077576081-172.17.0.14-1598599612093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-8d8ae311-5c15-42be-8d4d-519f95774f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-eb5d4352-882c-4d7d-b1cb-f8ffb178b93c,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-b72e5f8c-fa37-4bd8-b4bf-3e976ad00605,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9d4e91a3-8d17-45d0-84dd-28f5976717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-cc393ec1-b108-4c49-b48a-9ce6ff1a5f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-fbdb3a87-b8c1-4613-829d-6064db52de73,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-24c0e38f-2d0c-42a6-86b6-faa04aecff31,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-304f5b82-9f6b-4955-a13c-3fccc163995a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781339850-172.17.0.14-1598600359618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-5ec3eb19-599b-47f2-b273-08684d61d308,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0bf59544-7e9b-494b-a3f5-25e0dc63a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-5e1f4c8e-1ebc-4b4e-bc17-c50fd2e1f306,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-80355fb6-4aac-46b4-a472-dbf30da8d4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-abc9608c-a085-4a28-b5d5-0553d55a0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-64032090-e919-4166-a8f5-f63a24814714,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-9cdb08bc-c095-4b9b-899c-7bb1d74cbe80,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-761d7a56-851c-4b99-ac38-813119970213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781339850-172.17.0.14-1598600359618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-5ec3eb19-599b-47f2-b273-08684d61d308,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-0bf59544-7e9b-494b-a3f5-25e0dc63a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-5e1f4c8e-1ebc-4b4e-bc17-c50fd2e1f306,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-80355fb6-4aac-46b4-a472-dbf30da8d4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-abc9608c-a085-4a28-b5d5-0553d55a0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-64032090-e919-4166-a8f5-f63a24814714,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-9cdb08bc-c095-4b9b-899c-7bb1d74cbe80,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-761d7a56-851c-4b99-ac38-813119970213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748656760-172.17.0.14-1598600516730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-719f3ba9-7edb-45d3-8ffc-24b7ad6fa4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-4bc2cf74-df80-431c-9d52-1c1de3649356,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f36f1057-900b-4b6a-b1ff-adde26dd1070,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-7f4ccbf2-522a-4ee1-843c-5c097125b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-c6bc5d7f-92b9-4a55-974e-f5be5d6f2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-556ec01a-236a-4b9b-99b3-b5b4d7217bca,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-6770418e-b415-47ec-82cf-86aa2d520840,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f7c0726d-bba8-493f-b619-7772cbfdabe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748656760-172.17.0.14-1598600516730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-719f3ba9-7edb-45d3-8ffc-24b7ad6fa4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-4bc2cf74-df80-431c-9d52-1c1de3649356,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f36f1057-900b-4b6a-b1ff-adde26dd1070,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-7f4ccbf2-522a-4ee1-843c-5c097125b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-c6bc5d7f-92b9-4a55-974e-f5be5d6f2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-556ec01a-236a-4b9b-99b3-b5b4d7217bca,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-6770418e-b415-47ec-82cf-86aa2d520840,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f7c0726d-bba8-493f-b619-7772cbfdabe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231872133-172.17.0.14-1598600762991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-d383c1e9-61e3-4a91-a164-f08ff46b9208,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a3f856b2-fc20-462d-9e43-ea862e2489b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-b4091fed-e0ec-4331-b507-85b15b256eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-d985d883-be87-4e3e-aaf1-d90d3a743531,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d2916f82-5b7e-482c-bc82-2fe3ceaa3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-5da0063f-3260-4e55-a447-d80d6ba50e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-27f89640-fb47-4976-b5fa-68ec32029660,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-7cd45739-b4f3-475d-8420-80d38cdbbc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231872133-172.17.0.14-1598600762991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-d383c1e9-61e3-4a91-a164-f08ff46b9208,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-a3f856b2-fc20-462d-9e43-ea862e2489b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-b4091fed-e0ec-4331-b507-85b15b256eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-d985d883-be87-4e3e-aaf1-d90d3a743531,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-d2916f82-5b7e-482c-bc82-2fe3ceaa3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-5da0063f-3260-4e55-a447-d80d6ba50e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-27f89640-fb47-4976-b5fa-68ec32029660,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-7cd45739-b4f3-475d-8420-80d38cdbbc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170037403-172.17.0.14-1598600868292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-08b41552-6406-43bc-8fe2-4e1ea02e4079,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8b3194eb-a455-4da8-a494-57843a50eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-2560775a-8aeb-40eb-824d-b4de88e57613,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-ff7e7a45-b663-4aec-a272-2fc12f582228,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d626aec9-321f-4815-ba80-aede271482b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a2386580-0172-4bdf-b40f-e496696d55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-db16b336-85f6-496a-adb2-857d17e1e030,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-1980162f-82c7-49a6-a8f6-62c68d9a31f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170037403-172.17.0.14-1598600868292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-08b41552-6406-43bc-8fe2-4e1ea02e4079,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8b3194eb-a455-4da8-a494-57843a50eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-2560775a-8aeb-40eb-824d-b4de88e57613,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-ff7e7a45-b663-4aec-a272-2fc12f582228,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d626aec9-321f-4815-ba80-aede271482b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a2386580-0172-4bdf-b40f-e496696d55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-db16b336-85f6-496a-adb2-857d17e1e030,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-1980162f-82c7-49a6-a8f6-62c68d9a31f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610470436-172.17.0.14-1598601004282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-2e9c32b3-59bc-4995-81b1-c74dd5128e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-e7146fce-8876-4886-a24d-8a5b4a0d08df,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-df687fc8-850f-4cac-a5a5-e0cc7252d240,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4b36b0d9-b6c4-4f69-9724-83ad5942e937,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-0f667250-05e0-49d9-abde-afd6bf026644,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-bd8144fa-4e61-4685-a6a0-1466dbd80578,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-06763d63-3be6-4cef-8394-91d35841ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5f7f5fda-0f3e-4b5d-8348-baa5e1394d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610470436-172.17.0.14-1598601004282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-2e9c32b3-59bc-4995-81b1-c74dd5128e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-e7146fce-8876-4886-a24d-8a5b4a0d08df,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-df687fc8-850f-4cac-a5a5-e0cc7252d240,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4b36b0d9-b6c4-4f69-9724-83ad5942e937,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-0f667250-05e0-49d9-abde-afd6bf026644,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-bd8144fa-4e61-4685-a6a0-1466dbd80578,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-06763d63-3be6-4cef-8394-91d35841ff7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5f7f5fda-0f3e-4b5d-8348-baa5e1394d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754935343-172.17.0.14-1598601179467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-a9c4f322-e20d-4738-9267-1a3f17a6dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-ea651c41-7730-4a3e-8b75-2253c040b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-fa964465-b96b-4376-a8dc-917bd210817c,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-7553bf06-a6f2-4e80-a884-1c3d242255e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-a3006e92-2349-4891-a259-56700e34d972,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-5324738f-f5c1-40a3-be9a-49ac03d5dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-8cdac9cc-77e2-4fa6-9967-da98ceb8ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-2b359040-fb63-4ba7-b564-3535e5cd0f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754935343-172.17.0.14-1598601179467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-a9c4f322-e20d-4738-9267-1a3f17a6dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-ea651c41-7730-4a3e-8b75-2253c040b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-fa964465-b96b-4376-a8dc-917bd210817c,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-7553bf06-a6f2-4e80-a884-1c3d242255e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-a3006e92-2349-4891-a259-56700e34d972,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-5324738f-f5c1-40a3-be9a-49ac03d5dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-8cdac9cc-77e2-4fa6-9967-da98ceb8ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-2b359040-fb63-4ba7-b564-3535e5cd0f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058265399-172.17.0.14-1598601559171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-bc028887-08ea-47e3-9428-f0398400af23,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7f756b3c-0212-417c-aa0b-575a0b1eaba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6ea95523-0537-451e-ac2e-59c539f3a0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-e35fd9d0-0b68-47da-9aef-0cea55b73800,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b5b9bcf2-80fa-4e9b-8599-95e1cf3a3678,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-327b36ae-9596-4020-8379-b1d419dbdebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e95e7a11-a49b-4d69-af20-12ace6956016,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-9a66a89b-ac29-4c5b-b0c5-ec4347b7e7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058265399-172.17.0.14-1598601559171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-bc028887-08ea-47e3-9428-f0398400af23,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7f756b3c-0212-417c-aa0b-575a0b1eaba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-6ea95523-0537-451e-ac2e-59c539f3a0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-e35fd9d0-0b68-47da-9aef-0cea55b73800,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b5b9bcf2-80fa-4e9b-8599-95e1cf3a3678,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-327b36ae-9596-4020-8379-b1d419dbdebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e95e7a11-a49b-4d69-af20-12ace6956016,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-9a66a89b-ac29-4c5b-b0c5-ec4347b7e7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4959
