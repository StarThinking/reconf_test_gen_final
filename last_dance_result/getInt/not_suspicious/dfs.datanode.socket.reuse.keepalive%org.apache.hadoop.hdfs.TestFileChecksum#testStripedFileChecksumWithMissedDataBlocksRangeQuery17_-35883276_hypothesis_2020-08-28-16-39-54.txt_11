reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920274296-172.17.0.8-1598632991102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-19dd09ea-28c3-472c-a9ce-9bf1f928a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-bcb8ded4-d8d5-40d9-bb62-fdff0d290b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-96df0a51-ba7d-4791-bcc0-660d7f8ab9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-0e0c998a-bb96-45c6-a786-80616e0f31d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-fd005966-9704-486e-9b7c-4976de260608,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-8ece54ed-874b-4755-8dc1-6c91a42bd380,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-69734b42-ee8d-4abb-aad8-ce7aa2ad1b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-0b618a9a-c821-403d-91dc-d4495350f500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920274296-172.17.0.8-1598632991102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-19dd09ea-28c3-472c-a9ce-9bf1f928a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-bcb8ded4-d8d5-40d9-bb62-fdff0d290b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-96df0a51-ba7d-4791-bcc0-660d7f8ab9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-0e0c998a-bb96-45c6-a786-80616e0f31d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-fd005966-9704-486e-9b7c-4976de260608,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-8ece54ed-874b-4755-8dc1-6c91a42bd380,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-69734b42-ee8d-4abb-aad8-ce7aa2ad1b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-0b618a9a-c821-403d-91dc-d4495350f500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742296175-172.17.0.8-1598633052711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-7fd1742b-9ed8-4c54-8e24-4ea666821e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ede40af7-ddb7-407a-9da9-e595582eb642,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-2cae0148-0344-453e-a487-59b90088c994,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-93bb66bc-0983-4f8e-95c4-b7c0cd247948,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-ecc7fdec-3458-4b6d-91db-571037159d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-ed5348c4-c841-43de-97c0-0209c05e5680,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-299c95a0-d824-41bf-a839-434e7dfe4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-36b06535-af55-4c70-88cd-f6268b4b0c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742296175-172.17.0.8-1598633052711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-7fd1742b-9ed8-4c54-8e24-4ea666821e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-ede40af7-ddb7-407a-9da9-e595582eb642,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-2cae0148-0344-453e-a487-59b90088c994,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-93bb66bc-0983-4f8e-95c4-b7c0cd247948,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-ecc7fdec-3458-4b6d-91db-571037159d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-ed5348c4-c841-43de-97c0-0209c05e5680,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-299c95a0-d824-41bf-a839-434e7dfe4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-36b06535-af55-4c70-88cd-f6268b4b0c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672858922-172.17.0.8-1598633387744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-836ee747-5264-4e60-8041-9e04ce09ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-19c26745-5c8d-4444-a2f4-66b504ea85e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-11fff8d4-066e-4dbf-81d3-ca3fc9591747,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-5f6fb893-d2c5-4e12-8509-41fce4c1b758,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-b33e03b9-ceca-4041-92b1-1160aac036ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-be38adb2-fe04-4131-afbf-4cbe805b7136,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-d5d9db19-dae1-469d-83e9-d401ce683352,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-80c7544b-c60b-4aed-8913-c92b2d6ce62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672858922-172.17.0.8-1598633387744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-836ee747-5264-4e60-8041-9e04ce09ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-19c26745-5c8d-4444-a2f4-66b504ea85e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-11fff8d4-066e-4dbf-81d3-ca3fc9591747,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-5f6fb893-d2c5-4e12-8509-41fce4c1b758,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-b33e03b9-ceca-4041-92b1-1160aac036ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-be38adb2-fe04-4131-afbf-4cbe805b7136,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-d5d9db19-dae1-469d-83e9-d401ce683352,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-80c7544b-c60b-4aed-8913-c92b2d6ce62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765558026-172.17.0.8-1598633551345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-7f08eafd-f8ea-4588-a31b-0ecdc8a4feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-248d7130-cc7f-4e75-a155-10bc80c8fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-49a0ee3a-bbb0-4523-836b-621dd20aa7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-7edc1c4c-9a7a-4f26-a0b3-8fe7c3781666,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-bada3667-547f-49dc-b108-4e9e65867bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-d9e67665-4b8c-4cbf-830e-4f6eeebc6299,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-cc552718-1782-4f16-b0b9-ff6b6a580716,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-7cfa8503-c545-407d-ac8d-b2cd2a7616eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765558026-172.17.0.8-1598633551345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-7f08eafd-f8ea-4588-a31b-0ecdc8a4feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-248d7130-cc7f-4e75-a155-10bc80c8fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-49a0ee3a-bbb0-4523-836b-621dd20aa7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-7edc1c4c-9a7a-4f26-a0b3-8fe7c3781666,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-bada3667-547f-49dc-b108-4e9e65867bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-d9e67665-4b8c-4cbf-830e-4f6eeebc6299,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-cc552718-1782-4f16-b0b9-ff6b6a580716,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-7cfa8503-c545-407d-ac8d-b2cd2a7616eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726125634-172.17.0.8-1598633764288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-a681b4e9-6f8b-4da6-892c-0810d72003f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-87905090-e92f-4612-b553-103223fd2853,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-1219e2ea-78de-45d4-a506-f3c3f4498a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-79493c08-9b69-4831-accc-4c2710f5aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-93da0819-9f3b-4f2a-99ea-a57e90df6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-8d57f02e-9141-4ba0-88a5-4d44dadf4585,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-665930ce-8a04-440a-b9cd-3ab32ef87154,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-c8009fa5-a1c2-488f-b681-c4aa24da2736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726125634-172.17.0.8-1598633764288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-a681b4e9-6f8b-4da6-892c-0810d72003f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-87905090-e92f-4612-b553-103223fd2853,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-1219e2ea-78de-45d4-a506-f3c3f4498a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-79493c08-9b69-4831-accc-4c2710f5aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-93da0819-9f3b-4f2a-99ea-a57e90df6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-8d57f02e-9141-4ba0-88a5-4d44dadf4585,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-665930ce-8a04-440a-b9cd-3ab32ef87154,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-c8009fa5-a1c2-488f-b681-c4aa24da2736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024046434-172.17.0.8-1598634157395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-a19385d6-4d26-472a-b0a4-d4ae88dacb88,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d2d19e83-1c57-4ceb-98a7-7879074315f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-6f1419b4-8e7e-48dc-86d6-cfdb1319bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-13c3318c-be20-4597-90f5-a6246309ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-49221df9-07b9-4333-9ba6-5765b28e4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-1200a14a-3a0a-42b0-a76b-258414e7c4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-25a70b2c-a297-4f81-8242-34e52efd059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-83e96c00-a466-411f-b109-7278db0b3662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024046434-172.17.0.8-1598634157395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-a19385d6-4d26-472a-b0a4-d4ae88dacb88,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d2d19e83-1c57-4ceb-98a7-7879074315f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-6f1419b4-8e7e-48dc-86d6-cfdb1319bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-13c3318c-be20-4597-90f5-a6246309ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-49221df9-07b9-4333-9ba6-5765b28e4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-1200a14a-3a0a-42b0-a76b-258414e7c4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-25a70b2c-a297-4f81-8242-34e52efd059c,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-83e96c00-a466-411f-b109-7278db0b3662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274277817-172.17.0.8-1598634410544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-e47e2bc6-0c23-4c37-91f5-8cae533c1ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-0cdd4720-a414-4dba-b373-eb64bd7ef856,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-43d55727-d73d-4ee1-a070-e4a3671a9358,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-180bed87-243f-44f6-8f9e-3a519a66a7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-687b0943-de35-4623-9c21-3b8c1f86b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-453265de-77ab-40f6-a70f-a38f1332f225,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-58e36c0c-af84-4f6b-866f-550dd96f0a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-6ef517c2-eff9-4552-9270-967f6fadc458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274277817-172.17.0.8-1598634410544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-e47e2bc6-0c23-4c37-91f5-8cae533c1ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-0cdd4720-a414-4dba-b373-eb64bd7ef856,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-43d55727-d73d-4ee1-a070-e4a3671a9358,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-180bed87-243f-44f6-8f9e-3a519a66a7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-687b0943-de35-4623-9c21-3b8c1f86b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-453265de-77ab-40f6-a70f-a38f1332f225,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-58e36c0c-af84-4f6b-866f-550dd96f0a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-6ef517c2-eff9-4552-9270-967f6fadc458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651767007-172.17.0.8-1598634643900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-ba74fcdb-2d2b-4932-969d-4a18903c1f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-6e5d123c-25cc-4ff7-9e5a-ddaa642686bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-b96f87c7-756c-4646-826c-61960f1509e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-f1381e42-3285-4b72-9d3a-e8b482e7ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-1e80fd69-72d5-4c2e-8817-251381a3ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-71bfaf8d-309b-45d6-a83d-2e6f970f2ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-4c6985bd-3e31-4629-b4c4-a8e43a379e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-542f9261-e893-44ab-90d8-421386911859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651767007-172.17.0.8-1598634643900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-ba74fcdb-2d2b-4932-969d-4a18903c1f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-6e5d123c-25cc-4ff7-9e5a-ddaa642686bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-b96f87c7-756c-4646-826c-61960f1509e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-f1381e42-3285-4b72-9d3a-e8b482e7ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-1e80fd69-72d5-4c2e-8817-251381a3ec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-71bfaf8d-309b-45d6-a83d-2e6f970f2ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-4c6985bd-3e31-4629-b4c4-a8e43a379e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-542f9261-e893-44ab-90d8-421386911859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778340412-172.17.0.8-1598634849858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-01562af4-f408-4272-9653-a33bfbfc47fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-799120e4-f3ee-4351-bc4b-0d08e5b5846c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-36b64288-4cc1-4ed1-9b32-6eb08de00c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d5e99ee8-7c8b-42f3-a9ec-1bc1bd4c7ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-6f344c72-9cfa-4fee-91e6-23b8a355b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-d1800e09-87f7-4de1-8c9f-d5cfe38a92c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2693d720-7e87-488d-b564-6c3a5dfd4206,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-1d5b12cb-f89b-45ff-aa47-0298204bfd6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778340412-172.17.0.8-1598634849858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-01562af4-f408-4272-9653-a33bfbfc47fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-799120e4-f3ee-4351-bc4b-0d08e5b5846c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-36b64288-4cc1-4ed1-9b32-6eb08de00c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d5e99ee8-7c8b-42f3-a9ec-1bc1bd4c7ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-6f344c72-9cfa-4fee-91e6-23b8a355b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-d1800e09-87f7-4de1-8c9f-d5cfe38a92c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2693d720-7e87-488d-b564-6c3a5dfd4206,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-1d5b12cb-f89b-45ff-aa47-0298204bfd6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90911579-172.17.0.8-1598634889134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-ed804513-02fd-4ed9-9590-2d85abdb0de4,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-f5a3c922-c78c-440f-ba2f-a9c29fb9f973,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-116b342c-af06-4e77-84e8-410b136b2520,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ff284032-9a55-4dd8-a6b8-b8218474c0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-dfdc9ab9-3ad7-4cca-853d-389ce95c076f,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6df5652e-172f-46ec-98d2-a9f2715fe50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-26f1c597-1b1b-4808-b7ca-a3de72890715,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-ed392417-3370-46f2-a7b6-c05450d38c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90911579-172.17.0.8-1598634889134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-ed804513-02fd-4ed9-9590-2d85abdb0de4,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-f5a3c922-c78c-440f-ba2f-a9c29fb9f973,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-116b342c-af06-4e77-84e8-410b136b2520,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ff284032-9a55-4dd8-a6b8-b8218474c0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-dfdc9ab9-3ad7-4cca-853d-389ce95c076f,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-6df5652e-172f-46ec-98d2-a9f2715fe50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-26f1c597-1b1b-4808-b7ca-a3de72890715,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-ed392417-3370-46f2-a7b6-c05450d38c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781723487-172.17.0.8-1598634994870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-ea87ff42-b9f6-43f4-a57a-6680e0179881,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d81fec74-d6db-4981-9eca-a84d14195bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-e0361ce4-b4b9-44fa-afcb-66237402c8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-1246f55d-afc9-400e-8ee8-e7fd06894716,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-0b3c7c3a-3fa8-4ffc-9e37-ee87419f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-1a4770c1-d049-4e95-9133-d525c8a892e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-aed872e0-5d43-47db-96d3-691c6a5fb9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0a2a0498-e80f-42eb-b70a-19c49e604b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781723487-172.17.0.8-1598634994870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-ea87ff42-b9f6-43f4-a57a-6680e0179881,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d81fec74-d6db-4981-9eca-a84d14195bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-e0361ce4-b4b9-44fa-afcb-66237402c8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-1246f55d-afc9-400e-8ee8-e7fd06894716,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-0b3c7c3a-3fa8-4ffc-9e37-ee87419f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-1a4770c1-d049-4e95-9133-d525c8a892e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-aed872e0-5d43-47db-96d3-691c6a5fb9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0a2a0498-e80f-42eb-b70a-19c49e604b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719162419-172.17.0.8-1598635557245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-a6a9fb82-a1e1-41a7-a406-221e4d9b9c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-3e8e8d23-0b28-4c31-8836-f7f7f8cc0312,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-620b3f1d-5f15-4eca-a85b-e1bd998e95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-42d353fa-7b9b-4b3f-9ea7-18f53c45d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-e2f02307-fac4-46e3-ab15-74b75b30cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-a9003944-3d69-49e6-8de8-66226f0fa266,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-cbf71659-affd-4a62-95d2-5566e8bc779a,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-38892dc8-d3ea-4710-a745-bbb4d600d891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719162419-172.17.0.8-1598635557245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-a6a9fb82-a1e1-41a7-a406-221e4d9b9c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-3e8e8d23-0b28-4c31-8836-f7f7f8cc0312,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-620b3f1d-5f15-4eca-a85b-e1bd998e95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-42d353fa-7b9b-4b3f-9ea7-18f53c45d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-e2f02307-fac4-46e3-ab15-74b75b30cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-a9003944-3d69-49e6-8de8-66226f0fa266,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-cbf71659-affd-4a62-95d2-5566e8bc779a,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-38892dc8-d3ea-4710-a745-bbb4d600d891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792767903-172.17.0.8-1598635589148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-74347f95-bd8a-40e8-98de-dac27f555a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-37d7f282-0b05-4417-b8cc-4b2944a85196,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-319784c3-5308-4cd9-90ab-7281d2809b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-4b3148d1-7408-4a99-b8d6-535f513cbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-597534dc-61db-4490-b3a1-1dd9da3ada9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-67d433e6-51f3-4870-96b3-70765a9b6746,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-58f8826e-d3f7-4687-9258-e05bfba5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-8477464a-a635-42a3-988a-9267fe1a5f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792767903-172.17.0.8-1598635589148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-74347f95-bd8a-40e8-98de-dac27f555a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-37d7f282-0b05-4417-b8cc-4b2944a85196,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-319784c3-5308-4cd9-90ab-7281d2809b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-4b3148d1-7408-4a99-b8d6-535f513cbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-597534dc-61db-4490-b3a1-1dd9da3ada9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-67d433e6-51f3-4870-96b3-70765a9b6746,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-58f8826e-d3f7-4687-9258-e05bfba5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-8477464a-a635-42a3-988a-9267fe1a5f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547179407-172.17.0.8-1598635659805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-797a1205-ce17-4932-94ae-d774f8817c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2c04d92b-acd4-4344-8bfd-97c6012482e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-51b96745-6496-4ab8-9280-226aad449c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-b5ceac31-61f9-46fb-a26d-d1d0553c8e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-fd163eb5-f971-422e-944a-2862c7a7501d,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-70fa39e6-2941-4526-ad4d-6a9beb790e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-acce47a1-1920-4efb-81ac-3ff5820d69d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-d698bd47-10bd-4c1d-9d83-f336c659fffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547179407-172.17.0.8-1598635659805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-797a1205-ce17-4932-94ae-d774f8817c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2c04d92b-acd4-4344-8bfd-97c6012482e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-51b96745-6496-4ab8-9280-226aad449c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-b5ceac31-61f9-46fb-a26d-d1d0553c8e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-fd163eb5-f971-422e-944a-2862c7a7501d,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-70fa39e6-2941-4526-ad4d-6a9beb790e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-acce47a1-1920-4efb-81ac-3ff5820d69d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-d698bd47-10bd-4c1d-9d83-f336c659fffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981121820-172.17.0.8-1598635735823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38478,DS-a76ecb8f-7936-41a9-bb24-46c290faaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d022d240-328f-4834-83d8-7b6d59bbf4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-f4a691ce-2d71-4bf6-9e32-f246265f9ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-8203bbe2-f5cd-41e1-a069-183063c668c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-dce23b46-25f4-4cff-8d9c-cdb113037439,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-4e224b08-a8ef-44da-8687-7ba66a103f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b5ccd501-00ad-4179-98e8-ef5b8c15885c,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b0f8cf4c-fef5-4654-a56b-c5ea5b6e82d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981121820-172.17.0.8-1598635735823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38478,DS-a76ecb8f-7936-41a9-bb24-46c290faaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d022d240-328f-4834-83d8-7b6d59bbf4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-f4a691ce-2d71-4bf6-9e32-f246265f9ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-8203bbe2-f5cd-41e1-a069-183063c668c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-dce23b46-25f4-4cff-8d9c-cdb113037439,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-4e224b08-a8ef-44da-8687-7ba66a103f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b5ccd501-00ad-4179-98e8-ef5b8c15885c,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b0f8cf4c-fef5-4654-a56b-c5ea5b6e82d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2628110-172.17.0.8-1598635807100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-f188e979-6be3-436e-959b-78b0b1fb3935,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-bc238b82-257f-4d27-b452-db009643fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-fb2fa913-1c77-497b-a1ed-6bbe78f98d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-9ca8bfc3-dabf-4a5a-abf7-138dc2fcb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-147dc357-b0c1-473e-bea9-0b08cddc16c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4b104326-94f5-45d5-bbdb-e9f9a467a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-9ec2e3ac-a1ce-4bac-b9c9-0f092f140814,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-109f92e8-2478-4b9c-b245-7373f465deda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2628110-172.17.0.8-1598635807100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-f188e979-6be3-436e-959b-78b0b1fb3935,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-bc238b82-257f-4d27-b452-db009643fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-fb2fa913-1c77-497b-a1ed-6bbe78f98d50,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-9ca8bfc3-dabf-4a5a-abf7-138dc2fcb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-147dc357-b0c1-473e-bea9-0b08cddc16c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4b104326-94f5-45d5-bbdb-e9f9a467a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-9ec2e3ac-a1ce-4bac-b9c9-0f092f140814,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-109f92e8-2478-4b9c-b245-7373f465deda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152188693-172.17.0.8-1598636168903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-12642b61-1522-4a1f-9075-5a0a3e24203a,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-76f85dfa-a248-4e89-a336-9635f8769151,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-8f34ce42-17c9-4d8a-ba2d-cf332f175504,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-f9d7c1b9-f17d-4ba9-94c6-b105db999202,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-340c67c3-91a6-49f6-b7f5-c589f8c16134,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-fe5d1b76-67a8-4db0-be69-7ffc83308a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-918c1567-e0ae-4cba-93a6-ab11c3d2ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-04af494d-f8cb-4bb8-903f-ff2f7233a145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152188693-172.17.0.8-1598636168903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-12642b61-1522-4a1f-9075-5a0a3e24203a,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-76f85dfa-a248-4e89-a336-9635f8769151,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-8f34ce42-17c9-4d8a-ba2d-cf332f175504,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-f9d7c1b9-f17d-4ba9-94c6-b105db999202,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-340c67c3-91a6-49f6-b7f5-c589f8c16134,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-fe5d1b76-67a8-4db0-be69-7ffc83308a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-918c1567-e0ae-4cba-93a6-ab11c3d2ad6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-04af494d-f8cb-4bb8-903f-ff2f7233a145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246585324-172.17.0.8-1598636304541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-1f919cf9-f722-4643-887c-1f29699b7328,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a33ce365-e198-4391-a2ad-900fd57c2028,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-e88d74fa-58eb-4d05-a738-51ead328ef47,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f9f4cc1e-4cee-4063-bc4d-b9669a4da946,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-d0fcd946-34a1-4b1e-bb88-5ef3e1b975ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-cbb7c7d6-2772-4cb9-9930-08a1f792c906,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-878a557f-c4c1-42e3-8a4a-12d731a63629,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-165e63ae-a17c-46c8-b8f8-b8bc6f1feee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246585324-172.17.0.8-1598636304541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-1f919cf9-f722-4643-887c-1f29699b7328,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-a33ce365-e198-4391-a2ad-900fd57c2028,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-e88d74fa-58eb-4d05-a738-51ead328ef47,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f9f4cc1e-4cee-4063-bc4d-b9669a4da946,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-d0fcd946-34a1-4b1e-bb88-5ef3e1b975ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-cbb7c7d6-2772-4cb9-9930-08a1f792c906,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-878a557f-c4c1-42e3-8a4a-12d731a63629,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-165e63ae-a17c-46c8-b8f8-b8bc6f1feee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710190239-172.17.0.8-1598636483279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-0097f967-5d4d-4ef1-b386-c92488369408,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-90f5cc39-8067-48e3-96f1-f63fc6f5e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b02f891d-b595-4e2f-9ea4-7c683b91df56,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-3bd2bee2-9688-42e8-a5b3-47f7b44bd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-53881ba2-bd29-41c5-ad5c-bda1f9893177,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-4ed1d4ce-4c31-4bd2-a007-5caab7f23b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-92a835f4-30dc-4c83-93f8-fe8ee113085d,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-71bfa2e4-67b0-4ef9-8536-4295368568e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710190239-172.17.0.8-1598636483279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-0097f967-5d4d-4ef1-b386-c92488369408,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-90f5cc39-8067-48e3-96f1-f63fc6f5e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b02f891d-b595-4e2f-9ea4-7c683b91df56,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-3bd2bee2-9688-42e8-a5b3-47f7b44bd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-53881ba2-bd29-41c5-ad5c-bda1f9893177,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-4ed1d4ce-4c31-4bd2-a007-5caab7f23b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-92a835f4-30dc-4c83-93f8-fe8ee113085d,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-71bfa2e4-67b0-4ef9-8536-4295368568e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517412106-172.17.0.8-1598636588316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-3d94a750-674c-441d-b58c-6ab8cf8d4615,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-82e01c21-3efb-4332-973a-9fa082492966,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-0b300a8a-ba61-4d0b-bc6e-0579dc1d435e,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-614a3ace-1a82-43c3-8df4-3aa8a747f634,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-9359190f-575a-4e76-907e-86be5241ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-ff1e38b4-2c55-4c26-940c-1ed1a548d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-a0ce857e-5120-4593-afc0-64d2a81c9bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d37851f-4fcc-402d-be9d-90e41be8d10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517412106-172.17.0.8-1598636588316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-3d94a750-674c-441d-b58c-6ab8cf8d4615,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-82e01c21-3efb-4332-973a-9fa082492966,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-0b300a8a-ba61-4d0b-bc6e-0579dc1d435e,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-614a3ace-1a82-43c3-8df4-3aa8a747f634,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-9359190f-575a-4e76-907e-86be5241ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-ff1e38b4-2c55-4c26-940c-1ed1a548d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-a0ce857e-5120-4593-afc0-64d2a81c9bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1d37851f-4fcc-402d-be9d-90e41be8d10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379440674-172.17.0.8-1598637252197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44181,DS-f7a9ac6c-7808-4709-a905-adf9d8f2b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-b9c439f7-0bb4-4fbd-8754-b09f1e50ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-ac16fd90-9ef7-467e-9591-f00b4e5cf3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-51b175fc-f374-4829-b639-e4b9ca3549df,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-b0644475-6c91-44b3-834b-3605d28a2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d4882bbe-3930-4243-89c1-8f8671949fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-633c4c56-ee62-446d-8158-b10184f8dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-b543d12a-5d44-49e2-a834-4cf59337e9e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379440674-172.17.0.8-1598637252197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44181,DS-f7a9ac6c-7808-4709-a905-adf9d8f2b4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-b9c439f7-0bb4-4fbd-8754-b09f1e50ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-ac16fd90-9ef7-467e-9591-f00b4e5cf3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-51b175fc-f374-4829-b639-e4b9ca3549df,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-b0644475-6c91-44b3-834b-3605d28a2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d4882bbe-3930-4243-89c1-8f8671949fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-633c4c56-ee62-446d-8158-b10184f8dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-b543d12a-5d44-49e2-a834-4cf59337e9e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4958
