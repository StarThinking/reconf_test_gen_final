reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395642056-172.17.0.12-1598689598885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-169bc923-fa10-438f-bc67-40aed309d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-641d3dd0-159c-4d07-9093-037c2b4e5f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-70e2d738-c1eb-4f02-9c66-b2e42f29bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-3feaf296-2981-43bd-86c1-c17bd9d2af60,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-bd79f6b9-53e1-4c8f-8980-819348a0758a,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-e0ad7145-75a2-49dc-9c78-2559e8f278e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-26df9de1-5fe7-40a3-8d5b-f8fa4f891d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-acb6a466-d6c4-47bc-a7b1-b41e9e64cc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395642056-172.17.0.12-1598689598885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-169bc923-fa10-438f-bc67-40aed309d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-641d3dd0-159c-4d07-9093-037c2b4e5f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-70e2d738-c1eb-4f02-9c66-b2e42f29bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-3feaf296-2981-43bd-86c1-c17bd9d2af60,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-bd79f6b9-53e1-4c8f-8980-819348a0758a,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-e0ad7145-75a2-49dc-9c78-2559e8f278e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-26df9de1-5fe7-40a3-8d5b-f8fa4f891d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-acb6a466-d6c4-47bc-a7b1-b41e9e64cc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021989020-172.17.0.12-1598689778423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-cdeaa417-3697-43f9-b804-63e2dfcd71a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-6b557074-cb91-4708-87d8-aeaa9243fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-e57e6f17-b1a3-4078-8957-17042b1d99ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-0eb3d4ec-9dbb-4e28-9631-46d7680cbbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-8bee21d9-f041-4ef3-a4c6-ca5d7026b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-1f2a1323-da4e-44f4-8c91-b883513625a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-20377d07-00f2-41f1-bf9e-9133531d5e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-60dd9f4a-0800-424e-8065-2a6e07194b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021989020-172.17.0.12-1598689778423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-cdeaa417-3697-43f9-b804-63e2dfcd71a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-6b557074-cb91-4708-87d8-aeaa9243fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-e57e6f17-b1a3-4078-8957-17042b1d99ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-0eb3d4ec-9dbb-4e28-9631-46d7680cbbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-8bee21d9-f041-4ef3-a4c6-ca5d7026b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-1f2a1323-da4e-44f4-8c91-b883513625a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-20377d07-00f2-41f1-bf9e-9133531d5e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-60dd9f4a-0800-424e-8065-2a6e07194b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312235518-172.17.0.12-1598689946448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33847,DS-7926a0ea-769b-472f-9bc6-2cdaa691f715,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-5b881f5e-98cd-47ed-93da-242781853e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-e9072860-046c-4103-ab76-a2eeb5486c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-86247c1b-8f9e-40e5-b72c-03fd706d0691,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-92beaf71-8c66-4a9a-a60d-5ac7c638d566,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-e2af704b-1c6e-4b67-bead-437a0b5df988,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d9733a3b-840e-4be9-87a0-9f4360db942c,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-85c439b8-2c9f-4aa9-bd03-4351b95758c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312235518-172.17.0.12-1598689946448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33847,DS-7926a0ea-769b-472f-9bc6-2cdaa691f715,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-5b881f5e-98cd-47ed-93da-242781853e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-e9072860-046c-4103-ab76-a2eeb5486c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-86247c1b-8f9e-40e5-b72c-03fd706d0691,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-92beaf71-8c66-4a9a-a60d-5ac7c638d566,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-e2af704b-1c6e-4b67-bead-437a0b5df988,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d9733a3b-840e-4be9-87a0-9f4360db942c,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-85c439b8-2c9f-4aa9-bd03-4351b95758c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468653906-172.17.0.12-1598690415671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-e45be263-c145-4f4b-a5f5-5a783579be68,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-93a60692-be51-4e0a-a796-8b39e3c44ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-d9b00b5f-ff11-4b0c-880c-876bbf03082c,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-9dcf662f-ab12-46b8-aee6-2a25d250fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-57e3014e-0d4a-4586-9e40-d1a208e2df0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fdc2f458-fed0-44e6-9c35-8cd660cb7e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-3e1f3618-3835-46cc-8a08-50a5c621f340,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-fc5909c4-3c21-427c-9671-94d9f375dbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468653906-172.17.0.12-1598690415671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-e45be263-c145-4f4b-a5f5-5a783579be68,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-93a60692-be51-4e0a-a796-8b39e3c44ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-d9b00b5f-ff11-4b0c-880c-876bbf03082c,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-9dcf662f-ab12-46b8-aee6-2a25d250fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-57e3014e-0d4a-4586-9e40-d1a208e2df0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fdc2f458-fed0-44e6-9c35-8cd660cb7e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-3e1f3618-3835-46cc-8a08-50a5c621f340,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-fc5909c4-3c21-427c-9671-94d9f375dbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606130315-172.17.0.12-1598690478401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-4c0d5a8a-c27d-404d-b312-d4c125bece94,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-bb0dfe8e-c877-401c-b7b9-9106ed06c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-41e0ea9b-b128-447a-9de3-888f047a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-70778794-42ff-4893-88f1-d7b2e5c44d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-a9ac8fa7-9321-4c27-b834-fe55f31bef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-62834894-1122-448c-92a9-6ca26f28b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d6ae1279-d1d7-466e-a456-a583bc015a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-b64a48d3-a594-48ac-8106-aabfda093efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606130315-172.17.0.12-1598690478401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-4c0d5a8a-c27d-404d-b312-d4c125bece94,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-bb0dfe8e-c877-401c-b7b9-9106ed06c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-41e0ea9b-b128-447a-9de3-888f047a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-70778794-42ff-4893-88f1-d7b2e5c44d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-a9ac8fa7-9321-4c27-b834-fe55f31bef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-62834894-1122-448c-92a9-6ca26f28b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d6ae1279-d1d7-466e-a456-a583bc015a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-b64a48d3-a594-48ac-8106-aabfda093efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962888175-172.17.0.12-1598690551975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-5cc8e215-65b7-49fa-b73d-b64d0b7b0320,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-db58b000-852c-47c4-8732-4e96342a7701,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-88c0149a-1514-4f51-bb37-8d19a891e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-9f6a323c-58d8-4928-95a3-99cf04d7e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-92e8f6a7-0fe1-4cbf-a23f-3467ec64a215,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-10fef5fe-5172-49a7-a2e6-992a432da364,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9840d536-bfc4-4621-aa6d-7b8ac76e6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-8af43c49-f07c-43ad-bbbd-ac4ce9bc53b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962888175-172.17.0.12-1598690551975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-5cc8e215-65b7-49fa-b73d-b64d0b7b0320,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-db58b000-852c-47c4-8732-4e96342a7701,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-88c0149a-1514-4f51-bb37-8d19a891e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-9f6a323c-58d8-4928-95a3-99cf04d7e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-92e8f6a7-0fe1-4cbf-a23f-3467ec64a215,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-10fef5fe-5172-49a7-a2e6-992a432da364,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9840d536-bfc4-4621-aa6d-7b8ac76e6c95,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-8af43c49-f07c-43ad-bbbd-ac4ce9bc53b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464367936-172.17.0.12-1598690585479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-b663dee3-f7c3-4fe8-b7eb-a8ae0c994c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-65d0261b-f4af-430d-a6f5-0f9338ba4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-41f0e155-aa05-47a7-8735-632b64d0797c,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-8b243270-8068-4fce-9595-b97c070a84b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-557a82ba-41d4-4629-a399-d848d7574c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-70aca839-14bc-4f06-9801-eec6bb0cbd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-457d5284-c43b-411c-8d3c-ce64fb009629,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-2b9731b6-2f10-4a72-ad62-e118682129af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464367936-172.17.0.12-1598690585479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-b663dee3-f7c3-4fe8-b7eb-a8ae0c994c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-65d0261b-f4af-430d-a6f5-0f9338ba4cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-41f0e155-aa05-47a7-8735-632b64d0797c,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-8b243270-8068-4fce-9595-b97c070a84b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-557a82ba-41d4-4629-a399-d848d7574c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-70aca839-14bc-4f06-9801-eec6bb0cbd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-457d5284-c43b-411c-8d3c-ce64fb009629,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-2b9731b6-2f10-4a72-ad62-e118682129af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268439602-172.17.0.12-1598691632098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36257,DS-a7e1c8a0-685a-41f2-bfde-06b20d258923,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-61c9730e-62a7-42fa-85e3-9f81d7493724,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-887946b4-f6af-45d3-82e0-6d1a2107e810,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-54f2fec0-a95f-4e5f-9ae0-9d6bb17965e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-de6ca07b-1976-4009-bcfe-664481356e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-49a9a36a-b8ca-494e-8f56-99339b3efeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c3cf66ef-0e42-4120-a2be-08d2d10a4cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-6850e053-4b7c-4c6c-b149-b50cb8079c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268439602-172.17.0.12-1598691632098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36257,DS-a7e1c8a0-685a-41f2-bfde-06b20d258923,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-61c9730e-62a7-42fa-85e3-9f81d7493724,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-887946b4-f6af-45d3-82e0-6d1a2107e810,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-54f2fec0-a95f-4e5f-9ae0-9d6bb17965e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-de6ca07b-1976-4009-bcfe-664481356e72,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-49a9a36a-b8ca-494e-8f56-99339b3efeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c3cf66ef-0e42-4120-a2be-08d2d10a4cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-6850e053-4b7c-4c6c-b149-b50cb8079c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977970081-172.17.0.12-1598692141916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39364,DS-10c1f7e6-75e6-4bbf-900f-a24c91016ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-d13dfb0a-faf3-4d8a-a0f3-debddc0a6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-f71be6ab-c9f9-4dee-9597-a91cec219498,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-644e28ff-4d1b-460c-85bc-2236d6ba4857,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-7df45594-1e10-4402-b9a4-3daea66a3168,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-c022ac3a-6fd0-4b44-a793-e15a98e77dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-9ea5aa1a-98e5-4a0b-b2ac-771bffa85fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-903da309-6369-445a-a4d1-ed4b4270c6e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977970081-172.17.0.12-1598692141916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39364,DS-10c1f7e6-75e6-4bbf-900f-a24c91016ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-d13dfb0a-faf3-4d8a-a0f3-debddc0a6dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-f71be6ab-c9f9-4dee-9597-a91cec219498,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-644e28ff-4d1b-460c-85bc-2236d6ba4857,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-7df45594-1e10-4402-b9a4-3daea66a3168,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-c022ac3a-6fd0-4b44-a793-e15a98e77dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-9ea5aa1a-98e5-4a0b-b2ac-771bffa85fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-903da309-6369-445a-a4d1-ed4b4270c6e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548740361-172.17.0.12-1598692251612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-55f60227-b166-4bdf-af67-586d8662e007,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-e4b95398-d59d-4e6e-ae2d-cb9c70e8eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5c1f59c6-d9db-4bfa-99f8-a33c429c2964,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-3b8946ba-69f2-4169-8b0e-2e4bdc4a3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-25fd9f74-171f-4f5f-b47b-6750f6deb590,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-2bb051bb-4f43-4195-b7e6-9cd4b0ec38af,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-948dabf3-95ba-450a-acd5-1e4a7cc86672,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-dde8064d-006f-4d0a-be1c-ba723c3d8101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548740361-172.17.0.12-1598692251612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-55f60227-b166-4bdf-af67-586d8662e007,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-e4b95398-d59d-4e6e-ae2d-cb9c70e8eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5c1f59c6-d9db-4bfa-99f8-a33c429c2964,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-3b8946ba-69f2-4169-8b0e-2e4bdc4a3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-25fd9f74-171f-4f5f-b47b-6750f6deb590,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-2bb051bb-4f43-4195-b7e6-9cd4b0ec38af,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-948dabf3-95ba-450a-acd5-1e4a7cc86672,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-dde8064d-006f-4d0a-be1c-ba723c3d8101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256742277-172.17.0.12-1598692326131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-dd66329a-a264-49b3-a2b5-db4351a25516,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f961bdc7-81ea-4105-85d4-68e1ea15f697,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-e75907e1-6319-4599-8937-8b84fb445ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-d9117402-7171-4ffd-8f07-fd49528943f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-0117fef0-5eb0-4324-9099-fcae48bd291f,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1c033dd5-d034-4e85-b25c-5425dc10f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-84017a0d-570b-474e-b262-7381f4cc25ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-f6ce5e7b-56a7-480b-804a-0ac7b6551c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256742277-172.17.0.12-1598692326131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-dd66329a-a264-49b3-a2b5-db4351a25516,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f961bdc7-81ea-4105-85d4-68e1ea15f697,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-e75907e1-6319-4599-8937-8b84fb445ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-d9117402-7171-4ffd-8f07-fd49528943f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-0117fef0-5eb0-4324-9099-fcae48bd291f,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-1c033dd5-d034-4e85-b25c-5425dc10f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-84017a0d-570b-474e-b262-7381f4cc25ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-f6ce5e7b-56a7-480b-804a-0ac7b6551c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040336496-172.17.0.12-1598692582250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-39b3aaca-6533-480d-ae47-562637c14968,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-7a90c4b3-714d-4cc9-b25e-d756b09ce181,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-d3d50b2f-f232-432f-b8c9-db72898b8303,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b83db779-481b-4694-9c3d-77b6eed9fe01,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-03b23749-d520-4919-a6c1-342acef4bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-7e3bd59f-2fa0-41eb-a1d3-ce86ee27788e,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-eb7b38b5-3c40-480b-88f8-402431cb95ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-92282605-a30c-45a0-906d-a218da11719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040336496-172.17.0.12-1598692582250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-39b3aaca-6533-480d-ae47-562637c14968,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-7a90c4b3-714d-4cc9-b25e-d756b09ce181,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-d3d50b2f-f232-432f-b8c9-db72898b8303,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b83db779-481b-4694-9c3d-77b6eed9fe01,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-03b23749-d520-4919-a6c1-342acef4bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-7e3bd59f-2fa0-41eb-a1d3-ce86ee27788e,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-eb7b38b5-3c40-480b-88f8-402431cb95ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-92282605-a30c-45a0-906d-a218da11719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166199207-172.17.0.12-1598692649106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-8c24593c-d455-457f-b779-c88f30b4f381,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-97444db2-2de0-4f74-89d2-f269269b6c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-a2b4c706-1699-4445-80dc-3d034e6db866,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-dd51d6fe-4627-4d56-80c5-378bbee11c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d3828401-bcee-49d4-8698-064ee5721ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-d04baa19-2497-4041-9419-76911797acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-1453376b-f526-4cc5-aacb-9bac277174f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-2162dc41-ccb8-4040-bb60-030a4dbab542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166199207-172.17.0.12-1598692649106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-8c24593c-d455-457f-b779-c88f30b4f381,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-97444db2-2de0-4f74-89d2-f269269b6c92,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-a2b4c706-1699-4445-80dc-3d034e6db866,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-dd51d6fe-4627-4d56-80c5-378bbee11c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d3828401-bcee-49d4-8698-064ee5721ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-d04baa19-2497-4041-9419-76911797acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-1453376b-f526-4cc5-aacb-9bac277174f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-2162dc41-ccb8-4040-bb60-030a4dbab542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689691026-172.17.0.12-1598692717582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-e274e580-1b48-4cd5-8bfa-1f40db96aa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-b17b4f5e-811f-4413-81d6-be6462d40603,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-511e439e-1a4b-4b17-8865-e8fde0045179,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-d25e34db-40f1-4fe6-bb0e-6af8c0330676,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-709df3e5-7ffc-49fa-a43f-9feb7bdf8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-118e03a5-4b66-4354-9db5-07baaaca4f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-3682f99e-a1d0-4de0-91a0-f764acd34b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f0c86855-4067-461f-a617-01c6d938a7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689691026-172.17.0.12-1598692717582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-e274e580-1b48-4cd5-8bfa-1f40db96aa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-b17b4f5e-811f-4413-81d6-be6462d40603,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-511e439e-1a4b-4b17-8865-e8fde0045179,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-d25e34db-40f1-4fe6-bb0e-6af8c0330676,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-709df3e5-7ffc-49fa-a43f-9feb7bdf8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-118e03a5-4b66-4354-9db5-07baaaca4f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-3682f99e-a1d0-4de0-91a0-f764acd34b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-f0c86855-4067-461f-a617-01c6d938a7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81893406-172.17.0.12-1598692888835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-1613e9ff-e5fc-4a2d-aa94-954d3d2521f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-c5aa6bf9-4fb6-433c-a02c-128f629618ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-4e8ff609-973d-4c93-a723-4a3ad5d4ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-09ccf6df-886e-4190-9937-446a727df469,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-3dab093a-640d-4337-bd87-2b8ed51f8e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-3beae257-4385-48aa-91e9-0cf6393ea4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-6caf4fd0-5a5e-48a9-bd44-ee558240f187,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-2694e026-5b4d-4471-aae1-7db5d0b11846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81893406-172.17.0.12-1598692888835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-1613e9ff-e5fc-4a2d-aa94-954d3d2521f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-c5aa6bf9-4fb6-433c-a02c-128f629618ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-4e8ff609-973d-4c93-a723-4a3ad5d4ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-09ccf6df-886e-4190-9937-446a727df469,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-3dab093a-640d-4337-bd87-2b8ed51f8e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-3beae257-4385-48aa-91e9-0cf6393ea4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-6caf4fd0-5a5e-48a9-bd44-ee558240f187,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-2694e026-5b4d-4471-aae1-7db5d0b11846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529091388-172.17.0.12-1598693282044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-c050e57c-82af-43ec-93da-c300b2fcccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-969a4759-0899-405a-8131-ce09cc93bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-70c03e71-26bf-4a71-bcf5-d1ba77168a90,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-4b5ab904-3e0e-4a63-88ae-77354b3ca421,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d5c5bbb6-ee41-4fc4-b7ef-466a58b18e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-0aded314-44a2-4e1b-bade-832556529c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-e8e89048-2424-48b1-90b6-aeb8b0effd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-79c48ab6-548e-4d23-88e0-a9893b3b2818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529091388-172.17.0.12-1598693282044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-c050e57c-82af-43ec-93da-c300b2fcccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-969a4759-0899-405a-8131-ce09cc93bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-70c03e71-26bf-4a71-bcf5-d1ba77168a90,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-4b5ab904-3e0e-4a63-88ae-77354b3ca421,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-d5c5bbb6-ee41-4fc4-b7ef-466a58b18e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-0aded314-44a2-4e1b-bade-832556529c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-e8e89048-2424-48b1-90b6-aeb8b0effd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-79c48ab6-548e-4d23-88e0-a9893b3b2818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928180810-172.17.0.12-1598693505434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-63b63492-5b2a-4604-89cf-7350faaf081c,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-bcfeb7d1-5182-4ed5-8e1a-aff96fd34743,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b5ef49b4-ea7f-43be-92d9-19931e923d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-2aedb351-2bae-4892-b16a-4279b6f252ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-10a3da1f-968a-4539-9628-a92907889d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-1256f4d0-800e-4586-a881-cb66b9a767ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c79f7c02-8e88-4fa2-af37-a712361437e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-30898f21-ef14-4a91-9fe8-f8e7566e98f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928180810-172.17.0.12-1598693505434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-63b63492-5b2a-4604-89cf-7350faaf081c,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-bcfeb7d1-5182-4ed5-8e1a-aff96fd34743,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-b5ef49b4-ea7f-43be-92d9-19931e923d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-2aedb351-2bae-4892-b16a-4279b6f252ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-10a3da1f-968a-4539-9628-a92907889d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-1256f4d0-800e-4586-a881-cb66b9a767ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-c79f7c02-8e88-4fa2-af37-a712361437e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-30898f21-ef14-4a91-9fe8-f8e7566e98f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759594620-172.17.0.12-1598693687867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-f3ae917d-cf63-4b9b-9006-1a959904b499,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-30add939-40fe-4f7f-b483-a93ab936e125,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-2c2104f7-08bc-4686-871a-d3c2c3ef78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-5f51df3b-dd3c-44c2-952f-6a753b3096ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-df0ca410-36a3-435a-9c0e-597f89e35981,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-9bdd16c3-5aef-458f-a339-8c044a8767b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-af323660-ebfb-4c01-8ca4-288a2222d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-fbe54036-9df5-456c-895e-9f1c043e16e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759594620-172.17.0.12-1598693687867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-f3ae917d-cf63-4b9b-9006-1a959904b499,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-30add939-40fe-4f7f-b483-a93ab936e125,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-2c2104f7-08bc-4686-871a-d3c2c3ef78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-5f51df3b-dd3c-44c2-952f-6a753b3096ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-df0ca410-36a3-435a-9c0e-597f89e35981,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-9bdd16c3-5aef-458f-a339-8c044a8767b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-af323660-ebfb-4c01-8ca4-288a2222d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-fbe54036-9df5-456c-895e-9f1c043e16e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609770074-172.17.0.12-1598693797151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-08cbe10e-758f-4f11-8bc7-7b040724b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-43358cfa-ee20-4260-b5c6-cb740adde6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-8228e7a4-c6bb-4fee-99fe-a5d6acc5d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-473292a4-4e62-4dc8-b7e8-b597c364162a,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-b416700c-6964-4ac6-93ee-bf2bbabc3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-7372d4f8-11e7-40c9-8f28-6f5368ee25c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-9808edd8-3c49-4464-b212-2c436544af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-9fa4fb74-7c64-4413-b150-4ce16dad2b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609770074-172.17.0.12-1598693797151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-08cbe10e-758f-4f11-8bc7-7b040724b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-43358cfa-ee20-4260-b5c6-cb740adde6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-8228e7a4-c6bb-4fee-99fe-a5d6acc5d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-473292a4-4e62-4dc8-b7e8-b597c364162a,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-b416700c-6964-4ac6-93ee-bf2bbabc3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-7372d4f8-11e7-40c9-8f28-6f5368ee25c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-9808edd8-3c49-4464-b212-2c436544af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-9fa4fb74-7c64-4413-b150-4ce16dad2b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191559352-172.17.0.12-1598693944708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41016,DS-955e7ce4-9b15-4a78-9b03-17ce192692d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-762b4c00-9aff-41c1-af53-df5a83b2a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-3af86d2c-2956-4c88-9532-df4600a5a9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-7401cb93-7376-4fad-9c0a-ad856235c086,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-173b4ea5-07a5-4b8e-9474-cc649762e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a2a61624-065a-49f3-821b-033a08e60bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-af3be339-a3e8-4e2b-aab1-abbee1a6af97,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-c15cc8fd-61a9-45b1-ae48-f870cc0b58ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191559352-172.17.0.12-1598693944708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41016,DS-955e7ce4-9b15-4a78-9b03-17ce192692d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-762b4c00-9aff-41c1-af53-df5a83b2a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-3af86d2c-2956-4c88-9532-df4600a5a9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-7401cb93-7376-4fad-9c0a-ad856235c086,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-173b4ea5-07a5-4b8e-9474-cc649762e0de,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a2a61624-065a-49f3-821b-033a08e60bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-af3be339-a3e8-4e2b-aab1-abbee1a6af97,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-c15cc8fd-61a9-45b1-ae48-f870cc0b58ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630096582-172.17.0.12-1598694013787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-05deff66-984c-4153-b984-2128ac966af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-9b0f58a1-99b4-4b12-9ee5-89cc1c9242eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-80a4835b-d5d4-42c2-95d0-ca6722130d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0afad228-537c-4494-b561-a1134fe0afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-2f4b4faa-f507-4e2e-aa36-c4d290cdf071,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-24faef38-56e4-4e2e-b4ab-36c303133137,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-533322fd-3881-4123-86f3-8b7a503805ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-457687dc-0cfa-4c7d-a85f-70c01dc82bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630096582-172.17.0.12-1598694013787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43546,DS-05deff66-984c-4153-b984-2128ac966af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-9b0f58a1-99b4-4b12-9ee5-89cc1c9242eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-80a4835b-d5d4-42c2-95d0-ca6722130d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0afad228-537c-4494-b561-a1134fe0afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-2f4b4faa-f507-4e2e-aa36-c4d290cdf071,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-24faef38-56e4-4e2e-b4ab-36c303133137,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-533322fd-3881-4123-86f3-8b7a503805ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-457687dc-0cfa-4c7d-a85f-70c01dc82bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989728411-172.17.0.12-1598694084023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-8a02cf52-3d84-475a-906d-eaa4a8eed586,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-54ad292d-c6de-40ef-b001-7e872ffbbe09,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-202b5739-e348-4b5a-b24e-a9e266427b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-8e8dd321-2667-4e50-8c13-d27a2ce210e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-2313fe1f-9c17-4ac4-9a78-4e6a8fa466e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-53500f16-953c-4351-b942-744a1b6f272e,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-9271b1f3-11be-4fbe-aac4-3370f69e67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-ec452ff9-b063-4384-a3ae-5e9920105afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989728411-172.17.0.12-1598694084023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-8a02cf52-3d84-475a-906d-eaa4a8eed586,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-54ad292d-c6de-40ef-b001-7e872ffbbe09,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-202b5739-e348-4b5a-b24e-a9e266427b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-8e8dd321-2667-4e50-8c13-d27a2ce210e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-2313fe1f-9c17-4ac4-9a78-4e6a8fa466e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-53500f16-953c-4351-b942-744a1b6f272e,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-9271b1f3-11be-4fbe-aac4-3370f69e67bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-ec452ff9-b063-4384-a3ae-5e9920105afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433608089-172.17.0.12-1598694331569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34337,DS-18958dbc-39de-4702-a3b7-7fa2c367f152,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-f6a03fbd-ab6e-4222-9ddd-769d2a74e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-31213616-6dd2-4865-b88c-fc9313b5fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-dda26b9c-748a-451e-9256-0fd213336578,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-325ce4c2-db8f-4959-a24c-3611e871c098,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-baa2c77d-927f-41f4-b963-89e57b9d3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-b0627a80-b675-44f3-b3a1-0a52c725b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-bda5e7d7-45ea-47c2-a8f0-59bd82e0d03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433608089-172.17.0.12-1598694331569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34337,DS-18958dbc-39de-4702-a3b7-7fa2c367f152,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-f6a03fbd-ab6e-4222-9ddd-769d2a74e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-31213616-6dd2-4865-b88c-fc9313b5fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-dda26b9c-748a-451e-9256-0fd213336578,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-325ce4c2-db8f-4959-a24c-3611e871c098,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-baa2c77d-927f-41f4-b963-89e57b9d3a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-b0627a80-b675-44f3-b3a1-0a52c725b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-bda5e7d7-45ea-47c2-a8f0-59bd82e0d03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764364255-172.17.0.12-1598694475017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-a9ea371d-5754-47a9-ba24-7c2687d3254a,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-538bb48e-9ce1-4481-99e3-1ee9902fb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-81115e69-4cc2-45e8-9fe9-1e852fce29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-25ce3f65-1a09-45fc-b55a-ab9128b031c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-073ec14d-f0a7-4798-9c38-61863378538a,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-0abdbb1b-4c62-4556-b678-7d40bdf5f981,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-384585dc-2f75-4015-b086-f5d7bd4c5b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-54e70856-7522-4ea6-b506-fb8565d4916a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764364255-172.17.0.12-1598694475017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-a9ea371d-5754-47a9-ba24-7c2687d3254a,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-538bb48e-9ce1-4481-99e3-1ee9902fb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-81115e69-4cc2-45e8-9fe9-1e852fce29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-25ce3f65-1a09-45fc-b55a-ab9128b031c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-073ec14d-f0a7-4798-9c38-61863378538a,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-0abdbb1b-4c62-4556-b678-7d40bdf5f981,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-384585dc-2f75-4015-b086-f5d7bd4c5b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-54e70856-7522-4ea6-b506-fb8565d4916a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412980795-172.17.0.12-1598694503869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-9b9f3ff1-389b-4039-a007-55de878e0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-150206ef-aff7-488f-b881-4b34096e50b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-9c7ae452-c19f-42b2-99eb-82215dc184f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0ea29354-6688-425c-9d21-fca2e270cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-ae7c34e6-2217-4d7c-b65c-a496c742f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7843c2d7-c580-41fb-acd7-aad377d04810,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c4962969-8d10-4c0f-8758-9cd118bd9b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-2b8f3ef8-a0f0-4f49-a317-474470cb54c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412980795-172.17.0.12-1598694503869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-9b9f3ff1-389b-4039-a007-55de878e0f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-150206ef-aff7-488f-b881-4b34096e50b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-9c7ae452-c19f-42b2-99eb-82215dc184f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0ea29354-6688-425c-9d21-fca2e270cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-ae7c34e6-2217-4d7c-b65c-a496c742f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7843c2d7-c580-41fb-acd7-aad377d04810,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c4962969-8d10-4c0f-8758-9cd118bd9b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-2b8f3ef8-a0f0-4f49-a317-474470cb54c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5206
