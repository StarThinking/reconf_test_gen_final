reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186608096-172.17.0.9-1598514361605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-49353ed9-8929-4650-8dd8-6e8a9c3ea3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-c6656b2a-8bd6-4982-97df-423aa55e5b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-9b503272-5012-43d2-ad4f-c7f6b4a5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e7528843-ba4b-4cad-ad9d-11c030bc0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-37282354-e776-46da-94d8-0595907df2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-bd2b2ecf-30af-4c42-8df5-1a2eb843e369,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-ef2c97ab-eb29-45dd-b9d6-5011c5ae2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-68f31660-3d79-4690-ae39-97d389238edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186608096-172.17.0.9-1598514361605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-49353ed9-8929-4650-8dd8-6e8a9c3ea3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-c6656b2a-8bd6-4982-97df-423aa55e5b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-9b503272-5012-43d2-ad4f-c7f6b4a5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e7528843-ba4b-4cad-ad9d-11c030bc0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-37282354-e776-46da-94d8-0595907df2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-bd2b2ecf-30af-4c42-8df5-1a2eb843e369,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-ef2c97ab-eb29-45dd-b9d6-5011c5ae2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-68f31660-3d79-4690-ae39-97d389238edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018959158-172.17.0.9-1598514432119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-41b19db1-4129-4756-8e2a-cdc39f979a74,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-d5f0afe1-c594-4c1a-b0fa-bf5f61f86341,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-51553ec3-53e5-43b2-8532-532567ebb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-88d69141-b76a-4426-a020-eed6ef5bb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-b587dd5d-30e9-49ee-a3ff-fd286236de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-fe9088d3-361c-4aa8-9c2a-a419030d9a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-030223e7-8f3d-4c27-a29a-0bdde4e7f704,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-460d05b3-4606-4b6c-bf24-c88adb44e034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018959158-172.17.0.9-1598514432119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-41b19db1-4129-4756-8e2a-cdc39f979a74,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-d5f0afe1-c594-4c1a-b0fa-bf5f61f86341,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-51553ec3-53e5-43b2-8532-532567ebb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-88d69141-b76a-4426-a020-eed6ef5bb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-b587dd5d-30e9-49ee-a3ff-fd286236de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-fe9088d3-361c-4aa8-9c2a-a419030d9a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-030223e7-8f3d-4c27-a29a-0bdde4e7f704,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-460d05b3-4606-4b6c-bf24-c88adb44e034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339849006-172.17.0.9-1598514833795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-2ed3135f-707f-424e-9f58-b8c3f1dcb024,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-bc34176a-1867-4bf9-aca3-658f8e9460e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-9fbbcba0-58ea-47b4-8555-8732bc10ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-03b93785-72b8-434d-9659-f9f3ad1bf028,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-fcdfe04b-8d90-4622-b41a-34871a4d9c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-17bcb14c-3c96-4b7b-b849-0408dd4492ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-da209ea2-9a44-41df-96d8-84d94767d849,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-7284d590-ffe7-4852-8f12-542dbdfaf76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339849006-172.17.0.9-1598514833795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-2ed3135f-707f-424e-9f58-b8c3f1dcb024,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-bc34176a-1867-4bf9-aca3-658f8e9460e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-9fbbcba0-58ea-47b4-8555-8732bc10ce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-03b93785-72b8-434d-9659-f9f3ad1bf028,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-fcdfe04b-8d90-4622-b41a-34871a4d9c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-17bcb14c-3c96-4b7b-b849-0408dd4492ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-da209ea2-9a44-41df-96d8-84d94767d849,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-7284d590-ffe7-4852-8f12-542dbdfaf76c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703004346-172.17.0.9-1598514976656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-35da7190-423f-4ded-8935-bee1df450b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-627c342d-7dc9-461e-bdf9-848dc1c19e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-109e762e-8407-43f4-b714-24cf1af9b782,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-85a67fdb-9551-4b15-9bca-0731aac0becf,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-08d5739c-8487-4364-b0b6-1b42b7588950,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-ecd25df3-f2b7-4cb3-964a-ba1dc8b7cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-82dcfdba-f03b-4f36-b6c9-bf5fc6f66d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-b2bb850a-4c1a-4e20-a106-40c75266ff44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703004346-172.17.0.9-1598514976656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-35da7190-423f-4ded-8935-bee1df450b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-627c342d-7dc9-461e-bdf9-848dc1c19e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-109e762e-8407-43f4-b714-24cf1af9b782,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-85a67fdb-9551-4b15-9bca-0731aac0becf,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-08d5739c-8487-4364-b0b6-1b42b7588950,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-ecd25df3-f2b7-4cb3-964a-ba1dc8b7cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-82dcfdba-f03b-4f36-b6c9-bf5fc6f66d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-b2bb850a-4c1a-4e20-a106-40c75266ff44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094819885-172.17.0.9-1598515011997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-0e4cb7a7-1c26-445e-b5ad-db205d0c68db,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-998d071b-4980-45fe-9052-cfce545ba1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-efbafd61-f5c3-442e-8b6d-306803d4c9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-59e13b1e-3a85-4b96-b8c6-1a052daeb1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-00994b4e-31db-4bce-8c95-daebd0c0d253,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-711d6ac4-b2d0-4fdf-ab70-8289f57251bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4f9be8e9-226e-40b0-8997-cc0a6efffca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-6e532cbc-f632-4839-ae49-0ea362a741bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094819885-172.17.0.9-1598515011997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-0e4cb7a7-1c26-445e-b5ad-db205d0c68db,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-998d071b-4980-45fe-9052-cfce545ba1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-efbafd61-f5c3-442e-8b6d-306803d4c9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-59e13b1e-3a85-4b96-b8c6-1a052daeb1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-00994b4e-31db-4bce-8c95-daebd0c0d253,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-711d6ac4-b2d0-4fdf-ab70-8289f57251bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4f9be8e9-226e-40b0-8997-cc0a6efffca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-6e532cbc-f632-4839-ae49-0ea362a741bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66243930-172.17.0.9-1598515165059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-20a67e7a-6f7d-413c-a186-54a203de5bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-3fd90ce7-6b65-480a-b6de-61aa0dc95652,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-8102defb-816d-4789-9f6d-8d058d36fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d60ef250-d177-40ae-af6b-6a34222f2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-03f47ab9-ed22-4c42-9a39-d12ca3656dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e2a4a4df-9cd9-423e-9dee-5a8b7aea835e,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-856b2959-fe71-47ac-933b-8ac3bad34869,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-a713a39f-dd04-4044-93a0-e882feabd072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66243930-172.17.0.9-1598515165059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-20a67e7a-6f7d-413c-a186-54a203de5bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-3fd90ce7-6b65-480a-b6de-61aa0dc95652,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-8102defb-816d-4789-9f6d-8d058d36fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-d60ef250-d177-40ae-af6b-6a34222f2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-03f47ab9-ed22-4c42-9a39-d12ca3656dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e2a4a4df-9cd9-423e-9dee-5a8b7aea835e,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-856b2959-fe71-47ac-933b-8ac3bad34869,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-a713a39f-dd04-4044-93a0-e882feabd072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496930988-172.17.0.9-1598515738731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-42ba1f37-82cb-444c-86ee-2c40de2218f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-75f27285-f0b1-4a37-9d31-aac3acbafc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-54489731-0f33-4f45-a2ba-b176220bb727,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-59d5319c-64e7-424f-926c-c54a42f54179,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-9caec600-c969-4462-be76-a9055af19816,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-51fd0a0b-1471-4336-8d14-861338f2dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-cb265c9d-f5fa-46b4-bffe-dd3b90d9e136,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-8988b216-66bc-41d1-923a-f450acbe8f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496930988-172.17.0.9-1598515738731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-42ba1f37-82cb-444c-86ee-2c40de2218f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-75f27285-f0b1-4a37-9d31-aac3acbafc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-54489731-0f33-4f45-a2ba-b176220bb727,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-59d5319c-64e7-424f-926c-c54a42f54179,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-9caec600-c969-4462-be76-a9055af19816,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-51fd0a0b-1471-4336-8d14-861338f2dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-cb265c9d-f5fa-46b4-bffe-dd3b90d9e136,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-8988b216-66bc-41d1-923a-f450acbe8f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353567128-172.17.0.9-1598515775354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-b90cb8e8-6908-4d5a-8e7f-3fbca65ff852,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7519a0c5-2389-42b8-a4f2-e1b10499f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-053824ba-6145-4af6-b329-663b8bcc09c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-fd7201a5-3496-40a2-bf3c-bca62784aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-ac7f69b2-1f77-43fb-ba98-140e186bd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-28035c82-3f17-44c8-bdcf-1605b3ed1c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-9596a6fc-8afb-4c15-97a5-8302f231cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-2c4ec879-62c8-4b8c-992e-45d3acf83d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353567128-172.17.0.9-1598515775354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-b90cb8e8-6908-4d5a-8e7f-3fbca65ff852,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7519a0c5-2389-42b8-a4f2-e1b10499f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-053824ba-6145-4af6-b329-663b8bcc09c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-fd7201a5-3496-40a2-bf3c-bca62784aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-ac7f69b2-1f77-43fb-ba98-140e186bd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-28035c82-3f17-44c8-bdcf-1605b3ed1c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-9596a6fc-8afb-4c15-97a5-8302f231cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-2c4ec879-62c8-4b8c-992e-45d3acf83d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261009608-172.17.0.9-1598515805644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-03b3f7ed-b83e-471f-b2ee-b41ada8fbe44,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b47cf6fd-9900-46e8-baad-1518e7e26202,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-25cf0231-0942-49a1-b3e3-94867818efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-54ee3044-72dc-4e9e-9d87-45644bb411d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-65f8d4f9-d5d2-4f69-a286-67ce189b2926,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-67327d75-5e63-4426-9388-0348ea489e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-dd3d9f93-5518-49a7-a644-b2e69ff05c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-3794a462-ea41-4357-b851-cc1b91db786e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261009608-172.17.0.9-1598515805644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-03b3f7ed-b83e-471f-b2ee-b41ada8fbe44,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b47cf6fd-9900-46e8-baad-1518e7e26202,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-25cf0231-0942-49a1-b3e3-94867818efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-54ee3044-72dc-4e9e-9d87-45644bb411d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-65f8d4f9-d5d2-4f69-a286-67ce189b2926,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-67327d75-5e63-4426-9388-0348ea489e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-dd3d9f93-5518-49a7-a644-b2e69ff05c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-3794a462-ea41-4357-b851-cc1b91db786e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911029522-172.17.0.9-1598516026089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-171bd60f-f65a-4fe5-8b5a-b6ad4737fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-285f9a50-1480-4177-b710-9be3d53456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9d2d6812-65b8-4655-8c33-18819d9188c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-0460651a-c9ba-45f9-9c97-db53c5e0e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-19de73b8-0265-449d-ac5b-4062056785a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-328b2869-cf6d-4318-b29b-4652a83d278d,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-9856030a-229f-40f8-bb15-07e62451b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-02e17ecf-5526-4f58-a247-a0eae37664a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911029522-172.17.0.9-1598516026089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-171bd60f-f65a-4fe5-8b5a-b6ad4737fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-285f9a50-1480-4177-b710-9be3d53456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9d2d6812-65b8-4655-8c33-18819d9188c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-0460651a-c9ba-45f9-9c97-db53c5e0e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-19de73b8-0265-449d-ac5b-4062056785a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-328b2869-cf6d-4318-b29b-4652a83d278d,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-9856030a-229f-40f8-bb15-07e62451b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-02e17ecf-5526-4f58-a247-a0eae37664a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563001065-172.17.0.9-1598516097012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41935,DS-39d01a11-6eaf-481b-b395-8f2a18508098,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-4139da72-ed48-46cd-b39b-323734b67d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-50e23714-0c2b-4871-99b8-2bb84112278c,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-95444aef-8cb7-470d-a685-dcdad36454da,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-7ac8bceb-4c4b-4c7f-97df-ccb3210ee5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-6bf50f93-0c0a-4132-b9eb-3ba56cd729a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cd9cb385-5ea1-44d7-96d7-1fbb35c1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-9f2383a3-429e-4fa5-8908-7636d6fe0266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563001065-172.17.0.9-1598516097012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41935,DS-39d01a11-6eaf-481b-b395-8f2a18508098,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-4139da72-ed48-46cd-b39b-323734b67d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-50e23714-0c2b-4871-99b8-2bb84112278c,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-95444aef-8cb7-470d-a685-dcdad36454da,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-7ac8bceb-4c4b-4c7f-97df-ccb3210ee5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-6bf50f93-0c0a-4132-b9eb-3ba56cd729a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cd9cb385-5ea1-44d7-96d7-1fbb35c1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-9f2383a3-429e-4fa5-8908-7636d6fe0266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976115720-172.17.0.9-1598516245929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-839ca768-f149-4751-bda1-0013dc6860fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-7e484cf2-6390-495c-a881-6389721c3bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-926278a2-83af-42bd-9d3c-d5fa41a528b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-54304639-4179-421e-8895-144ec8bf4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-702b786e-bf66-4a98-a6c4-4ddecf7845f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-6c8b7089-cd25-40cc-9ca1-b2204e523c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-72bde251-f667-40fc-9e38-62ded5ebf71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-a2234d00-25bf-4d1e-be89-7b77d0279069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976115720-172.17.0.9-1598516245929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-839ca768-f149-4751-bda1-0013dc6860fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-7e484cf2-6390-495c-a881-6389721c3bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-926278a2-83af-42bd-9d3c-d5fa41a528b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-54304639-4179-421e-8895-144ec8bf4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-702b786e-bf66-4a98-a6c4-4ddecf7845f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-6c8b7089-cd25-40cc-9ca1-b2204e523c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-72bde251-f667-40fc-9e38-62ded5ebf71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-a2234d00-25bf-4d1e-be89-7b77d0279069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586871623-172.17.0.9-1598516538930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-cbf08ea9-be75-4177-b1db-09eef0c657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-4026f94c-f30a-4254-93cd-33876ee34b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-96e869cd-cb33-4791-b8fb-30e52573ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d53ecfea-95bc-4b56-9ddd-66cb3926cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-aefbe370-73fa-4020-8bc2-b892c1676843,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-802732e0-ab94-4d04-937e-553d9ea7583c,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-67da78c8-34f4-4c75-925f-2205fafea20f,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-68b05deb-fab8-42d8-b629-e189cd5e9b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586871623-172.17.0.9-1598516538930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-cbf08ea9-be75-4177-b1db-09eef0c657b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-4026f94c-f30a-4254-93cd-33876ee34b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-96e869cd-cb33-4791-b8fb-30e52573ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d53ecfea-95bc-4b56-9ddd-66cb3926cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-aefbe370-73fa-4020-8bc2-b892c1676843,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-802732e0-ab94-4d04-937e-553d9ea7583c,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-67da78c8-34f4-4c75-925f-2205fafea20f,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-68b05deb-fab8-42d8-b629-e189cd5e9b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540894454-172.17.0.9-1598516614169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-59b0340c-8ea1-4e21-a3f8-bf776fd95644,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-3c61aa87-8676-4059-8e36-d5a35dddcd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-9c934414-43c1-41ef-8d0a-43b720840369,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-2685af6b-d219-4394-aeb9-f8e6ff1e0919,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-3d95edc0-a4d0-4b32-bf5f-66d0ecf7af74,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-197e10bf-b91f-4a53-b4aa-139804e3cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3a595903-ee2c-4ed3-93bc-f30753ff96d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-4f64275c-6f26-4c7d-868e-1d6d5ab02c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540894454-172.17.0.9-1598516614169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-59b0340c-8ea1-4e21-a3f8-bf776fd95644,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-3c61aa87-8676-4059-8e36-d5a35dddcd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-9c934414-43c1-41ef-8d0a-43b720840369,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-2685af6b-d219-4394-aeb9-f8e6ff1e0919,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-3d95edc0-a4d0-4b32-bf5f-66d0ecf7af74,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-197e10bf-b91f-4a53-b4aa-139804e3cbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3a595903-ee2c-4ed3-93bc-f30753ff96d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-4f64275c-6f26-4c7d-868e-1d6d5ab02c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281047819-172.17.0.9-1598516653299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-ff920363-d78d-446b-9ca8-f67f1adca3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-047f1ebf-70f2-4e58-8c14-61be9a1a9852,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-1a2fb95c-946e-4dbd-9cc9-f2d8c8f6c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-fcc4cf0c-151c-42c7-a31a-e8929a19cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-431f983e-4d2e-4e80-85fe-7d19bf8737f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-cd15cdbf-b8df-4bb9-a09c-bbe9c453afde,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-70fbe4b3-b1e6-4c1d-aafc-a53c41fa5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-acb82f2e-f320-47ab-8dac-eb3ada7e372e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281047819-172.17.0.9-1598516653299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-ff920363-d78d-446b-9ca8-f67f1adca3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-047f1ebf-70f2-4e58-8c14-61be9a1a9852,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-1a2fb95c-946e-4dbd-9cc9-f2d8c8f6c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-fcc4cf0c-151c-42c7-a31a-e8929a19cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-431f983e-4d2e-4e80-85fe-7d19bf8737f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-cd15cdbf-b8df-4bb9-a09c-bbe9c453afde,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-70fbe4b3-b1e6-4c1d-aafc-a53c41fa5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-acb82f2e-f320-47ab-8dac-eb3ada7e372e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125123377-172.17.0.9-1598516696481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-57e7f04d-953f-42c7-8fe6-634e3ba39e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-251b73c2-1e02-453f-a28e-feee11c45398,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-a0385d1d-31da-44d7-9aa9-4cfa45c7b8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-b7d84f7c-28db-47a4-9d87-4c854f406154,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c73e3c68-c350-4c21-911c-5b7f94a0cded,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-10465bb4-31e9-43f5-a923-ab873fef8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5793dbba-6d3b-4965-9c96-74a5f5f0ca80,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e6ef9aec-c957-4a9f-a557-69c97e631a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125123377-172.17.0.9-1598516696481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43779,DS-57e7f04d-953f-42c7-8fe6-634e3ba39e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-251b73c2-1e02-453f-a28e-feee11c45398,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-a0385d1d-31da-44d7-9aa9-4cfa45c7b8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-b7d84f7c-28db-47a4-9d87-4c854f406154,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c73e3c68-c350-4c21-911c-5b7f94a0cded,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-10465bb4-31e9-43f5-a923-ab873fef8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5793dbba-6d3b-4965-9c96-74a5f5f0ca80,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e6ef9aec-c957-4a9f-a557-69c97e631a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750507686-172.17.0.9-1598517049680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-c74ac20f-60ba-48b0-9d06-3af1c63b33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-dec05ac5-8f0a-4d74-84ec-f64fc140bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-db580942-c4ec-4004-a39a-0de00d286528,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-646c72ef-6913-4101-8f34-80ddc3bd97bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-d579ac83-31fc-4f44-b89c-15cfd25c088c,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-6d06a7d2-dcdc-4a7e-afe7-96111ef26c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-97cfa178-57df-441d-8922-125bad730c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-67f94e6d-87a5-4d3a-b3c0-c17da1dcaa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750507686-172.17.0.9-1598517049680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35840,DS-c74ac20f-60ba-48b0-9d06-3af1c63b33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-dec05ac5-8f0a-4d74-84ec-f64fc140bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-db580942-c4ec-4004-a39a-0de00d286528,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-646c72ef-6913-4101-8f34-80ddc3bd97bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-d579ac83-31fc-4f44-b89c-15cfd25c088c,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-6d06a7d2-dcdc-4a7e-afe7-96111ef26c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-97cfa178-57df-441d-8922-125bad730c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-67f94e6d-87a5-4d3a-b3c0-c17da1dcaa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888112298-172.17.0.9-1598517409820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-b41652d5-83c5-46e0-8d65-7470ab9726b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-c09bd024-0aaa-40f8-bcdb-5f396c4639c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-c494e472-7858-40e4-a8e5-2c81971ee37b,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-ee9ebaab-9769-4ac4-8673-7f0c4090dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-93a429d3-4675-4755-9112-88bb0c3f970c,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-1ef876f1-5bd7-4bf4-a21c-f31cd3f2494c,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-15279a83-705f-4023-9f86-65f4a640978d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-cf39179f-b2bf-4130-b527-e05026024b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888112298-172.17.0.9-1598517409820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43159,DS-b41652d5-83c5-46e0-8d65-7470ab9726b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-c09bd024-0aaa-40f8-bcdb-5f396c4639c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-c494e472-7858-40e4-a8e5-2c81971ee37b,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-ee9ebaab-9769-4ac4-8673-7f0c4090dbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-93a429d3-4675-4755-9112-88bb0c3f970c,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-1ef876f1-5bd7-4bf4-a21c-f31cd3f2494c,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-15279a83-705f-4023-9f86-65f4a640978d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-cf39179f-b2bf-4130-b527-e05026024b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130051880-172.17.0.9-1598517556011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-ebade1ba-e995-4200-877b-ebfd5c2b3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-8b3665d2-d493-4f34-851c-2ae317d37a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-4531ea93-eb01-4329-9f6b-1cb721e82208,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-8cfb0ed1-92c3-434d-a42f-7fca4a8f3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8268140e-396a-4359-b268-1f94a0fd4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-cbe97206-1f01-4fd8-a1ed-2c7094d0cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-f3c472a4-c4c6-4948-942a-1dcf32e0dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-11ffd4ba-565c-4cc1-b94f-611dd1a0333e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130051880-172.17.0.9-1598517556011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-ebade1ba-e995-4200-877b-ebfd5c2b3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-8b3665d2-d493-4f34-851c-2ae317d37a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-4531ea93-eb01-4329-9f6b-1cb721e82208,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-8cfb0ed1-92c3-434d-a42f-7fca4a8f3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-8268140e-396a-4359-b268-1f94a0fd4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-cbe97206-1f01-4fd8-a1ed-2c7094d0cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-f3c472a4-c4c6-4948-942a-1dcf32e0dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-11ffd4ba-565c-4cc1-b94f-611dd1a0333e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749420420-172.17.0.9-1598517589807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-ec5aaf9f-97be-46bb-af11-c4ccd40b9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f6d2ac98-7409-45ff-bbd6-bff3d40eada2,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f3a6c352-fede-41da-bf00-504a8fdfad17,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-6aa9f9ff-65e4-4807-81c9-1d98d6235add,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-24d8370a-b626-4850-9966-ec659cf37385,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-bf05a35a-99f3-403a-940b-a163bebad8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-16b1470b-2dae-420c-a34c-d09ff404837c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-d75d8418-f6e6-4311-848b-d6f4eb71aa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749420420-172.17.0.9-1598517589807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-ec5aaf9f-97be-46bb-af11-c4ccd40b9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f6d2ac98-7409-45ff-bbd6-bff3d40eada2,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f3a6c352-fede-41da-bf00-504a8fdfad17,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-6aa9f9ff-65e4-4807-81c9-1d98d6235add,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-24d8370a-b626-4850-9966-ec659cf37385,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-bf05a35a-99f3-403a-940b-a163bebad8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-16b1470b-2dae-420c-a34c-d09ff404837c,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-d75d8418-f6e6-4311-848b-d6f4eb71aa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745030926-172.17.0.9-1598518001244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-72bf0fc7-427c-4e2d-bccc-8b52b0132505,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-4ff050e1-a0d1-446e-b7dc-e5f9e1130612,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-d18b4be7-97ca-4077-9d3a-b3b5b8530892,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-989a3092-d113-489f-8861-2b9a9842268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-b7adf39c-5386-404f-b6f1-1a2daea8a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-5819836b-fc30-40fa-b524-45a2b9b03195,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-7b19ae38-e51f-4bc3-a9cd-38a1f5e1ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-6705ab56-6dbf-4a09-ac11-168423c8b96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745030926-172.17.0.9-1598518001244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-72bf0fc7-427c-4e2d-bccc-8b52b0132505,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-4ff050e1-a0d1-446e-b7dc-e5f9e1130612,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-d18b4be7-97ca-4077-9d3a-b3b5b8530892,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-989a3092-d113-489f-8861-2b9a9842268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-b7adf39c-5386-404f-b6f1-1a2daea8a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-5819836b-fc30-40fa-b524-45a2b9b03195,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-7b19ae38-e51f-4bc3-a9cd-38a1f5e1ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-6705ab56-6dbf-4a09-ac11-168423c8b96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790693443-172.17.0.9-1598518112889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-5fab9a4f-a58a-44c9-aa07-58b797dd8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-6c9dc6ea-737d-4435-9c71-bae790f8d955,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-c35d7e34-a4b0-498e-abab-f5b0cabf74c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d5fcc0bb-0e42-4e4b-83bc-c86232603bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3d2ccec7-df4b-43b6-ae95-1678d2233cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-83fbc605-c76b-4218-b199-767b978158bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-c4cab6a2-3a01-466b-99d1-95f31b518d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-61059b57-4041-4bdf-8d16-5fb7561c476a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790693443-172.17.0.9-1598518112889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-5fab9a4f-a58a-44c9-aa07-58b797dd8be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-6c9dc6ea-737d-4435-9c71-bae790f8d955,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-c35d7e34-a4b0-498e-abab-f5b0cabf74c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d5fcc0bb-0e42-4e4b-83bc-c86232603bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3d2ccec7-df4b-43b6-ae95-1678d2233cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-83fbc605-c76b-4218-b199-767b978158bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-c4cab6a2-3a01-466b-99d1-95f31b518d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-61059b57-4041-4bdf-8d16-5fb7561c476a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357772467-172.17.0.9-1598518931458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-59ad591b-20c2-4fc5-aaa2-d6c266b1636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-03b78b62-3054-4a3c-8eec-6feeea3e79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-535bc8fc-fa2d-4fc0-810e-381b49a18197,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-9eb13672-bd55-4a10-9af2-b75be8078654,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-b8453b94-3da8-4161-8dd0-dc24b931dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-94829742-e19e-466c-b084-d6cd4473f13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-6595fa54-b23a-4d8e-aa33-f8d3e4efc2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c17a8e17-6db0-4c7a-90c2-db365d8b252b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357772467-172.17.0.9-1598518931458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33520,DS-59ad591b-20c2-4fc5-aaa2-d6c266b1636d,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-03b78b62-3054-4a3c-8eec-6feeea3e79bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-535bc8fc-fa2d-4fc0-810e-381b49a18197,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-9eb13672-bd55-4a10-9af2-b75be8078654,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-b8453b94-3da8-4161-8dd0-dc24b931dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-94829742-e19e-466c-b084-d6cd4473f13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-6595fa54-b23a-4d8e-aa33-f8d3e4efc2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c17a8e17-6db0-4c7a-90c2-db365d8b252b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900223236-172.17.0.9-1598519083359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-8863f85b-2c26-456e-991b-e6aff7e6f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-86ee3a39-c116-4b13-a4b8-c576a8e7500b,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-48350e58-2b08-4d13-a049-071859ac9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-b3a2d6e3-b06f-46f5-bf10-52913a772f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-b6d7742f-8501-4c19-b1d0-91934e5ec169,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-7a89d826-f528-490d-b5b6-767a288633d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-fb573f19-46b8-4b31-a1cc-aa60aba16ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-1b61e050-f1fe-4f6e-9d86-09767db70c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900223236-172.17.0.9-1598519083359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-8863f85b-2c26-456e-991b-e6aff7e6f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-86ee3a39-c116-4b13-a4b8-c576a8e7500b,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-48350e58-2b08-4d13-a049-071859ac9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-b3a2d6e3-b06f-46f5-bf10-52913a772f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-b6d7742f-8501-4c19-b1d0-91934e5ec169,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-7a89d826-f528-490d-b5b6-767a288633d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-fb573f19-46b8-4b31-a1cc-aa60aba16ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-1b61e050-f1fe-4f6e-9d86-09767db70c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023068679-172.17.0.9-1598519494971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45955,DS-8fcc0a36-238c-495b-9a3d-afdf53e32baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-fb8cbcc2-99f6-454f-a49f-8adca05ae05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-071bd2a3-77e5-4540-b204-22d32b751c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-63cae227-782e-41ae-9d2d-011cb14add78,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c40ed0bd-adcc-46c6-8c11-94cca3000e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-18130120-2791-4207-8055-84b5c112c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-84dfb2c0-7218-4326-9888-81b8399997c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-66969753-5675-4c38-bd1c-e803b1f1a165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023068679-172.17.0.9-1598519494971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45955,DS-8fcc0a36-238c-495b-9a3d-afdf53e32baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-fb8cbcc2-99f6-454f-a49f-8adca05ae05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-071bd2a3-77e5-4540-b204-22d32b751c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-63cae227-782e-41ae-9d2d-011cb14add78,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-c40ed0bd-adcc-46c6-8c11-94cca3000e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-18130120-2791-4207-8055-84b5c112c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-84dfb2c0-7218-4326-9888-81b8399997c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-66969753-5675-4c38-bd1c-e803b1f1a165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5480
