reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083402655-172.17.0.7-1598574463926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-ebcc64ec-aef4-4ece-88ad-dce65f15c3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-92cbb582-fe5e-4c6d-b4ff-ce8e2dae2885,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-f37c4f94-4118-4736-80ce-8855326c083e,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-6485f04c-1637-4165-b6dd-e37982558f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-bf847c1b-0170-4064-abf4-72aa06668619,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-581cc128-393c-45f5-a105-550489f5dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-b48de391-947e-4469-b42b-cb32b5bc4d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-3c8b8aac-ec55-4948-b6ac-c647d12c1e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083402655-172.17.0.7-1598574463926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-ebcc64ec-aef4-4ece-88ad-dce65f15c3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-92cbb582-fe5e-4c6d-b4ff-ce8e2dae2885,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-f37c4f94-4118-4736-80ce-8855326c083e,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-6485f04c-1637-4165-b6dd-e37982558f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-bf847c1b-0170-4064-abf4-72aa06668619,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-581cc128-393c-45f5-a105-550489f5dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-b48de391-947e-4469-b42b-cb32b5bc4d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-3c8b8aac-ec55-4948-b6ac-c647d12c1e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368881029-172.17.0.7-1598574589541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-6f289502-2009-412e-95fa-64102c848e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-d291c4a5-a9f6-434f-afa2-4cfda5c2fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-f776c5c4-0f5a-45b3-aae0-267851c64054,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-e1b7c8d4-01e3-43af-aff9-84da8e21076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-21c1f407-952a-44f3-a0f1-d91e48783f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-94010b63-e5a0-417f-9539-e0b0c84dfdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c47c1fda-4327-4b26-b40c-b31ea04e3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-9bb420c6-cd7c-4284-89f4-79f8f1c384f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368881029-172.17.0.7-1598574589541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39572,DS-6f289502-2009-412e-95fa-64102c848e97,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-d291c4a5-a9f6-434f-afa2-4cfda5c2fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-f776c5c4-0f5a-45b3-aae0-267851c64054,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-e1b7c8d4-01e3-43af-aff9-84da8e21076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-21c1f407-952a-44f3-a0f1-d91e48783f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-94010b63-e5a0-417f-9539-e0b0c84dfdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-c47c1fda-4327-4b26-b40c-b31ea04e3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-9bb420c6-cd7c-4284-89f4-79f8f1c384f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389115978-172.17.0.7-1598574886949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-b1b843fc-feff-4800-b7f5-cae3b30f85b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-eb424a0b-6c8e-4df4-bc99-97c59ba6cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-03b4ec8d-a113-4dcf-849e-3094c1fa6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-042df9a1-a2cc-4286-942e-c2aecd840eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-4751722c-6a09-463e-8387-5cde2a153adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-05458153-85bc-4763-acd4-9e1a61c42390,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-a8a07807-c6b6-415c-857d-6b9b3d2c02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-05209bc1-8fce-4747-83f2-77503587f5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389115978-172.17.0.7-1598574886949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-b1b843fc-feff-4800-b7f5-cae3b30f85b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-eb424a0b-6c8e-4df4-bc99-97c59ba6cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-03b4ec8d-a113-4dcf-849e-3094c1fa6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-042df9a1-a2cc-4286-942e-c2aecd840eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-4751722c-6a09-463e-8387-5cde2a153adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-05458153-85bc-4763-acd4-9e1a61c42390,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-a8a07807-c6b6-415c-857d-6b9b3d2c02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-05209bc1-8fce-4747-83f2-77503587f5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851561332-172.17.0.7-1598574921216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-e3285db2-b5eb-4e29-aa65-552d15cacb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-582015ee-ac78-48d0-b1fc-f581b0aa1ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6bcbd2b3-6333-436a-b6f0-c7f880755e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-153fef16-f67b-4809-94b7-4757e1736785,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-be0f3573-bfbb-432e-8ead-7b248e555576,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e730ba8a-0df7-4fb4-9a17-b5933a992d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b905869a-d9fd-428f-84e2-94cb991d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-f62db5db-437a-4df5-bcec-57ecb7460abf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851561332-172.17.0.7-1598574921216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-e3285db2-b5eb-4e29-aa65-552d15cacb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-582015ee-ac78-48d0-b1fc-f581b0aa1ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6bcbd2b3-6333-436a-b6f0-c7f880755e34,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-153fef16-f67b-4809-94b7-4757e1736785,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-be0f3573-bfbb-432e-8ead-7b248e555576,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e730ba8a-0df7-4fb4-9a17-b5933a992d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-b905869a-d9fd-428f-84e2-94cb991d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-f62db5db-437a-4df5-bcec-57ecb7460abf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453693514-172.17.0.7-1598575065826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-fa83d994-b7af-49fb-adbb-1597e6c7c377,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-0dfaddbd-f4f6-4467-9f68-37b3f9cf9075,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-af2604a6-5071-4aed-a979-3aafeb8890a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-144629bc-24c6-4c44-bfde-6f525fb1e58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-ad3882f8-c292-4a0f-b522-860a5b0e0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-a8c06a5f-dfea-4983-a451-bb6c904ef5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-07fb9cb0-42c2-46b6-b298-a41b0d3ce81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-d2ded3ea-fc34-4d53-968b-a6076a13a9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453693514-172.17.0.7-1598575065826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-fa83d994-b7af-49fb-adbb-1597e6c7c377,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-0dfaddbd-f4f6-4467-9f68-37b3f9cf9075,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-af2604a6-5071-4aed-a979-3aafeb8890a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-144629bc-24c6-4c44-bfde-6f525fb1e58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-ad3882f8-c292-4a0f-b522-860a5b0e0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-a8c06a5f-dfea-4983-a451-bb6c904ef5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-07fb9cb0-42c2-46b6-b298-a41b0d3ce81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-d2ded3ea-fc34-4d53-968b-a6076a13a9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3401275-172.17.0.7-1598575137237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45115,DS-e193e2f1-7da2-4573-a3b1-f490684f0313,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-07feb76a-01d5-45d0-b34b-0b54d30bc8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-9d18d5ec-7e0d-4c37-8c3f-b4f0d255b4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-e791389e-2b35-4325-9c37-854949448914,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-71dd6d00-72df-4211-af92-bba968445045,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-a61b2776-9cda-4091-934c-15e725b8ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-dcc7afe3-a27b-4302-879a-f897bd02bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-8978168b-bd16-498f-ae94-e948eb4bb35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3401275-172.17.0.7-1598575137237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45115,DS-e193e2f1-7da2-4573-a3b1-f490684f0313,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-07feb76a-01d5-45d0-b34b-0b54d30bc8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-9d18d5ec-7e0d-4c37-8c3f-b4f0d255b4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-e791389e-2b35-4325-9c37-854949448914,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-71dd6d00-72df-4211-af92-bba968445045,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-a61b2776-9cda-4091-934c-15e725b8ebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-dcc7afe3-a27b-4302-879a-f897bd02bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-8978168b-bd16-498f-ae94-e948eb4bb35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639215021-172.17.0.7-1598575216808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-f8b55953-34fb-456d-afcb-038516121808,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-f8e92e5d-f35c-4d35-85cb-ba4f9639b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-eeb6e45f-ed4c-4854-a424-da6733c848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-869028ad-0d7f-4e16-a374-ab1c3d27b037,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-a780be87-8579-44df-9822-52f538286938,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a2eaa93-1038-40e9-9de0-49342c2471de,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8228efa1-a650-48ed-b53a-6d8b889fcd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-cf9d75c5-e77b-46b1-a08e-26ff448a205d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639215021-172.17.0.7-1598575216808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-f8b55953-34fb-456d-afcb-038516121808,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-f8e92e5d-f35c-4d35-85cb-ba4f9639b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-eeb6e45f-ed4c-4854-a424-da6733c848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-869028ad-0d7f-4e16-a374-ab1c3d27b037,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-a780be87-8579-44df-9822-52f538286938,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a2eaa93-1038-40e9-9de0-49342c2471de,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8228efa1-a650-48ed-b53a-6d8b889fcd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-cf9d75c5-e77b-46b1-a08e-26ff448a205d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829986457-172.17.0.7-1598575604869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-6839e584-4567-41c0-93ec-a9520a547f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-1104679b-7be9-4434-b239-ec4439341ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-2079204a-35d1-4ecf-a043-8fa3d96a0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-66246d46-eb39-4b06-8d54-c2eed0309084,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-27146073-53a2-413b-b9fd-220c337277cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a82fc95f-895d-443f-9517-e84923c6f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f7af4697-c329-4ffe-97be-b31f1d0bd2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7f1edfcd-4aae-405c-ae22-842d1deaa779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829986457-172.17.0.7-1598575604869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-6839e584-4567-41c0-93ec-a9520a547f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-1104679b-7be9-4434-b239-ec4439341ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-2079204a-35d1-4ecf-a043-8fa3d96a0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-66246d46-eb39-4b06-8d54-c2eed0309084,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-27146073-53a2-413b-b9fd-220c337277cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a82fc95f-895d-443f-9517-e84923c6f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f7af4697-c329-4ffe-97be-b31f1d0bd2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7f1edfcd-4aae-405c-ae22-842d1deaa779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256303189-172.17.0.7-1598575635047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-c07a1b06-bdb3-4169-ad55-933a3b76a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-aa913d0c-f8b8-4fdb-b24a-dc79b477fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-1ec2021d-fb4f-4850-a147-8c9651f416a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-6ef2c240-a092-4474-a4c9-b211c74e3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-48e3e949-12ad-47e7-a5f3-d20a32cd8048,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-76e383d9-cfee-49df-aa3d-a243e7f2e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-94daf472-e60d-4ae5-9350-4e6ad8426ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-238135ac-af30-4e1d-b5a2-e298f552dcd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256303189-172.17.0.7-1598575635047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-c07a1b06-bdb3-4169-ad55-933a3b76a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-aa913d0c-f8b8-4fdb-b24a-dc79b477fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-1ec2021d-fb4f-4850-a147-8c9651f416a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-6ef2c240-a092-4474-a4c9-b211c74e3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-48e3e949-12ad-47e7-a5f3-d20a32cd8048,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-76e383d9-cfee-49df-aa3d-a243e7f2e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-94daf472-e60d-4ae5-9350-4e6ad8426ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-238135ac-af30-4e1d-b5a2-e298f552dcd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597615951-172.17.0.7-1598575719204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-1a3bd9b7-201e-4fff-8593-6e87012c2321,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-25e3dad9-7200-4408-b7c7-a41ee5858ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-2ce9e514-707c-4102-80f5-aa9673e72f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-2125e17c-f62e-4848-b7b9-9a67874c08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-fdd3f411-9844-4c14-871b-0d7e5d6a7386,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-914e8779-6ca0-4012-a8e0-1349051e34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-d3b4b440-0c0f-4d93-a258-2cfb5bcb4920,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-d3d1f07b-f78d-4c2c-b978-1c78fa25af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597615951-172.17.0.7-1598575719204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-1a3bd9b7-201e-4fff-8593-6e87012c2321,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-25e3dad9-7200-4408-b7c7-a41ee5858ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-2ce9e514-707c-4102-80f5-aa9673e72f96,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-2125e17c-f62e-4848-b7b9-9a67874c08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-fdd3f411-9844-4c14-871b-0d7e5d6a7386,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-914e8779-6ca0-4012-a8e0-1349051e34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-d3b4b440-0c0f-4d93-a258-2cfb5bcb4920,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-d3d1f07b-f78d-4c2c-b978-1c78fa25af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318050684-172.17.0.7-1598575834484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-7ed8d625-c0d6-47d7-ad07-588006ead4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-05f03779-6cc3-4579-a2c6-418ca36de83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-abe6e9de-8a24-4906-92e1-64425cac37ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1f2ea9eb-140f-4bb7-9324-d8c6504f8825,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-46b00ea6-346e-4dfe-882c-5413bb3c50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-fa76974e-b79f-4d9e-8a98-dc8d45547bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-feb2eb87-86f3-4519-b847-cfca53380ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-9d1a3f96-4c63-4bb8-9fe3-547801ddefc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318050684-172.17.0.7-1598575834484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-7ed8d625-c0d6-47d7-ad07-588006ead4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-05f03779-6cc3-4579-a2c6-418ca36de83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-abe6e9de-8a24-4906-92e1-64425cac37ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1f2ea9eb-140f-4bb7-9324-d8c6504f8825,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-46b00ea6-346e-4dfe-882c-5413bb3c50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-fa76974e-b79f-4d9e-8a98-dc8d45547bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-feb2eb87-86f3-4519-b847-cfca53380ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-9d1a3f96-4c63-4bb8-9fe3-547801ddefc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418697859-172.17.0.7-1598576114666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-16848b53-71c5-4393-a59d-6aa2a145112d,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-52474684-bbdf-4848-b478-be2438150731,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-3cebc35e-50fd-478b-82e7-3c8f9b6c55c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-a7e1c9b7-cf4c-4a9c-9097-e4b6caaeacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-88e217df-5bae-4183-b6a5-3463dc40d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-b4580580-bfac-4cc9-8ed0-8d35368be3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5f18f840-9d21-44bc-9c76-42f93ae577b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-9f596997-6e41-498c-9296-113e28cd9027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418697859-172.17.0.7-1598576114666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-16848b53-71c5-4393-a59d-6aa2a145112d,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-52474684-bbdf-4848-b478-be2438150731,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-3cebc35e-50fd-478b-82e7-3c8f9b6c55c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-a7e1c9b7-cf4c-4a9c-9097-e4b6caaeacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-88e217df-5bae-4183-b6a5-3463dc40d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-b4580580-bfac-4cc9-8ed0-8d35368be3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5f18f840-9d21-44bc-9c76-42f93ae577b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-9f596997-6e41-498c-9296-113e28cd9027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182023194-172.17.0.7-1598576232476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-cde30cc9-ed0d-4963-a791-3b99ad87d884,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f2a9c4f4-6aec-40a3-8eb6-49de782c2605,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-4c9fc982-7c48-404a-bbf5-ab5ef01bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-86e7e909-aa27-4561-b697-28c900cb5017,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-9557bf55-8c83-413e-8303-0bb558d74e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-102faee8-2b82-4ed4-8d09-ff468142e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ffe8d3ab-d633-4a42-af02-258b76983f25,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-3e56609a-86df-4d2c-af11-ca8466881fec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182023194-172.17.0.7-1598576232476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-cde30cc9-ed0d-4963-a791-3b99ad87d884,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f2a9c4f4-6aec-40a3-8eb6-49de782c2605,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-4c9fc982-7c48-404a-bbf5-ab5ef01bf4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-86e7e909-aa27-4561-b697-28c900cb5017,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-9557bf55-8c83-413e-8303-0bb558d74e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-102faee8-2b82-4ed4-8d09-ff468142e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ffe8d3ab-d633-4a42-af02-258b76983f25,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-3e56609a-86df-4d2c-af11-ca8466881fec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939503660-172.17.0.7-1598576276198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39547,DS-80b12fe0-05d3-44c7-a668-8b08db4a8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-81e0a800-af84-4e18-a96b-08db15c65562,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-e847ab24-9b5a-45f8-aa91-aa85e0ba5215,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1e93f240-1d24-4959-a66b-edca103a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-1dc50f93-7187-4a56-98d1-c91bdc2075d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-e94da164-fecb-4f77-b42c-644dfe866357,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-c9492f0c-99c9-4ca7-a7b7-0e84df934fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-37817ee4-1a17-42dd-8e53-11a8c264e8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939503660-172.17.0.7-1598576276198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39547,DS-80b12fe0-05d3-44c7-a668-8b08db4a8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-81e0a800-af84-4e18-a96b-08db15c65562,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-e847ab24-9b5a-45f8-aa91-aa85e0ba5215,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1e93f240-1d24-4959-a66b-edca103a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-1dc50f93-7187-4a56-98d1-c91bdc2075d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-e94da164-fecb-4f77-b42c-644dfe866357,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-c9492f0c-99c9-4ca7-a7b7-0e84df934fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-37817ee4-1a17-42dd-8e53-11a8c264e8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835144074-172.17.0.7-1598576612127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-dbfd3cb6-2e76-4191-bd7c-34f032f39582,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-936df4f8-b9e5-41b4-bdfd-2c83a1f36dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-c73b3841-c2f2-48f0-8083-a993da748a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0663fa71-5888-4e48-8f1c-983346ea0dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-5cf69373-165c-4d9f-8764-93a57a1965b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d13b0aae-a435-4990-b99b-d24d125a01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-ec7c24d1-110e-4dbe-a22a-3f47d4b96b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c9a019d5-df87-417d-b54b-cd07e00281e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835144074-172.17.0.7-1598576612127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-dbfd3cb6-2e76-4191-bd7c-34f032f39582,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-936df4f8-b9e5-41b4-bdfd-2c83a1f36dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-c73b3841-c2f2-48f0-8083-a993da748a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0663fa71-5888-4e48-8f1c-983346ea0dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-5cf69373-165c-4d9f-8764-93a57a1965b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d13b0aae-a435-4990-b99b-d24d125a01e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-ec7c24d1-110e-4dbe-a22a-3f47d4b96b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c9a019d5-df87-417d-b54b-cd07e00281e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603179329-172.17.0.7-1598576688405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7cd19e0f-4d87-4fc0-91d6-f10b720f2c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-e54279a6-d26e-4f25-aa34-6ff0306bd6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-f0c6e2a5-0088-4461-8367-01cbca7f461a,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1845da9f-2d8d-4727-bae1-ca69ba5c1e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-54f843a4-f226-437e-8568-d21341a6ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-f3ba1bf1-eff4-4079-ae95-5dfad4a08d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-bf123131-83d0-4cb0-9bbe-d1b447536423,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-ab7c0c3b-bb4c-45ff-b179-ca497ddfa3e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603179329-172.17.0.7-1598576688405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7cd19e0f-4d87-4fc0-91d6-f10b720f2c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-e54279a6-d26e-4f25-aa34-6ff0306bd6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-f0c6e2a5-0088-4461-8367-01cbca7f461a,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1845da9f-2d8d-4727-bae1-ca69ba5c1e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-54f843a4-f226-437e-8568-d21341a6ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-f3ba1bf1-eff4-4079-ae95-5dfad4a08d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-bf123131-83d0-4cb0-9bbe-d1b447536423,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-ab7c0c3b-bb4c-45ff-b179-ca497ddfa3e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615732511-172.17.0.7-1598576939823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-dd760fab-092a-43a2-81e7-9c14be9633ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2de8c692-8516-43c7-8f52-7a4356011f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-33b2e2ee-17d2-4ea5-9338-c9bcc937a621,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-db06cbe1-6548-4e7b-bf4c-31c5cb0462f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-78d3948e-d247-4b8c-82d6-14d29d987416,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ac9ac3f6-efff-4c73-8cce-6f1f4aa484a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-59520608-800d-422f-8537-679721e1efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-6a1a2fb8-d8a8-4502-91b7-201b5be91121,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615732511-172.17.0.7-1598576939823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-dd760fab-092a-43a2-81e7-9c14be9633ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2de8c692-8516-43c7-8f52-7a4356011f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-33b2e2ee-17d2-4ea5-9338-c9bcc937a621,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-db06cbe1-6548-4e7b-bf4c-31c5cb0462f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-78d3948e-d247-4b8c-82d6-14d29d987416,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ac9ac3f6-efff-4c73-8cce-6f1f4aa484a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-59520608-800d-422f-8537-679721e1efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-6a1a2fb8-d8a8-4502-91b7-201b5be91121,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485103098-172.17.0.7-1598577045195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-48b0fe95-e2be-4b9c-a172-99c37e583549,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d32078c9-539a-4b58-b6c9-2fb6f32cf884,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-6c90fe25-e549-48de-b1ef-28a9ba0a24c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-22a0d700-5950-4a72-a730-dceb1899c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-31ce68c7-88bb-49af-866b-9e77dabb2cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-d4a6588e-07c9-4402-b9c1-c936e1968673,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-0fd52180-9143-40db-826a-db2a543b9027,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1a8d36a1-f59d-42dc-972f-fb9dcb298b03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485103098-172.17.0.7-1598577045195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34483,DS-48b0fe95-e2be-4b9c-a172-99c37e583549,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-d32078c9-539a-4b58-b6c9-2fb6f32cf884,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-6c90fe25-e549-48de-b1ef-28a9ba0a24c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-22a0d700-5950-4a72-a730-dceb1899c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-31ce68c7-88bb-49af-866b-9e77dabb2cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-d4a6588e-07c9-4402-b9c1-c936e1968673,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-0fd52180-9143-40db-826a-db2a543b9027,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1a8d36a1-f59d-42dc-972f-fb9dcb298b03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258310356-172.17.0.7-1598577240374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-d450a5e9-0f12-4fb3-b438-db6ad5db0282,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-7e045db4-fc0f-4023-9e50-ce2b6d264860,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-88263ce2-33ca-48a6-80a6-c18a544e6d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-ec92b8c3-2920-45e8-9694-661a167e0225,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-92aebf94-ac6a-4683-9eda-aee1c1a65437,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-cc449ae3-6700-4f32-ab98-f8b04e3ffd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-e4322677-08e4-4c0a-ab4b-67e679b535d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-3c11214f-4fde-4c23-acd8-0b2e537fb0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258310356-172.17.0.7-1598577240374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-d450a5e9-0f12-4fb3-b438-db6ad5db0282,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-7e045db4-fc0f-4023-9e50-ce2b6d264860,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-88263ce2-33ca-48a6-80a6-c18a544e6d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-ec92b8c3-2920-45e8-9694-661a167e0225,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-92aebf94-ac6a-4683-9eda-aee1c1a65437,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-cc449ae3-6700-4f32-ab98-f8b04e3ffd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-e4322677-08e4-4c0a-ab4b-67e679b535d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-3c11214f-4fde-4c23-acd8-0b2e537fb0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784646949-172.17.0.7-1598577338013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-280fba77-e202-49a1-8815-5f0b330bde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ee1f8be2-8308-47b6-8a2b-92de9496106b,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-4374ad2b-2727-44cb-9005-68de2b5079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-e1afd0c1-c520-420d-aaa6-2460c1e98a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5867ea56-ef13-4a43-88ed-8e813c77d464,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-01b99c74-abe3-4afa-8e4c-e65716044642,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-14e33373-7fd0-4475-89d8-69537196a246,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-f6d8b67e-19d2-48fb-a2d4-29cade51c0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784646949-172.17.0.7-1598577338013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-280fba77-e202-49a1-8815-5f0b330bde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ee1f8be2-8308-47b6-8a2b-92de9496106b,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-4374ad2b-2727-44cb-9005-68de2b5079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-e1afd0c1-c520-420d-aaa6-2460c1e98a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-5867ea56-ef13-4a43-88ed-8e813c77d464,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-01b99c74-abe3-4afa-8e4c-e65716044642,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-14e33373-7fd0-4475-89d8-69537196a246,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-f6d8b67e-19d2-48fb-a2d4-29cade51c0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240225652-172.17.0.7-1598577489802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-1787eaae-7966-4147-acbd-8b1c5b1a3438,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-a8f4e8c8-9692-42c2-8847-331208777a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-7d006c16-7bbe-479d-b1b8-addcdd29d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-5a6d4149-cdb9-47ff-90d2-45033a9078e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-36ca2776-154f-4c70-94bb-06ebd4984ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-bcb76e90-725a-439e-a66b-e570ecf00996,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2cbcff94-edff-4740-b5c5-4692c16cda8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-7610294a-115c-4eee-a11b-119576b6aae5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240225652-172.17.0.7-1598577489802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-1787eaae-7966-4147-acbd-8b1c5b1a3438,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-a8f4e8c8-9692-42c2-8847-331208777a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-7d006c16-7bbe-479d-b1b8-addcdd29d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-5a6d4149-cdb9-47ff-90d2-45033a9078e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-36ca2776-154f-4c70-94bb-06ebd4984ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-bcb76e90-725a-439e-a66b-e570ecf00996,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2cbcff94-edff-4740-b5c5-4692c16cda8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-7610294a-115c-4eee-a11b-119576b6aae5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509909119-172.17.0.7-1598578266166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-a33cc956-e9e8-4702-8e96-ee3fcaafa846,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-7765fdf7-2834-4d16-96e5-2776ef331e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-d07c7b3f-7e9c-490d-962c-885fc769a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-ca0531b0-8a67-4d7b-9f76-5bcff1dcfe62,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-f85d3196-1475-43ba-8b9e-a54779028eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-91768699-b1c2-42c4-a3a8-646152019374,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-751ebfee-6b50-40ca-9856-35e3f87e3893,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-28dc7ed2-a10d-43fd-856a-3c156bbbaed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509909119-172.17.0.7-1598578266166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-a33cc956-e9e8-4702-8e96-ee3fcaafa846,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-7765fdf7-2834-4d16-96e5-2776ef331e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-d07c7b3f-7e9c-490d-962c-885fc769a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-ca0531b0-8a67-4d7b-9f76-5bcff1dcfe62,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-f85d3196-1475-43ba-8b9e-a54779028eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-91768699-b1c2-42c4-a3a8-646152019374,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-751ebfee-6b50-40ca-9856-35e3f87e3893,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-28dc7ed2-a10d-43fd-856a-3c156bbbaed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786010857-172.17.0.7-1598578438969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-6dedd895-8300-4ce7-aefd-0d92ab5d90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-5ea6703b-4e30-40ef-a6dd-fedd57a93430,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-8d2010ed-fe6b-4bec-85c5-efb0be7b9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-d5851088-0576-455f-8e6a-a1d67331dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-34cee983-4b0e-4c35-aff6-4afb814d951f,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-431e1e41-fb9d-4b57-a834-632e9f76a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-7ab24b80-9cce-45d0-9344-5b29b6e7e485,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1c5c8c3e-cafc-4e23-98da-53f36187229a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786010857-172.17.0.7-1598578438969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-6dedd895-8300-4ce7-aefd-0d92ab5d90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-5ea6703b-4e30-40ef-a6dd-fedd57a93430,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-8d2010ed-fe6b-4bec-85c5-efb0be7b9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-d5851088-0576-455f-8e6a-a1d67331dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-34cee983-4b0e-4c35-aff6-4afb814d951f,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-431e1e41-fb9d-4b57-a834-632e9f76a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-7ab24b80-9cce-45d0-9344-5b29b6e7e485,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1c5c8c3e-cafc-4e23-98da-53f36187229a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98944783-172.17.0.7-1598578544148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-6c46f588-e136-4717-ab0c-117bcf656378,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-6ba2209f-ee2c-49fc-9851-d2246c705ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c31c72bf-77aa-4b17-82f7-521a395b517d,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e73d5136-320f-4656-a99e-fc9553f4777f,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-865fec00-b39e-4e4b-882e-713c746d93c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c306fabd-c002-407f-ace8-b62b084f070a,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-5c1f1242-4f66-4dab-ac66-953a32d38f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-f00cdb1a-133a-4eaa-b306-2ba2449a5597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98944783-172.17.0.7-1598578544148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-6c46f588-e136-4717-ab0c-117bcf656378,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-6ba2209f-ee2c-49fc-9851-d2246c705ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c31c72bf-77aa-4b17-82f7-521a395b517d,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e73d5136-320f-4656-a99e-fc9553f4777f,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-865fec00-b39e-4e4b-882e-713c746d93c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c306fabd-c002-407f-ace8-b62b084f070a,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-5c1f1242-4f66-4dab-ac66-953a32d38f00,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-f00cdb1a-133a-4eaa-b306-2ba2449a5597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734446151-172.17.0.7-1598578950467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-53490f27-c4c4-44d3-86f7-1244eae9758c,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-9bf55ca3-e5f4-42be-8a40-6daa1e7f1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-62c43086-f11f-40c2-953d-23e43e0ff8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-5d77b22c-0ede-41bd-a491-6a0e15396cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-cac945ef-ff24-4706-9435-d3b389c6ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-72db03b9-f5b6-4bbe-a57f-2864dff09471,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b1cb42d3-40c8-4676-adf7-b765e4bddcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-d17cf301-cbaf-4686-938c-78899046c376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734446151-172.17.0.7-1598578950467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-53490f27-c4c4-44d3-86f7-1244eae9758c,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-9bf55ca3-e5f4-42be-8a40-6daa1e7f1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-62c43086-f11f-40c2-953d-23e43e0ff8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-5d77b22c-0ede-41bd-a491-6a0e15396cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-cac945ef-ff24-4706-9435-d3b389c6ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-72db03b9-f5b6-4bbe-a57f-2864dff09471,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b1cb42d3-40c8-4676-adf7-b765e4bddcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-d17cf301-cbaf-4686-938c-78899046c376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065061995-172.17.0.7-1598579564641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46711,DS-24b5257b-a8c1-4672-8859-f65073a046f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-4b9861eb-4ee1-4f2b-9a59-56b0353589ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d535dcf4-3860-4c11-812e-68519b159426,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-6b863461-76b4-43fb-a8df-395504005070,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ad1745bc-14b7-43cb-bfc9-7c1c6431d6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-560a7f8a-1224-43fa-a531-8459b192735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1e595090-77aa-4dbf-8313-341fb0971585,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-f957a10a-dbc8-4db8-acdc-73c0e8b9e749,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065061995-172.17.0.7-1598579564641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46711,DS-24b5257b-a8c1-4672-8859-f65073a046f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-4b9861eb-4ee1-4f2b-9a59-56b0353589ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d535dcf4-3860-4c11-812e-68519b159426,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-6b863461-76b4-43fb-a8df-395504005070,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ad1745bc-14b7-43cb-bfc9-7c1c6431d6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-560a7f8a-1224-43fa-a531-8459b192735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1e595090-77aa-4dbf-8313-341fb0971585,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-f957a10a-dbc8-4db8-acdc-73c0e8b9e749,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860671870-172.17.0.7-1598579683877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-54fad3f7-9cc9-46ee-9e08-0d7db03982ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-52ec67db-a9de-4541-bf88-f65843ea8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-fb69b6b5-154e-42f0-811c-3c9608ea6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-161c59ae-47bf-4e69-af65-55a9dce8de47,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-4c469e2c-d0ac-4025-8037-3749d2451133,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-d60eb455-6349-403a-842f-adb65e74945a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-ae71debf-06e0-4c53-803b-82773c729777,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-463b3e5f-65cd-481e-8764-456f937f6d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860671870-172.17.0.7-1598579683877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45767,DS-54fad3f7-9cc9-46ee-9e08-0d7db03982ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-52ec67db-a9de-4541-bf88-f65843ea8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-fb69b6b5-154e-42f0-811c-3c9608ea6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-161c59ae-47bf-4e69-af65-55a9dce8de47,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-4c469e2c-d0ac-4025-8037-3749d2451133,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-d60eb455-6349-403a-842f-adb65e74945a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-ae71debf-06e0-4c53-803b-82773c729777,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-463b3e5f-65cd-481e-8764-456f937f6d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5515
