reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825005740-172.17.0.2-1598568619375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-ed31c3ba-d170-481f-8865-a361b34f3de4,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-e6cddbf4-0dae-47ba-8f98-60dea71783a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-529351ef-2ea0-4ff1-9196-9c69e850f712,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-1c9836e9-d1d5-4386-a3d9-c9740fbbd194,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-c7d9991a-ab98-4448-b118-fd6ca5063b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d356e8fa-f722-48ff-99a3-2b45d34926fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-d613d2e7-1f5a-4f45-917c-3d7863393fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-57dfacb6-fc7d-4609-9c89-152f3970ddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825005740-172.17.0.2-1598568619375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-ed31c3ba-d170-481f-8865-a361b34f3de4,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-e6cddbf4-0dae-47ba-8f98-60dea71783a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-529351ef-2ea0-4ff1-9196-9c69e850f712,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-1c9836e9-d1d5-4386-a3d9-c9740fbbd194,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-c7d9991a-ab98-4448-b118-fd6ca5063b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d356e8fa-f722-48ff-99a3-2b45d34926fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-d613d2e7-1f5a-4f45-917c-3d7863393fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-57dfacb6-fc7d-4609-9c89-152f3970ddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441066702-172.17.0.2-1598568886534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-cce821c9-e3c7-485f-b564-991fa8649ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c904ed6f-dad9-4f4a-aa41-8d2a164c0fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-00a0290b-ce69-4bdb-80e5-5c178b1284dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b4450f8f-7a0d-495b-a23d-623b63720344,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a7b6e4c9-22ab-466c-a4e7-32305f856d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-9660607f-46c2-4990-b2e7-3d1f9931d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-4023866e-d6f1-460b-bae4-76d4e605a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-ccc5ac6c-0ccf-421f-a423-be0cc0ad7eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441066702-172.17.0.2-1598568886534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-cce821c9-e3c7-485f-b564-991fa8649ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-c904ed6f-dad9-4f4a-aa41-8d2a164c0fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-00a0290b-ce69-4bdb-80e5-5c178b1284dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b4450f8f-7a0d-495b-a23d-623b63720344,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a7b6e4c9-22ab-466c-a4e7-32305f856d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-9660607f-46c2-4990-b2e7-3d1f9931d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-4023866e-d6f1-460b-bae4-76d4e605a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-ccc5ac6c-0ccf-421f-a423-be0cc0ad7eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934368909-172.17.0.2-1598568930350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-dfb83dd9-fc80-44b6-a940-a83341ee580a,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b826a08f-7d2c-4cb2-9468-cba41e970c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-75b48910-38df-47db-b2ef-a59b547d2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-a914f50c-fa0e-42b1-93ea-cc940fbe1198,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a0ed8d37-6a48-472b-9d22-b990d8ba1ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-a6b72104-a3dd-4420-b008-f3194f423962,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-5d855c1f-3e77-4488-9b85-36efa18fbb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-b83d7eee-36bb-4267-adff-b9ac3765b3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934368909-172.17.0.2-1598568930350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-dfb83dd9-fc80-44b6-a940-a83341ee580a,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b826a08f-7d2c-4cb2-9468-cba41e970c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-75b48910-38df-47db-b2ef-a59b547d2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-a914f50c-fa0e-42b1-93ea-cc940fbe1198,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a0ed8d37-6a48-472b-9d22-b990d8ba1ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-a6b72104-a3dd-4420-b008-f3194f423962,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-5d855c1f-3e77-4488-9b85-36efa18fbb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-b83d7eee-36bb-4267-adff-b9ac3765b3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547199326-172.17.0.2-1598569331764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-49640689-8d27-4410-a59e-09e7bb75156b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-0f830698-40e7-409d-a1aa-95383c938795,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-36941373-46f9-496f-ab48-639a563d696c,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-84118845-8bb9-4587-af44-d720e9c741bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-3f4a5f43-6c35-4640-b2be-706aa7cc78a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-25995923-bc93-40f5-8322-55353fabfc25,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-3e2f9bcd-0400-438c-9186-15d6b1e1a49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-3ccba7b1-9fbe-44d0-b00a-c99a7e33e49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547199326-172.17.0.2-1598569331764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-49640689-8d27-4410-a59e-09e7bb75156b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-0f830698-40e7-409d-a1aa-95383c938795,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-36941373-46f9-496f-ab48-639a563d696c,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-84118845-8bb9-4587-af44-d720e9c741bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-3f4a5f43-6c35-4640-b2be-706aa7cc78a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-25995923-bc93-40f5-8322-55353fabfc25,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-3e2f9bcd-0400-438c-9186-15d6b1e1a49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-3ccba7b1-9fbe-44d0-b00a-c99a7e33e49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023748642-172.17.0.2-1598569914753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-eb5cfb60-69fb-4fc7-9aa5-d9141dbf4735,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-2e80158e-97d8-42c8-a679-874642a1fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-1a9fad50-5251-466d-b403-708635667bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-5cf3c63b-7ed9-4db8-b254-9e1bb7dd2d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-56beedb0-551e-4aa3-b131-94665fae0814,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b30e0c05-a32a-4648-9522-cb9ec79939f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-3781b047-e2e1-4bfb-b345-bc6189290fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-8e78179f-2655-4d45-80a9-d8f3ecde939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023748642-172.17.0.2-1598569914753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-eb5cfb60-69fb-4fc7-9aa5-d9141dbf4735,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-2e80158e-97d8-42c8-a679-874642a1fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-1a9fad50-5251-466d-b403-708635667bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-5cf3c63b-7ed9-4db8-b254-9e1bb7dd2d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-56beedb0-551e-4aa3-b131-94665fae0814,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b30e0c05-a32a-4648-9522-cb9ec79939f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-3781b047-e2e1-4bfb-b345-bc6189290fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-8e78179f-2655-4d45-80a9-d8f3ecde939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980997831-172.17.0.2-1598570875150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-ba00c734-9986-41af-a478-b49815a413a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-ae5e4722-1225-403d-a899-abc83e402d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-124da462-6fdf-471d-a0ea-6e80c2f864b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-950a9856-964c-4255-890f-b1f2c00344b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-92af36e4-efde-4cd8-81cd-5cf40b00830d,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-b0b61a1b-4dda-42c2-84df-3a1120d2f74c,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ef63d367-a8f9-44d0-b965-234eec729c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-8299e846-a87e-4535-88e9-7d64c5769f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980997831-172.17.0.2-1598570875150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-ba00c734-9986-41af-a478-b49815a413a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-ae5e4722-1225-403d-a899-abc83e402d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-124da462-6fdf-471d-a0ea-6e80c2f864b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-950a9856-964c-4255-890f-b1f2c00344b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-92af36e4-efde-4cd8-81cd-5cf40b00830d,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-b0b61a1b-4dda-42c2-84df-3a1120d2f74c,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-ef63d367-a8f9-44d0-b965-234eec729c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-8299e846-a87e-4535-88e9-7d64c5769f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227236795-172.17.0.2-1598571134575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-ac950797-16de-459f-a495-01f95a23d411,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-3514a0d6-0a38-4273-9744-567cae252ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-4f1062a4-d6e0-45da-82fb-eb2864eaa6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-2bbd3102-7f8f-49b2-a336-0cd75404ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-fd871f3b-808e-4f16-b8e5-a5c18b8f4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-ee759a46-db83-4ffd-9397-e40c79d209f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ebade409-5398-40f3-b28c-d3be6c32fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-0fa89a5d-8fdd-49cd-a057-13cf26787ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227236795-172.17.0.2-1598571134575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-ac950797-16de-459f-a495-01f95a23d411,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-3514a0d6-0a38-4273-9744-567cae252ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-4f1062a4-d6e0-45da-82fb-eb2864eaa6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-2bbd3102-7f8f-49b2-a336-0cd75404ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-fd871f3b-808e-4f16-b8e5-a5c18b8f4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-ee759a46-db83-4ffd-9397-e40c79d209f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-ebade409-5398-40f3-b28c-d3be6c32fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-0fa89a5d-8fdd-49cd-a057-13cf26787ba2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210484056-172.17.0.2-1598571433025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-7098e8af-d3a1-4ac1-89f9-7066b4dfd5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-96db9774-4a98-4f2b-a12b-256359853fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-9022dbe8-31a4-4a78-ac2c-accbb753a800,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-d2848cf1-2539-4aeb-b52d-5aa2b3a8b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-8dc3347e-8e43-452f-8647-0f92fe8a5fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3b74e438-6dbe-47a3-a8ab-ff516f5a2a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-32853e48-4a2e-4247-b20d-c4d76cb2d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-bccc1fa2-f55d-497d-ab9c-b63cfa5bdb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210484056-172.17.0.2-1598571433025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-7098e8af-d3a1-4ac1-89f9-7066b4dfd5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-96db9774-4a98-4f2b-a12b-256359853fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-9022dbe8-31a4-4a78-ac2c-accbb753a800,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-d2848cf1-2539-4aeb-b52d-5aa2b3a8b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-8dc3347e-8e43-452f-8647-0f92fe8a5fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3b74e438-6dbe-47a3-a8ab-ff516f5a2a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-32853e48-4a2e-4247-b20d-c4d76cb2d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-bccc1fa2-f55d-497d-ab9c-b63cfa5bdb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264765616-172.17.0.2-1598571508617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-5e8d0725-f8ca-4a9b-9360-8abd34bf58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-bbf18970-034c-47c6-97f4-eb1678b2bc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-cdc58ecf-19ff-48d0-81b6-e89915da69db,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-b4bdc664-026d-4de6-b73b-6fbb419fa286,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-c615692e-6536-4262-8981-014512e08c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-cd9da68d-cb84-4799-aa3c-92be16c903fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-d410cdc1-9ddd-4ee0-b2e7-d7de3c5eb778,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-58677bb4-b691-4cd9-be36-aece05db1202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264765616-172.17.0.2-1598571508617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36555,DS-5e8d0725-f8ca-4a9b-9360-8abd34bf58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-bbf18970-034c-47c6-97f4-eb1678b2bc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-cdc58ecf-19ff-48d0-81b6-e89915da69db,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-b4bdc664-026d-4de6-b73b-6fbb419fa286,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-c615692e-6536-4262-8981-014512e08c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-cd9da68d-cb84-4799-aa3c-92be16c903fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-d410cdc1-9ddd-4ee0-b2e7-d7de3c5eb778,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-58677bb4-b691-4cd9-be36-aece05db1202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884734019-172.17.0.2-1598572052826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-43217cad-7975-4d04-af47-6a0beb5007f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-04fc7be6-bd13-4c28-a03c-ec039b3d8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-6a02f17b-a78a-45ca-ba2f-f203b3887dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-43b6a460-31a2-4ce6-a78b-f5afb4543fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-88aecd96-7d88-4e56-b65d-a8b9801aa718,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-001df014-05fc-4363-b1a9-292530b31dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-7898bfe0-ce0f-4ad3-a870-d06a0c1e7590,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-9c973ad0-950d-4554-87f2-701287d415ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884734019-172.17.0.2-1598572052826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-43217cad-7975-4d04-af47-6a0beb5007f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-04fc7be6-bd13-4c28-a03c-ec039b3d8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-6a02f17b-a78a-45ca-ba2f-f203b3887dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-43b6a460-31a2-4ce6-a78b-f5afb4543fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-88aecd96-7d88-4e56-b65d-a8b9801aa718,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-001df014-05fc-4363-b1a9-292530b31dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-7898bfe0-ce0f-4ad3-a870-d06a0c1e7590,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-9c973ad0-950d-4554-87f2-701287d415ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467581480-172.17.0.2-1598572321633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-b6efbb01-d81e-46da-bae1-20ad9f68d093,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-0569ebbb-e03b-4ef6-85d6-ade19fe93781,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-10099571-36e9-4a21-ae40-15be5807c480,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2f3d6efa-965e-4367-9e15-1891d7d5fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-a8b7cbcc-e5cd-4979-8738-8c3e6dd5e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-f4f91722-0a3f-405b-ac05-737bbf237016,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-54303204-286b-409c-9ed1-62b39cfaa7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-26f383da-b8e7-485c-a122-69b8ac15aa15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467581480-172.17.0.2-1598572321633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-b6efbb01-d81e-46da-bae1-20ad9f68d093,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-0569ebbb-e03b-4ef6-85d6-ade19fe93781,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-10099571-36e9-4a21-ae40-15be5807c480,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-2f3d6efa-965e-4367-9e15-1891d7d5fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-a8b7cbcc-e5cd-4979-8738-8c3e6dd5e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-f4f91722-0a3f-405b-ac05-737bbf237016,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-54303204-286b-409c-9ed1-62b39cfaa7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-26f383da-b8e7-485c-a122-69b8ac15aa15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996458640-172.17.0.2-1598573488469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-bcccb72a-2985-42b3-91db-224f43ba7a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-20f8b2d2-dd9a-4d1b-ab41-8c6a7b466fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-1ddbf930-a6f1-4d91-b570-ea8116fdf3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-ea24fe02-17df-4a86-adad-f2109fb03613,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-13199aaa-d8bb-4b3d-9f05-19836fad402c,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-9d6677db-f785-4f08-a7b6-2983c2df7450,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-1afe2ef4-a5c5-408e-9196-32826d394a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-636806ec-6fff-4973-bdf1-87a2fc594690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996458640-172.17.0.2-1598573488469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-bcccb72a-2985-42b3-91db-224f43ba7a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-20f8b2d2-dd9a-4d1b-ab41-8c6a7b466fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-1ddbf930-a6f1-4d91-b570-ea8116fdf3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-ea24fe02-17df-4a86-adad-f2109fb03613,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-13199aaa-d8bb-4b3d-9f05-19836fad402c,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-9d6677db-f785-4f08-a7b6-2983c2df7450,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-1afe2ef4-a5c5-408e-9196-32826d394a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-636806ec-6fff-4973-bdf1-87a2fc594690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127529681-172.17.0.2-1598573570704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-34d82e5c-d1e3-42b7-b90d-4853d96536b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-f500511e-4691-4473-9387-828072e2b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-36a013ff-e35e-45ff-9647-6c8748a9fb51,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-db3e4c3a-9058-4af9-9e4c-ee42bde1c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-daac257f-1b4c-4df4-8fe4-931dfec32ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-6f23a7b2-1ceb-4147-97e8-6f5088b39bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-18aba1b6-4e73-462e-b3b6-1e20031e9127,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-04938111-1f31-4bd5-bcce-6571f444f297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127529681-172.17.0.2-1598573570704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-34d82e5c-d1e3-42b7-b90d-4853d96536b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-f500511e-4691-4473-9387-828072e2b8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-36a013ff-e35e-45ff-9647-6c8748a9fb51,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-db3e4c3a-9058-4af9-9e4c-ee42bde1c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-daac257f-1b4c-4df4-8fe4-931dfec32ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-6f23a7b2-1ceb-4147-97e8-6f5088b39bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-18aba1b6-4e73-462e-b3b6-1e20031e9127,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-04938111-1f31-4bd5-bcce-6571f444f297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5636
