reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955487808-172.17.0.6-1598548794182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-9932d792-089e-454a-88bc-eaf47ff40c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-337a2234-fde0-4288-b714-7ab1573244a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-c40f4726-33ee-4c3a-a67d-f5345d353e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-0b55a018-ee9f-4c45-9df2-36d0b237b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-ef4b5c6a-5e15-4d47-8943-5092807af4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-d641564a-1a33-4706-9c06-e8389a7c5408,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-fc31e8c0-2b09-41f0-bd3c-ccb0cc9ceb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-0dc1b48b-5687-44d0-9b82-0a9f610c1302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955487808-172.17.0.6-1598548794182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-9932d792-089e-454a-88bc-eaf47ff40c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-337a2234-fde0-4288-b714-7ab1573244a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-c40f4726-33ee-4c3a-a67d-f5345d353e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-0b55a018-ee9f-4c45-9df2-36d0b237b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-ef4b5c6a-5e15-4d47-8943-5092807af4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-d641564a-1a33-4706-9c06-e8389a7c5408,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-fc31e8c0-2b09-41f0-bd3c-ccb0cc9ceb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-0dc1b48b-5687-44d0-9b82-0a9f610c1302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753163888-172.17.0.6-1598549459280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-65069064-1e47-430c-b6c4-694b335ca015,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-fc8b29be-f40f-457c-adf4-06286edc4b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-57c16688-c639-403a-8c58-2c9ea93811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-3c13fb6f-3022-4a4c-bc48-a0b7f0857b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-a40f2a53-0a87-4d66-84a5-80a38c1f2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-b6944984-4473-4b2f-8bad-ec96d6313423,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-de0175f4-1deb-416b-b30f-a1217fadd9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-f9115187-1994-4d74-88d3-9d3a7aee6735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753163888-172.17.0.6-1598549459280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-65069064-1e47-430c-b6c4-694b335ca015,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-fc8b29be-f40f-457c-adf4-06286edc4b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-57c16688-c639-403a-8c58-2c9ea93811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-3c13fb6f-3022-4a4c-bc48-a0b7f0857b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-a40f2a53-0a87-4d66-84a5-80a38c1f2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-b6944984-4473-4b2f-8bad-ec96d6313423,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-de0175f4-1deb-416b-b30f-a1217fadd9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-f9115187-1994-4d74-88d3-9d3a7aee6735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582069462-172.17.0.6-1598549498303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-e8658b92-7cab-435d-b3f6-d531004facbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-739a02a6-4ad1-4ded-a021-8ec113d78d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-9b5e9c3c-c449-4e89-8b11-3847567da7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-cc934ec9-877f-4f2a-8097-d6047d22a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-a42e21ec-8be9-49c8-8c4b-2fffc4baebef,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-fa18c5cb-ea0b-498b-b9dc-7742434c86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9f56bfda-5f25-47de-b093-bea9452d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-14f48500-f90f-4962-87a5-cb9917912f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582069462-172.17.0.6-1598549498303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41871,DS-e8658b92-7cab-435d-b3f6-d531004facbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-739a02a6-4ad1-4ded-a021-8ec113d78d56,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-9b5e9c3c-c449-4e89-8b11-3847567da7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-cc934ec9-877f-4f2a-8097-d6047d22a9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-a42e21ec-8be9-49c8-8c4b-2fffc4baebef,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-fa18c5cb-ea0b-498b-b9dc-7742434c86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9f56bfda-5f25-47de-b093-bea9452d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-14f48500-f90f-4962-87a5-cb9917912f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689556852-172.17.0.6-1598549609059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-41e0c506-b076-49f7-a089-c1d2060d13b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c9f39f22-d4b8-4c85-8acf-a33518ec0bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-988213d5-7fcb-4ac0-9d38-5b399de56b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-eca82b8d-cd52-4cb2-8dbc-8a8bd3bf23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-cf03c539-4ee6-49f4-ba1d-464d61cbe1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-ab69e37e-9d12-48e1-b027-0f27aaf3141b,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-3ab51a29-49de-42cc-a645-0baa3429404e,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-71043cfb-1cc4-4622-8049-6de6f2e28558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689556852-172.17.0.6-1598549609059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-41e0c506-b076-49f7-a089-c1d2060d13b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c9f39f22-d4b8-4c85-8acf-a33518ec0bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-988213d5-7fcb-4ac0-9d38-5b399de56b32,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-eca82b8d-cd52-4cb2-8dbc-8a8bd3bf23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-cf03c539-4ee6-49f4-ba1d-464d61cbe1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-ab69e37e-9d12-48e1-b027-0f27aaf3141b,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-3ab51a29-49de-42cc-a645-0baa3429404e,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-71043cfb-1cc4-4622-8049-6de6f2e28558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200162735-172.17.0.6-1598549641969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46579,DS-8c0c648f-697e-4fb0-8f7c-b56a457ea6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-abc43267-ca7e-4409-bec6-2ec599c3958a,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-76ba8730-fc3c-46cf-af25-602d400261a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-1d76e2fd-cbac-4173-ada3-a155eac6af6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-e8cf869e-157c-4406-b314-c05cf67c24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d653e629-4185-4d83-a411-216bced8c884,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4aaca586-d3e9-49c0-b19a-5f920fbdcc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-9dfac10f-a23a-4ec8-aaf2-2c057fe3e5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200162735-172.17.0.6-1598549641969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46579,DS-8c0c648f-697e-4fb0-8f7c-b56a457ea6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-abc43267-ca7e-4409-bec6-2ec599c3958a,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-76ba8730-fc3c-46cf-af25-602d400261a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-1d76e2fd-cbac-4173-ada3-a155eac6af6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-e8cf869e-157c-4406-b314-c05cf67c24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d653e629-4185-4d83-a411-216bced8c884,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4aaca586-d3e9-49c0-b19a-5f920fbdcc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-9dfac10f-a23a-4ec8-aaf2-2c057fe3e5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229380998-172.17.0.6-1598549881543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-61dbb27c-51ba-4c62-8d74-58fe3f5d885c,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-2b0bc922-bb92-40dc-8344-427c44e2859e,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-4b3fc46a-ef48-4c9d-ab27-de6351a88ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-84d7beb3-c020-429c-8774-39fe265299bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-ff43ebc9-a159-43e3-8fc1-ac6925fd8750,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-958263f9-3c30-40bb-b098-866171a63dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-734cd2e7-2123-4193-9f95-06280c0ac99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-56a4b7cc-afd3-49e9-a20b-cfb60d472355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229380998-172.17.0.6-1598549881543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-61dbb27c-51ba-4c62-8d74-58fe3f5d885c,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-2b0bc922-bb92-40dc-8344-427c44e2859e,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-4b3fc46a-ef48-4c9d-ab27-de6351a88ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-84d7beb3-c020-429c-8774-39fe265299bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-ff43ebc9-a159-43e3-8fc1-ac6925fd8750,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-958263f9-3c30-40bb-b098-866171a63dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-734cd2e7-2123-4193-9f95-06280c0ac99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-56a4b7cc-afd3-49e9-a20b-cfb60d472355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410265146-172.17.0.6-1598551126860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-f1d86396-89f6-4e7e-966d-a7c22584871a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-373044ab-01e2-4c11-ad01-a0cf55c411c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8c468541-156c-4234-8f68-432fd17bd7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-6d3c609c-89ae-47c2-980c-a3fdb5e4e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-cceb4159-d45f-4fbd-9d08-269337f096a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-145b1462-187a-439d-bd11-f99efc701c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-d8fe66bc-bdf9-4538-b29a-702649b90c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-32ae5f33-5bf1-49c4-8073-b12594039a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410265146-172.17.0.6-1598551126860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-f1d86396-89f6-4e7e-966d-a7c22584871a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-373044ab-01e2-4c11-ad01-a0cf55c411c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-8c468541-156c-4234-8f68-432fd17bd7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-6d3c609c-89ae-47c2-980c-a3fdb5e4e6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-cceb4159-d45f-4fbd-9d08-269337f096a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-145b1462-187a-439d-bd11-f99efc701c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-d8fe66bc-bdf9-4538-b29a-702649b90c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-32ae5f33-5bf1-49c4-8073-b12594039a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692589422-172.17.0.6-1598551315843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-71450e6d-882e-41ec-9c7a-d529945dd2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-2ca38b78-2409-435a-bf03-a88218b5f851,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-cac7ced5-2ef3-45a7-8633-785ad17e267c,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-15784419-4b56-42e9-a23a-cc11b48aefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-a166650e-db8d-41fa-bbed-691d7ead0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-c222688a-b8e7-44e6-8f56-c58f7f416cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-dc4d0c3d-7c90-41ef-86db-eac35d570c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-5506e47f-de77-48f4-8ddd-ebd11d8f33ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692589422-172.17.0.6-1598551315843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-71450e6d-882e-41ec-9c7a-d529945dd2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-2ca38b78-2409-435a-bf03-a88218b5f851,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-cac7ced5-2ef3-45a7-8633-785ad17e267c,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-15784419-4b56-42e9-a23a-cc11b48aefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-a166650e-db8d-41fa-bbed-691d7ead0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-c222688a-b8e7-44e6-8f56-c58f7f416cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-dc4d0c3d-7c90-41ef-86db-eac35d570c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-5506e47f-de77-48f4-8ddd-ebd11d8f33ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746898185-172.17.0.6-1598551427703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-2810e77b-c9cc-4c57-bf8b-dab707fcaa24,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-3411a546-fcc2-479b-8e6e-b46526d586c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-1f5f3d5b-2030-49a0-95cf-ba26e7a3aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-de2184b8-f21a-4b48-aa70-772a388bbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-d17f4bba-2de1-422e-a697-462ae91d38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-c5864d36-a4cf-4dfb-a615-69665d0e7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-2db30ec2-4e13-4ce4-bbac-89815bb73a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-6d332807-5803-438e-a766-020c04a85169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746898185-172.17.0.6-1598551427703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-2810e77b-c9cc-4c57-bf8b-dab707fcaa24,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-3411a546-fcc2-479b-8e6e-b46526d586c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-1f5f3d5b-2030-49a0-95cf-ba26e7a3aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-de2184b8-f21a-4b48-aa70-772a388bbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-d17f4bba-2de1-422e-a697-462ae91d38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-c5864d36-a4cf-4dfb-a615-69665d0e7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-2db30ec2-4e13-4ce4-bbac-89815bb73a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-6d332807-5803-438e-a766-020c04a85169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239257739-172.17.0.6-1598551848569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-0aa59183-3319-4bf8-8f44-6c225c087950,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-1509fbfe-fd5f-4eff-ae34-0c452c00bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-61af6456-200c-4b6c-8bc2-bbeee02de84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-e5800ca3-5776-4cb0-a66f-b3d1f39cf621,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-9b72aa1c-c9b7-4dab-96c2-caaa2a0914b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-9345bfc7-9b99-4071-879c-1909a6322672,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-97907ff3-06f2-4821-8506-d487e544453e,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-07f4763d-5bed-49a9-8d68-e418afd403cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239257739-172.17.0.6-1598551848569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-0aa59183-3319-4bf8-8f44-6c225c087950,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-1509fbfe-fd5f-4eff-ae34-0c452c00bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-61af6456-200c-4b6c-8bc2-bbeee02de84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-e5800ca3-5776-4cb0-a66f-b3d1f39cf621,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-9b72aa1c-c9b7-4dab-96c2-caaa2a0914b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-9345bfc7-9b99-4071-879c-1909a6322672,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-97907ff3-06f2-4821-8506-d487e544453e,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-07f4763d-5bed-49a9-8d68-e418afd403cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828719255-172.17.0.6-1598551884535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-bc97e59c-ee4c-43f2-b885-336284251f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-650fa8eb-8c2b-4ce3-b9bc-d9f3fc09c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-5ce93767-46c7-4a47-83de-1362e48fcfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-bc8ee339-d1e0-4b3c-ae1a-f82ab5e427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-de0acffd-2b2e-4161-85aa-51cdffa4b230,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-316916bb-964b-47fd-88db-767ac5ba131a,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-68fa191a-2dec-484a-a909-f05f65d921ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-be9d53cb-b39d-4c92-b1fd-b14979b067f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828719255-172.17.0.6-1598551884535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-bc97e59c-ee4c-43f2-b885-336284251f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-650fa8eb-8c2b-4ce3-b9bc-d9f3fc09c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-5ce93767-46c7-4a47-83de-1362e48fcfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-bc8ee339-d1e0-4b3c-ae1a-f82ab5e427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-de0acffd-2b2e-4161-85aa-51cdffa4b230,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-316916bb-964b-47fd-88db-767ac5ba131a,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-68fa191a-2dec-484a-a909-f05f65d921ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-be9d53cb-b39d-4c92-b1fd-b14979b067f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828685211-172.17.0.6-1598551933600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-2abbbda1-eabd-4f37-b9e8-8a8d80b3096d,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-d47a26bd-9295-4ca0-a874-6eb071045c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-672fec9b-516f-481c-8dc5-c81759a226bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-772fb81d-25f9-4670-9c5b-c224d6679345,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-f7e9466b-1907-4572-bc50-3f355265ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-de3241f6-5854-462a-a007-27f0eae769b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-06aa0147-2d27-4dbe-9d8c-42a70410cb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-fcc706e3-b0fb-4529-9b90-c039a119e312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828685211-172.17.0.6-1598551933600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-2abbbda1-eabd-4f37-b9e8-8a8d80b3096d,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-d47a26bd-9295-4ca0-a874-6eb071045c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-672fec9b-516f-481c-8dc5-c81759a226bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-772fb81d-25f9-4670-9c5b-c224d6679345,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-f7e9466b-1907-4572-bc50-3f355265ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-de3241f6-5854-462a-a007-27f0eae769b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-06aa0147-2d27-4dbe-9d8c-42a70410cb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-fcc706e3-b0fb-4529-9b90-c039a119e312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427205809-172.17.0.6-1598551969915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36114,DS-b2a7438d-3be5-423b-8270-68b7b3dff8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-23bbaf59-a22e-4774-82d2-459b346a6882,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b7857d90-a79b-4c6f-bee8-c22694766dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-75775d9c-2f0f-4c15-ae6c-5ac11b49eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-39f43f1b-a95a-4107-8d2e-6b6911cc5deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-3de0a524-f3a2-4ef1-91e9-f68fd5dab6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-19e0201b-b984-4624-9f61-91e38b1f1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-7415b6de-618e-4666-89cc-f6cfc6bc5c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427205809-172.17.0.6-1598551969915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36114,DS-b2a7438d-3be5-423b-8270-68b7b3dff8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-23bbaf59-a22e-4774-82d2-459b346a6882,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-b7857d90-a79b-4c6f-bee8-c22694766dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-75775d9c-2f0f-4c15-ae6c-5ac11b49eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-39f43f1b-a95a-4107-8d2e-6b6911cc5deb,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-3de0a524-f3a2-4ef1-91e9-f68fd5dab6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-19e0201b-b984-4624-9f61-91e38b1f1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-7415b6de-618e-4666-89cc-f6cfc6bc5c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231694529-172.17.0.6-1598552046455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-16656ed1-f91b-4176-b46a-05c4886ece92,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0cdd3122-26de-4442-84ab-e827cabbcd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-592b22df-acde-42eb-93de-28cd84b8e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-852fa6c8-2430-48b5-b2bb-e5155713a2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-b5d9bbd6-a12b-4701-b41d-ae62852ea19b,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-a14c27ad-4c19-4900-a289-33975c4b777b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8a3bc648-ca04-458f-9ff3-6239ffa9ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2c0befeb-457e-4ccb-a014-628066d8729f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231694529-172.17.0.6-1598552046455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-16656ed1-f91b-4176-b46a-05c4886ece92,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0cdd3122-26de-4442-84ab-e827cabbcd18,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-592b22df-acde-42eb-93de-28cd84b8e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-852fa6c8-2430-48b5-b2bb-e5155713a2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-b5d9bbd6-a12b-4701-b41d-ae62852ea19b,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-a14c27ad-4c19-4900-a289-33975c4b777b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8a3bc648-ca04-458f-9ff3-6239ffa9ae72,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2c0befeb-457e-4ccb-a014-628066d8729f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159732367-172.17.0.6-1598552799371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-1a7639bc-4732-4d4a-b202-9556ba27f016,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-3ac07c21-7d86-4367-b22b-0540ac1e606b,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-8da73e01-27d6-4999-86a7-57b2bbaf8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9f0cf4b5-7187-489d-9448-3cc11c4e1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-3ca949a2-06e3-4332-bb85-99ff464d4024,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-bdbc8280-fb39-4d82-8b4d-bae18b203a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-7af560e2-cdbb-4564-9095-4a9fa28cd926,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-bf5213f0-54ac-482a-8962-c8c43cd7a7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159732367-172.17.0.6-1598552799371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-1a7639bc-4732-4d4a-b202-9556ba27f016,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-3ac07c21-7d86-4367-b22b-0540ac1e606b,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-8da73e01-27d6-4999-86a7-57b2bbaf8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9f0cf4b5-7187-489d-9448-3cc11c4e1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-3ca949a2-06e3-4332-bb85-99ff464d4024,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-bdbc8280-fb39-4d82-8b4d-bae18b203a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-7af560e2-cdbb-4564-9095-4a9fa28cd926,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-bf5213f0-54ac-482a-8962-c8c43cd7a7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37181716-172.17.0.6-1598553799592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-8be6ca07-5a99-4808-bd2c-62efe3889da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-cecbc50b-0c9d-40a6-ad18-13c20e532200,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-6faa4f89-a3c0-4807-b490-5985eef1936f,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c39f2cd8-519b-4780-a37a-fb066121c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-4f20cfb6-8e85-4b30-8aeb-3c5463eebe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-3e51220e-07c8-4ea6-95bf-d77f2abf3b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-611a4cfa-c627-4714-a78a-8394491e1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-7057e1e1-4194-4b4d-901d-119873784c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37181716-172.17.0.6-1598553799592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-8be6ca07-5a99-4808-bd2c-62efe3889da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-cecbc50b-0c9d-40a6-ad18-13c20e532200,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-6faa4f89-a3c0-4807-b490-5985eef1936f,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c39f2cd8-519b-4780-a37a-fb066121c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-4f20cfb6-8e85-4b30-8aeb-3c5463eebe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-3e51220e-07c8-4ea6-95bf-d77f2abf3b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-611a4cfa-c627-4714-a78a-8394491e1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-7057e1e1-4194-4b4d-901d-119873784c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193924513-172.17.0.6-1598553903095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-d9a90772-6252-4358-a86a-25ae546c541d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d117c741-46b3-4c65-be67-babf30aa7c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-94f3db1e-b0e2-4c62-adcf-ad7af2f24571,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-5dd2cff9-600d-47af-8ea1-5bd913ecea02,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-e8935ca7-507d-4570-9abb-5122cdb2f759,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-fc1db7f0-9da2-4714-86ed-b7d947a6faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2549c5c5-c3c6-4089-883e-38991f373a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-a3b35428-e019-4191-b88f-6d514886f421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193924513-172.17.0.6-1598553903095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-d9a90772-6252-4358-a86a-25ae546c541d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d117c741-46b3-4c65-be67-babf30aa7c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-94f3db1e-b0e2-4c62-adcf-ad7af2f24571,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-5dd2cff9-600d-47af-8ea1-5bd913ecea02,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-e8935ca7-507d-4570-9abb-5122cdb2f759,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-fc1db7f0-9da2-4714-86ed-b7d947a6faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2549c5c5-c3c6-4089-883e-38991f373a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-a3b35428-e019-4191-b88f-6d514886f421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173668494-172.17.0.6-1598554207130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-7970e120-faa9-4ebf-b09e-937e95cf9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-a251aad5-ddae-4935-b3de-63971391532b,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-ed5349b8-e4d2-4075-8071-7a46ee2b805e,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-6c531502-a194-4000-a7a9-0801778de310,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-e3b5ac16-b1da-44ee-a396-4dd5a568282e,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-cd9d3132-d790-4ae5-a7fa-7af1f150cc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-8829779c-c106-4de4-9897-426e63cd0c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-aee487ef-4019-4e51-9ded-d8a588e9e343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173668494-172.17.0.6-1598554207130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-7970e120-faa9-4ebf-b09e-937e95cf9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-a251aad5-ddae-4935-b3de-63971391532b,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-ed5349b8-e4d2-4075-8071-7a46ee2b805e,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-6c531502-a194-4000-a7a9-0801778de310,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-e3b5ac16-b1da-44ee-a396-4dd5a568282e,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-cd9d3132-d790-4ae5-a7fa-7af1f150cc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-8829779c-c106-4de4-9897-426e63cd0c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-aee487ef-4019-4e51-9ded-d8a588e9e343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5532
