reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672862979-172.17.0.5-1598523178014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-b811a2eb-151a-4204-b776-0ff8f20426c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-d6906b62-3558-4d08-91f0-eaa9321dc488,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-b7a60fe6-adfa-452d-b33c-1a972affeb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-01f626c6-394f-4cc6-ab00-32282ede2bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f7af34a6-6a32-4741-8f7c-ac81c81bebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-77226c34-30e5-40fe-8579-aa17b7413a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-e46d745d-eab6-424c-934c-67070b262cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-13011bd1-00d6-4abf-b6ce-42f178a2176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672862979-172.17.0.5-1598523178014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-b811a2eb-151a-4204-b776-0ff8f20426c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-d6906b62-3558-4d08-91f0-eaa9321dc488,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-b7a60fe6-adfa-452d-b33c-1a972affeb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-01f626c6-394f-4cc6-ab00-32282ede2bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f7af34a6-6a32-4741-8f7c-ac81c81bebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-77226c34-30e5-40fe-8579-aa17b7413a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-e46d745d-eab6-424c-934c-67070b262cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-13011bd1-00d6-4abf-b6ce-42f178a2176e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363931634-172.17.0.5-1598523215665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-b33c4503-514f-4815-9af6-9ec102180d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-0a727e93-5d10-474e-97b5-8e178e588c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-b49edc37-cd10-4c9a-b39b-ebe8c28e1854,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-8e6ac5cf-b7bb-4f3e-864b-b192fa2f1c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-859481e5-cfaf-4ad4-b9be-0f669ee24273,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f0d4d1ee-68a5-4099-8583-2fb740f1a971,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-a75c8b48-0a71-4ecb-9385-76ea7ba7d2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-8215df5e-3f19-43fc-a205-18e70e0cba56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363931634-172.17.0.5-1598523215665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41426,DS-b33c4503-514f-4815-9af6-9ec102180d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-0a727e93-5d10-474e-97b5-8e178e588c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-b49edc37-cd10-4c9a-b39b-ebe8c28e1854,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-8e6ac5cf-b7bb-4f3e-864b-b192fa2f1c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-859481e5-cfaf-4ad4-b9be-0f669ee24273,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f0d4d1ee-68a5-4099-8583-2fb740f1a971,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-a75c8b48-0a71-4ecb-9385-76ea7ba7d2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-8215df5e-3f19-43fc-a205-18e70e0cba56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065536984-172.17.0.5-1598523463198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-c584de3b-e543-47de-9ca0-a1918cbdef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-02fa63c8-bde4-4ec3-a0ce-8975efa0cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-ef9a4fa2-7743-412e-b228-e41014caacb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-fdde98f3-8871-4f09-be5d-45eac66901fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-8b7b7e00-196f-4cdc-8ccf-f25dfe487f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-cac78405-e93a-4567-a6cc-74666e6916db,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-0e2c0cac-afcb-4db6-babf-f7024b3244e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-490f8776-29eb-450a-89b2-e6889fa0a571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065536984-172.17.0.5-1598523463198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-c584de3b-e543-47de-9ca0-a1918cbdef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-02fa63c8-bde4-4ec3-a0ce-8975efa0cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-ef9a4fa2-7743-412e-b228-e41014caacb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-fdde98f3-8871-4f09-be5d-45eac66901fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-8b7b7e00-196f-4cdc-8ccf-f25dfe487f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-cac78405-e93a-4567-a6cc-74666e6916db,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-0e2c0cac-afcb-4db6-babf-f7024b3244e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-490f8776-29eb-450a-89b2-e6889fa0a571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374607928-172.17.0.5-1598523833916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-918c6748-7139-4a35-8915-1c8108c48b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-9ded4cbd-ccdc-49cf-9158-16a317ed2746,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-64de39f4-bbfc-42f1-88b6-23ff0d7673fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-66e2f331-e002-42dd-8a57-a0e835cc2c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-55c7db9e-9e17-47b4-abb1-19a6c0ec9ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-a72d9548-ec6c-4ffd-bd16-640024ae19ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-114ad89f-e900-4352-989d-88da54f3b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a41dece1-e9de-4c98-b449-5ae1d137355a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374607928-172.17.0.5-1598523833916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-918c6748-7139-4a35-8915-1c8108c48b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-9ded4cbd-ccdc-49cf-9158-16a317ed2746,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-64de39f4-bbfc-42f1-88b6-23ff0d7673fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-66e2f331-e002-42dd-8a57-a0e835cc2c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-55c7db9e-9e17-47b4-abb1-19a6c0ec9ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-a72d9548-ec6c-4ffd-bd16-640024ae19ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-114ad89f-e900-4352-989d-88da54f3b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a41dece1-e9de-4c98-b449-5ae1d137355a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317199805-172.17.0.5-1598523945431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-2acb5792-06e5-4ed6-bc11-055c73c5da2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-0622aa80-392b-4ee9-8dce-267319d15dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-bb51a9b7-7936-402a-9c55-5b8cd1e8d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0e373b2d-0cc7-45a6-986b-d5f566da2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-e93bd9e6-e7d1-4690-8244-c7d0fe7ed9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-24f5a3b7-837d-44c1-b1b1-a1afd2d3a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-eb7f05ca-e2b5-4456-b831-5b69e991d698,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-b2a90124-00c2-456b-b13c-163a4b1d1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317199805-172.17.0.5-1598523945431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-2acb5792-06e5-4ed6-bc11-055c73c5da2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-0622aa80-392b-4ee9-8dce-267319d15dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-bb51a9b7-7936-402a-9c55-5b8cd1e8d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-0e373b2d-0cc7-45a6-986b-d5f566da2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-e93bd9e6-e7d1-4690-8244-c7d0fe7ed9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-24f5a3b7-837d-44c1-b1b1-a1afd2d3a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-eb7f05ca-e2b5-4456-b831-5b69e991d698,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-b2a90124-00c2-456b-b13c-163a4b1d1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918761274-172.17.0.5-1598524444631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-dbd30f99-ea60-456f-84ef-3a020f44bbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-3a692908-3de8-4445-95fa-fc0839241ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-1199c123-bf78-48e1-96ba-8b1579fd008a,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-6130c611-eeec-494e-a035-ca8083f890ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b8351510-c320-4baf-885f-5e8ae0c00e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-9476fdd0-30ee-4979-b321-f4b9a989dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-53353e76-a2bd-4250-b992-d519b54f434b,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-a9b6f97e-44c7-4d26-9a70-68a9cdc007c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918761274-172.17.0.5-1598524444631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-dbd30f99-ea60-456f-84ef-3a020f44bbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-3a692908-3de8-4445-95fa-fc0839241ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-1199c123-bf78-48e1-96ba-8b1579fd008a,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-6130c611-eeec-494e-a035-ca8083f890ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-b8351510-c320-4baf-885f-5e8ae0c00e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-9476fdd0-30ee-4979-b321-f4b9a989dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-53353e76-a2bd-4250-b992-d519b54f434b,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-a9b6f97e-44c7-4d26-9a70-68a9cdc007c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166694618-172.17.0.5-1598525022324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-6d51666f-c4ad-42ee-9c54-7395d8b66b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-9f22cfaf-12ee-470d-b925-b7d9e364f174,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-73b40a9b-62b1-4a96-955a-9d99a9491c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-1d5fc303-f186-44e9-986b-928447f3ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d3c937b6-dc0c-4e26-8cea-dadd72aee603,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-3b65287e-1baa-4229-9238-2d62ec59bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-fb13a249-4ffb-4992-b98c-2b07018442c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-a2683fc6-409b-4643-bdd3-57b91ab4f36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166694618-172.17.0.5-1598525022324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-6d51666f-c4ad-42ee-9c54-7395d8b66b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-9f22cfaf-12ee-470d-b925-b7d9e364f174,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-73b40a9b-62b1-4a96-955a-9d99a9491c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-1d5fc303-f186-44e9-986b-928447f3ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d3c937b6-dc0c-4e26-8cea-dadd72aee603,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-3b65287e-1baa-4229-9238-2d62ec59bf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-fb13a249-4ffb-4992-b98c-2b07018442c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-a2683fc6-409b-4643-bdd3-57b91ab4f36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500128861-172.17.0.5-1598525056358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-d2fd1301-fc5c-467b-89f7-1b3f045132ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-70be4c7e-4aa5-42da-8dc2-9ba232f84660,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0fa53552-172f-4fcd-b346-1c6e09bf067b,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-d87db149-6050-45e9-8896-5d28d264f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-4eb9bd11-e206-471b-918d-4ca0c84e8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-3a9e53a8-e548-4a3d-846a-fc0ab889907c,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a88aa841-b6ac-4c89-8d1a-d165316fbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-2329443c-10c1-4ebc-8b74-34fdb415a7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500128861-172.17.0.5-1598525056358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-d2fd1301-fc5c-467b-89f7-1b3f045132ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-70be4c7e-4aa5-42da-8dc2-9ba232f84660,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0fa53552-172f-4fcd-b346-1c6e09bf067b,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-d87db149-6050-45e9-8896-5d28d264f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-4eb9bd11-e206-471b-918d-4ca0c84e8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-3a9e53a8-e548-4a3d-846a-fc0ab889907c,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a88aa841-b6ac-4c89-8d1a-d165316fbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-2329443c-10c1-4ebc-8b74-34fdb415a7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575605772-172.17.0.5-1598525095398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-8b343880-11a5-4e06-a96e-856a544ca03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-577ea12c-c11c-43ee-b138-3ef555f9b301,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f6be9c8c-f99d-4558-a31d-a3f5330bfbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-da2a0d26-1778-458a-90ab-7c442dbedb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-ce8b0106-76a2-402f-afaa-3a857f011f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-c2f54893-fd16-49a1-9435-104366da76a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-feaffee4-ab3a-4373-91bb-1fa493a55cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-6b953af0-df43-4c15-8ae5-3d0f26205b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575605772-172.17.0.5-1598525095398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-8b343880-11a5-4e06-a96e-856a544ca03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-577ea12c-c11c-43ee-b138-3ef555f9b301,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f6be9c8c-f99d-4558-a31d-a3f5330bfbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-da2a0d26-1778-458a-90ab-7c442dbedb67,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-ce8b0106-76a2-402f-afaa-3a857f011f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-c2f54893-fd16-49a1-9435-104366da76a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-feaffee4-ab3a-4373-91bb-1fa493a55cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-6b953af0-df43-4c15-8ae5-3d0f26205b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229209951-172.17.0.5-1598525310434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-253fcee3-61b4-4f25-b016-feab29fe56df,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-e267e971-45be-4c13-976b-4dd45d6b8c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-75dc66e2-f67a-4d60-9a22-4dcdf809ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-008d9885-b159-4c04-89f1-19f0c1259ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-043c7d68-5c74-4efe-82c4-a5d786b22490,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-245e7be5-f58c-460a-8e16-df6ef2de7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-a4e17bb6-8c1d-4045-b965-ef1b1494e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-3203c6fa-c923-4446-9c22-581ed29eaef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229209951-172.17.0.5-1598525310434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37582,DS-253fcee3-61b4-4f25-b016-feab29fe56df,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-e267e971-45be-4c13-976b-4dd45d6b8c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-75dc66e2-f67a-4d60-9a22-4dcdf809ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-008d9885-b159-4c04-89f1-19f0c1259ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-043c7d68-5c74-4efe-82c4-a5d786b22490,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-245e7be5-f58c-460a-8e16-df6ef2de7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-a4e17bb6-8c1d-4045-b965-ef1b1494e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-3203c6fa-c923-4446-9c22-581ed29eaef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778746394-172.17.0.5-1598525346949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39200,DS-6b74e9ee-5f6e-4046-85df-83c3a4047ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-9b840162-8e6c-4348-8474-07a291f9e681,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-4a7d08bb-f115-404e-85e2-dee2e401b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-259cf88f-2b9a-4375-b800-57030bfd4b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-09c56cce-2f9a-4e54-a84b-adde9081b463,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c4125d91-07ce-4afe-9c0e-4459b0a3e249,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-60f6eb3f-78a5-464c-a74f-c17fc691ca31,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7766a903-7015-46ca-9d10-62c58746c8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778746394-172.17.0.5-1598525346949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39200,DS-6b74e9ee-5f6e-4046-85df-83c3a4047ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-9b840162-8e6c-4348-8474-07a291f9e681,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-4a7d08bb-f115-404e-85e2-dee2e401b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-259cf88f-2b9a-4375-b800-57030bfd4b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-09c56cce-2f9a-4e54-a84b-adde9081b463,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c4125d91-07ce-4afe-9c0e-4459b0a3e249,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-60f6eb3f-78a5-464c-a74f-c17fc691ca31,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7766a903-7015-46ca-9d10-62c58746c8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736956741-172.17.0.5-1598525942316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-9ba34143-4bdb-44dc-bfe7-c5caec8051fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e64b303d-bdec-466a-8a0d-f544454943b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-18f6f6a0-29ac-4458-921b-6474d209d566,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-bab95f8e-e324-4c53-8a36-e55a2ebac304,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c58515b6-936c-401f-94fc-824a336c248f,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-1d7ce47a-5363-4cdf-95b2-f1d7af9a7aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-921e6640-cab7-4f68-82eb-c1c61e5dddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-9dabb41e-1971-4fde-b065-9c338767fb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736956741-172.17.0.5-1598525942316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-9ba34143-4bdb-44dc-bfe7-c5caec8051fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-e64b303d-bdec-466a-8a0d-f544454943b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-18f6f6a0-29ac-4458-921b-6474d209d566,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-bab95f8e-e324-4c53-8a36-e55a2ebac304,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c58515b6-936c-401f-94fc-824a336c248f,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-1d7ce47a-5363-4cdf-95b2-f1d7af9a7aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-921e6640-cab7-4f68-82eb-c1c61e5dddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-9dabb41e-1971-4fde-b065-9c338767fb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375493455-172.17.0.5-1598526042326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-02cd4cc4-9121-454b-878f-2b1f45873d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ba6ef7fc-07eb-4cc0-98f0-65885fd40ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-c0370ccd-2f47-454c-a351-aed00b94fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-1015e1db-f316-46e3-aa54-18844fb475fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-a8a25b05-7997-45ec-9302-68a22db8175a,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-6cfa724c-924b-4372-88b2-56a7365034c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-b1c7a309-c7f2-4edc-89fd-cb8a8f6eb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-9a9af85b-84a8-4d8e-b19e-bf621e8e1b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375493455-172.17.0.5-1598526042326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-02cd4cc4-9121-454b-878f-2b1f45873d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ba6ef7fc-07eb-4cc0-98f0-65885fd40ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-c0370ccd-2f47-454c-a351-aed00b94fe34,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-1015e1db-f316-46e3-aa54-18844fb475fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-a8a25b05-7997-45ec-9302-68a22db8175a,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-6cfa724c-924b-4372-88b2-56a7365034c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-b1c7a309-c7f2-4edc-89fd-cb8a8f6eb98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-9a9af85b-84a8-4d8e-b19e-bf621e8e1b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011033510-172.17.0.5-1598526139405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-14944402-0b3f-4b3d-b2e9-f55195b709d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-2cd9c221-d508-4358-9daf-948147559324,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-14af77e4-c107-4f7c-9261-1d13d6876012,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-4a8adf54-6c9e-4903-979c-8bd58086477c,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-8f8f4ef4-0d56-456a-8cf6-e2884e93d095,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-99d8c31b-f106-4fb4-a160-aebb4fa0d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-6f611b41-5bcd-4b54-ac1c-43f326519ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-d97d3a9f-c80d-4507-8ddf-ea09a8d4d9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011033510-172.17.0.5-1598526139405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-14944402-0b3f-4b3d-b2e9-f55195b709d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-2cd9c221-d508-4358-9daf-948147559324,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-14af77e4-c107-4f7c-9261-1d13d6876012,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-4a8adf54-6c9e-4903-979c-8bd58086477c,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-8f8f4ef4-0d56-456a-8cf6-e2884e93d095,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-99d8c31b-f106-4fb4-a160-aebb4fa0d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-6f611b41-5bcd-4b54-ac1c-43f326519ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-d97d3a9f-c80d-4507-8ddf-ea09a8d4d9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461300492-172.17.0.5-1598526514751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-51345c29-08db-4b13-9b17-a8c311425b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-28c74028-23db-443a-b3cb-9368e13db0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b0c257de-25cf-47c1-a774-643fe1555517,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-15725ae3-7a4e-4230-8009-65f5523cbbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-8fc7e41d-1923-48da-ba9f-10c3298c7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-c33d2af5-2b30-4434-922d-939795f6ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-b7f0e948-30c6-450c-ad99-fde2a3fe2f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-e4a4736c-8748-4229-927c-f92a40099205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461300492-172.17.0.5-1598526514751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-51345c29-08db-4b13-9b17-a8c311425b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-28c74028-23db-443a-b3cb-9368e13db0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-b0c257de-25cf-47c1-a774-643fe1555517,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-15725ae3-7a4e-4230-8009-65f5523cbbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-8fc7e41d-1923-48da-ba9f-10c3298c7fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-c33d2af5-2b30-4434-922d-939795f6ad6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-b7f0e948-30c6-450c-ad99-fde2a3fe2f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-e4a4736c-8748-4229-927c-f92a40099205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683855639-172.17.0.5-1598526791718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-0c838a01-e222-407d-b326-2fc868063ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-0f3dd54d-d169-47e6-9dfe-848158dd393d,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-3181748a-d147-4cb8-89c4-25f101d742b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-0eb2f7e2-1dfd-48cb-b068-a72f5fd9fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-6017e286-bc7b-45c0-a99e-f5baecf219d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-e7ecaefa-2147-4721-8eae-f96e9c1a6fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-d98ee010-9d54-44b6-9217-dfef06ffb44c,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-a36bfbfc-4e96-45c1-a05d-90478ed2f3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683855639-172.17.0.5-1598526791718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-0c838a01-e222-407d-b326-2fc868063ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-0f3dd54d-d169-47e6-9dfe-848158dd393d,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-3181748a-d147-4cb8-89c4-25f101d742b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-0eb2f7e2-1dfd-48cb-b068-a72f5fd9fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-6017e286-bc7b-45c0-a99e-f5baecf219d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-e7ecaefa-2147-4721-8eae-f96e9c1a6fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-d98ee010-9d54-44b6-9217-dfef06ffb44c,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-a36bfbfc-4e96-45c1-a05d-90478ed2f3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641603312-172.17.0.5-1598527448964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-e973e28d-72ea-4fbc-8c8f-cfe2eb24c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-56581370-a5e2-4581-8087-5b535b3e3338,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-40f8e924-ecce-4032-9fd4-9d7877fcc862,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-62f9fab5-e171-4ed6-81ec-e5b56face159,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-f9378a6c-aa62-42e7-8e36-09c0db797b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-c11efd81-03b5-4035-ab5e-c6a8bd9d3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-67cdddf5-dd55-46e3-87e9-3c28d791df18,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8f9796e4-bc0b-4ee1-a270-1753dc408f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641603312-172.17.0.5-1598527448964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-e973e28d-72ea-4fbc-8c8f-cfe2eb24c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-56581370-a5e2-4581-8087-5b535b3e3338,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-40f8e924-ecce-4032-9fd4-9d7877fcc862,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-62f9fab5-e171-4ed6-81ec-e5b56face159,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-f9378a6c-aa62-42e7-8e36-09c0db797b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-c11efd81-03b5-4035-ab5e-c6a8bd9d3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-67cdddf5-dd55-46e3-87e9-3c28d791df18,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-8f9796e4-bc0b-4ee1-a270-1753dc408f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109213989-172.17.0.5-1598527557206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-ba81cd74-1c30-4bfd-83c2-fd27a8b60a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-3cc4a4ec-2ec6-437e-8f84-a5fcef345dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-268f68fb-94fa-4ea5-9fee-f4d0d93ff576,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-4dbce583-ad94-4ad9-8b50-98f2b7287fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-7b9acf47-00eb-40d8-904e-5074965c60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-a93c1b9d-d819-4f6f-ad46-02eeacecec21,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ccf6937c-0406-44dd-b126-2bbdd3a2c557,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6bf41538-a6b0-4879-b936-246c5ceffc92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109213989-172.17.0.5-1598527557206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-ba81cd74-1c30-4bfd-83c2-fd27a8b60a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-3cc4a4ec-2ec6-437e-8f84-a5fcef345dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-268f68fb-94fa-4ea5-9fee-f4d0d93ff576,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-4dbce583-ad94-4ad9-8b50-98f2b7287fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-7b9acf47-00eb-40d8-904e-5074965c60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-a93c1b9d-d819-4f6f-ad46-02eeacecec21,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ccf6937c-0406-44dd-b126-2bbdd3a2c557,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6bf41538-a6b0-4879-b936-246c5ceffc92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040111942-172.17.0.5-1598527777430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-2f3bf1e7-126a-4114-89ba-de895424c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-cecc9ea6-e866-4c7d-9362-7502bdf7ad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-869dd034-e2c0-4929-b1f8-3239b313a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-3a8d7984-c538-49d9-bcb9-7a89f2a42f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-33bc5a95-e4ec-46df-909e-d8f7f09bf4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-9f9faadf-f702-485b-8b58-99a374b8455a,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-aae7ce9e-18ab-4eed-b306-002594c04ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a5356e15-ebce-429a-ac95-5a6d3f22e33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040111942-172.17.0.5-1598527777430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-2f3bf1e7-126a-4114-89ba-de895424c10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-cecc9ea6-e866-4c7d-9362-7502bdf7ad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-869dd034-e2c0-4929-b1f8-3239b313a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-3a8d7984-c538-49d9-bcb9-7a89f2a42f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-33bc5a95-e4ec-46df-909e-d8f7f09bf4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-9f9faadf-f702-485b-8b58-99a374b8455a,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-aae7ce9e-18ab-4eed-b306-002594c04ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a5356e15-ebce-429a-ac95-5a6d3f22e33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5323
