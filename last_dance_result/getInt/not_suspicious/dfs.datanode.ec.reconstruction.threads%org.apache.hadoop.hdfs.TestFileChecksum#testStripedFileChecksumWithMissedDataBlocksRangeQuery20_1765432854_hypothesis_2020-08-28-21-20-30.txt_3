reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925328344-172.17.0.16-1598649756892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39788,DS-fb6d1b2b-e66f-4285-b14b-92b4a2f675bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-1aba5788-1900-493b-a3db-3fd7577fb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-06c0d719-fb90-42ec-8529-46285c313bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ff9e6a63-f586-4c31-8cf0-de56558b1b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a42967f4-c515-4f9d-b365-bf36c97c407e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-ad6fc632-37a9-4ba3-beb3-7cb8009c811d,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-055e6d93-565c-4284-9e29-860d5d922159,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c7f7ea2d-8403-4a00-8113-f2aef0b1030e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925328344-172.17.0.16-1598649756892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39788,DS-fb6d1b2b-e66f-4285-b14b-92b4a2f675bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-1aba5788-1900-493b-a3db-3fd7577fb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-06c0d719-fb90-42ec-8529-46285c313bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ff9e6a63-f586-4c31-8cf0-de56558b1b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a42967f4-c515-4f9d-b365-bf36c97c407e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-ad6fc632-37a9-4ba3-beb3-7cb8009c811d,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-055e6d93-565c-4284-9e29-860d5d922159,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c7f7ea2d-8403-4a00-8113-f2aef0b1030e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140908574-172.17.0.16-1598649980636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-c380bb22-9e00-403e-be04-7d77bd62b735,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9c74dd88-a98d-41ed-9390-2b206f167110,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-6fb85a8f-a507-4037-87c3-fccce444191b,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-5162508b-4a25-4a42-92ae-043635cf0df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-fdc279d6-bf20-4652-9629-fdaf2670a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-3f257ca3-3837-4ea8-8105-e56519eb92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-31828fbb-f88a-4976-82ff-2132fec4d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8830fe5a-efb4-4612-b57e-e070ace629f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140908574-172.17.0.16-1598649980636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-c380bb22-9e00-403e-be04-7d77bd62b735,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9c74dd88-a98d-41ed-9390-2b206f167110,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-6fb85a8f-a507-4037-87c3-fccce444191b,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-5162508b-4a25-4a42-92ae-043635cf0df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-fdc279d6-bf20-4652-9629-fdaf2670a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-3f257ca3-3837-4ea8-8105-e56519eb92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-31828fbb-f88a-4976-82ff-2132fec4d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8830fe5a-efb4-4612-b57e-e070ace629f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135972078-172.17.0.16-1598650760359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-59ac4365-3ef0-4697-8657-220f9dc617ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-9e2ced5d-1e2a-4bbc-89d8-6c4b7d7ccad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-3e664719-9a66-45ac-806c-30a3b3f35fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b5606c22-5a54-47ef-83b2-55fbc64bc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-c963baeb-ce99-4377-be16-e3d33392e347,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-5c98f6ba-7ea1-4567-b7f3-8553db6b22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-7ac971c4-4f28-4b98-9494-07c802132cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-5b7c18f8-d511-42f1-9f66-54c0bd520c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135972078-172.17.0.16-1598650760359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-59ac4365-3ef0-4697-8657-220f9dc617ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-9e2ced5d-1e2a-4bbc-89d8-6c4b7d7ccad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-3e664719-9a66-45ac-806c-30a3b3f35fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b5606c22-5a54-47ef-83b2-55fbc64bc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-c963baeb-ce99-4377-be16-e3d33392e347,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-5c98f6ba-7ea1-4567-b7f3-8553db6b22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-7ac971c4-4f28-4b98-9494-07c802132cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-5b7c18f8-d511-42f1-9f66-54c0bd520c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111822182-172.17.0.16-1598651228696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-dad9b66d-d6e7-4323-b1d6-06c45ae95939,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-85777953-b81d-4d1b-80f5-cc37813a3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-8a81a0f4-8e54-4357-948b-d89cf53a7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-eb67bfa2-c0a5-48f9-9f9d-c3cf0acbe2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-28415b3f-425c-421f-833c-7f57d44dc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-0d595648-2383-4663-9137-04658ff77ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-434acace-db13-4f87-9da8-6c130e72908e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-6eda7a77-4c70-4fdc-a904-6a35e9b2ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111822182-172.17.0.16-1598651228696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-dad9b66d-d6e7-4323-b1d6-06c45ae95939,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-85777953-b81d-4d1b-80f5-cc37813a3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-8a81a0f4-8e54-4357-948b-d89cf53a7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-eb67bfa2-c0a5-48f9-9f9d-c3cf0acbe2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-28415b3f-425c-421f-833c-7f57d44dc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-0d595648-2383-4663-9137-04658ff77ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-434acace-db13-4f87-9da8-6c130e72908e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-6eda7a77-4c70-4fdc-a904-6a35e9b2ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862918553-172.17.0.16-1598651807622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-26d68aa3-e1e1-4fb9-b69d-99f58bde7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f6c87f4a-e0a8-4585-982c-5dac051226e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-b4028a23-1d76-40e3-8b0d-c925a3343b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-506127cc-19d8-46e0-a3a1-ab099aceec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-8a6726fe-40a8-471d-9c56-97d20da6d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-c80bff9f-bad7-4625-a7c2-b17a935686e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-4dcba67e-d69b-4a64-a1d4-cbf281e0ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-86ef2aa3-1cc7-4fe4-a2a8-bc6bdf572dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862918553-172.17.0.16-1598651807622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-26d68aa3-e1e1-4fb9-b69d-99f58bde7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f6c87f4a-e0a8-4585-982c-5dac051226e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-b4028a23-1d76-40e3-8b0d-c925a3343b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-506127cc-19d8-46e0-a3a1-ab099aceec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-8a6726fe-40a8-471d-9c56-97d20da6d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-c80bff9f-bad7-4625-a7c2-b17a935686e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-4dcba67e-d69b-4a64-a1d4-cbf281e0ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-86ef2aa3-1cc7-4fe4-a2a8-bc6bdf572dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623424146-172.17.0.16-1598653025183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-80748748-ef5f-4f2f-8439-1ac6e2c4eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-088e9c3c-6d2f-4ac2-824b-622f06bf114b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-473ac401-75a6-4220-8b98-13cd64fc9583,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-9b4c17c2-040c-4887-b756-b6a6dcb730e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-74af7607-57b8-4223-bfd7-e8a6c280bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-94e8a672-5fec-4232-9179-da4f43c7647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-b4286a35-a129-444a-b1ff-21b4056575e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-2b3bd6ee-e693-4f03-b338-e5aba77d0297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623424146-172.17.0.16-1598653025183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-80748748-ef5f-4f2f-8439-1ac6e2c4eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-088e9c3c-6d2f-4ac2-824b-622f06bf114b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-473ac401-75a6-4220-8b98-13cd64fc9583,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-9b4c17c2-040c-4887-b756-b6a6dcb730e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-74af7607-57b8-4223-bfd7-e8a6c280bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-94e8a672-5fec-4232-9179-da4f43c7647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-b4286a35-a129-444a-b1ff-21b4056575e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-2b3bd6ee-e693-4f03-b338-e5aba77d0297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536339331-172.17.0.16-1598653092780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-09229204-9a3e-4ab5-a1cc-825159a9ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-904fbffd-85fc-4b92-b6f9-93f64f94e519,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-0a873ee2-fd61-41b4-8dc6-505c361b03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-c9896944-cd3b-4cf4-b41d-9b0cefa0fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-60342436-c6db-4306-86f8-56945d98eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-64b2c9b2-fda6-43d3-a8d1-e07cf0565fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-e913ad3e-7d78-421c-b3e6-191fedb20aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-b36d3099-1a54-4f49-be50-41f8137841b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536339331-172.17.0.16-1598653092780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-09229204-9a3e-4ab5-a1cc-825159a9ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-904fbffd-85fc-4b92-b6f9-93f64f94e519,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-0a873ee2-fd61-41b4-8dc6-505c361b03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-c9896944-cd3b-4cf4-b41d-9b0cefa0fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-60342436-c6db-4306-86f8-56945d98eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-64b2c9b2-fda6-43d3-a8d1-e07cf0565fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-e913ad3e-7d78-421c-b3e6-191fedb20aed,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-b36d3099-1a54-4f49-be50-41f8137841b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574571764-172.17.0.16-1598653195778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-5b96b923-eb3d-4c01-90ff-62bd6f1766fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7f88da91-b489-4d39-a1e3-ab1571781573,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-58a44bb7-03e1-4dc1-b500-5e94d9ac6690,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-5a17a17c-9afb-4d55-b52d-fb9de906f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-b0542b60-0437-4fb0-9abb-63da23d2b579,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-6da25bea-02c1-4b97-a62b-aa9455ee1df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-92263235-bfd0-49ca-8b49-d81daf587169,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-adcaa72c-84ca-4c1b-828c-b3063114134b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574571764-172.17.0.16-1598653195778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-5b96b923-eb3d-4c01-90ff-62bd6f1766fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7f88da91-b489-4d39-a1e3-ab1571781573,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-58a44bb7-03e1-4dc1-b500-5e94d9ac6690,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-5a17a17c-9afb-4d55-b52d-fb9de906f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-b0542b60-0437-4fb0-9abb-63da23d2b579,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-6da25bea-02c1-4b97-a62b-aa9455ee1df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-92263235-bfd0-49ca-8b49-d81daf587169,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-adcaa72c-84ca-4c1b-828c-b3063114134b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040957933-172.17.0.16-1598653704399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-23647182-1f5b-4afa-b153-cd15c48e1178,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-8e9d0cfc-f5f1-43fd-b454-a1509c37f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-c8c32176-a262-4b53-9c2c-8d63234b440b,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-16da7052-9b6b-41d1-a9a1-5c850872fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-7feaee00-5873-4ab0-b221-6c4c3bc5e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-7e3d47e4-a913-412b-8851-ba90fa55fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a405db74-036e-49a0-b09d-6dd9f486dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f781d5f6-4c98-426f-8f5a-50d091626598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040957933-172.17.0.16-1598653704399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-23647182-1f5b-4afa-b153-cd15c48e1178,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-8e9d0cfc-f5f1-43fd-b454-a1509c37f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-c8c32176-a262-4b53-9c2c-8d63234b440b,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-16da7052-9b6b-41d1-a9a1-5c850872fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-7feaee00-5873-4ab0-b221-6c4c3bc5e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-7e3d47e4-a913-412b-8851-ba90fa55fad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a405db74-036e-49a0-b09d-6dd9f486dcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f781d5f6-4c98-426f-8f5a-50d091626598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50471108-172.17.0.16-1598653775512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-67965abd-bef6-42c2-9b78-c2af9afd03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-4716c22e-8acd-49fd-bf6e-919f3ba0f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-ed6a2d26-184c-4e49-bf42-cdd395f9a86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-199ef55a-f3ab-44ac-be48-f269761eb6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-89b72f5f-717b-41dd-9e00-2919d97d9f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-7456d37e-3df4-4a3a-8ca3-7bd0661246a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-83c9efbf-0f40-4735-8aa5-e75d1fac20f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-222e1105-4fea-45cd-8dfa-8b1343c82789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50471108-172.17.0.16-1598653775512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-67965abd-bef6-42c2-9b78-c2af9afd03b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-4716c22e-8acd-49fd-bf6e-919f3ba0f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-ed6a2d26-184c-4e49-bf42-cdd395f9a86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-199ef55a-f3ab-44ac-be48-f269761eb6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-89b72f5f-717b-41dd-9e00-2919d97d9f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-7456d37e-3df4-4a3a-8ca3-7bd0661246a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-83c9efbf-0f40-4735-8aa5-e75d1fac20f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-222e1105-4fea-45cd-8dfa-8b1343c82789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768877621-172.17.0.16-1598653962914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-d6f1bdc9-efbb-4108-9bbf-258b0a8e933c,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-2fd6d3fa-6bf2-4822-91a5-508c8aff3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-3ac36ad4-2325-420b-a3be-3a78fcf07479,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-55c07eb2-ce7e-49e9-99ef-9b90a06d0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-1f1b3783-221a-4235-b62c-65925a676401,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-d924331d-c606-4753-8c9a-747e9cfe4823,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-754acb4b-23f1-4d6c-8c1f-7987ef70b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-f83a2c89-1b91-42fa-ab5a-e3e02e544e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768877621-172.17.0.16-1598653962914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-d6f1bdc9-efbb-4108-9bbf-258b0a8e933c,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-2fd6d3fa-6bf2-4822-91a5-508c8aff3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-3ac36ad4-2325-420b-a3be-3a78fcf07479,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-55c07eb2-ce7e-49e9-99ef-9b90a06d0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-1f1b3783-221a-4235-b62c-65925a676401,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-d924331d-c606-4753-8c9a-747e9cfe4823,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-754acb4b-23f1-4d6c-8c1f-7987ef70b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-f83a2c89-1b91-42fa-ab5a-e3e02e544e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948301293-172.17.0.16-1598654550758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33576,DS-1b362123-b3e7-427f-9837-f328a310b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-940ba6ee-1998-4d8f-90d1-d55a662a7dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-4ace333d-97c6-4fbb-828b-5bf3ce152214,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-aa5919bf-6f6c-4cb6-a2ed-ca38321e27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-e4c2e1ee-376d-469d-8e3e-1b9b933263ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-fed94f3f-4971-4aff-b098-318a3a539280,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-3396ec94-b312-418c-a679-81838dee1c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-f5700408-06ab-4178-9e3b-9de968f6fc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948301293-172.17.0.16-1598654550758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33576,DS-1b362123-b3e7-427f-9837-f328a310b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-940ba6ee-1998-4d8f-90d1-d55a662a7dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-4ace333d-97c6-4fbb-828b-5bf3ce152214,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-aa5919bf-6f6c-4cb6-a2ed-ca38321e27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-e4c2e1ee-376d-469d-8e3e-1b9b933263ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-fed94f3f-4971-4aff-b098-318a3a539280,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-3396ec94-b312-418c-a679-81838dee1c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-f5700408-06ab-4178-9e3b-9de968f6fc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326257391-172.17.0.16-1598654654562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-ac912ccc-b409-42e5-90c8-12918bebe97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-eecef3e8-dd32-4ce9-b806-a03f66e5148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-31257e8a-4a35-4082-919a-8884c13bfd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-09be0821-84b7-4911-8b1b-cf63e9c865e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-cb7d70d8-4cdf-4433-8288-27e344bbb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-2fd42f72-7f7c-44ee-ba58-4a6bcf224eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-889f7edb-5590-49c6-9f95-ffc7b395350c,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-6e1314c2-bcfa-4c48-bf3b-6676c0dd74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326257391-172.17.0.16-1598654654562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-ac912ccc-b409-42e5-90c8-12918bebe97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-eecef3e8-dd32-4ce9-b806-a03f66e5148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-31257e8a-4a35-4082-919a-8884c13bfd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-09be0821-84b7-4911-8b1b-cf63e9c865e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-cb7d70d8-4cdf-4433-8288-27e344bbb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-2fd42f72-7f7c-44ee-ba58-4a6bcf224eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-889f7edb-5590-49c6-9f95-ffc7b395350c,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-6e1314c2-bcfa-4c48-bf3b-6676c0dd74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253202352-172.17.0.16-1598654769880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-c74faee3-8be4-4dfc-a8be-87fb7c27429b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-d912fa56-0471-40a0-9121-bc44990e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-608d5d28-3007-4b25-b871-0867915d64ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-5860b997-f74c-415a-800a-b237ed8d0884,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-deadf6bc-b543-4d0d-94e3-bed998aea6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a89f1b16-2382-49a6-ba16-44896c9cdfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-abe02eec-1549-4cdc-867a-8bc124614170,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-0451783c-3da1-4c7c-8b09-38ff929f0f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253202352-172.17.0.16-1598654769880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-c74faee3-8be4-4dfc-a8be-87fb7c27429b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-d912fa56-0471-40a0-9121-bc44990e3470,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-608d5d28-3007-4b25-b871-0867915d64ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-5860b997-f74c-415a-800a-b237ed8d0884,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-deadf6bc-b543-4d0d-94e3-bed998aea6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-a89f1b16-2382-49a6-ba16-44896c9cdfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-abe02eec-1549-4cdc-867a-8bc124614170,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-0451783c-3da1-4c7c-8b09-38ff929f0f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019675670-172.17.0.16-1598654808392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-3b1dcabc-e926-4a74-a87b-7a29fa3d2289,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a3d5b3b6-a4f0-4075-a8cf-e9ad0bc58610,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-c2c6f894-a76a-42d5-a52e-66cb95f43414,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-df189c87-0003-41ae-9d7e-be34cc80bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e497ae41-009e-475f-a2f5-765acbfaa841,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-6ca94be1-c48a-48ea-9e01-8494de4bc63d,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-d1e6f3a3-c7e7-402d-b5bf-f9c31ebace2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-bedb4df1-c45e-4234-bf4a-da2985617fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019675670-172.17.0.16-1598654808392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-3b1dcabc-e926-4a74-a87b-7a29fa3d2289,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-a3d5b3b6-a4f0-4075-a8cf-e9ad0bc58610,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-c2c6f894-a76a-42d5-a52e-66cb95f43414,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-df189c87-0003-41ae-9d7e-be34cc80bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e497ae41-009e-475f-a2f5-765acbfaa841,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-6ca94be1-c48a-48ea-9e01-8494de4bc63d,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-d1e6f3a3-c7e7-402d-b5bf-f9c31ebace2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-bedb4df1-c45e-4234-bf4a-da2985617fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5308
