reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339286153-172.17.0.10-1598684098707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-4bfd540c-2783-4a14-8479-3fa5b450d567,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-ccd16e35-5a4c-4055-9b1c-46fc3edf77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-2313e354-02f3-4b6f-8360-5e8d5ec8d203,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-7d431f23-8b05-4282-8eff-ad74d66175c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-3e52c342-a56d-4806-8226-9556de34df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-80ffb185-d5ef-442c-a7a3-b8e21fdf277c,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-f77c36c7-83e9-4a7b-a692-88130ebe7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-98785a38-fa96-42c0-9ff8-6bbe7db4c92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339286153-172.17.0.10-1598684098707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-4bfd540c-2783-4a14-8479-3fa5b450d567,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-ccd16e35-5a4c-4055-9b1c-46fc3edf77ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-2313e354-02f3-4b6f-8360-5e8d5ec8d203,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-7d431f23-8b05-4282-8eff-ad74d66175c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-3e52c342-a56d-4806-8226-9556de34df1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-80ffb185-d5ef-442c-a7a3-b8e21fdf277c,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-f77c36c7-83e9-4a7b-a692-88130ebe7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-98785a38-fa96-42c0-9ff8-6bbe7db4c92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454297122-172.17.0.10-1598684255209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-76385834-a1d8-409e-9835-b7301f9ea6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-68740321-63b5-4af7-8bdd-026b59b5d708,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-590765fc-41b9-43fd-91af-b457b27dfac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-086165c7-6284-4de9-b804-3ae290bf74c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-a4e34c83-0ba5-4a67-8c87-8a4fa123f177,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-57e0e06f-1834-4896-9e8e-4b0851849999,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-61c24980-194f-41b1-8b06-6a6c7056b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-f2509675-df54-406e-b372-e01e2f9fdd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454297122-172.17.0.10-1598684255209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-76385834-a1d8-409e-9835-b7301f9ea6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-68740321-63b5-4af7-8bdd-026b59b5d708,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-590765fc-41b9-43fd-91af-b457b27dfac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-086165c7-6284-4de9-b804-3ae290bf74c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-a4e34c83-0ba5-4a67-8c87-8a4fa123f177,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-57e0e06f-1834-4896-9e8e-4b0851849999,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-61c24980-194f-41b1-8b06-6a6c7056b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-f2509675-df54-406e-b372-e01e2f9fdd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323143512-172.17.0.10-1598684290378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-cc78573e-0813-40ff-8e4b-2e2f51d6a5da,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-062fcf52-344d-415f-ab7f-61262570b008,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-4fdae812-c2c8-4789-b8f6-746841de668b,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-28a15b39-1fd0-4153-b351-5d49bfd66971,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-a9442274-8511-4e36-b402-c28e563a6824,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b4d340cf-005e-4b10-b141-7f615d4f0121,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-a2186c1a-5afd-45e2-9b92-deedd8caebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-c797afeb-11a0-4dbe-b578-c10b2e75c6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323143512-172.17.0.10-1598684290378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-cc78573e-0813-40ff-8e4b-2e2f51d6a5da,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-062fcf52-344d-415f-ab7f-61262570b008,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-4fdae812-c2c8-4789-b8f6-746841de668b,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-28a15b39-1fd0-4153-b351-5d49bfd66971,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-a9442274-8511-4e36-b402-c28e563a6824,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b4d340cf-005e-4b10-b141-7f615d4f0121,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-a2186c1a-5afd-45e2-9b92-deedd8caebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-c797afeb-11a0-4dbe-b578-c10b2e75c6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068900721-172.17.0.10-1598684485010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-883150ec-6f7b-4182-8c60-038f66a92fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0f75adbb-9e26-4260-ad57-687fe3c55572,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-e48c11de-adb3-41a3-9c71-5a315c46f375,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-918db643-da9d-4eb0-b1f9-2c057178cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3bbe43c0-5a60-4d8a-8c4e-acee314bb4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-5f18b484-ab24-4110-ae3f-d1756b22034e,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-7bf4a6e9-cb05-4f47-9e22-c888c00c1398,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-142d9c1f-7e74-4a3b-ac25-ce6920ea69bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068900721-172.17.0.10-1598684485010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-883150ec-6f7b-4182-8c60-038f66a92fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0f75adbb-9e26-4260-ad57-687fe3c55572,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-e48c11de-adb3-41a3-9c71-5a315c46f375,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-918db643-da9d-4eb0-b1f9-2c057178cf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3bbe43c0-5a60-4d8a-8c4e-acee314bb4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-5f18b484-ab24-4110-ae3f-d1756b22034e,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-7bf4a6e9-cb05-4f47-9e22-c888c00c1398,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-142d9c1f-7e74-4a3b-ac25-ce6920ea69bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062208808-172.17.0.10-1598684521395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-c6a0846b-a7f0-42b9-b2d4-c60dfad02935,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5547cbbc-1f1c-4708-b674-bf629fc776ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-bf4eea33-22f8-4711-a7be-1171ac039fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-6f436ddb-3fca-4580-83d8-b6626b1f71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-b06b5e19-2a4e-49cf-b8da-d8b6c43a4537,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-24b2cdfe-0049-42c6-a20c-3ce993fdfffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f2c4b06d-a5ea-4962-b4a5-92d4dfc0349d,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-77997140-9fb3-4ecb-bba6-766472e65e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062208808-172.17.0.10-1598684521395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-c6a0846b-a7f0-42b9-b2d4-c60dfad02935,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5547cbbc-1f1c-4708-b674-bf629fc776ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-bf4eea33-22f8-4711-a7be-1171ac039fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-6f436ddb-3fca-4580-83d8-b6626b1f71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-b06b5e19-2a4e-49cf-b8da-d8b6c43a4537,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-24b2cdfe-0049-42c6-a20c-3ce993fdfffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f2c4b06d-a5ea-4962-b4a5-92d4dfc0349d,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-77997140-9fb3-4ecb-bba6-766472e65e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141197182-172.17.0.10-1598685080527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-751b3b23-2cb9-40e7-8c9d-ecbda127181b,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-dd124a4d-12b4-4142-9be7-7c7409334dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-24ad7e76-eca8-42c9-bb64-5ee3690f67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-fdacff02-8ded-42b3-9a09-9a197ccd5efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-574d878e-3c14-43c9-89cb-c2910473921f,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-8cfdfc4d-5124-441d-8683-b3a4094a9904,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-28ddb19c-7ece-4acd-99fb-c2904e4d3527,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d1b74610-7665-403c-a432-5a7e1c5c2289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141197182-172.17.0.10-1598685080527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-751b3b23-2cb9-40e7-8c9d-ecbda127181b,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-dd124a4d-12b4-4142-9be7-7c7409334dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-24ad7e76-eca8-42c9-bb64-5ee3690f67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-fdacff02-8ded-42b3-9a09-9a197ccd5efe,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-574d878e-3c14-43c9-89cb-c2910473921f,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-8cfdfc4d-5124-441d-8683-b3a4094a9904,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-28ddb19c-7ece-4acd-99fb-c2904e4d3527,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d1b74610-7665-403c-a432-5a7e1c5c2289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015973485-172.17.0.10-1598685119451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-914429cf-8b01-437d-9ee6-9d11c19a2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d3bb1103-82d9-48bf-b731-e57aa4e3ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-062ca025-885e-4ddb-831b-3a6ad3f7a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-141211cb-27d9-4241-be8a-657403a51d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7696347e-4e53-4b45-9b44-a201c660626a,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-7f61f37c-9d19-4d66-b805-79dd2b414402,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-68747959-6ca9-408d-b1bb-062ed5a06fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2bd35ca5-086c-4ddd-8ff1-d6a593c4ad56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015973485-172.17.0.10-1598685119451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-914429cf-8b01-437d-9ee6-9d11c19a2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d3bb1103-82d9-48bf-b731-e57aa4e3ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-062ca025-885e-4ddb-831b-3a6ad3f7a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-141211cb-27d9-4241-be8a-657403a51d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7696347e-4e53-4b45-9b44-a201c660626a,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-7f61f37c-9d19-4d66-b805-79dd2b414402,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-68747959-6ca9-408d-b1bb-062ed5a06fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2bd35ca5-086c-4ddd-8ff1-d6a593c4ad56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76983442-172.17.0.10-1598685967983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-706f709e-c863-4312-b841-bd1e03e37e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-ad10ba92-abc1-4495-8ee3-0b9946bc3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-0c769048-703c-4456-a57c-7558bcfef94a,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-7b5f007f-76dc-4b96-81e9-72d6eb3badf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9d604b89-1204-4636-9d63-2f42ec529861,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-e8515902-63e5-4057-bbc4-3b002193eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-38c751ff-97df-436f-b4d6-3f2a194f2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-3708bac6-fdc1-4542-bbc4-950b35754dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76983442-172.17.0.10-1598685967983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-706f709e-c863-4312-b841-bd1e03e37e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-ad10ba92-abc1-4495-8ee3-0b9946bc3c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-0c769048-703c-4456-a57c-7558bcfef94a,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-7b5f007f-76dc-4b96-81e9-72d6eb3badf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9d604b89-1204-4636-9d63-2f42ec529861,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-e8515902-63e5-4057-bbc4-3b002193eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-38c751ff-97df-436f-b4d6-3f2a194f2a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-3708bac6-fdc1-4542-bbc4-950b35754dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951816220-172.17.0.10-1598686241467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-5e2e7608-ac29-407b-9d2c-aaec83cdaad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-e329d947-b61b-478b-b8d8-cebd08878013,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-e5629e90-453d-42cc-94de-58c8272417ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-82a2a6b0-ba91-41a1-8f90-5dde3e59e065,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-be0dea0c-1d04-4e49-9d76-3677d736a614,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6b490608-6f82-47b6-950b-1f1d80cac217,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-74b2ebb0-80b0-4b79-8d2a-b02fb70019cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-303b8c18-8d2e-4823-b3cf-0ef3c2628d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951816220-172.17.0.10-1598686241467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36214,DS-5e2e7608-ac29-407b-9d2c-aaec83cdaad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-e329d947-b61b-478b-b8d8-cebd08878013,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-e5629e90-453d-42cc-94de-58c8272417ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-82a2a6b0-ba91-41a1-8f90-5dde3e59e065,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-be0dea0c-1d04-4e49-9d76-3677d736a614,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-6b490608-6f82-47b6-950b-1f1d80cac217,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-74b2ebb0-80b0-4b79-8d2a-b02fb70019cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-303b8c18-8d2e-4823-b3cf-0ef3c2628d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481984363-172.17.0.10-1598686380305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-27168f05-563d-45da-a18e-ba08f266b3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6bc40d0c-5520-4947-822b-542ab58e698d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d0bbcaa1-a97f-4642-aa02-d20e822656e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-6e73b5d8-348b-4057-8c76-512bbf890944,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-43196f5c-3af6-42cc-b5e9-d9f15b6145e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-ecf32a92-a094-4250-b72e-f5d42f7fe5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-0a421b5e-20ab-47e1-a164-0bb51c9c602b,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-21fbd6a3-4a4b-43ab-96e0-c06318e56794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481984363-172.17.0.10-1598686380305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-27168f05-563d-45da-a18e-ba08f266b3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6bc40d0c-5520-4947-822b-542ab58e698d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d0bbcaa1-a97f-4642-aa02-d20e822656e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-6e73b5d8-348b-4057-8c76-512bbf890944,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-43196f5c-3af6-42cc-b5e9-d9f15b6145e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-ecf32a92-a094-4250-b72e-f5d42f7fe5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-0a421b5e-20ab-47e1-a164-0bb51c9c602b,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-21fbd6a3-4a4b-43ab-96e0-c06318e56794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825637126-172.17.0.10-1598686853711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-7c6b8779-e572-425e-87aa-54836e75a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-f4e9101d-a172-4c61-9a88-acf97850ce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e71d1610-9d55-4f40-b1b9-2740abd42a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-20e1a583-d0f0-4d89-8bed-85edfd38baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-79e1c2e6-a6dd-4f85-9f27-58cb0dada9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-571aee8b-25ae-4804-bf81-7ac0466878f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-269c1e93-f6bc-4308-b815-f23e081afaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-50bfb4b4-cea1-4d61-b030-201b12cdfe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825637126-172.17.0.10-1598686853711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-7c6b8779-e572-425e-87aa-54836e75a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-f4e9101d-a172-4c61-9a88-acf97850ce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e71d1610-9d55-4f40-b1b9-2740abd42a05,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-20e1a583-d0f0-4d89-8bed-85edfd38baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-79e1c2e6-a6dd-4f85-9f27-58cb0dada9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-571aee8b-25ae-4804-bf81-7ac0466878f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-269c1e93-f6bc-4308-b815-f23e081afaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-50bfb4b4-cea1-4d61-b030-201b12cdfe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470776151-172.17.0.10-1598687560474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-9848b2c5-238c-4bb4-bf81-dc79a886320a,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f12c536f-e6f3-454a-a9a0-19eb26f9f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a5b72d47-8959-4003-8ceb-8edf7d53250a,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-79d9de7a-2528-45e7-9a25-7ef60c43bee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7fa7e3af-cb99-4c3e-b129-c5621bbddc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-5fe35f24-87b6-470b-9df0-b1dc13035b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-88264201-f3f9-430a-8a01-14f6aa36d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-595612a9-5f01-40d3-9326-398a94b157f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470776151-172.17.0.10-1598687560474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-9848b2c5-238c-4bb4-bf81-dc79a886320a,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f12c536f-e6f3-454a-a9a0-19eb26f9f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a5b72d47-8959-4003-8ceb-8edf7d53250a,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-79d9de7a-2528-45e7-9a25-7ef60c43bee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7fa7e3af-cb99-4c3e-b129-c5621bbddc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-5fe35f24-87b6-470b-9df0-b1dc13035b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-88264201-f3f9-430a-8a01-14f6aa36d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-595612a9-5f01-40d3-9326-398a94b157f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976423440-172.17.0.10-1598687760389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-b0c090d8-e0e1-4667-9733-83fa5024a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-74144c27-05af-4e03-aac2-70f4b809a157,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-9a567bfc-625b-4e1b-823b-bde27f767e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-5f627bda-3a39-418d-a0b1-595391085f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-d72a2af6-1289-4fe8-af10-313b865ca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7728d614-76c6-45f6-8591-cae10b1a785b,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-0d7df689-6367-4504-90c6-3dc02a900356,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-21cacadb-a91a-42c5-be50-b8c83dd2510e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976423440-172.17.0.10-1598687760389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-b0c090d8-e0e1-4667-9733-83fa5024a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-74144c27-05af-4e03-aac2-70f4b809a157,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-9a567bfc-625b-4e1b-823b-bde27f767e39,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-5f627bda-3a39-418d-a0b1-595391085f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-d72a2af6-1289-4fe8-af10-313b865ca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7728d614-76c6-45f6-8591-cae10b1a785b,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-0d7df689-6367-4504-90c6-3dc02a900356,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-21cacadb-a91a-42c5-be50-b8c83dd2510e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315605785-172.17.0.10-1598688793389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-5eb2a23f-d27f-4a73-ba7f-88a175e5a2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-98b1f6a1-d6ed-4d61-9528-b52e64fd5a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-9ddcadf6-117c-40c5-8bc4-a78e7d6ab623,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-5e15d139-c130-47cb-940b-23003a19552e,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-042a9593-104e-44f1-a618-1f0dccdad916,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-d86b71ff-d983-4f02-b046-a5e6a8e15986,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-62ac3645-36d2-48ef-8caa-84231ee4852e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-e0c1ed9b-edd6-4fd9-bb1c-7399fdd6485b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315605785-172.17.0.10-1598688793389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-5eb2a23f-d27f-4a73-ba7f-88a175e5a2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-98b1f6a1-d6ed-4d61-9528-b52e64fd5a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-9ddcadf6-117c-40c5-8bc4-a78e7d6ab623,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-5e15d139-c130-47cb-940b-23003a19552e,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-042a9593-104e-44f1-a618-1f0dccdad916,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-d86b71ff-d983-4f02-b046-a5e6a8e15986,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-62ac3645-36d2-48ef-8caa-84231ee4852e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-e0c1ed9b-edd6-4fd9-bb1c-7399fdd6485b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843847037-172.17.0.10-1598688820660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42877,DS-6267f443-d875-42c3-9db6-7dbd89fdff13,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-ed0d3fc5-fbe9-447b-86fd-cc3bbc9d0407,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-c702f1fc-b8f9-45ee-b03e-46f3d959f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-dc77ce56-8cbf-4575-a9cd-7f191ca75b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-a32f3831-8e78-4434-bbb6-6a195957ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-04e568fc-b419-42fd-b282-98df0548bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-bcc30d5b-7359-45e7-9940-59bd8746e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-29478d76-b9eb-4d2f-b1bf-99797212fff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843847037-172.17.0.10-1598688820660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42877,DS-6267f443-d875-42c3-9db6-7dbd89fdff13,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-ed0d3fc5-fbe9-447b-86fd-cc3bbc9d0407,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-c702f1fc-b8f9-45ee-b03e-46f3d959f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-dc77ce56-8cbf-4575-a9cd-7f191ca75b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-a32f3831-8e78-4434-bbb6-6a195957ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-04e568fc-b419-42fd-b282-98df0548bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-bcc30d5b-7359-45e7-9940-59bd8746e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-29478d76-b9eb-4d2f-b1bf-99797212fff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744257775-172.17.0.10-1598688905275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-77ee3414-f956-4708-8751-f26d6c263b38,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-d37d22d8-a82e-4722-aac8-e36dffb8106e,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-8f69f47f-0ff3-47fb-bd06-bbda88149b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-7f01ef04-80d2-464b-8278-e45f1b7697e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-b96d7dbc-9cef-4b19-947c-7c0c548991ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-443c1e6f-be05-4f34-b843-74bfec22b413,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c04cf2ec-0ecb-4a03-b058-74c1b068f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-d83ccff1-2b31-4c2a-a175-64f987846481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744257775-172.17.0.10-1598688905275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-77ee3414-f956-4708-8751-f26d6c263b38,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-d37d22d8-a82e-4722-aac8-e36dffb8106e,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-8f69f47f-0ff3-47fb-bd06-bbda88149b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-7f01ef04-80d2-464b-8278-e45f1b7697e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-b96d7dbc-9cef-4b19-947c-7c0c548991ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-443c1e6f-be05-4f34-b843-74bfec22b413,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c04cf2ec-0ecb-4a03-b058-74c1b068f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-d83ccff1-2b31-4c2a-a175-64f987846481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923585161-172.17.0.10-1598688978828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-fde3ec69-9d9e-47f4-bd02-f2192809f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-0a819c76-fc53-4a0f-ba7d-8c1185809fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-c8e309be-8409-4916-9823-2757a9427365,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-699514e4-5247-4cd4-b630-1f4ff5ac1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-ba800a7f-57e3-408e-aaa7-0433832c7560,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-97e86e51-1664-4b90-8fb0-123eb3f2dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-dfe00fab-496b-4dc3-963e-ff191ce2ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-0791c300-b52f-4538-912a-35fd1e44f850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923585161-172.17.0.10-1598688978828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-fde3ec69-9d9e-47f4-bd02-f2192809f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-0a819c76-fc53-4a0f-ba7d-8c1185809fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-c8e309be-8409-4916-9823-2757a9427365,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-699514e4-5247-4cd4-b630-1f4ff5ac1b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-ba800a7f-57e3-408e-aaa7-0433832c7560,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-97e86e51-1664-4b90-8fb0-123eb3f2dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-dfe00fab-496b-4dc3-963e-ff191ce2ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-0791c300-b52f-4538-912a-35fd1e44f850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548847466-172.17.0.10-1598689351514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-8ad2a551-23f2-4c87-81cf-a4aa65e457d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-98f2d1d4-2938-42b4-badd-59cf65ba30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-1b0c8d2e-60a8-4cf3-87ed-165a8f212f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-85ce8bbd-1fcd-408f-b5e7-2acabeaf2429,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f84a21d3-7729-4fee-89fb-26394272382b,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-6f9388cf-3111-457c-b551-1a871eb288be,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b795a978-e5cb-49dd-aea4-7b60fecb22ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-78a2a791-2bb2-456d-82e3-d247754c1a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548847466-172.17.0.10-1598689351514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-8ad2a551-23f2-4c87-81cf-a4aa65e457d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-98f2d1d4-2938-42b4-badd-59cf65ba30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-1b0c8d2e-60a8-4cf3-87ed-165a8f212f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-85ce8bbd-1fcd-408f-b5e7-2acabeaf2429,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f84a21d3-7729-4fee-89fb-26394272382b,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-6f9388cf-3111-457c-b551-1a871eb288be,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-b795a978-e5cb-49dd-aea4-7b60fecb22ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-78a2a791-2bb2-456d-82e3-d247754c1a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381400754-172.17.0.10-1598689432742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-19c4dd96-1280-4f13-9fff-fc685b3e96bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-464357ff-73e2-4d38-ae11-68fd64a6a426,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-7a717af3-b986-4de1-9bb5-bb37a4649767,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-7462f1cc-9e46-468c-b670-c94180154d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-71e1d3ee-bbe3-47e0-88d6-685dbf5d73c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-2c082c4f-154d-42ea-a2f4-5f4448bb064e,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-9f4c34f9-fac3-42c6-9165-2b39d899b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-de7a4e3b-2605-4152-bdb0-320bec868098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381400754-172.17.0.10-1598689432742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-19c4dd96-1280-4f13-9fff-fc685b3e96bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-464357ff-73e2-4d38-ae11-68fd64a6a426,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-7a717af3-b986-4de1-9bb5-bb37a4649767,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-7462f1cc-9e46-468c-b670-c94180154d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-71e1d3ee-bbe3-47e0-88d6-685dbf5d73c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-2c082c4f-154d-42ea-a2f4-5f4448bb064e,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-9f4c34f9-fac3-42c6-9165-2b39d899b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-de7a4e3b-2605-4152-bdb0-320bec868098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5681
