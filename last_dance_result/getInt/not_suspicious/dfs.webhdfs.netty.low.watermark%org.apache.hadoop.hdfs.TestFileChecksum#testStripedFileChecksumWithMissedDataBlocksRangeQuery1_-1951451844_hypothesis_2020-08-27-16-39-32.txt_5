reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343425387-172.17.0.18-1598547065095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-b4d0626e-1efa-4008-bd61-2cead26fe988,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-cd1dd92e-1bc4-41cb-9ccc-28e591ffa450,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-caf2b216-bbc2-4328-ba4d-e4ef59df6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-009def6a-9ad3-4731-8d0c-2f95946dc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-81277eb3-7601-4f72-9543-7f3bc3cccb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-686228b1-88e1-4d80-be99-e612aa615319,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9e039c00-6aaa-4ed8-bc33-990f527f830c,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-0ec4769f-4744-4a61-be3b-26088d816732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343425387-172.17.0.18-1598547065095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-b4d0626e-1efa-4008-bd61-2cead26fe988,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-cd1dd92e-1bc4-41cb-9ccc-28e591ffa450,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-caf2b216-bbc2-4328-ba4d-e4ef59df6d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-009def6a-9ad3-4731-8d0c-2f95946dc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-81277eb3-7601-4f72-9543-7f3bc3cccb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-686228b1-88e1-4d80-be99-e612aa615319,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9e039c00-6aaa-4ed8-bc33-990f527f830c,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-0ec4769f-4744-4a61-be3b-26088d816732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356726865-172.17.0.18-1598547203982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-0226fbfb-535c-4fef-a019-ff12e3b69c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-bca8ac55-ba2f-480e-9218-0edb7c477f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-be739e2e-7f81-4433-a44e-efb2a7a1aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-e469b8d0-6a2d-4259-96ca-1996ac74b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-b486f357-a645-4d44-b7b5-b7e44c640f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-1d4cb4d2-00f5-4219-9fe5-37765c014490,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-537dc21d-c86f-4349-a0f4-5ae0de919b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-ed2f42fc-4171-48c0-870e-2a00847cbf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356726865-172.17.0.18-1598547203982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-0226fbfb-535c-4fef-a019-ff12e3b69c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-bca8ac55-ba2f-480e-9218-0edb7c477f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-be739e2e-7f81-4433-a44e-efb2a7a1aaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-e469b8d0-6a2d-4259-96ca-1996ac74b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-b486f357-a645-4d44-b7b5-b7e44c640f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-1d4cb4d2-00f5-4219-9fe5-37765c014490,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-537dc21d-c86f-4349-a0f4-5ae0de919b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-ed2f42fc-4171-48c0-870e-2a00847cbf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924051731-172.17.0.18-1598548196628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-5a71eef8-9199-430a-8c88-0f6cc34203a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5f00e8fc-52be-4765-a111-78d7d3efe998,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-520626c4-e7ac-45cd-a720-8684fe46c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-42d429f8-9b99-4146-9af8-2037b8bb57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-594f0b13-b675-4c96-8312-b23779348b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-06d876eb-f861-4da8-871a-a78d76a5b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-fea6f15c-f2bc-4823-88b9-9d53083e8e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-deec2d86-2742-498c-8180-a9bfd241e088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924051731-172.17.0.18-1598548196628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-5a71eef8-9199-430a-8c88-0f6cc34203a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5f00e8fc-52be-4765-a111-78d7d3efe998,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-520626c4-e7ac-45cd-a720-8684fe46c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-42d429f8-9b99-4146-9af8-2037b8bb57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-594f0b13-b675-4c96-8312-b23779348b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-06d876eb-f861-4da8-871a-a78d76a5b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-fea6f15c-f2bc-4823-88b9-9d53083e8e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-deec2d86-2742-498c-8180-a9bfd241e088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895069109-172.17.0.18-1598548447983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-ba529de3-165d-4cbf-b7f1-d8964de2a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-7c35cf01-672f-4d56-a336-61c0bd122408,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-2930818c-9287-46ec-958d-a3ebafa501ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-81135439-d965-4b04-bed0-1576b51dc73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-2c0bbf0f-da06-4726-aedb-cf7ad5db3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-e4c9462b-4c84-453f-abd0-822016ae4a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-b9a2531d-0377-481e-be40-6b7076a31d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-fc902818-34ee-4181-a22c-c917dcefe1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895069109-172.17.0.18-1598548447983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-ba529de3-165d-4cbf-b7f1-d8964de2a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-7c35cf01-672f-4d56-a336-61c0bd122408,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-2930818c-9287-46ec-958d-a3ebafa501ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-81135439-d965-4b04-bed0-1576b51dc73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-2c0bbf0f-da06-4726-aedb-cf7ad5db3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-e4c9462b-4c84-453f-abd0-822016ae4a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-b9a2531d-0377-481e-be40-6b7076a31d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-fc902818-34ee-4181-a22c-c917dcefe1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753905603-172.17.0.18-1598548643713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-2c8aa579-c5d7-40c4-b8cd-0d624df534cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-57f0079b-7de0-4b2b-bd27-ca3d5c36a468,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-bfd07dc2-4de4-42d5-828b-78056818213f,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-b3e64b2f-eb82-4d6a-9099-f1eeed0c81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-5fb137f9-4cc8-4554-a8f5-50ef8e9c39f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-0df60dbc-7935-4cc5-bd46-e4959c255d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-f0ec3bce-e66b-4a08-8081-bacdde00f501,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a33ef1f8-a7c6-4010-ac76-ecc64ea45836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753905603-172.17.0.18-1598548643713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-2c8aa579-c5d7-40c4-b8cd-0d624df534cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-57f0079b-7de0-4b2b-bd27-ca3d5c36a468,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-bfd07dc2-4de4-42d5-828b-78056818213f,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-b3e64b2f-eb82-4d6a-9099-f1eeed0c81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-5fb137f9-4cc8-4554-a8f5-50ef8e9c39f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-0df60dbc-7935-4cc5-bd46-e4959c255d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-f0ec3bce-e66b-4a08-8081-bacdde00f501,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a33ef1f8-a7c6-4010-ac76-ecc64ea45836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34978348-172.17.0.18-1598548684085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-10b92581-b223-48fa-b407-6b87056cc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-5059eb10-d0ee-4e44-9aa8-aec52bc9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-cd32b328-21a0-40b2-949a-67e209fc5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-0dd615d9-62ca-44bc-8580-f2cb11dfc208,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-44ce04ab-5e36-4efc-a2e8-8574ed3bf69a,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-2c4cc1bd-b7a7-4b49-ac4b-87c8dac6f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-85984c7d-87b3-43a5-8085-5939dcfecd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-46687c51-74a1-475d-af5b-f3bfe4ee9b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34978348-172.17.0.18-1598548684085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-10b92581-b223-48fa-b407-6b87056cc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-5059eb10-d0ee-4e44-9aa8-aec52bc9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-cd32b328-21a0-40b2-949a-67e209fc5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-0dd615d9-62ca-44bc-8580-f2cb11dfc208,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-44ce04ab-5e36-4efc-a2e8-8574ed3bf69a,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-2c4cc1bd-b7a7-4b49-ac4b-87c8dac6f74f,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-85984c7d-87b3-43a5-8085-5939dcfecd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-46687c51-74a1-475d-af5b-f3bfe4ee9b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526441275-172.17.0.18-1598548913618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-883fc191-476b-4718-95dd-b9db7af08f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-31094115-ff95-49b5-8ed5-8e0b9bd11a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-b21f81f4-2e25-4126-9dd3-8d2ab753e841,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-d670bf57-f397-41c9-aff4-9921fdfd8269,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-7d532996-155a-4b61-b6d6-12599052373e,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-08cab69c-030e-46d4-bba9-e6352177c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-640a91e4-8900-4bac-ba11-67bd4328be05,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-533b37f3-c4a1-48d4-b659-f0c08ab78ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526441275-172.17.0.18-1598548913618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-883fc191-476b-4718-95dd-b9db7af08f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-31094115-ff95-49b5-8ed5-8e0b9bd11a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-b21f81f4-2e25-4126-9dd3-8d2ab753e841,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-d670bf57-f397-41c9-aff4-9921fdfd8269,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-7d532996-155a-4b61-b6d6-12599052373e,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-08cab69c-030e-46d4-bba9-e6352177c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-640a91e4-8900-4bac-ba11-67bd4328be05,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-533b37f3-c4a1-48d4-b659-f0c08ab78ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061953042-172.17.0.18-1598549111663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-ff84a5a2-78b3-4e9c-bc40-decfbe215daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-78a203c8-d323-43d5-a2b8-95f5a86537e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-8d42b272-e74e-4217-b88e-1503ae8b0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-49b57543-30cc-4ee9-96c4-15c26cf6db83,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6e249458-2840-49b5-b1b2-f5fdccacc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-a8396b11-c54b-4778-938d-bf313ec98b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-b4cdaef2-1b72-4169-bd5d-f4ad183c260a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-86c00b7d-3e32-411b-897f-3de22276b170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061953042-172.17.0.18-1598549111663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-ff84a5a2-78b3-4e9c-bc40-decfbe215daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-78a203c8-d323-43d5-a2b8-95f5a86537e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-8d42b272-e74e-4217-b88e-1503ae8b0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-49b57543-30cc-4ee9-96c4-15c26cf6db83,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-6e249458-2840-49b5-b1b2-f5fdccacc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-a8396b11-c54b-4778-938d-bf313ec98b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-b4cdaef2-1b72-4169-bd5d-f4ad183c260a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-86c00b7d-3e32-411b-897f-3de22276b170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122760644-172.17.0.18-1598549260284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-75c7cfca-4870-4ef0-a00a-5b84cbf3300a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-67e4a594-0f41-4949-b5bc-9a29ad15171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-67f9e292-f296-4c1d-874d-d94890e0e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-c0797a8b-f859-4a7b-86b7-5471ec60f300,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-ec3b87b4-833c-4591-8f55-1f2b7e9c5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-902ad751-aa88-400e-8495-1b79fc4abd42,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-fb9442d1-f27f-47d9-9f5f-b3b236947924,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-ad401e70-1e98-42f9-a817-5ef9214fa884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122760644-172.17.0.18-1598549260284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-75c7cfca-4870-4ef0-a00a-5b84cbf3300a,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-67e4a594-0f41-4949-b5bc-9a29ad15171e,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-67f9e292-f296-4c1d-874d-d94890e0e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-c0797a8b-f859-4a7b-86b7-5471ec60f300,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-ec3b87b4-833c-4591-8f55-1f2b7e9c5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-902ad751-aa88-400e-8495-1b79fc4abd42,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-fb9442d1-f27f-47d9-9f5f-b3b236947924,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-ad401e70-1e98-42f9-a817-5ef9214fa884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061865546-172.17.0.18-1598549427259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-9564a3b1-416d-4154-b051-0540df716e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-7ed28d80-f45d-46eb-9f8b-8e442f0f8315,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-aa6363a6-91c9-4ca5-b0f4-ce67e2925be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-4a79ea99-2c56-4d72-8131-254b96d8194e,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-6f82be95-ee25-41bf-8f2e-263fde6cde83,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-00ba65e7-fc48-4342-8fbb-62b7f6cdf4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-c11448cb-3525-469d-8833-2e75b2559be8,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-e72ed6c0-3acc-407e-a73a-f28cba02ddd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061865546-172.17.0.18-1598549427259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-9564a3b1-416d-4154-b051-0540df716e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-7ed28d80-f45d-46eb-9f8b-8e442f0f8315,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-aa6363a6-91c9-4ca5-b0f4-ce67e2925be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-4a79ea99-2c56-4d72-8131-254b96d8194e,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-6f82be95-ee25-41bf-8f2e-263fde6cde83,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-00ba65e7-fc48-4342-8fbb-62b7f6cdf4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-c11448cb-3525-469d-8833-2e75b2559be8,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-e72ed6c0-3acc-407e-a73a-f28cba02ddd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184816569-172.17.0.18-1598549568188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-e75e6917-58ed-4753-860f-389c3e9cbe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-a57bb4d7-86a6-4baa-a253-565823928809,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-efe8295f-30e5-4b2b-bfd0-08e08c3bc99a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-bd08e3f6-a6b2-4f5d-b301-eeefc788ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-a7933573-9fc1-4c98-958b-0ead536b2731,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c0c6db85-2b16-4b5f-b76e-a4c6fc80da87,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-fb66f9aa-32a0-4bd7-94ca-c6dca651ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3655cb0a-da44-4fc7-ae19-106721a8eb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184816569-172.17.0.18-1598549568188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-e75e6917-58ed-4753-860f-389c3e9cbe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-a57bb4d7-86a6-4baa-a253-565823928809,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-efe8295f-30e5-4b2b-bfd0-08e08c3bc99a,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-bd08e3f6-a6b2-4f5d-b301-eeefc788ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-a7933573-9fc1-4c98-958b-0ead536b2731,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c0c6db85-2b16-4b5f-b76e-a4c6fc80da87,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-fb66f9aa-32a0-4bd7-94ca-c6dca651ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3655cb0a-da44-4fc7-ae19-106721a8eb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344375704-172.17.0.18-1598549791459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-5d603cbf-bfac-40c8-a9b9-cb888ca22d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-57897cae-7297-438b-ba6f-7b4bce81a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-771f67c5-dc80-4cef-9a9b-840cd1cacdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-e873f05b-748b-4538-b40e-cd72f8903b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-e9c217a0-0c98-4584-ad0b-4566a88d6212,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-aa0a32d5-38c3-4012-a220-e82d2c50e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2de28d85-eecc-42cb-9229-0049bba8bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-1d0cfd43-bd38-4e0e-82c3-2e2c00d86895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344375704-172.17.0.18-1598549791459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-5d603cbf-bfac-40c8-a9b9-cb888ca22d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-57897cae-7297-438b-ba6f-7b4bce81a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-771f67c5-dc80-4cef-9a9b-840cd1cacdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-e873f05b-748b-4538-b40e-cd72f8903b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-e9c217a0-0c98-4584-ad0b-4566a88d6212,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-aa0a32d5-38c3-4012-a220-e82d2c50e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2de28d85-eecc-42cb-9229-0049bba8bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-1d0cfd43-bd38-4e0e-82c3-2e2c00d86895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877113913-172.17.0.18-1598549994131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-df865b1a-2cdf-429e-899f-18815100b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ca938c83-2e27-48f3-952d-afd684d4f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-2ff9cef1-7e4d-4cac-a929-cdbbb015481f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7cec4a41-6987-4504-a047-26888192227c,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-e0087e0b-4aba-47c3-b490-a147e02d5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-02c5b2e2-e29f-4409-8186-ecb8cd61413f,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-7360ef08-0e13-4930-9940-76c5182fe052,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-6f8aefa3-3699-47f8-ba8d-20496ad7af52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877113913-172.17.0.18-1598549994131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-df865b1a-2cdf-429e-899f-18815100b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ca938c83-2e27-48f3-952d-afd684d4f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-2ff9cef1-7e4d-4cac-a929-cdbbb015481f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-7cec4a41-6987-4504-a047-26888192227c,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-e0087e0b-4aba-47c3-b490-a147e02d5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-02c5b2e2-e29f-4409-8186-ecb8cd61413f,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-7360ef08-0e13-4930-9940-76c5182fe052,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-6f8aefa3-3699-47f8-ba8d-20496ad7af52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780671817-172.17.0.18-1598550026115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-0881e8ba-6b57-43ba-984d-af43144736fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-1bf7a68b-cc7d-47ef-b1e3-f8ab3b9d647f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-de874b7c-aaa6-4f9b-9054-1af4446f4aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-53904903-a674-4ee8-a4f3-f56539c77380,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-803be2e7-a785-473a-8c73-a0dedd5cfd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-7e98148e-8985-4963-8605-8470c9373792,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-9d1f4c74-88a0-4f5b-b89e-4ad51ee27eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-bcc4ba8e-6638-4db6-9142-285288143917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780671817-172.17.0.18-1598550026115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-0881e8ba-6b57-43ba-984d-af43144736fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-1bf7a68b-cc7d-47ef-b1e3-f8ab3b9d647f,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-de874b7c-aaa6-4f9b-9054-1af4446f4aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-53904903-a674-4ee8-a4f3-f56539c77380,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-803be2e7-a785-473a-8c73-a0dedd5cfd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-7e98148e-8985-4963-8605-8470c9373792,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-9d1f4c74-88a0-4f5b-b89e-4ad51ee27eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-bcc4ba8e-6638-4db6-9142-285288143917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668940901-172.17.0.18-1598550060626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-d978c085-cf76-4c43-9464-d0c9c8d5fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-42dbdc7a-3144-407e-84fd-9f479d592af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-f2f73d04-7db6-4ebf-a7c0-0afbfbb92e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-2b1ebb33-3f5e-4392-a183-66476b9ea2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-e58fd5fa-ee1e-4586-98c5-28c396891a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-c14e14a0-11c2-4949-a066-47e35558bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-82e7440e-58ff-4aa2-86e8-e2b2361e6780,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-250e3aed-89a9-401b-8477-17a64f8e2dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668940901-172.17.0.18-1598550060626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-d978c085-cf76-4c43-9464-d0c9c8d5fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-42dbdc7a-3144-407e-84fd-9f479d592af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-f2f73d04-7db6-4ebf-a7c0-0afbfbb92e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-2b1ebb33-3f5e-4392-a183-66476b9ea2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-e58fd5fa-ee1e-4586-98c5-28c396891a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-c14e14a0-11c2-4949-a066-47e35558bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-82e7440e-58ff-4aa2-86e8-e2b2361e6780,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-250e3aed-89a9-401b-8477-17a64f8e2dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514519142-172.17.0.18-1598550094839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-5b69a923-c3dd-4920-80d5-07c8964b2ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c235ab5e-26fa-4474-9cb4-1c3a77fd3f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-09cd1507-1a0a-4dfa-9f69-b908173c471d,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-e16a0ce4-5819-47b9-99f9-0118889ed8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-3f5d59fb-4643-41c4-ac78-adec225b6112,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-9901b04b-0245-413d-96dc-9ae8e39d0417,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-88fc2f34-543b-47c1-a6a9-1838cd0092ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-c3f07b72-d869-454a-8b64-f3033241210e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514519142-172.17.0.18-1598550094839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-5b69a923-c3dd-4920-80d5-07c8964b2ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c235ab5e-26fa-4474-9cb4-1c3a77fd3f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-09cd1507-1a0a-4dfa-9f69-b908173c471d,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-e16a0ce4-5819-47b9-99f9-0118889ed8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-3f5d59fb-4643-41c4-ac78-adec225b6112,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-9901b04b-0245-413d-96dc-9ae8e39d0417,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-88fc2f34-543b-47c1-a6a9-1838cd0092ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-c3f07b72-d869-454a-8b64-f3033241210e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988483762-172.17.0.18-1598550728057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-3220ce89-a81f-4ba4-ad7f-ae4f5076779f,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-92372fc9-baca-4f5d-9136-27314085ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-8bb6f1ef-911c-4560-8e9b-ac31df951f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-963b5d35-d4f0-4a1b-bebb-1ae0e9d5a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-08d01c6b-36fd-4281-bebc-697194639c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-8f80a569-06c7-43c0-b576-bb007c947f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c2e45a5f-5414-4f1b-9eda-c0c48f604898,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-3cdc2020-f6ce-4cdf-889f-5575d16e842b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988483762-172.17.0.18-1598550728057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34548,DS-3220ce89-a81f-4ba4-ad7f-ae4f5076779f,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-92372fc9-baca-4f5d-9136-27314085ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-8bb6f1ef-911c-4560-8e9b-ac31df951f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-963b5d35-d4f0-4a1b-bebb-1ae0e9d5a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-08d01c6b-36fd-4281-bebc-697194639c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-8f80a569-06c7-43c0-b576-bb007c947f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c2e45a5f-5414-4f1b-9eda-c0c48f604898,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-3cdc2020-f6ce-4cdf-889f-5575d16e842b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336696437-172.17.0.18-1598551089101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-8a031c01-8c1b-4d7b-8ba7-3d24f3cc3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-ffe8a200-69e6-4bd9-803b-e71ae3e0edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-76899bf1-a1f3-44c4-a6ef-33ffd34e2cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b861e3b7-02c5-44fb-af52-ca0147650a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1604e7e5-c7e2-4a48-854f-7a68afca72d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1f9fcbca-6eb1-4c58-bdbb-d1c35e852bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-bf6311ed-41e2-4a4e-950f-fb7548fb71aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-ade809bb-a5f0-42cc-9ad7-d304e71d87fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336696437-172.17.0.18-1598551089101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-8a031c01-8c1b-4d7b-8ba7-3d24f3cc3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-ffe8a200-69e6-4bd9-803b-e71ae3e0edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-76899bf1-a1f3-44c4-a6ef-33ffd34e2cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-b861e3b7-02c5-44fb-af52-ca0147650a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1604e7e5-c7e2-4a48-854f-7a68afca72d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-1f9fcbca-6eb1-4c58-bdbb-d1c35e852bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-bf6311ed-41e2-4a4e-950f-fb7548fb71aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-ade809bb-a5f0-42cc-9ad7-d304e71d87fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088261251-172.17.0.18-1598551131431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38168,DS-90dfc0ab-98cb-4bc2-957f-e44d720d0050,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-e2fd8a9a-1526-4de7-acd0-877262acfc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-64c63f39-d3d6-4b5d-914f-dcdb15737f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-c18364bc-3579-494b-9788-0962091b06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-c51789ae-3eef-4573-9e60-814449165877,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-c54c5015-7385-4faf-bd7c-9fc24c81d415,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f94147a8-59b7-411d-8ba4-30b4b3a0ec15,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-e6d9048a-3f17-4bd8-bdfe-f42870369f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088261251-172.17.0.18-1598551131431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38168,DS-90dfc0ab-98cb-4bc2-957f-e44d720d0050,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-e2fd8a9a-1526-4de7-acd0-877262acfc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-64c63f39-d3d6-4b5d-914f-dcdb15737f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-c18364bc-3579-494b-9788-0962091b06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-c51789ae-3eef-4573-9e60-814449165877,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-c54c5015-7385-4faf-bd7c-9fc24c81d415,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f94147a8-59b7-411d-8ba4-30b4b3a0ec15,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-e6d9048a-3f17-4bd8-bdfe-f42870369f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501436334-172.17.0.18-1598551282880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38102,DS-6b1bccd4-ff86-48b9-9e75-83a0d8ecf889,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-8e0a008e-beca-4a81-8ec2-5f283cd00e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-709d7375-146c-437f-84ae-20661b456dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-6ee5cfac-c32a-41f6-a745-ca0c85bda529,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-fd8688dd-acca-4921-84a3-c3b4730319ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-69f30a95-2c83-4864-aabb-e207fce57c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-fc16b72d-957a-4ac1-a7a0-6dcf391f2208,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-a40a326d-6e64-476b-9285-f8adccbad273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501436334-172.17.0.18-1598551282880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38102,DS-6b1bccd4-ff86-48b9-9e75-83a0d8ecf889,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-8e0a008e-beca-4a81-8ec2-5f283cd00e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-709d7375-146c-437f-84ae-20661b456dad,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-6ee5cfac-c32a-41f6-a745-ca0c85bda529,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-fd8688dd-acca-4921-84a3-c3b4730319ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-69f30a95-2c83-4864-aabb-e207fce57c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-fc16b72d-957a-4ac1-a7a0-6dcf391f2208,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-a40a326d-6e64-476b-9285-f8adccbad273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617472831-172.17.0.18-1598551434967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-22d7565c-0ea6-4081-b3b3-930be46b9465,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-fc833c56-bf01-4a81-a093-cebb6d55c535,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d508e10c-0b69-4cd8-bb44-8b36a705aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-50ebfc88-8a46-423e-bcff-eadbd537ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-456f7b05-b2a8-4e68-a5f4-84ff75932ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-5bce13bd-c0af-4dd3-a5ea-0f995fb424f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-877093d7-d88f-462c-9527-68a4475cdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-fe788ea0-324d-45dd-99e0-bf54b769b025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617472831-172.17.0.18-1598551434967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-22d7565c-0ea6-4081-b3b3-930be46b9465,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-fc833c56-bf01-4a81-a093-cebb6d55c535,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d508e10c-0b69-4cd8-bb44-8b36a705aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-50ebfc88-8a46-423e-bcff-eadbd537ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-456f7b05-b2a8-4e68-a5f4-84ff75932ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-5bce13bd-c0af-4dd3-a5ea-0f995fb424f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-877093d7-d88f-462c-9527-68a4475cdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-fe788ea0-324d-45dd-99e0-bf54b769b025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5119
