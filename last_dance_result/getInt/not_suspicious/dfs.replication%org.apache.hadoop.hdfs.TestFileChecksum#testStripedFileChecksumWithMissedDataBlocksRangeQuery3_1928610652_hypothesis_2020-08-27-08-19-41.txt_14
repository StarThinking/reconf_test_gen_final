reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177388220-172.17.0.14-1598516775657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-a1886843-0947-4f6d-b14e-8295526ed5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-f95f1297-5ae9-446a-a510-3ce9000b6789,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-f7caa939-6bcf-4984-bbc0-d8269aa04d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-ec6f63c9-5ed8-4307-8765-81420a051257,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-ea8fb7f8-02ee-4dad-a97b-38a0fbea22d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-7477e19f-130f-41fd-b21c-7488d71ec144,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-677b82df-01d0-4c19-89dc-85b26137e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d56d201e-125e-4d07-bce4-7e08504a4b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177388220-172.17.0.14-1598516775657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-a1886843-0947-4f6d-b14e-8295526ed5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-f95f1297-5ae9-446a-a510-3ce9000b6789,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-f7caa939-6bcf-4984-bbc0-d8269aa04d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-ec6f63c9-5ed8-4307-8765-81420a051257,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-ea8fb7f8-02ee-4dad-a97b-38a0fbea22d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-7477e19f-130f-41fd-b21c-7488d71ec144,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-677b82df-01d0-4c19-89dc-85b26137e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-d56d201e-125e-4d07-bce4-7e08504a4b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151780427-172.17.0.14-1598516877957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-fa0ad450-4728-4d91-918e-738967ee3b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-6f67e0cf-a059-4655-a0f0-1beb8f5ba36f,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-e8cd6594-cd3c-477d-b6b6-f1899dbe4414,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-d85f7f16-6ffc-4293-b924-346ab64ec60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-232fb140-e272-4082-9c56-5afbe2985edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-5f63fa11-5d23-450e-8db5-134d5ce106ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-e549890b-2852-4b8a-ad02-a096109bb48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-2d9ddef4-3abd-4498-93a6-e07e666c24bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151780427-172.17.0.14-1598516877957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-fa0ad450-4728-4d91-918e-738967ee3b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-6f67e0cf-a059-4655-a0f0-1beb8f5ba36f,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-e8cd6594-cd3c-477d-b6b6-f1899dbe4414,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-d85f7f16-6ffc-4293-b924-346ab64ec60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-232fb140-e272-4082-9c56-5afbe2985edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-5f63fa11-5d23-450e-8db5-134d5ce106ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-e549890b-2852-4b8a-ad02-a096109bb48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-2d9ddef4-3abd-4498-93a6-e07e666c24bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789865835-172.17.0.14-1598517251771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-3519c63b-c788-4d5c-8d68-5fea81920df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e1e130a8-df30-44f1-8750-96a32640d469,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-4bd534c7-ac14-4fc1-a9aa-0f0c0a027a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-8e8d5081-3e87-4524-a60c-1530b264b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-128d1a57-176b-4cec-a958-cf7007635281,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-4b1a7959-a617-4b7d-9078-6beac4d4bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-f172398b-f977-4c72-bf0c-13328510f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-b12c3115-671f-41bc-9518-7f2896344c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789865835-172.17.0.14-1598517251771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-3519c63b-c788-4d5c-8d68-5fea81920df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e1e130a8-df30-44f1-8750-96a32640d469,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-4bd534c7-ac14-4fc1-a9aa-0f0c0a027a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-8e8d5081-3e87-4524-a60c-1530b264b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-128d1a57-176b-4cec-a958-cf7007635281,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-4b1a7959-a617-4b7d-9078-6beac4d4bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-f172398b-f977-4c72-bf0c-13328510f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-b12c3115-671f-41bc-9518-7f2896344c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496287702-172.17.0.14-1598518151033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-733ad1b1-253e-4bf5-ba48-f17bcc26598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-ea571824-25a1-4383-aa27-29dbdaf07540,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-f140ff9a-280c-40bb-8e66-e93336867456,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-7d280260-6a09-46a3-8978-c7d22806b472,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-20cadeee-5028-4510-8632-fe515717aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-08812d9e-7c61-47c2-a05e-172bb99d0cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-561b2e17-74dc-44a8-b358-84e7231412ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-9115de27-fd74-4090-a750-47f86e162696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496287702-172.17.0.14-1598518151033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-733ad1b1-253e-4bf5-ba48-f17bcc26598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-ea571824-25a1-4383-aa27-29dbdaf07540,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-f140ff9a-280c-40bb-8e66-e93336867456,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-7d280260-6a09-46a3-8978-c7d22806b472,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-20cadeee-5028-4510-8632-fe515717aa87,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-08812d9e-7c61-47c2-a05e-172bb99d0cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-561b2e17-74dc-44a8-b358-84e7231412ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-9115de27-fd74-4090-a750-47f86e162696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155903568-172.17.0.14-1598518899468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-23b6ffcf-8a97-45cb-a754-1fd00dd29423,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-d245ff29-128f-48e3-8be2-15b36cf21b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-d40008f7-e921-4b9e-9e99-cbdfd4d95382,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-acec5dd9-c2ae-451b-a58a-83f074dfba93,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-7e8182d9-3051-4c05-bcdf-783999a27471,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-89563dc2-6b64-4015-856b-7ac3bb634b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-59d89c9b-d4bc-44cf-b341-45fa4d95f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-9fc2443b-092e-45df-8ebb-cb82e5548962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155903568-172.17.0.14-1598518899468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-23b6ffcf-8a97-45cb-a754-1fd00dd29423,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-d245ff29-128f-48e3-8be2-15b36cf21b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-d40008f7-e921-4b9e-9e99-cbdfd4d95382,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-acec5dd9-c2ae-451b-a58a-83f074dfba93,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-7e8182d9-3051-4c05-bcdf-783999a27471,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-89563dc2-6b64-4015-856b-7ac3bb634b88,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-59d89c9b-d4bc-44cf-b341-45fa4d95f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-9fc2443b-092e-45df-8ebb-cb82e5548962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368614535-172.17.0.14-1598519352645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-314ccdf8-e4c3-41e0-9b7c-a22398567416,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ef5cb2b9-e467-4515-bde6-31d77fe303c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-eee06262-45a5-443c-a2ab-301de2015007,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-2b12a40e-e521-4f44-9621-2781949663ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5a137190-a5ca-4d5a-a5df-b0aced03201b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-7fdc9c43-ae38-417c-8a18-bac80e46a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-27762c34-6dee-497a-a1ca-9f47d94d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c30dcdee-8ec7-4fb9-8d40-0cc73c4c1e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368614535-172.17.0.14-1598519352645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-314ccdf8-e4c3-41e0-9b7c-a22398567416,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-ef5cb2b9-e467-4515-bde6-31d77fe303c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-eee06262-45a5-443c-a2ab-301de2015007,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-2b12a40e-e521-4f44-9621-2781949663ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-5a137190-a5ca-4d5a-a5df-b0aced03201b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-7fdc9c43-ae38-417c-8a18-bac80e46a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-27762c34-6dee-497a-a1ca-9f47d94d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c30dcdee-8ec7-4fb9-8d40-0cc73c4c1e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399469132-172.17.0.14-1598519746131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2cc0eb80-afba-40d1-9457-6c4f05020b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-82d0ce71-be81-4ad0-b8ba-12b508059463,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-326df8d6-3617-453d-b629-e2c4ecd053b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-dcd4a2c7-3edc-414e-a691-379298c9fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-8fd14247-41d4-4e44-ae3d-44bd9ddb3f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-0824b559-1daf-4774-a479-8d9250480f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-b364380c-ea71-4578-97a2-b0bcca6a7b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-19ff584f-98b3-427b-bf14-e6d14277d5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399469132-172.17.0.14-1598519746131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2cc0eb80-afba-40d1-9457-6c4f05020b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-82d0ce71-be81-4ad0-b8ba-12b508059463,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-326df8d6-3617-453d-b629-e2c4ecd053b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-dcd4a2c7-3edc-414e-a691-379298c9fefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-8fd14247-41d4-4e44-ae3d-44bd9ddb3f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-0824b559-1daf-4774-a479-8d9250480f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-b364380c-ea71-4578-97a2-b0bcca6a7b45,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-19ff584f-98b3-427b-bf14-e6d14277d5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149739581-172.17.0.14-1598520101673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-c26f1c57-3d81-45bf-b12c-6e083025b562,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-f74c4303-1d86-4650-8401-ada57147600e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f663747b-4166-4071-a5d5-6d373a0b4557,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d0ddd7fe-e7e4-4e10-93de-336763404e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d572369e-518d-46d8-a364-78636b81769f,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-f698c188-7992-4d20-b50a-ffb4d24f3097,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-b819b04c-06fa-4924-90ac-7b24e526ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-1bcb2248-182d-49c7-acd1-270e1365137e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149739581-172.17.0.14-1598520101673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-c26f1c57-3d81-45bf-b12c-6e083025b562,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-f74c4303-1d86-4650-8401-ada57147600e,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-f663747b-4166-4071-a5d5-6d373a0b4557,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d0ddd7fe-e7e4-4e10-93de-336763404e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d572369e-518d-46d8-a364-78636b81769f,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-f698c188-7992-4d20-b50a-ffb4d24f3097,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-b819b04c-06fa-4924-90ac-7b24e526ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-1bcb2248-182d-49c7-acd1-270e1365137e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91440429-172.17.0.14-1598520780025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-f8ab5306-daef-4d2c-8e2d-b554f78fa998,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-c174ce15-8d93-4830-bb36-83311efa5b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-66f4f907-b5a1-4ce4-bbf8-f596880b54e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-694e7292-a251-4d94-b5c4-2406d06aad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fddf058c-764c-4497-bf86-1064519d01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-50349841-d9a1-481b-9f73-753df36256fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-b7acb92c-a9f1-463d-b8ef-890fb781defe,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-f71b1c1f-4915-4226-8d62-281408cb56d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91440429-172.17.0.14-1598520780025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-f8ab5306-daef-4d2c-8e2d-b554f78fa998,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-c174ce15-8d93-4830-bb36-83311efa5b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-66f4f907-b5a1-4ce4-bbf8-f596880b54e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-694e7292-a251-4d94-b5c4-2406d06aad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fddf058c-764c-4497-bf86-1064519d01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-50349841-d9a1-481b-9f73-753df36256fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-b7acb92c-a9f1-463d-b8ef-890fb781defe,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-f71b1c1f-4915-4226-8d62-281408cb56d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601671738-172.17.0.14-1598521036433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-ae6c0679-0f7c-4e28-8a6a-3188c2675b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-6dd60cc1-aee5-48fe-b6c4-07e1e2b5d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-b9c976bb-103e-4df7-bdfd-61d339f103d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-424b389e-48a1-4f84-ac3a-e6a7520eefec,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-dd36a67b-73e0-4e38-be4e-9cc85daf919e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-47457d9c-6076-41b1-b8d2-eb18bc971c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-957df350-0992-417a-b917-2e3a28faab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-7d37ade1-e194-42e8-a2f3-829c96b47d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601671738-172.17.0.14-1598521036433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40399,DS-ae6c0679-0f7c-4e28-8a6a-3188c2675b42,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-6dd60cc1-aee5-48fe-b6c4-07e1e2b5d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-b9c976bb-103e-4df7-bdfd-61d339f103d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-424b389e-48a1-4f84-ac3a-e6a7520eefec,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-dd36a67b-73e0-4e38-be4e-9cc85daf919e,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-47457d9c-6076-41b1-b8d2-eb18bc971c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-957df350-0992-417a-b917-2e3a28faab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-7d37ade1-e194-42e8-a2f3-829c96b47d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550602207-172.17.0.14-1598521464076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-2a7f921d-7ce3-4d00-bc24-fd0df08691e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-e97e99fa-9f8f-41b7-a1a5-1b4091e93b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-14e4c214-e9e6-483b-9fc8-6b8c9fb92d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-adb20cb5-a7bb-4d10-b8bf-25b28df39418,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-f7dca604-170d-4c40-9077-6726d9c1994c,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-cd486d68-3b4c-49d9-b53e-a1f9f5f4c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-bf85bd96-1364-457d-9fa9-1f5ad86d6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-4fc09870-6adc-44f8-9deb-592ae52ae044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550602207-172.17.0.14-1598521464076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-2a7f921d-7ce3-4d00-bc24-fd0df08691e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-e97e99fa-9f8f-41b7-a1a5-1b4091e93b75,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-14e4c214-e9e6-483b-9fc8-6b8c9fb92d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-adb20cb5-a7bb-4d10-b8bf-25b28df39418,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-f7dca604-170d-4c40-9077-6726d9c1994c,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-cd486d68-3b4c-49d9-b53e-a1f9f5f4c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-bf85bd96-1364-457d-9fa9-1f5ad86d6a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-4fc09870-6adc-44f8-9deb-592ae52ae044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5101
