reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559295290-172.17.0.11-1598667028526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-e00dc864-5e4b-4107-881b-f960c0c3338b,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-a3d111c5-9fad-49da-a3a5-c48611ce9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-fd41b2cc-8a24-4af7-8948-fbd5a6f23df4,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-4482eeac-c370-43e6-af41-f48294b4e099,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-e440b56f-ec3b-4816-9fe2-8be391c6a41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-785d8c7e-bfc3-411d-89f6-e9d1f462a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-9e77ba75-eed0-400c-a7d0-ecd8af3c6d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-aadf1212-8897-4216-9e07-b46811ebad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559295290-172.17.0.11-1598667028526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-e00dc864-5e4b-4107-881b-f960c0c3338b,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-a3d111c5-9fad-49da-a3a5-c48611ce9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-fd41b2cc-8a24-4af7-8948-fbd5a6f23df4,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-4482eeac-c370-43e6-af41-f48294b4e099,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-e440b56f-ec3b-4816-9fe2-8be391c6a41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-785d8c7e-bfc3-411d-89f6-e9d1f462a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-9e77ba75-eed0-400c-a7d0-ecd8af3c6d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-aadf1212-8897-4216-9e07-b46811ebad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527834609-172.17.0.11-1598667074974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-163404fc-fd7e-4f57-947b-7761d8f7d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-664ba076-76b7-447b-a205-d5d66c4e41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-c596afd7-c682-458d-aae6-871a03cfc0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-c9e6cb70-7876-4690-ab6c-3015630156b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-54d73ab3-9f9b-4618-a9b2-b5386523471e,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4bf67acd-dc58-4b33-ac45-d0b9e42e3494,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-cb9fe1c4-3537-4a43-8f7c-f8f75b2a896f,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-033abaa1-5d43-4a02-aa0d-f3d47ce14780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527834609-172.17.0.11-1598667074974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-163404fc-fd7e-4f57-947b-7761d8f7d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-664ba076-76b7-447b-a205-d5d66c4e41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-c596afd7-c682-458d-aae6-871a03cfc0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-c9e6cb70-7876-4690-ab6c-3015630156b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-54d73ab3-9f9b-4618-a9b2-b5386523471e,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4bf67acd-dc58-4b33-ac45-d0b9e42e3494,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-cb9fe1c4-3537-4a43-8f7c-f8f75b2a896f,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-033abaa1-5d43-4a02-aa0d-f3d47ce14780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664466802-172.17.0.11-1598667149658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-d698e8f9-f502-4627-a7a1-285fd082e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-5b56ce0f-ec15-4c09-af2a-fb0c4fc61309,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-d06521bd-e145-47c5-a2a8-041e767001dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-9e30e77e-7f8b-4b13-92a5-6f396fe13e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-06d3ab29-ea5b-4904-8c35-811b1b5d9632,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-7478f147-806a-4323-93f4-955ff3071cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-96a883d1-7b0e-472e-9ca4-0cf3c0bc3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e846fab5-721e-46f2-8996-e7e0165f168a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664466802-172.17.0.11-1598667149658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-d698e8f9-f502-4627-a7a1-285fd082e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-5b56ce0f-ec15-4c09-af2a-fb0c4fc61309,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-d06521bd-e145-47c5-a2a8-041e767001dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-9e30e77e-7f8b-4b13-92a5-6f396fe13e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-06d3ab29-ea5b-4904-8c35-811b1b5d9632,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-7478f147-806a-4323-93f4-955ff3071cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-96a883d1-7b0e-472e-9ca4-0cf3c0bc3ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e846fab5-721e-46f2-8996-e7e0165f168a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871505983-172.17.0.11-1598667677015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-55fec8a4-be12-483f-a94c-047afc317690,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-a86c9be4-acc9-4e5d-9557-6c4a3bdc5540,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-611ef7dd-97ba-4300-82c9-bdaff82dd2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-0c616640-dff1-4744-b627-b46c2ec99bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c38f7572-c206-426d-92c8-1db58586005f,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a6ff801f-4376-4178-a8a7-731686b0b1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-88398cc3-f743-4f68-93ff-46bf47924c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-046324e3-62de-44c8-bf84-6b87943105f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871505983-172.17.0.11-1598667677015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-55fec8a4-be12-483f-a94c-047afc317690,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-a86c9be4-acc9-4e5d-9557-6c4a3bdc5540,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-611ef7dd-97ba-4300-82c9-bdaff82dd2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-0c616640-dff1-4744-b627-b46c2ec99bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c38f7572-c206-426d-92c8-1db58586005f,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a6ff801f-4376-4178-a8a7-731686b0b1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-88398cc3-f743-4f68-93ff-46bf47924c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-046324e3-62de-44c8-bf84-6b87943105f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196730165-172.17.0.11-1598668036460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38351,DS-2132b4fc-711d-4e51-9387-75b4d1c7e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-65362ff2-1afb-4972-9ace-f2b4bf3efd24,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-a5c81fbf-4338-4592-bfce-7e7280f40759,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-35774e96-b51f-4503-b9a2-da30474a58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-acaa1c4a-bfd2-4bfe-9132-92033b0f40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-528eebaf-739c-447b-8325-9eab081ddd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-d4635d58-d8b1-4633-9d3d-796c26157f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-3d8a5d68-bc64-44a5-a816-ce09aa0ca3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196730165-172.17.0.11-1598668036460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38351,DS-2132b4fc-711d-4e51-9387-75b4d1c7e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-65362ff2-1afb-4972-9ace-f2b4bf3efd24,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-a5c81fbf-4338-4592-bfce-7e7280f40759,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-35774e96-b51f-4503-b9a2-da30474a58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-acaa1c4a-bfd2-4bfe-9132-92033b0f40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-528eebaf-739c-447b-8325-9eab081ddd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-d4635d58-d8b1-4633-9d3d-796c26157f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-3d8a5d68-bc64-44a5-a816-ce09aa0ca3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087253697-172.17.0.11-1598668109683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-e80ad028-927d-4437-8705-600b3b325908,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-855fab3e-e8a8-4c08-8b7e-7f2de6c80abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-201edac9-6e10-42a7-aa83-cf02567c6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-6f723063-5dc7-4dcf-a6ef-bd8b58a81c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d0134622-c39f-4764-9874-1d7688f8fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-d4c61d71-00b2-4901-90f9-3b8b880e0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-2ab0f729-1d22-4892-9df0-5901b21355a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-076da0f8-51c9-40b4-be15-997de6b27ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087253697-172.17.0.11-1598668109683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-e80ad028-927d-4437-8705-600b3b325908,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-855fab3e-e8a8-4c08-8b7e-7f2de6c80abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-201edac9-6e10-42a7-aa83-cf02567c6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-6f723063-5dc7-4dcf-a6ef-bd8b58a81c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-d0134622-c39f-4764-9874-1d7688f8fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-d4c61d71-00b2-4901-90f9-3b8b880e0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-2ab0f729-1d22-4892-9df0-5901b21355a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-076da0f8-51c9-40b4-be15-997de6b27ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801736460-172.17.0.11-1598668143011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-d862c36e-ceee-4119-8ba5-d16eee1ce744,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c1a51233-5452-4dae-a886-b3a9aa01b23c,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-63d60cb5-104d-4b9e-9533-b7acdf8508f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-730dcd86-0ff0-4233-8b0d-4220264452d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-477b03b7-08b2-446a-81d7-43ece285663c,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-243fdf89-5776-4bfa-a9fb-ef239451b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-ecfda953-5404-4847-acf1-409e64aa9378,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-230e466a-e8ad-4318-84ba-1e9f88c5a6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801736460-172.17.0.11-1598668143011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-d862c36e-ceee-4119-8ba5-d16eee1ce744,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c1a51233-5452-4dae-a886-b3a9aa01b23c,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-63d60cb5-104d-4b9e-9533-b7acdf8508f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-730dcd86-0ff0-4233-8b0d-4220264452d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-477b03b7-08b2-446a-81d7-43ece285663c,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-243fdf89-5776-4bfa-a9fb-ef239451b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-ecfda953-5404-4847-acf1-409e64aa9378,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-230e466a-e8ad-4318-84ba-1e9f88c5a6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439698531-172.17.0.11-1598669161789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-f48420a6-07a3-44c9-88d3-e0da3ab73bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-b583d011-b8d2-47fe-a8b7-75e46b5a84d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-bcaf1247-4058-44c3-a79b-7c337486d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a63559c1-ff54-44a7-9b18-99a78489b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-cc04eb96-a7f3-4e11-88fc-887e451c95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-1c65cf67-a57e-4838-9c79-346b55dfb916,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-4e5e5e4c-51fc-4ef3-8985-807c10ca62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-bd5b2788-6051-48eb-8bc4-bbb9e576d128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439698531-172.17.0.11-1598669161789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-f48420a6-07a3-44c9-88d3-e0da3ab73bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-b583d011-b8d2-47fe-a8b7-75e46b5a84d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-bcaf1247-4058-44c3-a79b-7c337486d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a63559c1-ff54-44a7-9b18-99a78489b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-cc04eb96-a7f3-4e11-88fc-887e451c95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-1c65cf67-a57e-4838-9c79-346b55dfb916,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-4e5e5e4c-51fc-4ef3-8985-807c10ca62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-bd5b2788-6051-48eb-8bc4-bbb9e576d128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184077892-172.17.0.11-1598669396931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-805e2072-5856-48d8-8acb-0404748077d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-61add520-29fc-418d-9e1a-c2de0fe63311,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f77de11e-d8ce-489d-b2fc-e3148e572224,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-f1e858df-7840-4506-88f8-8b46885b6094,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-b38ea5b1-cb39-423a-838b-8c20b9a8f653,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-5e965109-dd8f-4d9d-ad5a-c67b92a66856,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-10bff798-713b-4530-8522-a4cf74d2c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-6c542c47-6bc6-4cf8-b07b-7f7b704b0ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184077892-172.17.0.11-1598669396931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-805e2072-5856-48d8-8acb-0404748077d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-61add520-29fc-418d-9e1a-c2de0fe63311,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f77de11e-d8ce-489d-b2fc-e3148e572224,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-f1e858df-7840-4506-88f8-8b46885b6094,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-b38ea5b1-cb39-423a-838b-8c20b9a8f653,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-5e965109-dd8f-4d9d-ad5a-c67b92a66856,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-10bff798-713b-4530-8522-a4cf74d2c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-6c542c47-6bc6-4cf8-b07b-7f7b704b0ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450809968-172.17.0.11-1598669437967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-4309ae20-72e5-4cec-a458-c7207d3fa293,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-4d58b3fa-4fed-4330-b6dd-c70f9b2bc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ca6b06f2-e480-4c59-ba58-3acddc09cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-ed02a0bf-2a86-4025-ad4f-45f2409598ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-1e110090-7853-4f23-bef8-6b9cb8f16149,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e2b70f5a-9a19-421e-83b9-48766572db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-eba2dfb1-4442-48b8-8fb2-4d9d2484e225,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-895b0da9-f1d7-47e4-99ef-5f29e33a944e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450809968-172.17.0.11-1598669437967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-4309ae20-72e5-4cec-a458-c7207d3fa293,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-4d58b3fa-4fed-4330-b6dd-c70f9b2bc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ca6b06f2-e480-4c59-ba58-3acddc09cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-ed02a0bf-2a86-4025-ad4f-45f2409598ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-1e110090-7853-4f23-bef8-6b9cb8f16149,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e2b70f5a-9a19-421e-83b9-48766572db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-eba2dfb1-4442-48b8-8fb2-4d9d2484e225,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-895b0da9-f1d7-47e4-99ef-5f29e33a944e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056615524-172.17.0.11-1598669470921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39512,DS-d6e557bf-c847-4af0-9954-3b95b70cab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4813dc8d-bb13-4efc-bc11-fb8981b48a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-df3c8603-0736-42ab-b905-6ac858900139,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-15af4e0b-0a26-4779-bd25-b5bac775ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-48fb1394-55b8-4bf2-932c-9b39014891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-08c84e01-101e-4207-8dfd-b14855e7124f,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-07d027ab-3915-456d-bda1-f1886fde428b,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-e3cf0f01-ac03-4192-82e5-4b5252b70189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056615524-172.17.0.11-1598669470921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39512,DS-d6e557bf-c847-4af0-9954-3b95b70cab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4813dc8d-bb13-4efc-bc11-fb8981b48a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-df3c8603-0736-42ab-b905-6ac858900139,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-15af4e0b-0a26-4779-bd25-b5bac775ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-48fb1394-55b8-4bf2-932c-9b39014891bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-08c84e01-101e-4207-8dfd-b14855e7124f,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-07d027ab-3915-456d-bda1-f1886fde428b,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-e3cf0f01-ac03-4192-82e5-4b5252b70189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117358558-172.17.0.11-1598669755010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-462ab614-85c2-4a17-9488-607650262a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-98eecc63-6770-4379-a115-a367c00c59a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-bcc70db4-8dd1-4cf9-9731-76a326b05e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-bfe47e6b-9bab-4a02-9bed-2bf53b7751a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d0bd46bc-91ac-48a9-9389-9168273d9c60,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-079f7e54-abed-47b6-9add-3807aecacd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-900cfcc5-96f4-4fd3-92c8-67f0f1d3bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-fad37962-64fa-46a2-9d09-11a1da4b58f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117358558-172.17.0.11-1598669755010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-462ab614-85c2-4a17-9488-607650262a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-98eecc63-6770-4379-a115-a367c00c59a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-bcc70db4-8dd1-4cf9-9731-76a326b05e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-bfe47e6b-9bab-4a02-9bed-2bf53b7751a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d0bd46bc-91ac-48a9-9389-9168273d9c60,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-079f7e54-abed-47b6-9add-3807aecacd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-900cfcc5-96f4-4fd3-92c8-67f0f1d3bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-fad37962-64fa-46a2-9d09-11a1da4b58f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941266203-172.17.0.11-1598670025590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-7045a243-7971-47db-88d0-f80f9d182b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-fb1587cf-df4f-42ac-b285-73afcbeb2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-f3a2707a-185d-4dd7-ba10-1b79b4d3f272,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-d5a48266-1c2d-461b-b39c-346fd5ca27e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e143fec1-644e-4737-8256-27c17f52881b,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-9395d264-4be0-4c65-8d89-7e358725cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-65d970cb-87ae-4d1c-b5de-f674f549e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-e640b434-30db-411c-9a25-672305d62baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941266203-172.17.0.11-1598670025590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-7045a243-7971-47db-88d0-f80f9d182b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-fb1587cf-df4f-42ac-b285-73afcbeb2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-f3a2707a-185d-4dd7-ba10-1b79b4d3f272,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-d5a48266-1c2d-461b-b39c-346fd5ca27e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e143fec1-644e-4737-8256-27c17f52881b,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-9395d264-4be0-4c65-8d89-7e358725cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-65d970cb-87ae-4d1c-b5de-f674f549e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-e640b434-30db-411c-9a25-672305d62baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093627483-172.17.0.11-1598670168723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34145,DS-07c55ea8-9903-464c-8584-4a3b05436963,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-b332a60f-fc51-4c0f-a447-9f7df5077520,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-328e9586-3ab0-46f8-9d92-fad846f4f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-860f792b-4531-4567-8541-116b37740dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-8961f917-f740-478f-aeff-a8ed2224892b,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-3f618477-5bf4-4014-8fd4-5b5d5b466b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-57ce790e-0d9f-4ac9-81bb-8934a6ad016d,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-0b3cfab5-80f2-47e5-9516-b477601dd85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093627483-172.17.0.11-1598670168723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34145,DS-07c55ea8-9903-464c-8584-4a3b05436963,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-b332a60f-fc51-4c0f-a447-9f7df5077520,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-328e9586-3ab0-46f8-9d92-fad846f4f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-860f792b-4531-4567-8541-116b37740dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-8961f917-f740-478f-aeff-a8ed2224892b,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-3f618477-5bf4-4014-8fd4-5b5d5b466b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-57ce790e-0d9f-4ac9-81bb-8934a6ad016d,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-0b3cfab5-80f2-47e5-9516-b477601dd85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843447799-172.17.0.11-1598670501635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34154,DS-dfc9c45e-375b-471e-8ed9-900f78abf021,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-fd57f8cc-b98c-4b73-b8cb-b62900da5032,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-ed11f82e-a918-41f1-bd74-501f6842dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b3e56275-0c2e-428b-9f22-89c44eec122f,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-5c2ab245-3eee-40d1-8b86-3eb796845a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d8847a71-0b25-4ca6-a3d7-45e56d2385c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-996b5332-f528-4352-a8d2-bb42e2186e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-c695d1d1-065b-4c9e-a175-25250e227025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843447799-172.17.0.11-1598670501635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34154,DS-dfc9c45e-375b-471e-8ed9-900f78abf021,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-fd57f8cc-b98c-4b73-b8cb-b62900da5032,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-ed11f82e-a918-41f1-bd74-501f6842dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b3e56275-0c2e-428b-9f22-89c44eec122f,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-5c2ab245-3eee-40d1-8b86-3eb796845a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d8847a71-0b25-4ca6-a3d7-45e56d2385c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-996b5332-f528-4352-a8d2-bb42e2186e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-c695d1d1-065b-4c9e-a175-25250e227025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425624052-172.17.0.11-1598670961598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-8093c171-bad8-4577-8459-2b2382bfc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-02248499-a82f-4cc9-8944-3b17c2e1e483,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-a50f7ac6-209f-470e-9980-26f84676ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-f1798390-bbc7-4b9b-b604-119b396df9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-faee8610-d095-4278-a898-9d76b663286c,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-cfb50723-43ef-4f5f-b9fb-8e13669d518d,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-e3633a8d-67de-4a47-aa6f-09ac169e1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-090d711d-9636-479a-b1f5-003dc6d1508f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425624052-172.17.0.11-1598670961598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-8093c171-bad8-4577-8459-2b2382bfc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-02248499-a82f-4cc9-8944-3b17c2e1e483,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-a50f7ac6-209f-470e-9980-26f84676ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-f1798390-bbc7-4b9b-b604-119b396df9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-faee8610-d095-4278-a898-9d76b663286c,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-cfb50723-43ef-4f5f-b9fb-8e13669d518d,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-e3633a8d-67de-4a47-aa6f-09ac169e1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-090d711d-9636-479a-b1f5-003dc6d1508f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687331475-172.17.0.11-1598671314211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-d8d5ebda-f12b-437d-9be1-9d1f0db54691,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-1b3b1ea5-eae0-44e9-8fdb-90061b9222e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-cfcc3580-ca08-41f6-9d8b-13ce7ff2f07e,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-788eeda9-b2f4-4aa9-a01f-49fc22accb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-a38f28ac-f5e1-499d-b62a-729bdc76a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-16c1400f-3520-46ca-81e5-150bab6dff40,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-d267b4e4-4861-4e1a-a40d-c1b6f3cb9682,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-f525b218-7a06-447c-abd4-ffb2fbb17f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687331475-172.17.0.11-1598671314211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-d8d5ebda-f12b-437d-9be1-9d1f0db54691,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-1b3b1ea5-eae0-44e9-8fdb-90061b9222e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-cfcc3580-ca08-41f6-9d8b-13ce7ff2f07e,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-788eeda9-b2f4-4aa9-a01f-49fc22accb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-a38f28ac-f5e1-499d-b62a-729bdc76a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-16c1400f-3520-46ca-81e5-150bab6dff40,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-d267b4e4-4861-4e1a-a40d-c1b6f3cb9682,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-f525b218-7a06-447c-abd4-ffb2fbb17f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314654155-172.17.0.11-1598671661587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-19950a68-0bdd-49d5-8254-6a45f3c23288,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0181b5d0-cdea-41b2-a80d-3516b6a87095,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-1431138a-416a-4100-883b-5db96515c7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2e378214-baf8-4605-aafa-56afda7417b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-66fb2c64-8906-48c2-be77-61952f915ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-3156dc75-b269-45c6-b0b5-0405ae6f4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-7baf2f7a-8290-46cd-859b-cabd6d9ab9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-11cf5120-874e-43e8-a43d-df7709cb8769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314654155-172.17.0.11-1598671661587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39093,DS-19950a68-0bdd-49d5-8254-6a45f3c23288,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0181b5d0-cdea-41b2-a80d-3516b6a87095,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-1431138a-416a-4100-883b-5db96515c7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2e378214-baf8-4605-aafa-56afda7417b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-66fb2c64-8906-48c2-be77-61952f915ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-3156dc75-b269-45c6-b0b5-0405ae6f4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-7baf2f7a-8290-46cd-859b-cabd6d9ab9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-11cf5120-874e-43e8-a43d-df7709cb8769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517727251-172.17.0.11-1598671801840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-536a8a00-0c97-4ae0-9062-a5298573f495,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-23c610bb-7b24-4d5b-ba4b-9c0b7c32840a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-2eb5fb62-5ec5-4d9d-9f22-4b59e1522902,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-9b0e2b0b-53dd-4b0c-9e3e-1bd3baef5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-68feba6a-df83-497e-995d-e25b10e740c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-0665246a-2d18-47a9-86d5-da60f0372998,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-25652db4-13ae-4669-9d68-9510672a0e41,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-bae8a2fd-b558-446c-bfc1-d9d969c91bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517727251-172.17.0.11-1598671801840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-536a8a00-0c97-4ae0-9062-a5298573f495,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-23c610bb-7b24-4d5b-ba4b-9c0b7c32840a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-2eb5fb62-5ec5-4d9d-9f22-4b59e1522902,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-9b0e2b0b-53dd-4b0c-9e3e-1bd3baef5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-68feba6a-df83-497e-995d-e25b10e740c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-0665246a-2d18-47a9-86d5-da60f0372998,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-25652db4-13ae-4669-9d68-9510672a0e41,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-bae8a2fd-b558-446c-bfc1-d9d969c91bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5540
